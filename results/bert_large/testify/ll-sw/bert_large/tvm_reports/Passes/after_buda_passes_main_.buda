{
    "graph": {},
    "nodes": {
        "add_1004": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1005",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1004",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1003"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31ba9a90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1004
        },
        "add_1011": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1012",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1011",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1010"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1011
        },
        "add_1016": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1017",
                "layernorm_1027"
            ],
            "ir": "pybuda",
            "name": "add_1016",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1015"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output, 0x19bb3910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1016
        },
        "add_1018": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1019",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1018",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1017"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1018
        },
        "add_1023": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1024",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1023",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1022"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1023
        },
        "add_1028": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1029",
                "layernorm_1051"
            ],
            "ir": "pybuda",
            "name": "add_1028",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1027"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a5206a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1028
        },
        "add_1030": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1031",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1030",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1029"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1030
        },
        "add_1040": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1041",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1040",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1039"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a509a40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1040
        },
        "add_1047": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1048",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1047",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1046"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1047
        },
        "add_1052": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1053",
                "layernorm_1063"
            ],
            "ir": "pybuda",
            "name": "add_1052",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1051"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9c3520), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1052
        },
        "add_1054": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1055",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1054",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1053"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1054
        },
        "add_1059": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1060",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1059",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1058"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1059
        },
        "add_1064": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1065",
                "layernorm_1087"
            ],
            "ir": "pybuda",
            "name": "add_1064",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1063"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a500890), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1064
        },
        "add_1066": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1067",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1066",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1065"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1066
        },
        "add_1076": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1077",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1076",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1075"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91823d90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1076
        },
        "add_1083": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1084",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1083",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1082"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1083
        },
        "add_1088": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1089",
                "layernorm_1099"
            ],
            "ir": "pybuda",
            "name": "add_1088",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1087"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output, 0x2fb49910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1088
        },
        "add_1090": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1091",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1090",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1089"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1090
        },
        "add_1095": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1096",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1095",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1094"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1095
        },
        "add_1100": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1101",
                "layernorm_1123"
            ],
            "ir": "pybuda",
            "name": "add_1100",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1099"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a45ddb0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1100
        },
        "add_1102": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1103",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1102",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1101"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1102
        },
        "add_1112": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1113",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1112",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1111"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4890c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1112
        },
        "add_1119": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1120",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1119",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1118"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1119
        },
        "add_1124": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1125",
                "layernorm_1135"
            ],
            "ir": "pybuda",
            "name": "add_1124",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1123"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output, 0x8ab077c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1124
        },
        "add_1126": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1127",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1126",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1125"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1126
        },
        "add_1131": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1132",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1131",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1130"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1131
        },
        "add_1136": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1137",
                "layernorm_1159"
            ],
            "ir": "pybuda",
            "name": "add_1136",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1135"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba60c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1136
        },
        "add_1138": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1139",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1138",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1137"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1138
        },
        "add_1148": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1149",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1148",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1147"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bbfab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1148
        },
        "add_1155": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1156",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1155",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1154"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1155
        },
        "add_1160": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1161",
                "layernorm_1171"
            ],
            "ir": "pybuda",
            "name": "add_1160",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output, 0x917a5e00), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1160
        },
        "add_1162": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1163",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1162",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1161"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1162
        },
        "add_1167": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1168",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1167",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1166"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1167
        },
        "add_1172": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1173",
                "layernorm_1195"
            ],
            "ir": "pybuda",
            "name": "add_1172",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1171"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba7070), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1172
        },
        "add_1174": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1175",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1174",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1173"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1174
        },
        "add_1184": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1185",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1184",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1183"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b5bbd0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1184
        },
        "add_1191": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1192",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1191",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1190"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1191
        },
        "add_1196": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1197",
                "layernorm_1207"
            ],
            "ir": "pybuda",
            "name": "add_1196",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1195"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9be180), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1196
        },
        "add_1198": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1199",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1198",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1197"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1198
        },
        "add_1203": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1204",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1203",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1202"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1203
        },
        "add_1208": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1209",
                "layernorm_1231"
            ],
            "ir": "pybuda",
            "name": "add_1208",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1207"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x8ab53930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1208
        },
        "add_1210": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1211",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1210",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1209"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1210
        },
        "add_1220": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1221",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1220",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1219"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9e4730), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1220
        },
        "add_1227": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1228",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1227",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1226"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1227
        },
        "add_1232": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1233",
                "layernorm_1243"
            ],
            "ir": "pybuda",
            "name": "add_1232",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1231"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output, 0xd950e20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1232
        },
        "add_1234": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1235",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1234",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1233"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1234
        },
        "add_1239": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1240",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1239",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1238"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1239
        },
        "add_1244": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1245",
                "nn.dropout_1267"
            ],
            "ir": "pybuda",
            "name": "add_1244",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1243"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xd96bf40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1244
        },
        "add_1246": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1247",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1246",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1245"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1246
        },
        "add_1256": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1257",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_1256",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9182dc30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1256
        },
        "add_1263": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1264",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1263",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1262"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1263
        },
        "add_1269": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "add_1270",
                "embedding_1275"
            ],
            "ir": "pybuda",
            "name": "add_1269",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add_, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x8ab40e80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1269
        },
        "add_1270": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "embedding_1271",
                "embedding_1273"
            ],
            "ir": "pybuda",
            "name": "add_1270",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x79f6e300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1270
        },
        "add_1284": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1285",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1284",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1283"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1284
        },
        "add_1302": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1303",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1302",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1301"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1302
        },
        "add_1319": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1320",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1319",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1318"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1319
        },
        "add_1331": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1332",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1331",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1330"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1331
        },
        "add_1348": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1349",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1348",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1347"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1348
        },
        "add_1360": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1361",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1360",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1359"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1360
        },
        "add_1377": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1378",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1377",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1376"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1377
        },
        "add_1389": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1390",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1389",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1388"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1389
        },
        "add_1406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1407",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1406",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1405"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1406
        },
        "add_1418": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1419",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1418",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1417"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1418
        },
        "add_1435": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1436",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1435",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1434"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1435
        },
        "add_1447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1448",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1447",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1446"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1447
        },
        "add_1464": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1465",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1464",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1463"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1464
        },
        "add_1476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1477",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1476",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1475"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1476
        },
        "add_1493": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1494",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1493",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1492"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1493
        },
        "add_1505": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1506",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1505",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1504"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1505
        },
        "add_1522": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1523",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1522",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1521"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1522
        },
        "add_1534": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1535",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1534",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1533"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1534
        },
        "add_1551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1552",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1551",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1550"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1551
        },
        "add_1563": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1564",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1563",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1562"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1563
        },
        "add_1580": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1581",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1580",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1579"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1580
        },
        "add_1592": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1593",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1592",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1591"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1592
        },
        "add_1609": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1610",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1609",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1608"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1609
        },
        "add_1621": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1622",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1621",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1620"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1621
        },
        "add_1638": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1639",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1638",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1637"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1638
        },
        "add_1650": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1651",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1650",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1649"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1650
        },
        "add_1667": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1668",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1667",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1666"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1667
        },
        "add_1679": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1680",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1679",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1678"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1679
        },
        "add_1696": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1697",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1695"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1696
        },
        "add_1708": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1709",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1708",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1707"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1708
        },
        "add_1725": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1726",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1725",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1724"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1725
        },
        "add_1737": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1738",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1737",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1736"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1737
        },
        "add_1754": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1755",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1754",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1753"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1754
        },
        "add_1766": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1767",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1766",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1765"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1766
        },
        "add_1783": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1784",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1783",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1782"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1783
        },
        "add_1795": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1796",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1795",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1794"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1795
        },
        "add_1812": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1813",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1812",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1811"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1812
        },
        "add_1824": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1825",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1824",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1823"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1824
        },
        "add_1841": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1842",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1841",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1840"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1841
        },
        "add_1853": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1854",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1853",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1852"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1853
        },
        "add_1870": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1871",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1870",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1869"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1870
        },
        "add_1882": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1883",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1882",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1881"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1882
        },
        "add_1899": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1900",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1899",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1898"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1899
        },
        "add_1911": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1912",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1911",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1910"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1911
        },
        "add_1928": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1929",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1928",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1927"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1928
        },
        "add_1940": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1941",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1940",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1939"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1940
        },
        "add_1957": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1958",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1957",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1956"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1957
        },
        "add_1969": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1970",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1969",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1968"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1969
        },
        "add_1985": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1986",
                "strided_slice_1990"
            ],
            "ir": "pybuda",
            "name": "add_1985",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1984"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1985
        },
        "add_400": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_401",
                "strided_slice_1983"
            ],
            "ir": "pybuda",
            "name": "add_400",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_399"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 400
        },
        "add_404": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_405",
                "layernorm_415"
            ],
            "ir": "pybuda",
            "name": "add_404",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_403"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output, 0x94142930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 404
        },
        "add_406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_407",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_406",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_405"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 406
        },
        "add_411": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_412",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_411",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_410"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 411
        },
        "add_416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_417",
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "add_416",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x126d55e0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 416
        },
        "add_418": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_419",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_418",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_417"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 418
        },
        "add_428": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_429",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_428",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94190e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 428
        },
        "add_435": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_436",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_435",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_434"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 435
        },
        "add_440": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_441",
                "layernorm_451"
            ],
            "ir": "pybuda",
            "name": "add_440",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output, 0x126a7350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 440
        },
        "add_442": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_443",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_442",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_441"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 442
        },
        "add_447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_448",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_447",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_446"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 447
        },
        "add_452": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_453",
                "layernorm_475"
            ],
            "ir": "pybuda",
            "name": "add_452",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x917b0210), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 452
        },
        "add_454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_455",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_454",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_453"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 454
        },
        "add_464": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_465",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_464",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f668f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 464
        },
        "add_471": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_472",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_471",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_470"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 471
        },
        "add_476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_477",
                "layernorm_487"
            ],
            "ir": "pybuda",
            "name": "add_476",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_475"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output, 0x941d25a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 476
        },
        "add_478": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_479",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_478",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_477"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 478
        },
        "add_483": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_484",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_483",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_482"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 483
        },
        "add_488": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_489",
                "layernorm_511"
            ],
            "ir": "pybuda",
            "name": "add_488",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_487"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x94179fa0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 488
        },
        "add_490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_491",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_490",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_489"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 490
        },
        "add_500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_501",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_500",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_499"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126af900), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 500
        },
        "add_507": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_508",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_507",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_506"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 507
        },
        "add_512": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_513",
                "layernorm_523"
            ],
            "ir": "pybuda",
            "name": "add_512",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a445480), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 512
        },
        "add_514": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_515",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_514",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_513"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 514
        },
        "add_519": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_520",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_519",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_518"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 519
        },
        "add_524": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_525",
                "layernorm_547"
            ],
            "ir": "pybuda",
            "name": "add_524",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf78a620), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 524
        },
        "add_526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_527",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_526",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_525"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 526
        },
        "add_536": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_537",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_536",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049c80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 536
        },
        "add_543": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_544",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_543",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_542"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 543
        },
        "add_548": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_549",
                "layernorm_559"
            ],
            "ir": "pybuda",
            "name": "add_548",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output, 0xf739860), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 548
        },
        "add_550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_551",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_550",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_549"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 550
        },
        "add_555": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_556",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_555",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_554"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 555
        },
        "add_560": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_561",
                "layernorm_583"
            ],
            "ir": "pybuda",
            "name": "add_560",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_559"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b39bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 560
        },
        "add_562": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_563",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_562",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_561"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 562
        },
        "add_572": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_573",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_572",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3652b260), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 572
        },
        "add_579": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_580",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_579",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_578"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 579
        },
        "add_584": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_585",
                "layernorm_595"
            ],
            "ir": "pybuda",
            "name": "add_584",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_583"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output, 0x27f39310), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 584
        },
        "add_586": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_587",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_586",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_585"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 586
        },
        "add_591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_592",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_591",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_590"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 591
        },
        "add_596": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_597",
                "layernorm_619"
            ],
            "ir": "pybuda",
            "name": "add_596",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_595"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf76bc40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 596
        },
        "add_598": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_599",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_598",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_597"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 598
        },
        "add_608": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_609",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_608",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fecf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 608
        },
        "add_615": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_616",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_615",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_614"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 615
        },
        "add_620": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_621",
                "layernorm_631"
            ],
            "ir": "pybuda",
            "name": "add_620",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_619"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9d6cf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 620
        },
        "add_622": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_623",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_622",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_621"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 622
        },
        "add_627": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_628",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_627",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_626"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 627
        },
        "add_632": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_633",
                "layernorm_655"
            ],
            "ir": "pybuda",
            "name": "add_632",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_631"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x150b3e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 632
        },
        "add_634": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_635",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_634",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_633"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 634
        },
        "add_644": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_645",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_644",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_643"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf81bf50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 644
        },
        "add_651": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_652",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_651",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_650"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 651
        },
        "add_656": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_657",
                "layernorm_667"
            ],
            "ir": "pybuda",
            "name": "add_656",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_655"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output, 0x3645c290), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 656
        },
        "add_658": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_659",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_658",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_657"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 658
        },
        "add_663": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_664",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_663",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_662"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 663
        },
        "add_668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_669",
                "layernorm_691"
            ],
            "ir": "pybuda",
            "name": "add_668",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x280244f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 668
        },
        "add_670": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_671",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_670",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_669"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 670
        },
        "add_680": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_681",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_680",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3643dac0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 680
        },
        "add_687": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_688",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_687",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_686"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 687
        },
        "add_692": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_693",
                "layernorm_703"
            ],
            "ir": "pybuda",
            "name": "add_692",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_691"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output, 0x27fce810), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 692
        },
        "add_694": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_695",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_694",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_693"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 694
        },
        "add_699": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_700",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_699",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_698"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 699
        },
        "add_704": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_705",
                "layernorm_727"
            ],
            "ir": "pybuda",
            "name": "add_704",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x15061a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 704
        },
        "add_706": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_707",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_706",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_705"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 706
        },
        "add_716": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_717",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_716",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c9850), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 716
        },
        "add_723": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_724",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_723",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_722"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 723
        },
        "add_728": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_729",
                "layernorm_739"
            ],
            "ir": "pybuda",
            "name": "add_728",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_727"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a4d73f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 728
        },
        "add_730": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_731",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_730",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_729"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 730
        },
        "add_735": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_736",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_735",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_734"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 735
        },
        "add_740": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_741",
                "layernorm_763"
            ],
            "ir": "pybuda",
            "name": "add_740",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x27f42770), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 740
        },
        "add_742": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_743",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_742",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_741"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 742
        },
        "add_752": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_753",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_752",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fa7ca0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 752
        },
        "add_759": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_760",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_759",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_758"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 759
        },
        "add_764": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_765",
                "layernorm_775"
            ],
            "ir": "pybuda",
            "name": "add_764",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e53a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 764
        },
        "add_766": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_767",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_766",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_765"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 766
        },
        "add_771": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_772",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_771",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_770"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 771
        },
        "add_776": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_777",
                "layernorm_799"
            ],
            "ir": "pybuda",
            "name": "add_776",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_775"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf826d40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 776
        },
        "add_778": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_779",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_778",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_777"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 778
        },
        "add_788": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_789",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_788",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_787"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19be8370), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 788
        },
        "add_795": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_796",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_795",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_794"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 795
        },
        "add_800": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_801",
                "layernorm_811"
            ],
            "ir": "pybuda",
            "name": "add_800",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_799"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output, 0x31bc3c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 800
        },
        "add_802": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_803",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_802",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_801"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 802
        },
        "add_807": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_808",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_807",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_806"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 807
        },
        "add_812": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_813",
                "layernorm_835"
            ],
            "ir": "pybuda",
            "name": "add_812",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b3d300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 812
        },
        "add_814": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_815",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_814",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_813"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 814
        },
        "add_824": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_825",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_824",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_823"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824de0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 824
        },
        "add_831": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_832",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_831",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_830"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 831
        },
        "add_836": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_837",
                "layernorm_847"
            ],
            "ir": "pybuda",
            "name": "add_836",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_835"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output, 0xf76f920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 836
        },
        "add_838": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_839",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_838",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_837"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 838
        },
        "add_843": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_844",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_843",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_842"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 843
        },
        "add_848": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_849",
                "layernorm_871"
            ],
            "ir": "pybuda",
            "name": "add_848",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_847"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b40c10), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 848
        },
        "add_850": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_851",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_850",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_849"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 850
        },
        "add_860": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_861",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_860",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_859"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a503c30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 860
        },
        "add_867": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_868",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_867",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_866"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 867
        },
        "add_872": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_873",
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "add_872",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output, 0xda20c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 872
        },
        "add_874": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_875",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_874",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_873"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 874
        },
        "add_879": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_880",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_879",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_878"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 879
        },
        "add_884": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_885",
                "layernorm_907"
            ],
            "ir": "pybuda",
            "name": "add_884",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a518f60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 884
        },
        "add_886": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_887",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_886",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_885"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 886
        },
        "add_896": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_897",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_896",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3648ed50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 896
        },
        "add_903": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_904",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_903",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_902"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 903
        },
        "add_908": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_909",
                "layernorm_919"
            ],
            "ir": "pybuda",
            "name": "add_908",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_907"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e4190), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 908
        },
        "add_910": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_911",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_910",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_909"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 910
        },
        "add_915": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_916",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_915",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_914"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 915
        },
        "add_920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_921",
                "layernorm_943"
            ],
            "ir": "pybuda",
            "name": "add_920",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_919"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a4cfa80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 920
        },
        "add_922": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_923",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_922",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_921"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 922
        },
        "add_932": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_933",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_932",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_931"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36458280), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 932
        },
        "add_939": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_940",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_939",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_938"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 939
        },
        "add_944": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_945",
                "layernorm_955"
            ],
            "ir": "pybuda",
            "name": "add_944",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_943"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output, 0x36446a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 944
        },
        "add_946": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_947",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_946",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_945"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 946
        },
        "add_951": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_952",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_951",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_950"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 951
        },
        "add_956": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_957",
                "layernorm_979"
            ],
            "ir": "pybuda",
            "name": "add_956",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xda20440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 956
        },
        "add_958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_959",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_958",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_957"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 958
        },
        "add_968": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_969",
                "multiply_1291"
            ],
            "ir": "pybuda",
            "name": "add_968",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b6cff0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 968
        },
        "add_975": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_976",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_975",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_974"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 975
        },
        "add_980": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_981",
                "layernorm_991"
            ],
            "ir": "pybuda",
            "name": "add_980",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_979"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output, 0x31b556d0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 980
        },
        "add_982": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_983",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_982",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_981"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 982
        },
        "add_987": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_988",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_987",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_986"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 987
        },
        "add_992": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_993",
                "layernorm_1015"
            ],
            "ir": "pybuda",
            "name": "add_992",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_991"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a505020), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 992
        },
        "add_994": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_995",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_994",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_993"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 994
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "attention_mask_1",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1295"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 8
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 7
        },
        "bert.embeddings.position_embeddings.weight": {
            "cache": {
                "shape": [
                    "512",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1275"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 5
        },
        "bert.embeddings.position_ids": {
            "cache": {
                "shape": [
                    "1",
                    "512"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_ids",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_1277"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 6
        },
        "bert.embeddings.token_type_embeddings.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.token_type_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1273"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 4
        },
        "bert.embeddings.word_embeddings.weight": {
            "cache": {
                "shape": [
                    "28996",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.word_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1271"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 3
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1243"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 18
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1243"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 17
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1246"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 16
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1308"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 15
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1284"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 12
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1288"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 11
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1263"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 10
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1279"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 9
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1302"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 14
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1306"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 13
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1239"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 20
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1310"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 19
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1231"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 24
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1231"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 23
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1234"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 22
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1312"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 21
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1207"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 34
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1207"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 33
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1210"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 32
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1337"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 31
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1319"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 28
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1323"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 27
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1227"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 26
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1314"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 25
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1331"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 30
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1335"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 29
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1203"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 36
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1339"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 35
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1195"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 40
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1195"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 39
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1198"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 38
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1341"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 37
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 178
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 177
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_886"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 176
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1598"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 175
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1580"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 172
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1584"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 171
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_903"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 170
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1575"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 169
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 174
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1596"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 173
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_879"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 180
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1600"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 179
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_871"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 184
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_871"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 183
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_874"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 182
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1602"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 181
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_847"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 194
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_847"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 193
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_850"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 192
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1627"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 191
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1609"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 188
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1613"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 187
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_867"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 186
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1604"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 185
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1621"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 190
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1625"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 189
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_843"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 196
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1629"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 195
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_835"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 200
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_835"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 199
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_838"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 198
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 197
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_811"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 210
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_811"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 209
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_814"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 208
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1656"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 207
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1638"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 204
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1642"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 203
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_831"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 202
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1633"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 201
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1650"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 206
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1654"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 205
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_807"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 212
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1658"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 211
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_799"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 216
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_799"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 215
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_802"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 214
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1660"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 213
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_775"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 226
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_775"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 225
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_778"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 224
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1685"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 223
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1667"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 220
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1671"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 219
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_795"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 218
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1662"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 217
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1679"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 222
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1683"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 221
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_771"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 228
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1687"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 227
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_763"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 232
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_763"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 231
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_766"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 230
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1689"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 229
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_739"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 242
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_739"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 241
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_742"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 240
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1714"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 239
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1696"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 236
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1700"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 235
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_759"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 234
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1691"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 233
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1708"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 238
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1712"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 237
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_735"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 244
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1716"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 243
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_727"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 248
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_727"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 247
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_730"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 246
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1718"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 245
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_703"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 258
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_703"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 257
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_706"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 256
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1743"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 255
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1725"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 252
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1729"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 251
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_723"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 250
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1720"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 249
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1737"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 254
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1741"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 253
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_699"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 260
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1745"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 259
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_691"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 264
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_691"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 263
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_694"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 262
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1747"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 261
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_667"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 274
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_667"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 273
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_670"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 272
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 271
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1754"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 268
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1758"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 267
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_687"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 266
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1749"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 265
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1766"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 270
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1770"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 269
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_663"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 276
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1774"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 275
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_655"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 280
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_655"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 279
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_658"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 278
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1776"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 277
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 290
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 289
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_634"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 288
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1801"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 287
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1783"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 284
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1787"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 283
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_651"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 282
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1778"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 281
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1795"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 286
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1799"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 285
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_627"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 292
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1803"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 291
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_619"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 296
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_619"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 295
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_622"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 294
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1805"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 293
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_595"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 306
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_595"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 305
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_598"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 304
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1830"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 303
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1812"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 300
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1816"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 299
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_615"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 298
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1807"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 297
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1824"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 302
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1828"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 301
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_591"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 308
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1832"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 307
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_583"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 312
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_583"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 311
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_586"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 310
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1834"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 309
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_559"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 322
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_559"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 321
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_562"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 320
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1859"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 319
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1841"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 316
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1845"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 315
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_579"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 314
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1836"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 313
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1853"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 318
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1857"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 317
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_555"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 324
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1861"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 323
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_547"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 328
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_547"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 327
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_550"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 326
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1863"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 325
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1171"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 50
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1171"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 49
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1174"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 48
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1366"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 47
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1348"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 44
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1352"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 43
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1191"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 42
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1343"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 41
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1360"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 46
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1364"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 45
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1167"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 52
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1368"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 51
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1159"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 56
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1159"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 55
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1162"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 54
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1370"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 53
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_523"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 338
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_523"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 337
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_526"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 336
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1888"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 335
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1870"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 332
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1874"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 331
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_543"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 330
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1865"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 329
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1882"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 334
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1886"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 333
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_519"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 340
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1890"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 339
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_511"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 344
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_511"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 343
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_514"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 342
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1892"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 341
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_487"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 354
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_487"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 353
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_490"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 352
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1917"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 351
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1899"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 348
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1903"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 347
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_507"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 346
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1894"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 345
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1911"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 350
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1915"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 349
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_483"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 356
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1919"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 355
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_475"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 360
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_475"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 359
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_478"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 358
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1921"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 357
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 370
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 369
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 368
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1946"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 367
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1928"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 364
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1932"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 363
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_471"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 362
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1923"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 361
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1940"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 366
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1944"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 365
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_447"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 372
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1948"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 371
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 376
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 375
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_442"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 374
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1950"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 373
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_415"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 386
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_415"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 385
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_418"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 384
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1975"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 383
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1957"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 380
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1961"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 379
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_435"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 378
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1952"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 377
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1969"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 382
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1973"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 381
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_411"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 388
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1977"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 387
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_403"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 392
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_403"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 391
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_406"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 390
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1979"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 389
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1135"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 66
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1135"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 65
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1138"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 64
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1395"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 63
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1377"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 60
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1381"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 59
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1155"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 58
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1372"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 57
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1389"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 62
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1393"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 61
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1131"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 68
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1397"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 67
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1123"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 72
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1123"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 71
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1126"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 70
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1399"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 69
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1099"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 82
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1099"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 81
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1102"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 80
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1424"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 79
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1406"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 76
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1410"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 75
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1119"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 74
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1401"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 73
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1418"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 78
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1422"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 77
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1095"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 84
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1426"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 83
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1087"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 88
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1087"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 87
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1090"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 86
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1428"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 85
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1063"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 98
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1063"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 97
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1066"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 96
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1453"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 95
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1435"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 92
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 91
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1083"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 90
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1430"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 89
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1447"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 94
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1451"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 93
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1059"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 100
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1455"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 99
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1051"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 104
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1051"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 103
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1054"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 102
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1457"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 101
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1027"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 114
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1027"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 113
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1030"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 112
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1482"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 111
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1464"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 108
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1468"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 107
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1047"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 106
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1459"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 105
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 110
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1480"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 109
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1023"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 116
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 115
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1015"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 120
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1015"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 119
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1018"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 118
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1486"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 117
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_991"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 130
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_991"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 129
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_994"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 128
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1511"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 127
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1493"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 124
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1497"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 123
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1011"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 122
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1488"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 121
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1505"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 126
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1509"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 125
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_987"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 132
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1513"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 131
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_979"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 136
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_979"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 135
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_982"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 134
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1515"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 133
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_955"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 146
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_955"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 145
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 144
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1540"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 143
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 140
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1526"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 139
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_975"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 138
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1517"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 137
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1534"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 142
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1538"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 141
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_951"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 148
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1542"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 147
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_943"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 152
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_943"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 151
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_946"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 150
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1544"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 149
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_919"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 162
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_919"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 161
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_922"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 160
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1569"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 159
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1551"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 156
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1555"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 155
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_939"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 154
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 153
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1563"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 158
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1567"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 157
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_915"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 164
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1571"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 163
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_907"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 168
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_907"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 167
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_910"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 166
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1573"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 165
        },
        "cast_1272": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_ids"
            ],
            "ir": "pybuda",
            "name": "cast_1272",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1271"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1272
        },
        "cast_1274": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_1"
            ],
            "ir": "pybuda",
            "name": "cast_1274",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1273"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1274
        },
        "cast_1276": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_1277"
            ],
            "ir": "pybuda",
            "name": "cast_1276",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1275"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1276
        },
        "cast_1294": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "reshape_1295"
            ],
            "ir": "pybuda",
            "name": "cast_1294",
            "opcode": "RelayOp",
            "output_nodes": [
                "subtract_1292"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::to, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917a3500), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1294
        },
        "constant_1290": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1290",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1289"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1290
        },
        "constant_1293": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1293",
            "opcode": "Input",
            "output_nodes": [
                "subtract_1292"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1293
        },
        "constant_1296": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1296",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1291"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1296
        },
        "constant_1325": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1325",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1324"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1325
        },
        "constant_1354": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1354",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1353"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1354
        },
        "constant_1383": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1383",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1382"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1383
        },
        "constant_1412": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1412",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1411"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1412
        },
        "constant_1441": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1441",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1440"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1441
        },
        "constant_1470": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1470",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1469"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1470
        },
        "constant_1499": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1499",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1498"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1499
        },
        "constant_1528": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1528",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1527"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1528
        },
        "constant_1557": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1557",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1556"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1557
        },
        "constant_1586": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1586",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1585"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1586
        },
        "constant_1615": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1615",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1614"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1615
        },
        "constant_1644": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1644",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1643"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1644
        },
        "constant_1673": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1673",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1672"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1673
        },
        "constant_1702": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1702",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1701"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1702
        },
        "constant_1731": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1731",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1730"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1731
        },
        "constant_1760": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1760",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1759"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1760
        },
        "constant_1789": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1789",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1788"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1789
        },
        "constant_1818": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1818",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1817"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1818
        },
        "constant_1847": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1847",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1846"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1847
        },
        "constant_1876": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1876",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1875"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1876
        },
        "constant_1905": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1905",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1904"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1905
        },
        "constant_1934": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1934",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1933"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1934
        },
        "constant_1963": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1963",
            "opcode": "Input",
            "output_nodes": [
                "reciprocal_1962"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1963
        },
        "embedding_1271": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.word_embeddings.weight",
                "cast_1272"
            ],
            "ir": "pybuda",
            "name": "embedding_1271",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1270"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1271
        },
        "embedding_1273": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.token_type_embeddings.weight",
                "cast_1274"
            ],
            "ir": "pybuda",
            "name": "embedding_1273",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1270"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1273
        },
        "embedding_1275": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_embeddings.weight",
                "cast_1276"
            ],
            "ir": "pybuda",
            "name": "embedding_1275",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1275
        },
        "gelu_1022": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1023"
            ],
            "ir": "pybuda",
            "name": "gelu_1022",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1022
        },
        "gelu_1058": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1059"
            ],
            "ir": "pybuda",
            "name": "gelu_1058",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1057"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1058
        },
        "gelu_1094": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1095"
            ],
            "ir": "pybuda",
            "name": "gelu_1094",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1093"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1094
        },
        "gelu_1130": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1131"
            ],
            "ir": "pybuda",
            "name": "gelu_1130",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1129"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1130
        },
        "gelu_1166": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1167"
            ],
            "ir": "pybuda",
            "name": "gelu_1166",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1165"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1166
        },
        "gelu_1202": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1203"
            ],
            "ir": "pybuda",
            "name": "gelu_1202",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1201"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1202
        },
        "gelu_1238": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1239"
            ],
            "ir": "pybuda",
            "name": "gelu_1238",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1237"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1238
        },
        "gelu_410": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_411"
            ],
            "ir": "pybuda",
            "name": "gelu_410",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_409"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 410
        },
        "gelu_446": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_447"
            ],
            "ir": "pybuda",
            "name": "gelu_446",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 446
        },
        "gelu_482": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_483"
            ],
            "ir": "pybuda",
            "name": "gelu_482",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 482
        },
        "gelu_518": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_519"
            ],
            "ir": "pybuda",
            "name": "gelu_518",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 518
        },
        "gelu_554": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_555"
            ],
            "ir": "pybuda",
            "name": "gelu_554",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 554
        },
        "gelu_590": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_591"
            ],
            "ir": "pybuda",
            "name": "gelu_590",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 590
        },
        "gelu_626": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_627"
            ],
            "ir": "pybuda",
            "name": "gelu_626",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_625"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 626
        },
        "gelu_662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_663"
            ],
            "ir": "pybuda",
            "name": "gelu_662",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_661"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 662
        },
        "gelu_698": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_699"
            ],
            "ir": "pybuda",
            "name": "gelu_698",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 698
        },
        "gelu_734": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_735"
            ],
            "ir": "pybuda",
            "name": "gelu_734",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 734
        },
        "gelu_770": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_771"
            ],
            "ir": "pybuda",
            "name": "gelu_770",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_769"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 770
        },
        "gelu_806": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_807"
            ],
            "ir": "pybuda",
            "name": "gelu_806",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_805"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 806
        },
        "gelu_842": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_843"
            ],
            "ir": "pybuda",
            "name": "gelu_842",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 842
        },
        "gelu_878": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_879"
            ],
            "ir": "pybuda",
            "name": "gelu_878",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_877"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 878
        },
        "gelu_914": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_915"
            ],
            "ir": "pybuda",
            "name": "gelu_914",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_913"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 914
        },
        "gelu_950": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_951"
            ],
            "ir": "pybuda",
            "name": "gelu_950",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_949"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 950
        },
        "gelu_986": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_987"
            ],
            "ir": "pybuda",
            "name": "gelu_986",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 986
        },
        "input_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_1",
            "opcode": "Input",
            "output_nodes": [
                "cast_1274"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1
        },
        "input_ids": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_ids",
            "opcode": "Input",
            "output_nodes": [
                "cast_1272"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 0
        },
        "layernorm_1015": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1016",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1015",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_992",
                "reshape_1014"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a456e70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1015
        },
        "layernorm_1027": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1028",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1027",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1016",
                "reshape_1026"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19c0dd00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1027
        },
        "layernorm_1051": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1052",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1051",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1028",
                "reshape_1050"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4d52d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1051
        },
        "layernorm_1063": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1064",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1063",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1052",
                "reshape_1062"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b49cb0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1063
        },
        "layernorm_1087": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1088",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1087",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1064",
                "reshape_1086"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19bc47e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1087
        },
        "layernorm_1099": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1100",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1099",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1088",
                "reshape_1098"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9bd4d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1099
        },
        "layernorm_1123": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1124",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1123",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1100",
                "reshape_1122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b96410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1123
        },
        "layernorm_1135": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1136",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1135",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1124",
                "reshape_1134"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xda08cd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1135
        },
        "layernorm_1159": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1160",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1159",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1136",
                "reshape_1158"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b59000), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1159
        },
        "layernorm_1171": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1172",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1171",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1160",
                "reshape_1170"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917ab600), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1171
        },
        "layernorm_1195": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1196",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1195",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1172",
                "reshape_1194"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9e7790), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1195
        },
        "layernorm_1207": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1208",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1207",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1196",
                "reshape_1206"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x91832300), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1207
        },
        "layernorm_1231": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1232",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1231",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1208",
                "reshape_1230"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9182e6e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1231
        },
        "layernorm_1243": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1244",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1243",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1232",
                "reshape_1242"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917a5390), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1243
        },
        "layernorm_1268": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1269",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1268",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1267"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x918210f0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1268
        },
        "layernorm_403": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_404",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_403",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fd6f10), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 403
        },
        "layernorm_415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_416",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_415",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_404",
                "reshape_414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x37bd6810), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 415
        },
        "layernorm_439": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_440",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_439",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_416",
                "reshape_438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x126ea410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 439
        },
        "layernorm_451": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_452",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_451",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_440",
                "reshape_450"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf75bdf0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 451
        },
        "layernorm_475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_476",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_475",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_452",
                "reshape_474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x12643c20), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 475
        },
        "layernorm_487": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_488",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_487",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_476",
                "reshape_486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150af8e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 487
        },
        "layernorm_511": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_512",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_511",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_488",
                "reshape_510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7f9e90), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 511
        },
        "layernorm_523": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_524",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_523",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_512",
                "reshape_522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b4f460), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 523
        },
        "layernorm_547": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_548",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_547",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_524",
                "reshape_546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9420f530), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 547
        },
        "layernorm_559": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_560",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_559",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_548",
                "reshape_558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941de800), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 559
        },
        "layernorm_583": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_584",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_583",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_560",
                "reshape_582"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150a6c60), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 583
        },
        "layernorm_595": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_596",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_595",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_584",
                "reshape_594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941f5c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 595
        },
        "layernorm_619": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_620",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_619",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_596",
                "reshape_618"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150e9f80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 619
        },
        "layernorm_631": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_632",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_631",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_620",
                "reshape_630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d5c70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 631
        },
        "layernorm_655": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_656",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_655",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_632",
                "reshape_654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf774ee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 655
        },
        "layernorm_667": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_668",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_667",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_656",
                "reshape_666"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4bcfd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 667
        },
        "layernorm_691": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_692",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_691",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_668",
                "reshape_690"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9fb7d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 691
        },
        "layernorm_703": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_704",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_703",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_692",
                "reshape_702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fe2d50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 703
        },
        "layernorm_727": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_728",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_727",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_704",
                "reshape_726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4996b0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 727
        },
        "layernorm_739": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_740",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_739",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_728",
                "reshape_738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7674e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 739
        },
        "layernorm_763": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_764",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_763",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_740",
                "reshape_762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf749490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 763
        },
        "layernorm_775": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_776",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_775",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_764",
                "reshape_774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x365122e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 775
        },
        "layernorm_799": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_800",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_799",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_776",
                "reshape_798"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d91c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 799
        },
        "layernorm_811": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_812",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_811",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_800",
                "reshape_810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4fc5e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 811
        },
        "layernorm_835": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_836",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_835",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_812",
                "reshape_834"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd974ae0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 835
        },
        "layernorm_847": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_848",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_847",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_836",
                "reshape_846"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b455d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 847
        },
        "layernorm_871": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_872",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_871",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_848",
                "reshape_870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd98ab70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 871
        },
        "layernorm_883": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_884",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_883",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_872",
                "reshape_882"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x364f4230), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 883
        },
        "layernorm_907": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_908",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_907",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_884",
                "reshape_906"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a472c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 907
        },
        "layernorm_919": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_920",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_919",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_908",
                "reshape_918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a48aee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 919
        },
        "layernorm_943": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_944",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_943",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_920",
                "reshape_942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31c24e00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 943
        },
        "layernorm_955": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_956",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_955",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_944",
                "reshape_954"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd99a490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 955
        },
        "layernorm_979": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_980",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_979",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_956",
                "reshape_978"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd95cb50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 979
        },
        "layernorm_991": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_992",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_991",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_980",
                "reshape_990"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b8d0c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 991
        },
        "multiply_1005": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1006",
                "reciprocal_1498"
            ],
            "ir": "pybuda",
            "name": "multiply_1005",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49cbc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1005
        },
        "multiply_1041": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1042",
                "reciprocal_1469"
            ],
            "ir": "pybuda",
            "name": "multiply_1041",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1040"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511f40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1041
        },
        "multiply_1077": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1078",
                "reciprocal_1440"
            ],
            "ir": "pybuda",
            "name": "multiply_1077",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1076"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c22f20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1077
        },
        "multiply_1113": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1114",
                "reciprocal_1411"
            ],
            "ir": "pybuda",
            "name": "multiply_1113",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1112"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917b72e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1113
        },
        "multiply_1149": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1150",
                "reciprocal_1382"
            ],
            "ir": "pybuda",
            "name": "multiply_1149",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1148"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91820730), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1149
        },
        "multiply_1185": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1186",
                "reciprocal_1353"
            ],
            "ir": "pybuda",
            "name": "multiply_1185",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1184"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd960e90), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1185
        },
        "multiply_1221": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1222",
                "reciprocal_1324"
            ],
            "ir": "pybuda",
            "name": "multiply_1221",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1220"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8abc4710), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1221
        },
        "multiply_1257": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1258",
                "reciprocal_1289"
            ],
            "ir": "pybuda",
            "name": "multiply_1257",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1256"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91826840), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1257
        },
        "multiply_1291": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "subtract_1292",
                "constant_1296"
            ],
            "ir": "pybuda",
            "name": "multiply_1291",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_428",
                "add_464",
                "add_500",
                "add_536",
                "add_572",
                "add_608",
                "add_644",
                "add_680",
                "add_716",
                "add_752",
                "add_788",
                "add_824",
                "add_860",
                "add_896",
                "add_932",
                "add_968",
                "add_1004",
                "add_1040",
                "add_1076",
                "add_1112",
                "add_1148",
                "add_1184",
                "add_1220",
                "add_1256"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::mul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x8ab56a50), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1291
        },
        "multiply_429": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_430",
                "reciprocal_1962"
            ],
            "ir": "pybuda",
            "name": "multiply_429",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ec890), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 429
        },
        "multiply_465": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_466",
                "reciprocal_1933"
            ],
            "ir": "pybuda",
            "name": "multiply_465",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94171620), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 465
        },
        "multiply_501": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_502",
                "reciprocal_1904"
            ],
            "ir": "pybuda",
            "name": "multiply_501",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28007220), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 501
        },
        "multiply_537": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_538",
                "reciprocal_1875"
            ],
            "ir": "pybuda",
            "name": "multiply_537",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf805110), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 537
        },
        "multiply_573": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_574",
                "reciprocal_1846"
            ],
            "ir": "pybuda",
            "name": "multiply_573",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb4f1e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 573
        },
        "multiply_609": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_610",
                "reciprocal_1817"
            ],
            "ir": "pybuda",
            "name": "multiply_609",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27ff1540), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 609
        },
        "multiply_645": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_646",
                "reciprocal_1788"
            ],
            "ir": "pybuda",
            "name": "multiply_645",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_644"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fcd060), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 645
        },
        "multiply_681": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_682",
                "reciprocal_1759"
            ],
            "ir": "pybuda",
            "name": "multiply_681",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f69850), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 681
        },
        "multiply_717": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_718",
                "reciprocal_1730"
            ],
            "ir": "pybuda",
            "name": "multiply_717",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d3100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 717
        },
        "multiply_753": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_754",
                "reciprocal_1701"
            ],
            "ir": "pybuda",
            "name": "multiply_753",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f45150), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 753
        },
        "multiply_789": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_790",
                "reciprocal_1672"
            ],
            "ir": "pybuda",
            "name": "multiply_789",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_788"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82ecd0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 789
        },
        "multiply_825": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_826",
                "reciprocal_1643"
            ],
            "ir": "pybuda",
            "name": "multiply_825",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_824"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda30d90), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 825
        },
        "multiply_861": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_862",
                "reciprocal_1614"
            ],
            "ir": "pybuda",
            "name": "multiply_861",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_860"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364688e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 861
        },
        "multiply_897": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_898",
                "reciprocal_1585"
            ],
            "ir": "pybuda",
            "name": "multiply_897",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_896"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36433ac0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 897
        },
        "multiply_933": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_934",
                "reciprocal_1556"
            ],
            "ir": "pybuda",
            "name": "multiply_933",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_932"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bfe2e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 933
        },
        "multiply_969": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_970",
                "reciprocal_1527"
            ],
            "ir": "pybuda",
            "name": "multiply_969",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_968"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf19c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 969
        },
        "nn.batch_matmul_1000": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1001",
                "transpose_1500"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1000",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1000
        },
        "nn.batch_matmul_1007": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1008",
                "transpose_1489"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1007",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1007
        },
        "nn.batch_matmul_1036": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1037",
                "transpose_1471"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1036",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1036
        },
        "nn.batch_matmul_1043": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1044",
                "transpose_1460"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1043",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1043
        },
        "nn.batch_matmul_1072": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1073",
                "transpose_1442"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1072",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1071"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1072
        },
        "nn.batch_matmul_1079": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1080",
                "transpose_1431"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1079",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1079
        },
        "nn.batch_matmul_1108": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1109",
                "transpose_1413"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1108",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1108
        },
        "nn.batch_matmul_1115": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1116",
                "transpose_1402"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1115",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1114"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1115
        },
        "nn.batch_matmul_1144": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1145",
                "transpose_1384"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1144",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1144
        },
        "nn.batch_matmul_1151": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1152",
                "transpose_1373"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1151",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1151
        },
        "nn.batch_matmul_1180": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1181",
                "transpose_1355"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1180",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1179"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1180
        },
        "nn.batch_matmul_1187": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1188",
                "transpose_1344"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1187",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1186"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1187
        },
        "nn.batch_matmul_1216": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1217",
                "transpose_1326"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1216",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1215"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1216
        },
        "nn.batch_matmul_1223": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1224",
                "transpose_1315"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1223",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1223
        },
        "nn.batch_matmul_1252": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1253",
                "transpose_1297"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1252",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1252
        },
        "nn.batch_matmul_1259": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1260",
                "transpose_1280"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1259",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1259
        },
        "nn.batch_matmul_424": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_425",
                "transpose_1964"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_424",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 424
        },
        "nn.batch_matmul_431": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_432",
                "transpose_1953"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_431",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 431
        },
        "nn.batch_matmul_460": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_461",
                "transpose_1935"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_460",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 460
        },
        "nn.batch_matmul_467": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_468",
                "transpose_1924"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_467",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 467
        },
        "nn.batch_matmul_496": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_497",
                "transpose_1906"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_496",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 496
        },
        "nn.batch_matmul_503": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_504",
                "transpose_1895"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_503",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 503
        },
        "nn.batch_matmul_532": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_533",
                "transpose_1877"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_532",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 532
        },
        "nn.batch_matmul_539": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_540",
                "transpose_1866"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_539",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 539
        },
        "nn.batch_matmul_568": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_569",
                "transpose_1848"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_568",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 568
        },
        "nn.batch_matmul_575": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_576",
                "transpose_1837"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_575",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 575
        },
        "nn.batch_matmul_604": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_605",
                "transpose_1819"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_604",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 604
        },
        "nn.batch_matmul_611": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_612",
                "transpose_1808"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_611",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 611
        },
        "nn.batch_matmul_640": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_641",
                "transpose_1790"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_640",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 640
        },
        "nn.batch_matmul_647": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_648",
                "transpose_1779"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_647",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 647
        },
        "nn.batch_matmul_676": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_677",
                "transpose_1761"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_676",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 676
        },
        "nn.batch_matmul_683": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_684",
                "transpose_1750"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_683",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 683
        },
        "nn.batch_matmul_712": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_713",
                "transpose_1732"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_712",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 712
        },
        "nn.batch_matmul_719": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_720",
                "transpose_1721"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_719",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 719
        },
        "nn.batch_matmul_748": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_749",
                "transpose_1703"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_748",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 748
        },
        "nn.batch_matmul_755": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_756",
                "transpose_1692"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_755",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 755
        },
        "nn.batch_matmul_784": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_785",
                "transpose_1674"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_784",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 784
        },
        "nn.batch_matmul_791": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_792",
                "transpose_1663"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_791",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_790"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 791
        },
        "nn.batch_matmul_820": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_821",
                "transpose_1645"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_820",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 820
        },
        "nn.batch_matmul_827": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_828",
                "transpose_1634"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_827",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 827
        },
        "nn.batch_matmul_856": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_857",
                "transpose_1616"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_856",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 856
        },
        "nn.batch_matmul_863": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_864",
                "transpose_1605"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_863",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 863
        },
        "nn.batch_matmul_892": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_893",
                "transpose_1587"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_892",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_891"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 892
        },
        "nn.batch_matmul_899": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_900",
                "transpose_1576"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_899",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_898"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 899
        },
        "nn.batch_matmul_928": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_929",
                "transpose_1558"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_928",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_927"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 928
        },
        "nn.batch_matmul_935": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_936",
                "transpose_1547"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_935",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 935
        },
        "nn.batch_matmul_964": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_965",
                "transpose_1529"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_964",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 964
        },
        "nn.batch_matmul_971": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_972",
                "transpose_1518"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_971",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 971
        },
        "nn.dense_1013": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1014",
                "transpose_1487"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1013",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1012"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1013
        },
        "nn.dense_1020": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1021",
                "transpose_1485"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1020",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1019"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1020
        },
        "nn.dense_1025": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1026",
                "transpose_1483"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1025",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1024"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1025
        },
        "nn.dense_1032": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1033",
                "transpose_1481"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1032",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1031"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1032
        },
        "nn.dense_1049": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1050",
                "transpose_1458"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1049",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1048"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1049
        },
        "nn.dense_1056": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1057",
                "transpose_1456"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1056",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1055"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1056
        },
        "nn.dense_1061": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1062",
                "transpose_1454"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1061",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1060"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1061
        },
        "nn.dense_1068": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1069",
                "transpose_1452"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1068",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1067"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1068
        },
        "nn.dense_1085": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1086",
                "transpose_1429"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1085",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1084"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1085
        },
        "nn.dense_1092": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1093",
                "transpose_1427"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1092",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1091"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1092
        },
        "nn.dense_1097": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1098",
                "transpose_1425"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1097",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1097
        },
        "nn.dense_1104": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1105",
                "transpose_1423"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1104",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1104
        },
        "nn.dense_1121": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1122",
                "transpose_1400"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1121",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1120"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1121
        },
        "nn.dense_1128": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1129",
                "transpose_1398"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1128",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1128
        },
        "nn.dense_1133": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1134",
                "transpose_1396"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1133",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1132"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1133
        },
        "nn.dense_1140": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1141",
                "transpose_1394"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1140",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1139"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1140
        },
        "nn.dense_1157": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1158",
                "transpose_1371"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1157",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1156"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1157
        },
        "nn.dense_1164": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1165",
                "transpose_1369"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1164",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1163"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1164
        },
        "nn.dense_1169": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1170",
                "transpose_1367"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1169",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1168"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1169
        },
        "nn.dense_1176": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1177",
                "transpose_1365"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1176",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1175"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1176
        },
        "nn.dense_1193": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1194",
                "transpose_1342"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1193",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1192"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1193
        },
        "nn.dense_1200": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1201",
                "transpose_1340"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1200",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1199"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1200
        },
        "nn.dense_1205": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1206",
                "transpose_1338"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1205",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1204"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1205
        },
        "nn.dense_1212": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1213",
                "transpose_1336"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1212",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1211"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1212
        },
        "nn.dense_1229": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1230",
                "transpose_1313"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1229",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1228"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1229
        },
        "nn.dense_1236": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1237",
                "transpose_1311"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1236",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1235"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1236
        },
        "nn.dense_1241": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1242",
                "transpose_1309"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1241",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1240"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1241
        },
        "nn.dense_1248": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1249",
                "transpose_1307"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1248",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1247"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1248
        },
        "nn.dense_1265": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1266",
                "transpose_1278"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1265",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1264"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1265
        },
        "nn.dense_1286": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1266",
                "transpose_1287"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1286",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1285"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1286
        },
        "nn.dense_1304": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1266",
                "transpose_1305"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1304",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1303"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1304
        },
        "nn.dense_1321": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1230",
                "transpose_1322"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1321",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1320"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1321
        },
        "nn.dense_1333": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1230",
                "transpose_1334"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1333",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1332"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1333
        },
        "nn.dense_1350": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1194",
                "transpose_1351"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1350",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1349"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1350
        },
        "nn.dense_1362": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1194",
                "transpose_1363"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1362",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1361"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1362
        },
        "nn.dense_1379": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1158",
                "transpose_1380"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1379",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1378"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1379
        },
        "nn.dense_1391": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1158",
                "transpose_1392"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1391",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1391
        },
        "nn.dense_1408": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1122",
                "transpose_1409"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1408",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1408
        },
        "nn.dense_1420": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1122",
                "transpose_1421"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1420",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1420
        },
        "nn.dense_1437": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1086",
                "transpose_1438"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1437",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1437
        },
        "nn.dense_1449": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1086",
                "transpose_1450"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1449",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1449
        },
        "nn.dense_1466": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1050",
                "transpose_1467"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1466",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1466
        },
        "nn.dense_1478": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1050",
                "transpose_1479"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1478",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1478
        },
        "nn.dense_1495": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1014",
                "transpose_1496"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1495",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1495
        },
        "nn.dense_1507": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1014",
                "transpose_1508"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1507",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1507
        },
        "nn.dense_1524": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_978",
                "transpose_1525"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1524",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1524
        },
        "nn.dense_1536": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_978",
                "transpose_1537"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1536",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1536
        },
        "nn.dense_1553": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_942",
                "transpose_1554"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1553",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1553
        },
        "nn.dense_1565": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_942",
                "transpose_1566"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1565",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1565
        },
        "nn.dense_1582": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_906",
                "transpose_1583"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1582",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1581"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1582
        },
        "nn.dense_1594": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_906",
                "transpose_1595"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1594",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1594
        },
        "nn.dense_1611": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_870",
                "transpose_1612"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1611",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1611
        },
        "nn.dense_1623": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_870",
                "transpose_1624"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1623",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1623
        },
        "nn.dense_1640": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_834",
                "transpose_1641"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1640",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1640
        },
        "nn.dense_1652": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_834",
                "transpose_1653"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1652",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1652
        },
        "nn.dense_1669": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_798",
                "transpose_1670"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1669",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1668"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1669
        },
        "nn.dense_1681": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_798",
                "transpose_1682"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1681",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1681
        },
        "nn.dense_1698": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_762",
                "transpose_1699"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1698",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1698
        },
        "nn.dense_1710": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_762",
                "transpose_1711"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1710",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1710
        },
        "nn.dense_1727": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_726",
                "transpose_1728"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1727",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1727
        },
        "nn.dense_1739": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_726",
                "transpose_1740"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1739",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1739
        },
        "nn.dense_1756": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_690",
                "transpose_1757"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1756",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1756
        },
        "nn.dense_1768": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_690",
                "transpose_1769"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1768",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1767"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1768
        },
        "nn.dense_1785": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_654",
                "transpose_1786"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1785",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1785
        },
        "nn.dense_1797": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_654",
                "transpose_1798"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1797",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1796"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1797
        },
        "nn.dense_1814": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_618",
                "transpose_1815"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1814",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1814
        },
        "nn.dense_1826": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_618",
                "transpose_1827"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1826",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1825"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1826
        },
        "nn.dense_1843": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_582",
                "transpose_1844"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1843",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1842"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1843
        },
        "nn.dense_1855": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_582",
                "transpose_1856"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1855",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1855
        },
        "nn.dense_1872": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_546",
                "transpose_1873"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1872",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1872
        },
        "nn.dense_1884": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_546",
                "transpose_1885"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1884",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1883"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1884
        },
        "nn.dense_1901": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_510",
                "transpose_1902"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1901",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1901
        },
        "nn.dense_1913": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_510",
                "transpose_1914"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1913",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1913
        },
        "nn.dense_1930": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_474",
                "transpose_1931"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1930",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1929"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1930
        },
        "nn.dense_1942": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_474",
                "transpose_1943"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1942",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1941"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1942
        },
        "nn.dense_1959": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_438",
                "transpose_1960"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1959",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1958"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1959
        },
        "nn.dense_1971": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_438",
                "transpose_1972"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1971",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1971
        },
        "nn.dense_1986": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_402",
                "transpose_1987"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1986",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1985"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "nn.dense",
            "unique_id": 1986
        },
        "nn.dense_401": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_402",
                "transpose_1980"
            ],
            "ir": "pybuda",
            "name": "nn.dense_401",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_400"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "nn.dense",
            "unique_id": 401
        },
        "nn.dense_408": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_409",
                "transpose_1978"
            ],
            "ir": "pybuda",
            "name": "nn.dense_408",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 408
        },
        "nn.dense_413": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_414",
                "transpose_1976"
            ],
            "ir": "pybuda",
            "name": "nn.dense_413",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 413
        },
        "nn.dense_420": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_421",
                "transpose_1974"
            ],
            "ir": "pybuda",
            "name": "nn.dense_420",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 420
        },
        "nn.dense_437": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_438",
                "transpose_1951"
            ],
            "ir": "pybuda",
            "name": "nn.dense_437",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 437
        },
        "nn.dense_444": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_445",
                "transpose_1949"
            ],
            "ir": "pybuda",
            "name": "nn.dense_444",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 444
        },
        "nn.dense_449": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_450",
                "transpose_1947"
            ],
            "ir": "pybuda",
            "name": "nn.dense_449",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 449
        },
        "nn.dense_456": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_457",
                "transpose_1945"
            ],
            "ir": "pybuda",
            "name": "nn.dense_456",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 456
        },
        "nn.dense_473": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_474",
                "transpose_1922"
            ],
            "ir": "pybuda",
            "name": "nn.dense_473",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_472"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 473
        },
        "nn.dense_480": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_481",
                "transpose_1920"
            ],
            "ir": "pybuda",
            "name": "nn.dense_480",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_479"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 480
        },
        "nn.dense_485": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_486",
                "transpose_1918"
            ],
            "ir": "pybuda",
            "name": "nn.dense_485",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 485
        },
        "nn.dense_492": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_493",
                "transpose_1916"
            ],
            "ir": "pybuda",
            "name": "nn.dense_492",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_491"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 492
        },
        "nn.dense_509": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_510",
                "transpose_1893"
            ],
            "ir": "pybuda",
            "name": "nn.dense_509",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_508"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 509
        },
        "nn.dense_516": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_517",
                "transpose_1891"
            ],
            "ir": "pybuda",
            "name": "nn.dense_516",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 516
        },
        "nn.dense_521": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_522",
                "transpose_1889"
            ],
            "ir": "pybuda",
            "name": "nn.dense_521",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_520"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 521
        },
        "nn.dense_528": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_529",
                "transpose_1887"
            ],
            "ir": "pybuda",
            "name": "nn.dense_528",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 528
        },
        "nn.dense_545": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_546",
                "transpose_1864"
            ],
            "ir": "pybuda",
            "name": "nn.dense_545",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_544"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 545
        },
        "nn.dense_552": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_553",
                "transpose_1862"
            ],
            "ir": "pybuda",
            "name": "nn.dense_552",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 552
        },
        "nn.dense_557": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_558",
                "transpose_1860"
            ],
            "ir": "pybuda",
            "name": "nn.dense_557",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_556"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 557
        },
        "nn.dense_564": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_565",
                "transpose_1858"
            ],
            "ir": "pybuda",
            "name": "nn.dense_564",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 564
        },
        "nn.dense_581": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_582",
                "transpose_1835"
            ],
            "ir": "pybuda",
            "name": "nn.dense_581",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_580"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 581
        },
        "nn.dense_588": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_589",
                "transpose_1833"
            ],
            "ir": "pybuda",
            "name": "nn.dense_588",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 588
        },
        "nn.dense_593": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_594",
                "transpose_1831"
            ],
            "ir": "pybuda",
            "name": "nn.dense_593",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 593
        },
        "nn.dense_600": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_601",
                "transpose_1829"
            ],
            "ir": "pybuda",
            "name": "nn.dense_600",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 600
        },
        "nn.dense_617": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_618",
                "transpose_1806"
            ],
            "ir": "pybuda",
            "name": "nn.dense_617",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 617
        },
        "nn.dense_624": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_625",
                "transpose_1804"
            ],
            "ir": "pybuda",
            "name": "nn.dense_624",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 624
        },
        "nn.dense_629": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_630",
                "transpose_1802"
            ],
            "ir": "pybuda",
            "name": "nn.dense_629",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 629
        },
        "nn.dense_636": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_637",
                "transpose_1800"
            ],
            "ir": "pybuda",
            "name": "nn.dense_636",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 636
        },
        "nn.dense_653": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_654",
                "transpose_1777"
            ],
            "ir": "pybuda",
            "name": "nn.dense_653",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 653
        },
        "nn.dense_660": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_661",
                "transpose_1775"
            ],
            "ir": "pybuda",
            "name": "nn.dense_660",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_659"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 660
        },
        "nn.dense_665": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_666",
                "transpose_1773"
            ],
            "ir": "pybuda",
            "name": "nn.dense_665",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 665
        },
        "nn.dense_672": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_673",
                "transpose_1771"
            ],
            "ir": "pybuda",
            "name": "nn.dense_672",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 672
        },
        "nn.dense_689": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_690",
                "transpose_1748"
            ],
            "ir": "pybuda",
            "name": "nn.dense_689",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 689
        },
        "nn.dense_696": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_697",
                "transpose_1746"
            ],
            "ir": "pybuda",
            "name": "nn.dense_696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 696
        },
        "nn.dense_701": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_702",
                "transpose_1744"
            ],
            "ir": "pybuda",
            "name": "nn.dense_701",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 701
        },
        "nn.dense_708": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_709",
                "transpose_1742"
            ],
            "ir": "pybuda",
            "name": "nn.dense_708",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_707"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 708
        },
        "nn.dense_725": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_726",
                "transpose_1719"
            ],
            "ir": "pybuda",
            "name": "nn.dense_725",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_724"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 725
        },
        "nn.dense_732": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_733",
                "transpose_1717"
            ],
            "ir": "pybuda",
            "name": "nn.dense_732",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 732
        },
        "nn.dense_737": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_738",
                "transpose_1715"
            ],
            "ir": "pybuda",
            "name": "nn.dense_737",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_736"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 737
        },
        "nn.dense_744": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_745",
                "transpose_1713"
            ],
            "ir": "pybuda",
            "name": "nn.dense_744",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_743"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 744
        },
        "nn.dense_761": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_762",
                "transpose_1690"
            ],
            "ir": "pybuda",
            "name": "nn.dense_761",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_760"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 761
        },
        "nn.dense_768": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_769",
                "transpose_1688"
            ],
            "ir": "pybuda",
            "name": "nn.dense_768",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_767"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 768
        },
        "nn.dense_773": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_774",
                "transpose_1686"
            ],
            "ir": "pybuda",
            "name": "nn.dense_773",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_772"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 773
        },
        "nn.dense_780": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_781",
                "transpose_1684"
            ],
            "ir": "pybuda",
            "name": "nn.dense_780",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 780
        },
        "nn.dense_797": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_798",
                "transpose_1661"
            ],
            "ir": "pybuda",
            "name": "nn.dense_797",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_796"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 797
        },
        "nn.dense_804": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_805",
                "transpose_1659"
            ],
            "ir": "pybuda",
            "name": "nn.dense_804",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_803"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 804
        },
        "nn.dense_809": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_810",
                "transpose_1657"
            ],
            "ir": "pybuda",
            "name": "nn.dense_809",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 809
        },
        "nn.dense_816": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_817",
                "transpose_1655"
            ],
            "ir": "pybuda",
            "name": "nn.dense_816",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_815"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 816
        },
        "nn.dense_833": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_834",
                "transpose_1632"
            ],
            "ir": "pybuda",
            "name": "nn.dense_833",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_832"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 833
        },
        "nn.dense_840": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_841",
                "transpose_1630"
            ],
            "ir": "pybuda",
            "name": "nn.dense_840",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 840
        },
        "nn.dense_845": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_846",
                "transpose_1628"
            ],
            "ir": "pybuda",
            "name": "nn.dense_845",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_844"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 845
        },
        "nn.dense_852": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_853",
                "transpose_1626"
            ],
            "ir": "pybuda",
            "name": "nn.dense_852",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_851"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 852
        },
        "nn.dense_869": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_870",
                "transpose_1603"
            ],
            "ir": "pybuda",
            "name": "nn.dense_869",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 869
        },
        "nn.dense_876": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_877",
                "transpose_1601"
            ],
            "ir": "pybuda",
            "name": "nn.dense_876",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 876
        },
        "nn.dense_881": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_882",
                "transpose_1599"
            ],
            "ir": "pybuda",
            "name": "nn.dense_881",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 881
        },
        "nn.dense_888": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_889",
                "transpose_1597"
            ],
            "ir": "pybuda",
            "name": "nn.dense_888",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_887"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 888
        },
        "nn.dense_905": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_906",
                "transpose_1574"
            ],
            "ir": "pybuda",
            "name": "nn.dense_905",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_904"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 905
        },
        "nn.dense_912": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_913",
                "transpose_1572"
            ],
            "ir": "pybuda",
            "name": "nn.dense_912",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 912
        },
        "nn.dense_917": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_918",
                "transpose_1570"
            ],
            "ir": "pybuda",
            "name": "nn.dense_917",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_916"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 917
        },
        "nn.dense_924": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_925",
                "transpose_1568"
            ],
            "ir": "pybuda",
            "name": "nn.dense_924",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 924
        },
        "nn.dense_941": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_942",
                "transpose_1545"
            ],
            "ir": "pybuda",
            "name": "nn.dense_941",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_940"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 941
        },
        "nn.dense_948": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_949",
                "transpose_1543"
            ],
            "ir": "pybuda",
            "name": "nn.dense_948",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_947"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 948
        },
        "nn.dense_953": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_954",
                "transpose_1541"
            ],
            "ir": "pybuda",
            "name": "nn.dense_953",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_952"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 953
        },
        "nn.dense_960": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_961",
                "transpose_1539"
            ],
            "ir": "pybuda",
            "name": "nn.dense_960",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 960
        },
        "nn.dense_977": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_978",
                "transpose_1516"
            ],
            "ir": "pybuda",
            "name": "nn.dense_977",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_976"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 977
        },
        "nn.dense_984": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_985",
                "transpose_1514"
            ],
            "ir": "pybuda",
            "name": "nn.dense_984",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_983"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 984
        },
        "nn.dense_989": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_990",
                "transpose_1512"
            ],
            "ir": "pybuda",
            "name": "nn.dense_989",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_988"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 989
        },
        "nn.dense_996": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_997",
                "transpose_1510"
            ],
            "ir": "pybuda",
            "name": "nn.dense_996",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_995"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 996
        },
        "nn.dropout_1002": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1003"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1002",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1001"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1002
        },
        "nn.dropout_1017": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1018"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1017",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1016"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1017
        },
        "nn.dropout_1029": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1030"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1029",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1028"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1029
        },
        "nn.dropout_1038": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1039"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1038",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1037"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1038
        },
        "nn.dropout_1053": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1054"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1053",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1052"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1053
        },
        "nn.dropout_1065": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1066"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1065",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1064"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1065
        },
        "nn.dropout_1074": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1075"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1074",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1073"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1074
        },
        "nn.dropout_1089": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1090"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1089",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1088"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1089
        },
        "nn.dropout_1101": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1102"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1101",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1100"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1101
        },
        "nn.dropout_1110": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1111"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1110",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1109"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1110
        },
        "nn.dropout_1125": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1126"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1125",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1124"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1125
        },
        "nn.dropout_1137": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1138"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1137",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1136"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1137
        },
        "nn.dropout_1146": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1147"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1146",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1145"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1146
        },
        "nn.dropout_1161": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1162"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1161",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1160"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1161
        },
        "nn.dropout_1173": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1174"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1173",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1172"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1173
        },
        "nn.dropout_1182": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1183"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1182",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1181"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1182
        },
        "nn.dropout_1197": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1198"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1197",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1196"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1197
        },
        "nn.dropout_1209": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1210"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1209",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1208"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1209
        },
        "nn.dropout_1218": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1219"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1218",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1217"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1218
        },
        "nn.dropout_1233": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1234"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1233",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1232"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1233
        },
        "nn.dropout_1245": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1246"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1245",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1244"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1245
        },
        "nn.dropout_1254": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1255"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1254",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1253"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1254
        },
        "nn.dropout_1267": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1268"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1267",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1244",
                "reshape_1266"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1267
        },
        "nn.dropout_405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_406"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_405",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_404"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 405
        },
        "nn.dropout_417": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_418"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_417",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_416"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 417
        },
        "nn.dropout_426": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_427"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_426",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_425"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 426
        },
        "nn.dropout_441": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_442"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_441",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_440"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 441
        },
        "nn.dropout_453": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_454"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_453",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_452"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 453
        },
        "nn.dropout_462": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_463"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_462",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_461"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 462
        },
        "nn.dropout_477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_478"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_477",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_476"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 477
        },
        "nn.dropout_489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_490"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_489",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_488"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 489
        },
        "nn.dropout_498": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_499"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_498",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_497"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 498
        },
        "nn.dropout_513": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_514"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_513",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_512"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 513
        },
        "nn.dropout_525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_526"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_525",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_524"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 525
        },
        "nn.dropout_534": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_535"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_534",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_533"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 534
        },
        "nn.dropout_549": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_550"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_549",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_548"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 549
        },
        "nn.dropout_561": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_562"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_561",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_560"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 561
        },
        "nn.dropout_570": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_571"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_570",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_569"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 570
        },
        "nn.dropout_585": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_586"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_585",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_584"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 585
        },
        "nn.dropout_597": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_598"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_597",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_596"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 597
        },
        "nn.dropout_606": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_607"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_606",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_605"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 606
        },
        "nn.dropout_621": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_622"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_621",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_620"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 621
        },
        "nn.dropout_633": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_634"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_633",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_632"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 633
        },
        "nn.dropout_642": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_643"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_642",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_641"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 642
        },
        "nn.dropout_657": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_658"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_657",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_656"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 657
        },
        "nn.dropout_669": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_670"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_669",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_668"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 669
        },
        "nn.dropout_678": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_679"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_678",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_677"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 678
        },
        "nn.dropout_693": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_694"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_693",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_692"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 693
        },
        "nn.dropout_705": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_706"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_705",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_704"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 705
        },
        "nn.dropout_714": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_715"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_714",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_713"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 714
        },
        "nn.dropout_729": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_730"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_729",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_728"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 729
        },
        "nn.dropout_741": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_742"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_741",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_740"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 741
        },
        "nn.dropout_750": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_751"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_750",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_749"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 750
        },
        "nn.dropout_765": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_766"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_765",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_764"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 765
        },
        "nn.dropout_777": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_778"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_777",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_776"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 777
        },
        "nn.dropout_786": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_787"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_786",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_785"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 786
        },
        "nn.dropout_801": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_802"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_801",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_800"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 801
        },
        "nn.dropout_813": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_814"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_813",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_812"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 813
        },
        "nn.dropout_822": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_823"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_822",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_821"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 822
        },
        "nn.dropout_837": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_838"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_837",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_836"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 837
        },
        "nn.dropout_849": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_850"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_849",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_848"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 849
        },
        "nn.dropout_858": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_859"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_858",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_857"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 858
        },
        "nn.dropout_873": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_874"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_873",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_872"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 873
        },
        "nn.dropout_885": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_886"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_885",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_884"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 885
        },
        "nn.dropout_894": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_895"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_894",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_893"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 894
        },
        "nn.dropout_909": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_910"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_909",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_908"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 909
        },
        "nn.dropout_921": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_922"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_921",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_920"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 921
        },
        "nn.dropout_930": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_931"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_930",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_929"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 930
        },
        "nn.dropout_945": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_946"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_945",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_944"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 945
        },
        "nn.dropout_957": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_958"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_957",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_956"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 957
        },
        "nn.dropout_966": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_967"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_966",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_965"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 966
        },
        "nn.dropout_981": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_982"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_981",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_980"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 981
        },
        "nn.dropout_993": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_994"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_993",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_992"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 993
        },
        "nn.softmax_1003": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1004"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1003",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bdeb50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1003
        },
        "nn.softmax_1039": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1040"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1039",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1038"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511de0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1039
        },
        "nn.softmax_1075": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1076"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1075",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1074"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49d340), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1075
        },
        "nn.softmax_1111": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1112"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1111",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c25db0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1111
        },
        "nn.softmax_1147": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1148"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1147",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1146"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c1d990), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1147
        },
        "nn.softmax_1183": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1184"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1183",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1182"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b65130), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1183
        },
        "nn.softmax_1219": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1220"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1219",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1218"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98a870), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1219
        },
        "nn.softmax_1255": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1256"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1255",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1254"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9af750), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1255
        },
        "nn.softmax_427": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_428"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_427",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37bd2dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 427
        },
        "nn.softmax_463": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_464"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_463",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_462"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9422d960), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 463
        },
        "nn.softmax_499": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_500"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_499",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7b0540), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 499
        },
        "nn.softmax_535": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_536"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_535",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126863e0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 535
        },
        "nn.softmax_571": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_572"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_571",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1270), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 571
        },
        "nn.softmax_607": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_608"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_607",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9723b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 607
        },
        "nn.softmax_643": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_644"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_643",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_642"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28027dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 643
        },
        "nn.softmax_679": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_680"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_679",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150e2880), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 679
        },
        "nn.softmax_715": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_716"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_715",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_714"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15044f50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 715
        },
        "nn.softmax_751": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_752"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_751",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x280119a0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 751
        },
        "nn.softmax_787": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_788"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_787",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f55ff0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 787
        },
        "nn.softmax_823": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_824"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_823",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_822"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98d0b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 823
        },
        "nn.softmax_859": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_860"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_859",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_858"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf778820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 859
        },
        "nn.softmax_895": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_896"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_895",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_894"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364e52c0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 895
        },
        "nn.softmax_931": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_932"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_931",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36479bd0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 931
        },
        "nn.softmax_967": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_968"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_967",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_966"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c23820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 967
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    "2"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_1983",
                "strided_slice_1990"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 394
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_1982",
                "strided_slice_1989"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 393
        },
        "reciprocal_1289": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1290"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1289",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1257"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1289
        },
        "reciprocal_1324": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1325"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1324",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1221"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1324
        },
        "reciprocal_1353": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1354"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1353",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1185"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1353
        },
        "reciprocal_1382": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1383"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1382",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1149"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1382
        },
        "reciprocal_1411": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1412"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1411",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1113"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1411
        },
        "reciprocal_1440": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1441"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1440",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1077"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1440
        },
        "reciprocal_1469": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1470"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1469",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1041"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1469
        },
        "reciprocal_1498": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1499"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1498",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1005"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1498
        },
        "reciprocal_1527": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1528"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1527",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_969"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1527
        },
        "reciprocal_1556": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1557"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1556",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_933"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1556
        },
        "reciprocal_1585": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1586"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1585",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_897"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1585
        },
        "reciprocal_1614": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1615"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1614",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_861"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1614
        },
        "reciprocal_1643": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1644"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1643",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_825"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1643
        },
        "reciprocal_1672": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1673"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1672",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_789"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1672
        },
        "reciprocal_1701": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1702"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1701",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_753"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1701
        },
        "reciprocal_1730": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1731"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1730",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_717"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1730
        },
        "reciprocal_1759": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1760"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1759",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_681"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1759
        },
        "reciprocal_1788": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1789"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1788",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_645"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1788
        },
        "reciprocal_1817": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1818"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1817",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_609"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1817
        },
        "reciprocal_1846": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1847"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1846",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_573"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1846
        },
        "reciprocal_1875": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1876"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1875",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_537"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1875
        },
        "reciprocal_1904": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1905"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1904",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_501"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1904
        },
        "reciprocal_1933": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1934"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1933",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_465"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1933
        },
        "reciprocal_1962": {
            "cache": {
                "shape": []
            },
            "class": "reciprocal",
            "epoch": 0,
            "input_nodes": [
                "constant_1963"
            ],
            "ir": "pybuda",
            "name": "reciprocal_1962",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_429"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reciprocal",
            "unique_id": 1962
        },
        "reshape_1001": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1002"
            ],
            "ir": "pybuda",
            "name": "reshape_1001",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1000"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1001
        },
        "reshape_1006": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1007"
            ],
            "ir": "pybuda",
            "name": "reshape_1006",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1005"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1006
        },
        "reshape_1008": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1009"
            ],
            "ir": "pybuda",
            "name": "reshape_1008",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1007"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1008
        },
        "reshape_1010": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1011"
            ],
            "ir": "pybuda",
            "name": "reshape_1010",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1009"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1010
        },
        "reshape_1012": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1013"
            ],
            "ir": "pybuda",
            "name": "reshape_1012",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1011"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1012
        },
        "reshape_1014": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1015"
            ],
            "ir": "pybuda",
            "name": "reshape_1014",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1013",
                "nn.dense_1495",
                "nn.dense_1507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1014
        },
        "reshape_1019": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1020"
            ],
            "ir": "pybuda",
            "name": "reshape_1019",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1018"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1019
        },
        "reshape_1021": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1022"
            ],
            "ir": "pybuda",
            "name": "reshape_1021",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1020"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1021
        },
        "reshape_1024": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1025"
            ],
            "ir": "pybuda",
            "name": "reshape_1024",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1023"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1024
        },
        "reshape_1026": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1027"
            ],
            "ir": "pybuda",
            "name": "reshape_1026",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1025"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1026
        },
        "reshape_1031": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1032"
            ],
            "ir": "pybuda",
            "name": "reshape_1031",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1030"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1031
        },
        "reshape_1033": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1034"
            ],
            "ir": "pybuda",
            "name": "reshape_1033",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1032"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1033
        },
        "reshape_1035": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1036"
            ],
            "ir": "pybuda",
            "name": "reshape_1035",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1034"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1035
        },
        "reshape_1037": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1038"
            ],
            "ir": "pybuda",
            "name": "reshape_1037",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1036"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1037
        },
        "reshape_1042": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1043"
            ],
            "ir": "pybuda",
            "name": "reshape_1042",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1042
        },
        "reshape_1044": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1045"
            ],
            "ir": "pybuda",
            "name": "reshape_1044",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1043"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1044
        },
        "reshape_1046": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1047"
            ],
            "ir": "pybuda",
            "name": "reshape_1046",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1045"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1046
        },
        "reshape_1048": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1049"
            ],
            "ir": "pybuda",
            "name": "reshape_1048",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1047"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1048
        },
        "reshape_1050": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1051"
            ],
            "ir": "pybuda",
            "name": "reshape_1050",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1049",
                "nn.dense_1466",
                "nn.dense_1478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1050
        },
        "reshape_1055": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1056"
            ],
            "ir": "pybuda",
            "name": "reshape_1055",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1054"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1055
        },
        "reshape_1057": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1058"
            ],
            "ir": "pybuda",
            "name": "reshape_1057",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1056"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1057
        },
        "reshape_1060": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1061"
            ],
            "ir": "pybuda",
            "name": "reshape_1060",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1060
        },
        "reshape_1062": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1063"
            ],
            "ir": "pybuda",
            "name": "reshape_1062",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1061"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1062
        },
        "reshape_1067": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1068"
            ],
            "ir": "pybuda",
            "name": "reshape_1067",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1067
        },
        "reshape_1069": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1070"
            ],
            "ir": "pybuda",
            "name": "reshape_1069",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1068"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1069
        },
        "reshape_1071": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1072"
            ],
            "ir": "pybuda",
            "name": "reshape_1071",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1071
        },
        "reshape_1073": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1074"
            ],
            "ir": "pybuda",
            "name": "reshape_1073",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1072"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1073
        },
        "reshape_1078": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1079"
            ],
            "ir": "pybuda",
            "name": "reshape_1078",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1077"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1078
        },
        "reshape_1080": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1081"
            ],
            "ir": "pybuda",
            "name": "reshape_1080",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1079"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1080
        },
        "reshape_1082": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1083"
            ],
            "ir": "pybuda",
            "name": "reshape_1082",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1081"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1082
        },
        "reshape_1084": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1085"
            ],
            "ir": "pybuda",
            "name": "reshape_1084",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1083"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1084
        },
        "reshape_1086": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1087"
            ],
            "ir": "pybuda",
            "name": "reshape_1086",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1085",
                "nn.dense_1437",
                "nn.dense_1449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1086
        },
        "reshape_1091": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1092"
            ],
            "ir": "pybuda",
            "name": "reshape_1091",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1090"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1091
        },
        "reshape_1093": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1094"
            ],
            "ir": "pybuda",
            "name": "reshape_1093",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1092"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1093
        },
        "reshape_1096": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1097"
            ],
            "ir": "pybuda",
            "name": "reshape_1096",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1095"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1096
        },
        "reshape_1098": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1099"
            ],
            "ir": "pybuda",
            "name": "reshape_1098",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1097"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1098
        },
        "reshape_1103": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1104"
            ],
            "ir": "pybuda",
            "name": "reshape_1103",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1102"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1103
        },
        "reshape_1105": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1106"
            ],
            "ir": "pybuda",
            "name": "reshape_1105",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1104"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1105
        },
        "reshape_1107": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1108"
            ],
            "ir": "pybuda",
            "name": "reshape_1107",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1106"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1107
        },
        "reshape_1109": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1110"
            ],
            "ir": "pybuda",
            "name": "reshape_1109",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1108"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1109
        },
        "reshape_1114": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1115"
            ],
            "ir": "pybuda",
            "name": "reshape_1114",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1113"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1114
        },
        "reshape_1116": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1117"
            ],
            "ir": "pybuda",
            "name": "reshape_1116",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1115"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1116
        },
        "reshape_1118": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1119"
            ],
            "ir": "pybuda",
            "name": "reshape_1118",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1117"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1118
        },
        "reshape_1120": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1121"
            ],
            "ir": "pybuda",
            "name": "reshape_1120",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1119"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1120
        },
        "reshape_1122": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1123"
            ],
            "ir": "pybuda",
            "name": "reshape_1122",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1121",
                "nn.dense_1408",
                "nn.dense_1420"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1122
        },
        "reshape_1127": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1128"
            ],
            "ir": "pybuda",
            "name": "reshape_1127",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1127
        },
        "reshape_1129": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1130"
            ],
            "ir": "pybuda",
            "name": "reshape_1129",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1128"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1129
        },
        "reshape_1132": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1133"
            ],
            "ir": "pybuda",
            "name": "reshape_1132",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1131"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1132
        },
        "reshape_1134": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1135"
            ],
            "ir": "pybuda",
            "name": "reshape_1134",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1133"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1134
        },
        "reshape_1139": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1140"
            ],
            "ir": "pybuda",
            "name": "reshape_1139",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1138"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1139
        },
        "reshape_1141": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1142"
            ],
            "ir": "pybuda",
            "name": "reshape_1141",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1140"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1141
        },
        "reshape_1143": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1144"
            ],
            "ir": "pybuda",
            "name": "reshape_1143",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1142"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1143
        },
        "reshape_1145": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1146"
            ],
            "ir": "pybuda",
            "name": "reshape_1145",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1145
        },
        "reshape_1150": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1151"
            ],
            "ir": "pybuda",
            "name": "reshape_1150",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1149"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1150
        },
        "reshape_1152": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1153"
            ],
            "ir": "pybuda",
            "name": "reshape_1152",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1151"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1152
        },
        "reshape_1154": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1155"
            ],
            "ir": "pybuda",
            "name": "reshape_1154",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1153"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1154
        },
        "reshape_1156": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1157"
            ],
            "ir": "pybuda",
            "name": "reshape_1156",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1155"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1156
        },
        "reshape_1158": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1159"
            ],
            "ir": "pybuda",
            "name": "reshape_1158",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1157",
                "nn.dense_1379",
                "nn.dense_1391"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1158
        },
        "reshape_1163": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1164"
            ],
            "ir": "pybuda",
            "name": "reshape_1163",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1162"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1163
        },
        "reshape_1165": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1166"
            ],
            "ir": "pybuda",
            "name": "reshape_1165",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1164"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1165
        },
        "reshape_1168": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1169"
            ],
            "ir": "pybuda",
            "name": "reshape_1168",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1167"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1168
        },
        "reshape_1170": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1171"
            ],
            "ir": "pybuda",
            "name": "reshape_1170",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1169"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1170
        },
        "reshape_1175": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1176"
            ],
            "ir": "pybuda",
            "name": "reshape_1175",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1174"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1175
        },
        "reshape_1177": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1178"
            ],
            "ir": "pybuda",
            "name": "reshape_1177",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1176"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1177
        },
        "reshape_1179": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1180"
            ],
            "ir": "pybuda",
            "name": "reshape_1179",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1178"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1179
        },
        "reshape_1181": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1182"
            ],
            "ir": "pybuda",
            "name": "reshape_1181",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1180"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1181
        },
        "reshape_1186": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1187"
            ],
            "ir": "pybuda",
            "name": "reshape_1186",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1185"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1186
        },
        "reshape_1188": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1189"
            ],
            "ir": "pybuda",
            "name": "reshape_1188",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1187"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1188
        },
        "reshape_1190": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1191"
            ],
            "ir": "pybuda",
            "name": "reshape_1190",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1189"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1190
        },
        "reshape_1192": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1193"
            ],
            "ir": "pybuda",
            "name": "reshape_1192",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1192
        },
        "reshape_1194": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1195"
            ],
            "ir": "pybuda",
            "name": "reshape_1194",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1193",
                "nn.dense_1350",
                "nn.dense_1362"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1194
        },
        "reshape_1199": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1200"
            ],
            "ir": "pybuda",
            "name": "reshape_1199",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1198"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1199
        },
        "reshape_1201": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1202"
            ],
            "ir": "pybuda",
            "name": "reshape_1201",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1200"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1201
        },
        "reshape_1204": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1205"
            ],
            "ir": "pybuda",
            "name": "reshape_1204",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1203"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1204
        },
        "reshape_1206": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1207"
            ],
            "ir": "pybuda",
            "name": "reshape_1206",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1205"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1206
        },
        "reshape_1211": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1212"
            ],
            "ir": "pybuda",
            "name": "reshape_1211",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1210"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1211
        },
        "reshape_1213": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1214"
            ],
            "ir": "pybuda",
            "name": "reshape_1213",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1212"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1213
        },
        "reshape_1215": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1216"
            ],
            "ir": "pybuda",
            "name": "reshape_1215",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1214"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1215
        },
        "reshape_1217": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1218"
            ],
            "ir": "pybuda",
            "name": "reshape_1217",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1216"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1217
        },
        "reshape_1222": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1223"
            ],
            "ir": "pybuda",
            "name": "reshape_1222",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1222
        },
        "reshape_1224": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1225"
            ],
            "ir": "pybuda",
            "name": "reshape_1224",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1223"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1224
        },
        "reshape_1226": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1227"
            ],
            "ir": "pybuda",
            "name": "reshape_1226",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1225"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1226
        },
        "reshape_1228": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1229"
            ],
            "ir": "pybuda",
            "name": "reshape_1228",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1227"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1228
        },
        "reshape_1230": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1231"
            ],
            "ir": "pybuda",
            "name": "reshape_1230",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1229",
                "nn.dense_1321",
                "nn.dense_1333"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1230
        },
        "reshape_1235": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1236"
            ],
            "ir": "pybuda",
            "name": "reshape_1235",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1234"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1235
        },
        "reshape_1237": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1238"
            ],
            "ir": "pybuda",
            "name": "reshape_1237",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1236"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1237
        },
        "reshape_1240": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1241"
            ],
            "ir": "pybuda",
            "name": "reshape_1240",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1239"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1240
        },
        "reshape_1242": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1243"
            ],
            "ir": "pybuda",
            "name": "reshape_1242",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1241"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1242
        },
        "reshape_1247": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1248"
            ],
            "ir": "pybuda",
            "name": "reshape_1247",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1246"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1247
        },
        "reshape_1249": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1250"
            ],
            "ir": "pybuda",
            "name": "reshape_1249",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1248"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1249
        },
        "reshape_1251": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1252"
            ],
            "ir": "pybuda",
            "name": "reshape_1251",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1250"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1251
        },
        "reshape_1253": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1254"
            ],
            "ir": "pybuda",
            "name": "reshape_1253",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1252"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1253
        },
        "reshape_1258": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1259"
            ],
            "ir": "pybuda",
            "name": "reshape_1258",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1257"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1258
        },
        "reshape_1260": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1261"
            ],
            "ir": "pybuda",
            "name": "reshape_1260",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1259"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1260
        },
        "reshape_1262": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1263"
            ],
            "ir": "pybuda",
            "name": "reshape_1262",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1261"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1262
        },
        "reshape_1264": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1265"
            ],
            "ir": "pybuda",
            "name": "reshape_1264",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1263"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1264
        },
        "reshape_1266": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1267"
            ],
            "ir": "pybuda",
            "name": "reshape_1266",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1265",
                "nn.dense_1286",
                "nn.dense_1304"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1266
        },
        "reshape_1281": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1282"
            ],
            "ir": "pybuda",
            "name": "reshape_1281",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1280"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1281
        },
        "reshape_1283": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1284"
            ],
            "ir": "pybuda",
            "name": "reshape_1283",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1282"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1283
        },
        "reshape_1285": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1286"
            ],
            "ir": "pybuda",
            "name": "reshape_1285",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1284"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1285
        },
        "reshape_1295": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "attention_mask_1"
            ],
            "ir": "pybuda",
            "name": "reshape_1295",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1294"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1295
        },
        "reshape_1298": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1299"
            ],
            "ir": "pybuda",
            "name": "reshape_1298",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1297"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1298
        },
        "reshape_1301": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1302"
            ],
            "ir": "pybuda",
            "name": "reshape_1301",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1300"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1301
        },
        "reshape_1303": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1304"
            ],
            "ir": "pybuda",
            "name": "reshape_1303",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1302"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1303
        },
        "reshape_1316": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1317"
            ],
            "ir": "pybuda",
            "name": "reshape_1316",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1315"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1316
        },
        "reshape_1318": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1319"
            ],
            "ir": "pybuda",
            "name": "reshape_1318",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1317"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1318
        },
        "reshape_1320": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1321"
            ],
            "ir": "pybuda",
            "name": "reshape_1320",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1319"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1320
        },
        "reshape_1327": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1328"
            ],
            "ir": "pybuda",
            "name": "reshape_1327",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1326"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1327
        },
        "reshape_1330": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1331"
            ],
            "ir": "pybuda",
            "name": "reshape_1330",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1329"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1330
        },
        "reshape_1332": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1333"
            ],
            "ir": "pybuda",
            "name": "reshape_1332",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1331"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1332
        },
        "reshape_1345": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1346"
            ],
            "ir": "pybuda",
            "name": "reshape_1345",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1344"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1345
        },
        "reshape_1347": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1348"
            ],
            "ir": "pybuda",
            "name": "reshape_1347",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1346"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1347
        },
        "reshape_1349": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1350"
            ],
            "ir": "pybuda",
            "name": "reshape_1349",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1348"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1349
        },
        "reshape_1356": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1357"
            ],
            "ir": "pybuda",
            "name": "reshape_1356",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1355"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1356
        },
        "reshape_1359": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1360"
            ],
            "ir": "pybuda",
            "name": "reshape_1359",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1358"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1359
        },
        "reshape_1361": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1362"
            ],
            "ir": "pybuda",
            "name": "reshape_1361",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1360"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1361
        },
        "reshape_1374": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1375"
            ],
            "ir": "pybuda",
            "name": "reshape_1374",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1373"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1374
        },
        "reshape_1376": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1377"
            ],
            "ir": "pybuda",
            "name": "reshape_1376",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1375"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1376
        },
        "reshape_1378": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1379"
            ],
            "ir": "pybuda",
            "name": "reshape_1378",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1377"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1378
        },
        "reshape_1385": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1386"
            ],
            "ir": "pybuda",
            "name": "reshape_1385",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1384"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1385
        },
        "reshape_1388": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1389"
            ],
            "ir": "pybuda",
            "name": "reshape_1388",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1387"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1388
        },
        "reshape_1390": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1391"
            ],
            "ir": "pybuda",
            "name": "reshape_1390",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1389"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1390
        },
        "reshape_1403": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1404"
            ],
            "ir": "pybuda",
            "name": "reshape_1403",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1403
        },
        "reshape_1405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1406"
            ],
            "ir": "pybuda",
            "name": "reshape_1405",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1404"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1405
        },
        "reshape_1407": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1408"
            ],
            "ir": "pybuda",
            "name": "reshape_1407",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1407
        },
        "reshape_1414": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1415"
            ],
            "ir": "pybuda",
            "name": "reshape_1414",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1414
        },
        "reshape_1417": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1418"
            ],
            "ir": "pybuda",
            "name": "reshape_1417",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1416"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1417
        },
        "reshape_1419": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1420"
            ],
            "ir": "pybuda",
            "name": "reshape_1419",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1418"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1419
        },
        "reshape_1432": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1433"
            ],
            "ir": "pybuda",
            "name": "reshape_1432",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1432
        },
        "reshape_1434": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1435"
            ],
            "ir": "pybuda",
            "name": "reshape_1434",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1433"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1434
        },
        "reshape_1436": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1437"
            ],
            "ir": "pybuda",
            "name": "reshape_1436",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1436
        },
        "reshape_1443": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1444"
            ],
            "ir": "pybuda",
            "name": "reshape_1443",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1443
        },
        "reshape_1446": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1447"
            ],
            "ir": "pybuda",
            "name": "reshape_1446",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1446
        },
        "reshape_1448": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1449"
            ],
            "ir": "pybuda",
            "name": "reshape_1448",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1448
        },
        "reshape_1461": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1462"
            ],
            "ir": "pybuda",
            "name": "reshape_1461",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1461
        },
        "reshape_1463": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1464"
            ],
            "ir": "pybuda",
            "name": "reshape_1463",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1462"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1463
        },
        "reshape_1465": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1466"
            ],
            "ir": "pybuda",
            "name": "reshape_1465",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1465
        },
        "reshape_1472": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1473"
            ],
            "ir": "pybuda",
            "name": "reshape_1472",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1471"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1472
        },
        "reshape_1475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1476"
            ],
            "ir": "pybuda",
            "name": "reshape_1475",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1475
        },
        "reshape_1477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1478"
            ],
            "ir": "pybuda",
            "name": "reshape_1477",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1477
        },
        "reshape_1490": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1491"
            ],
            "ir": "pybuda",
            "name": "reshape_1490",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1489"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1490
        },
        "reshape_1492": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1493"
            ],
            "ir": "pybuda",
            "name": "reshape_1492",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1491"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1492
        },
        "reshape_1494": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1495"
            ],
            "ir": "pybuda",
            "name": "reshape_1494",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1494
        },
        "reshape_1501": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1502"
            ],
            "ir": "pybuda",
            "name": "reshape_1501",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1501
        },
        "reshape_1504": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1505"
            ],
            "ir": "pybuda",
            "name": "reshape_1504",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1504
        },
        "reshape_1506": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1507"
            ],
            "ir": "pybuda",
            "name": "reshape_1506",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1505"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1506
        },
        "reshape_1519": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1520"
            ],
            "ir": "pybuda",
            "name": "reshape_1519",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1519
        },
        "reshape_1521": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1522"
            ],
            "ir": "pybuda",
            "name": "reshape_1521",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1520"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1521
        },
        "reshape_1523": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1524"
            ],
            "ir": "pybuda",
            "name": "reshape_1523",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1523
        },
        "reshape_1530": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1531"
            ],
            "ir": "pybuda",
            "name": "reshape_1530",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1530
        },
        "reshape_1533": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1534"
            ],
            "ir": "pybuda",
            "name": "reshape_1533",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1533
        },
        "reshape_1535": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1536"
            ],
            "ir": "pybuda",
            "name": "reshape_1535",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1535
        },
        "reshape_1548": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1549"
            ],
            "ir": "pybuda",
            "name": "reshape_1548",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1548
        },
        "reshape_1550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1551"
            ],
            "ir": "pybuda",
            "name": "reshape_1550",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1549"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1550
        },
        "reshape_1552": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1553"
            ],
            "ir": "pybuda",
            "name": "reshape_1552",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1552
        },
        "reshape_1559": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1560"
            ],
            "ir": "pybuda",
            "name": "reshape_1559",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1559
        },
        "reshape_1562": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1563"
            ],
            "ir": "pybuda",
            "name": "reshape_1562",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1562
        },
        "reshape_1564": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1565"
            ],
            "ir": "pybuda",
            "name": "reshape_1564",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1564
        },
        "reshape_1577": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1578"
            ],
            "ir": "pybuda",
            "name": "reshape_1577",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1577
        },
        "reshape_1579": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1580"
            ],
            "ir": "pybuda",
            "name": "reshape_1579",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1579
        },
        "reshape_1581": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1582"
            ],
            "ir": "pybuda",
            "name": "reshape_1581",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1580"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1581
        },
        "reshape_1588": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1589"
            ],
            "ir": "pybuda",
            "name": "reshape_1588",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1588
        },
        "reshape_1591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1592"
            ],
            "ir": "pybuda",
            "name": "reshape_1591",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1591
        },
        "reshape_1593": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1594"
            ],
            "ir": "pybuda",
            "name": "reshape_1593",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1593
        },
        "reshape_1606": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1607"
            ],
            "ir": "pybuda",
            "name": "reshape_1606",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1605"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1606
        },
        "reshape_1608": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1609"
            ],
            "ir": "pybuda",
            "name": "reshape_1608",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1608
        },
        "reshape_1610": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1611"
            ],
            "ir": "pybuda",
            "name": "reshape_1610",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1610
        },
        "reshape_1617": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1618"
            ],
            "ir": "pybuda",
            "name": "reshape_1617",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1617
        },
        "reshape_1620": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1621"
            ],
            "ir": "pybuda",
            "name": "reshape_1620",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1619"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1620
        },
        "reshape_1622": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1623"
            ],
            "ir": "pybuda",
            "name": "reshape_1622",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1621"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1622
        },
        "reshape_1635": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1636"
            ],
            "ir": "pybuda",
            "name": "reshape_1635",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1635
        },
        "reshape_1637": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1638"
            ],
            "ir": "pybuda",
            "name": "reshape_1637",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1637
        },
        "reshape_1639": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1640"
            ],
            "ir": "pybuda",
            "name": "reshape_1639",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1639
        },
        "reshape_1646": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1647"
            ],
            "ir": "pybuda",
            "name": "reshape_1646",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1646
        },
        "reshape_1649": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1650"
            ],
            "ir": "pybuda",
            "name": "reshape_1649",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1649
        },
        "reshape_1651": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1652"
            ],
            "ir": "pybuda",
            "name": "reshape_1651",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1650"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1651
        },
        "reshape_1664": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1665"
            ],
            "ir": "pybuda",
            "name": "reshape_1664",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1664
        },
        "reshape_1666": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1667"
            ],
            "ir": "pybuda",
            "name": "reshape_1666",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1666
        },
        "reshape_1668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1669"
            ],
            "ir": "pybuda",
            "name": "reshape_1668",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1668
        },
        "reshape_1675": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1676"
            ],
            "ir": "pybuda",
            "name": "reshape_1675",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1675
        },
        "reshape_1678": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1679"
            ],
            "ir": "pybuda",
            "name": "reshape_1678",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1677"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1678
        },
        "reshape_1680": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1681"
            ],
            "ir": "pybuda",
            "name": "reshape_1680",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1680
        },
        "reshape_1693": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1694"
            ],
            "ir": "pybuda",
            "name": "reshape_1693",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1692"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1693
        },
        "reshape_1695": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1696"
            ],
            "ir": "pybuda",
            "name": "reshape_1695",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1695
        },
        "reshape_1697": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1698"
            ],
            "ir": "pybuda",
            "name": "reshape_1697",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1697
        },
        "reshape_1704": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1705"
            ],
            "ir": "pybuda",
            "name": "reshape_1704",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1704
        },
        "reshape_1707": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1708"
            ],
            "ir": "pybuda",
            "name": "reshape_1707",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1706"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1707
        },
        "reshape_1709": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1710"
            ],
            "ir": "pybuda",
            "name": "reshape_1709",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1709
        },
        "reshape_1722": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1723"
            ],
            "ir": "pybuda",
            "name": "reshape_1722",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1721"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1722
        },
        "reshape_1724": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1725"
            ],
            "ir": "pybuda",
            "name": "reshape_1724",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1724
        },
        "reshape_1726": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1727"
            ],
            "ir": "pybuda",
            "name": "reshape_1726",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1726
        },
        "reshape_1733": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1734"
            ],
            "ir": "pybuda",
            "name": "reshape_1733",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1733
        },
        "reshape_1736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1737"
            ],
            "ir": "pybuda",
            "name": "reshape_1736",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1735"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1736
        },
        "reshape_1738": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1739"
            ],
            "ir": "pybuda",
            "name": "reshape_1738",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1738
        },
        "reshape_1751": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1752"
            ],
            "ir": "pybuda",
            "name": "reshape_1751",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1751
        },
        "reshape_1753": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1754"
            ],
            "ir": "pybuda",
            "name": "reshape_1753",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1753
        },
        "reshape_1755": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1756"
            ],
            "ir": "pybuda",
            "name": "reshape_1755",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1755
        },
        "reshape_1762": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1763"
            ],
            "ir": "pybuda",
            "name": "reshape_1762",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1761"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1762
        },
        "reshape_1765": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1766"
            ],
            "ir": "pybuda",
            "name": "reshape_1765",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1764"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1765
        },
        "reshape_1767": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1768"
            ],
            "ir": "pybuda",
            "name": "reshape_1767",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1766"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1767
        },
        "reshape_1780": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1781"
            ],
            "ir": "pybuda",
            "name": "reshape_1780",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1780
        },
        "reshape_1782": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1783"
            ],
            "ir": "pybuda",
            "name": "reshape_1782",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1781"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1782
        },
        "reshape_1784": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1785"
            ],
            "ir": "pybuda",
            "name": "reshape_1784",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1784
        },
        "reshape_1791": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1792"
            ],
            "ir": "pybuda",
            "name": "reshape_1791",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1790"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1791
        },
        "reshape_1794": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1795"
            ],
            "ir": "pybuda",
            "name": "reshape_1794",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1794
        },
        "reshape_1796": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1797"
            ],
            "ir": "pybuda",
            "name": "reshape_1796",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1795"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1796
        },
        "reshape_1809": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1810"
            ],
            "ir": "pybuda",
            "name": "reshape_1809",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1809
        },
        "reshape_1811": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1812"
            ],
            "ir": "pybuda",
            "name": "reshape_1811",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1811
        },
        "reshape_1813": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1814"
            ],
            "ir": "pybuda",
            "name": "reshape_1813",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1812"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1813
        },
        "reshape_1820": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1821"
            ],
            "ir": "pybuda",
            "name": "reshape_1820",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1820
        },
        "reshape_1823": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1824"
            ],
            "ir": "pybuda",
            "name": "reshape_1823",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1822"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1823
        },
        "reshape_1825": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1826"
            ],
            "ir": "pybuda",
            "name": "reshape_1825",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1824"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1825
        },
        "reshape_1838": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1839"
            ],
            "ir": "pybuda",
            "name": "reshape_1838",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1837"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1838
        },
        "reshape_1840": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1841"
            ],
            "ir": "pybuda",
            "name": "reshape_1840",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1840
        },
        "reshape_1842": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1843"
            ],
            "ir": "pybuda",
            "name": "reshape_1842",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1842
        },
        "reshape_1849": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1850"
            ],
            "ir": "pybuda",
            "name": "reshape_1849",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1849
        },
        "reshape_1852": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1853"
            ],
            "ir": "pybuda",
            "name": "reshape_1852",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1851"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1852
        },
        "reshape_1854": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1855"
            ],
            "ir": "pybuda",
            "name": "reshape_1854",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1853"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1854
        },
        "reshape_1867": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1868"
            ],
            "ir": "pybuda",
            "name": "reshape_1867",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1866"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1867
        },
        "reshape_1869": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1870"
            ],
            "ir": "pybuda",
            "name": "reshape_1869",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1869
        },
        "reshape_1871": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1872"
            ],
            "ir": "pybuda",
            "name": "reshape_1871",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1871
        },
        "reshape_1878": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1879"
            ],
            "ir": "pybuda",
            "name": "reshape_1878",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1877"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1878
        },
        "reshape_1881": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1882"
            ],
            "ir": "pybuda",
            "name": "reshape_1881",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1881
        },
        "reshape_1883": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1884"
            ],
            "ir": "pybuda",
            "name": "reshape_1883",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1882"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1883
        },
        "reshape_1896": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1897"
            ],
            "ir": "pybuda",
            "name": "reshape_1896",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1896
        },
        "reshape_1898": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1899"
            ],
            "ir": "pybuda",
            "name": "reshape_1898",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1898
        },
        "reshape_1900": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1901"
            ],
            "ir": "pybuda",
            "name": "reshape_1900",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1899"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1900
        },
        "reshape_1907": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1908"
            ],
            "ir": "pybuda",
            "name": "reshape_1907",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1906"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1907
        },
        "reshape_1910": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1911"
            ],
            "ir": "pybuda",
            "name": "reshape_1910",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1909"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1910
        },
        "reshape_1912": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1913"
            ],
            "ir": "pybuda",
            "name": "reshape_1912",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1912
        },
        "reshape_1925": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1926"
            ],
            "ir": "pybuda",
            "name": "reshape_1925",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1925
        },
        "reshape_1927": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1928"
            ],
            "ir": "pybuda",
            "name": "reshape_1927",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1926"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1927
        },
        "reshape_1929": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1930"
            ],
            "ir": "pybuda",
            "name": "reshape_1929",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1928"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1929
        },
        "reshape_1936": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1937"
            ],
            "ir": "pybuda",
            "name": "reshape_1936",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1935"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1936
        },
        "reshape_1939": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1940"
            ],
            "ir": "pybuda",
            "name": "reshape_1939",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1938"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1939
        },
        "reshape_1941": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1942"
            ],
            "ir": "pybuda",
            "name": "reshape_1941",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1940"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1941
        },
        "reshape_1954": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1955"
            ],
            "ir": "pybuda",
            "name": "reshape_1954",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1954
        },
        "reshape_1956": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1957"
            ],
            "ir": "pybuda",
            "name": "reshape_1956",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1956
        },
        "reshape_1958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1959"
            ],
            "ir": "pybuda",
            "name": "reshape_1958",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1958
        },
        "reshape_1965": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1966"
            ],
            "ir": "pybuda",
            "name": "reshape_1965",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1964"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1965
        },
        "reshape_1968": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1969"
            ],
            "ir": "pybuda",
            "name": "reshape_1968",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1968
        },
        "reshape_1970": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1971"
            ],
            "ir": "pybuda",
            "name": "reshape_1970",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1969"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1970
        },
        "reshape_1984": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1985"
            ],
            "ir": "pybuda",
            "name": "reshape_1984",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_397",
                "tuple_398",
                "tuple_397"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reshape",
            "unique_id": 1984
        },
        "reshape_1991": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "tuple_397"
            ],
            "ir": "pybuda",
            "name": "reshape_1991",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1991
        },
        "reshape_396": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "tuple_397"
            ],
            "ir": "pybuda",
            "name": "reshape_396",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 396
        },
        "reshape_399": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_400"
            ],
            "ir": "pybuda",
            "name": "reshape_399",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_397",
                "tuple_398",
                "tuple_397"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reshape",
            "unique_id": 399
        },
        "reshape_402": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_403"
            ],
            "ir": "pybuda",
            "name": "reshape_402",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_401",
                "nn.dense_1986"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 402
        },
        "reshape_407": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_408"
            ],
            "ir": "pybuda",
            "name": "reshape_407",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 407
        },
        "reshape_409": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_410"
            ],
            "ir": "pybuda",
            "name": "reshape_409",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_408"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 409
        },
        "reshape_412": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_413"
            ],
            "ir": "pybuda",
            "name": "reshape_412",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_411"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 412
        },
        "reshape_414": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_415"
            ],
            "ir": "pybuda",
            "name": "reshape_414",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 414
        },
        "reshape_419": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_420"
            ],
            "ir": "pybuda",
            "name": "reshape_419",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_418"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 419
        },
        "reshape_421": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_422"
            ],
            "ir": "pybuda",
            "name": "reshape_421",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_420"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 421
        },
        "reshape_423": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_424"
            ],
            "ir": "pybuda",
            "name": "reshape_423",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_422"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 423
        },
        "reshape_425": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_426"
            ],
            "ir": "pybuda",
            "name": "reshape_425",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 425
        },
        "reshape_430": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_431"
            ],
            "ir": "pybuda",
            "name": "reshape_430",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 430
        },
        "reshape_432": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_433"
            ],
            "ir": "pybuda",
            "name": "reshape_432",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 432
        },
        "reshape_434": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_435"
            ],
            "ir": "pybuda",
            "name": "reshape_434",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_433"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 434
        },
        "reshape_436": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_437"
            ],
            "ir": "pybuda",
            "name": "reshape_436",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 436
        },
        "reshape_438": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "reshape_438",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_437",
                "nn.dense_1959",
                "nn.dense_1971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 438
        },
        "reshape_443": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_444"
            ],
            "ir": "pybuda",
            "name": "reshape_443",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 443
        },
        "reshape_445": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_446"
            ],
            "ir": "pybuda",
            "name": "reshape_445",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 445
        },
        "reshape_448": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_449"
            ],
            "ir": "pybuda",
            "name": "reshape_448",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 448
        },
        "reshape_450": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_451"
            ],
            "ir": "pybuda",
            "name": "reshape_450",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 450
        },
        "reshape_455": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_456"
            ],
            "ir": "pybuda",
            "name": "reshape_455",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_454"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 455
        },
        "reshape_457": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_458"
            ],
            "ir": "pybuda",
            "name": "reshape_457",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 457
        },
        "reshape_459": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_460"
            ],
            "ir": "pybuda",
            "name": "reshape_459",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_458"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 459
        },
        "reshape_461": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_462"
            ],
            "ir": "pybuda",
            "name": "reshape_461",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 461
        },
        "reshape_466": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_467"
            ],
            "ir": "pybuda",
            "name": "reshape_466",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 466
        },
        "reshape_468": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_469"
            ],
            "ir": "pybuda",
            "name": "reshape_468",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 468
        },
        "reshape_470": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_471"
            ],
            "ir": "pybuda",
            "name": "reshape_470",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 470
        },
        "reshape_472": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_473"
            ],
            "ir": "pybuda",
            "name": "reshape_472",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_471"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 472
        },
        "reshape_474": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_475"
            ],
            "ir": "pybuda",
            "name": "reshape_474",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_473",
                "nn.dense_1930",
                "nn.dense_1942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 474
        },
        "reshape_479": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_480"
            ],
            "ir": "pybuda",
            "name": "reshape_479",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 479
        },
        "reshape_481": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_482"
            ],
            "ir": "pybuda",
            "name": "reshape_481",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_480"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 481
        },
        "reshape_484": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_485"
            ],
            "ir": "pybuda",
            "name": "reshape_484",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 484
        },
        "reshape_486": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_487"
            ],
            "ir": "pybuda",
            "name": "reshape_486",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_485"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 486
        },
        "reshape_491": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_492"
            ],
            "ir": "pybuda",
            "name": "reshape_491",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 491
        },
        "reshape_493": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_494"
            ],
            "ir": "pybuda",
            "name": "reshape_493",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_492"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 493
        },
        "reshape_495": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_496"
            ],
            "ir": "pybuda",
            "name": "reshape_495",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 495
        },
        "reshape_497": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_498"
            ],
            "ir": "pybuda",
            "name": "reshape_497",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_496"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 497
        },
        "reshape_502": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_503"
            ],
            "ir": "pybuda",
            "name": "reshape_502",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 502
        },
        "reshape_504": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_505"
            ],
            "ir": "pybuda",
            "name": "reshape_504",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 504
        },
        "reshape_506": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_507"
            ],
            "ir": "pybuda",
            "name": "reshape_506",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_505"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 506
        },
        "reshape_508": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_509"
            ],
            "ir": "pybuda",
            "name": "reshape_508",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 508
        },
        "reshape_510": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_511"
            ],
            "ir": "pybuda",
            "name": "reshape_510",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_509",
                "nn.dense_1901",
                "nn.dense_1913"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 510
        },
        "reshape_515": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_516"
            ],
            "ir": "pybuda",
            "name": "reshape_515",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_514"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 515
        },
        "reshape_517": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_518"
            ],
            "ir": "pybuda",
            "name": "reshape_517",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 517
        },
        "reshape_520": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_521"
            ],
            "ir": "pybuda",
            "name": "reshape_520",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 520
        },
        "reshape_522": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_523"
            ],
            "ir": "pybuda",
            "name": "reshape_522",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_521"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 522
        },
        "reshape_527": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_528"
            ],
            "ir": "pybuda",
            "name": "reshape_527",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_526"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 527
        },
        "reshape_529": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_530"
            ],
            "ir": "pybuda",
            "name": "reshape_529",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 529
        },
        "reshape_531": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_532"
            ],
            "ir": "pybuda",
            "name": "reshape_531",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 531
        },
        "reshape_533": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_534"
            ],
            "ir": "pybuda",
            "name": "reshape_533",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 533
        },
        "reshape_538": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_539"
            ],
            "ir": "pybuda",
            "name": "reshape_538",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 538
        },
        "reshape_540": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_541"
            ],
            "ir": "pybuda",
            "name": "reshape_540",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 540
        },
        "reshape_542": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_543"
            ],
            "ir": "pybuda",
            "name": "reshape_542",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_541"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 542
        },
        "reshape_544": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_545"
            ],
            "ir": "pybuda",
            "name": "reshape_544",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 544
        },
        "reshape_546": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_547"
            ],
            "ir": "pybuda",
            "name": "reshape_546",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_545",
                "nn.dense_1872",
                "nn.dense_1884"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 546
        },
        "reshape_551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_552"
            ],
            "ir": "pybuda",
            "name": "reshape_551",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 551
        },
        "reshape_553": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_554"
            ],
            "ir": "pybuda",
            "name": "reshape_553",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 553
        },
        "reshape_556": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_557"
            ],
            "ir": "pybuda",
            "name": "reshape_556",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_555"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 556
        },
        "reshape_558": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_559"
            ],
            "ir": "pybuda",
            "name": "reshape_558",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_557"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 558
        },
        "reshape_563": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_564"
            ],
            "ir": "pybuda",
            "name": "reshape_563",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 563
        },
        "reshape_565": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_566"
            ],
            "ir": "pybuda",
            "name": "reshape_565",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 565
        },
        "reshape_567": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_568"
            ],
            "ir": "pybuda",
            "name": "reshape_567",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_566"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 567
        },
        "reshape_569": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_570"
            ],
            "ir": "pybuda",
            "name": "reshape_569",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 569
        },
        "reshape_574": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_575"
            ],
            "ir": "pybuda",
            "name": "reshape_574",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_573"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 574
        },
        "reshape_576": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_577"
            ],
            "ir": "pybuda",
            "name": "reshape_576",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_575"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 576
        },
        "reshape_578": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_579"
            ],
            "ir": "pybuda",
            "name": "reshape_578",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_577"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 578
        },
        "reshape_580": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_581"
            ],
            "ir": "pybuda",
            "name": "reshape_580",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 580
        },
        "reshape_582": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_583"
            ],
            "ir": "pybuda",
            "name": "reshape_582",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_581",
                "nn.dense_1843",
                "nn.dense_1855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 582
        },
        "reshape_587": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_588"
            ],
            "ir": "pybuda",
            "name": "reshape_587",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 587
        },
        "reshape_589": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_590"
            ],
            "ir": "pybuda",
            "name": "reshape_589",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_588"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 589
        },
        "reshape_592": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_593"
            ],
            "ir": "pybuda",
            "name": "reshape_592",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 592
        },
        "reshape_594": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_595"
            ],
            "ir": "pybuda",
            "name": "reshape_594",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 594
        },
        "reshape_599": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_600"
            ],
            "ir": "pybuda",
            "name": "reshape_599",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_598"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 599
        },
        "reshape_601": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_602"
            ],
            "ir": "pybuda",
            "name": "reshape_601",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 601
        },
        "reshape_603": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_604"
            ],
            "ir": "pybuda",
            "name": "reshape_603",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 603
        },
        "reshape_605": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_606"
            ],
            "ir": "pybuda",
            "name": "reshape_605",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_604"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 605
        },
        "reshape_610": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_611"
            ],
            "ir": "pybuda",
            "name": "reshape_610",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 610
        },
        "reshape_612": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_613"
            ],
            "ir": "pybuda",
            "name": "reshape_612",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_611"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 612
        },
        "reshape_614": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_615"
            ],
            "ir": "pybuda",
            "name": "reshape_614",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 614
        },
        "reshape_616": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_617"
            ],
            "ir": "pybuda",
            "name": "reshape_616",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 616
        },
        "reshape_618": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_619"
            ],
            "ir": "pybuda",
            "name": "reshape_618",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_617",
                "nn.dense_1814",
                "nn.dense_1826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 618
        },
        "reshape_623": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_624"
            ],
            "ir": "pybuda",
            "name": "reshape_623",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 623
        },
        "reshape_625": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_626"
            ],
            "ir": "pybuda",
            "name": "reshape_625",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 625
        },
        "reshape_628": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_629"
            ],
            "ir": "pybuda",
            "name": "reshape_628",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 628
        },
        "reshape_630": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_631"
            ],
            "ir": "pybuda",
            "name": "reshape_630",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 630
        },
        "reshape_635": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_636"
            ],
            "ir": "pybuda",
            "name": "reshape_635",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 635
        },
        "reshape_637": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_638"
            ],
            "ir": "pybuda",
            "name": "reshape_637",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 637
        },
        "reshape_639": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_640"
            ],
            "ir": "pybuda",
            "name": "reshape_639",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 639
        },
        "reshape_641": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_642"
            ],
            "ir": "pybuda",
            "name": "reshape_641",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_640"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 641
        },
        "reshape_646": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_647"
            ],
            "ir": "pybuda",
            "name": "reshape_646",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 646
        },
        "reshape_648": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_649"
            ],
            "ir": "pybuda",
            "name": "reshape_648",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 648
        },
        "reshape_650": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_651"
            ],
            "ir": "pybuda",
            "name": "reshape_650",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_649"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 650
        },
        "reshape_652": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_653"
            ],
            "ir": "pybuda",
            "name": "reshape_652",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 652
        },
        "reshape_654": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_655"
            ],
            "ir": "pybuda",
            "name": "reshape_654",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_653",
                "nn.dense_1785",
                "nn.dense_1797"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 654
        },
        "reshape_659": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_660"
            ],
            "ir": "pybuda",
            "name": "reshape_659",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_658"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 659
        },
        "reshape_661": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_662"
            ],
            "ir": "pybuda",
            "name": "reshape_661",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_660"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 661
        },
        "reshape_664": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_665"
            ],
            "ir": "pybuda",
            "name": "reshape_664",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 664
        },
        "reshape_666": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_667"
            ],
            "ir": "pybuda",
            "name": "reshape_666",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 666
        },
        "reshape_671": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_672"
            ],
            "ir": "pybuda",
            "name": "reshape_671",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 671
        },
        "reshape_673": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_674"
            ],
            "ir": "pybuda",
            "name": "reshape_673",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_672"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 673
        },
        "reshape_675": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_676"
            ],
            "ir": "pybuda",
            "name": "reshape_675",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 675
        },
        "reshape_677": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_678"
            ],
            "ir": "pybuda",
            "name": "reshape_677",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 677
        },
        "reshape_682": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_683"
            ],
            "ir": "pybuda",
            "name": "reshape_682",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 682
        },
        "reshape_684": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_685"
            ],
            "ir": "pybuda",
            "name": "reshape_684",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 684
        },
        "reshape_686": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_687"
            ],
            "ir": "pybuda",
            "name": "reshape_686",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_685"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 686
        },
        "reshape_688": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_689"
            ],
            "ir": "pybuda",
            "name": "reshape_688",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 688
        },
        "reshape_690": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_691"
            ],
            "ir": "pybuda",
            "name": "reshape_690",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_689",
                "nn.dense_1756",
                "nn.dense_1768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 690
        },
        "reshape_695": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_696"
            ],
            "ir": "pybuda",
            "name": "reshape_695",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 695
        },
        "reshape_697": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_698"
            ],
            "ir": "pybuda",
            "name": "reshape_697",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 697
        },
        "reshape_700": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_701"
            ],
            "ir": "pybuda",
            "name": "reshape_700",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_699"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 700
        },
        "reshape_702": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_703"
            ],
            "ir": "pybuda",
            "name": "reshape_702",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 702
        },
        "reshape_707": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_708"
            ],
            "ir": "pybuda",
            "name": "reshape_707",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_706"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 707
        },
        "reshape_709": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_710"
            ],
            "ir": "pybuda",
            "name": "reshape_709",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 709
        },
        "reshape_711": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_712"
            ],
            "ir": "pybuda",
            "name": "reshape_711",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 711
        },
        "reshape_713": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_714"
            ],
            "ir": "pybuda",
            "name": "reshape_713",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_712"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 713
        },
        "reshape_718": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_719"
            ],
            "ir": "pybuda",
            "name": "reshape_718",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 718
        },
        "reshape_720": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_721"
            ],
            "ir": "pybuda",
            "name": "reshape_720",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_719"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 720
        },
        "reshape_722": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_723"
            ],
            "ir": "pybuda",
            "name": "reshape_722",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_721"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 722
        },
        "reshape_724": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_725"
            ],
            "ir": "pybuda",
            "name": "reshape_724",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 724
        },
        "reshape_726": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_727"
            ],
            "ir": "pybuda",
            "name": "reshape_726",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_725",
                "nn.dense_1727",
                "nn.dense_1739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 726
        },
        "reshape_731": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_732"
            ],
            "ir": "pybuda",
            "name": "reshape_731",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_730"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 731
        },
        "reshape_733": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_734"
            ],
            "ir": "pybuda",
            "name": "reshape_733",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 733
        },
        "reshape_736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_737"
            ],
            "ir": "pybuda",
            "name": "reshape_736",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_735"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 736
        },
        "reshape_738": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_739"
            ],
            "ir": "pybuda",
            "name": "reshape_738",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 738
        },
        "reshape_743": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_744"
            ],
            "ir": "pybuda",
            "name": "reshape_743",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_742"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 743
        },
        "reshape_745": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_746"
            ],
            "ir": "pybuda",
            "name": "reshape_745",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_744"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 745
        },
        "reshape_747": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_748"
            ],
            "ir": "pybuda",
            "name": "reshape_747",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 747
        },
        "reshape_749": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_750"
            ],
            "ir": "pybuda",
            "name": "reshape_749",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_748"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 749
        },
        "reshape_754": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_755"
            ],
            "ir": "pybuda",
            "name": "reshape_754",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_753"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 754
        },
        "reshape_756": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_757"
            ],
            "ir": "pybuda",
            "name": "reshape_756",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 756
        },
        "reshape_758": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_759"
            ],
            "ir": "pybuda",
            "name": "reshape_758",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 758
        },
        "reshape_760": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_761"
            ],
            "ir": "pybuda",
            "name": "reshape_760",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 760
        },
        "reshape_762": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_763"
            ],
            "ir": "pybuda",
            "name": "reshape_762",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_761",
                "nn.dense_1698",
                "nn.dense_1710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 762
        },
        "reshape_767": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_768"
            ],
            "ir": "pybuda",
            "name": "reshape_767",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_766"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 767
        },
        "reshape_769": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_770"
            ],
            "ir": "pybuda",
            "name": "reshape_769",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 769
        },
        "reshape_772": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_773"
            ],
            "ir": "pybuda",
            "name": "reshape_772",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 772
        },
        "reshape_774": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_775"
            ],
            "ir": "pybuda",
            "name": "reshape_774",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_773"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 774
        },
        "reshape_779": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_780"
            ],
            "ir": "pybuda",
            "name": "reshape_779",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 779
        },
        "reshape_781": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_782"
            ],
            "ir": "pybuda",
            "name": "reshape_781",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 781
        },
        "reshape_783": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_784"
            ],
            "ir": "pybuda",
            "name": "reshape_783",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_782"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 783
        },
        "reshape_785": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_786"
            ],
            "ir": "pybuda",
            "name": "reshape_785",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 785
        },
        "reshape_790": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_791"
            ],
            "ir": "pybuda",
            "name": "reshape_790",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_789"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 790
        },
        "reshape_792": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_793"
            ],
            "ir": "pybuda",
            "name": "reshape_792",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 792
        },
        "reshape_794": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_795"
            ],
            "ir": "pybuda",
            "name": "reshape_794",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 794
        },
        "reshape_796": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_797"
            ],
            "ir": "pybuda",
            "name": "reshape_796",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_795"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 796
        },
        "reshape_798": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_799"
            ],
            "ir": "pybuda",
            "name": "reshape_798",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_797",
                "nn.dense_1669",
                "nn.dense_1681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 798
        },
        "reshape_803": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_804"
            ],
            "ir": "pybuda",
            "name": "reshape_803",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_802"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 803
        },
        "reshape_805": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_806"
            ],
            "ir": "pybuda",
            "name": "reshape_805",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_804"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 805
        },
        "reshape_808": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_809"
            ],
            "ir": "pybuda",
            "name": "reshape_808",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_807"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 808
        },
        "reshape_810": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_811"
            ],
            "ir": "pybuda",
            "name": "reshape_810",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 810
        },
        "reshape_815": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_816"
            ],
            "ir": "pybuda",
            "name": "reshape_815",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_814"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 815
        },
        "reshape_817": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_818"
            ],
            "ir": "pybuda",
            "name": "reshape_817",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_816"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 817
        },
        "reshape_819": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_820"
            ],
            "ir": "pybuda",
            "name": "reshape_819",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_818"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 819
        },
        "reshape_821": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_822"
            ],
            "ir": "pybuda",
            "name": "reshape_821",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_820"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 821
        },
        "reshape_826": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_827"
            ],
            "ir": "pybuda",
            "name": "reshape_826",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_825"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 826
        },
        "reshape_828": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_829"
            ],
            "ir": "pybuda",
            "name": "reshape_828",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_827"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 828
        },
        "reshape_830": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_831"
            ],
            "ir": "pybuda",
            "name": "reshape_830",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_829"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 830
        },
        "reshape_832": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_833"
            ],
            "ir": "pybuda",
            "name": "reshape_832",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 832
        },
        "reshape_834": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_835"
            ],
            "ir": "pybuda",
            "name": "reshape_834",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_833",
                "nn.dense_1640",
                "nn.dense_1652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 834
        },
        "reshape_839": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_840"
            ],
            "ir": "pybuda",
            "name": "reshape_839",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 839
        },
        "reshape_841": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_842"
            ],
            "ir": "pybuda",
            "name": "reshape_841",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_840"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 841
        },
        "reshape_844": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_845"
            ],
            "ir": "pybuda",
            "name": "reshape_844",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_843"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 844
        },
        "reshape_846": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_847"
            ],
            "ir": "pybuda",
            "name": "reshape_846",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_845"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 846
        },
        "reshape_851": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_852"
            ],
            "ir": "pybuda",
            "name": "reshape_851",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 851
        },
        "reshape_853": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_854"
            ],
            "ir": "pybuda",
            "name": "reshape_853",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_852"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 853
        },
        "reshape_855": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_856"
            ],
            "ir": "pybuda",
            "name": "reshape_855",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 855
        },
        "reshape_857": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_858"
            ],
            "ir": "pybuda",
            "name": "reshape_857",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_856"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 857
        },
        "reshape_862": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_863"
            ],
            "ir": "pybuda",
            "name": "reshape_862",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_861"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 862
        },
        "reshape_864": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_865"
            ],
            "ir": "pybuda",
            "name": "reshape_864",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 864
        },
        "reshape_866": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_867"
            ],
            "ir": "pybuda",
            "name": "reshape_866",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_865"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 866
        },
        "reshape_868": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_869"
            ],
            "ir": "pybuda",
            "name": "reshape_868",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 868
        },
        "reshape_870": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_871"
            ],
            "ir": "pybuda",
            "name": "reshape_870",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_869",
                "nn.dense_1611",
                "nn.dense_1623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 870
        },
        "reshape_875": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_876"
            ],
            "ir": "pybuda",
            "name": "reshape_875",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 875
        },
        "reshape_877": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_878"
            ],
            "ir": "pybuda",
            "name": "reshape_877",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_876"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 877
        },
        "reshape_880": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_881"
            ],
            "ir": "pybuda",
            "name": "reshape_880",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 880
        },
        "reshape_882": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "reshape_882",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 882
        },
        "reshape_887": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_888"
            ],
            "ir": "pybuda",
            "name": "reshape_887",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_886"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 887
        },
        "reshape_889": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_890"
            ],
            "ir": "pybuda",
            "name": "reshape_889",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 889
        },
        "reshape_891": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_892"
            ],
            "ir": "pybuda",
            "name": "reshape_891",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_890"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 891
        },
        "reshape_893": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_894"
            ],
            "ir": "pybuda",
            "name": "reshape_893",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_892"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 893
        },
        "reshape_898": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_899"
            ],
            "ir": "pybuda",
            "name": "reshape_898",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 898
        },
        "reshape_900": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_901"
            ],
            "ir": "pybuda",
            "name": "reshape_900",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_899"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 900
        },
        "reshape_902": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_903"
            ],
            "ir": "pybuda",
            "name": "reshape_902",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_901"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 902
        },
        "reshape_904": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_905"
            ],
            "ir": "pybuda",
            "name": "reshape_904",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_903"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 904
        },
        "reshape_906": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_907"
            ],
            "ir": "pybuda",
            "name": "reshape_906",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_905",
                "nn.dense_1582",
                "nn.dense_1594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 906
        },
        "reshape_911": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_912"
            ],
            "ir": "pybuda",
            "name": "reshape_911",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_910"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 911
        },
        "reshape_913": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_914"
            ],
            "ir": "pybuda",
            "name": "reshape_913",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 913
        },
        "reshape_916": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_917"
            ],
            "ir": "pybuda",
            "name": "reshape_916",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_915"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 916
        },
        "reshape_918": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_919"
            ],
            "ir": "pybuda",
            "name": "reshape_918",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_917"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 918
        },
        "reshape_923": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_924"
            ],
            "ir": "pybuda",
            "name": "reshape_923",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 923
        },
        "reshape_925": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_926"
            ],
            "ir": "pybuda",
            "name": "reshape_925",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 925
        },
        "reshape_927": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_928"
            ],
            "ir": "pybuda",
            "name": "reshape_927",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_926"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 927
        },
        "reshape_929": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_930"
            ],
            "ir": "pybuda",
            "name": "reshape_929",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_928"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 929
        },
        "reshape_934": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_935"
            ],
            "ir": "pybuda",
            "name": "reshape_934",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_933"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 934
        },
        "reshape_936": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_937"
            ],
            "ir": "pybuda",
            "name": "reshape_936",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_935"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 936
        },
        "reshape_938": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_939"
            ],
            "ir": "pybuda",
            "name": "reshape_938",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 938
        },
        "reshape_940": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_941"
            ],
            "ir": "pybuda",
            "name": "reshape_940",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_939"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 940
        },
        "reshape_942": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_943"
            ],
            "ir": "pybuda",
            "name": "reshape_942",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_941",
                "nn.dense_1553",
                "nn.dense_1565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 942
        },
        "reshape_947": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_948"
            ],
            "ir": "pybuda",
            "name": "reshape_947",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_946"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 947
        },
        "reshape_949": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_950"
            ],
            "ir": "pybuda",
            "name": "reshape_949",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 949
        },
        "reshape_952": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_953"
            ],
            "ir": "pybuda",
            "name": "reshape_952",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_951"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 952
        },
        "reshape_954": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_955"
            ],
            "ir": "pybuda",
            "name": "reshape_954",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 954
        },
        "reshape_959": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_960"
            ],
            "ir": "pybuda",
            "name": "reshape_959",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 959
        },
        "reshape_961": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_962"
            ],
            "ir": "pybuda",
            "name": "reshape_961",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_960"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 961
        },
        "reshape_963": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_964"
            ],
            "ir": "pybuda",
            "name": "reshape_963",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_962"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 963
        },
        "reshape_965": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_966"
            ],
            "ir": "pybuda",
            "name": "reshape_965",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_964"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 965
        },
        "reshape_970": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_971"
            ],
            "ir": "pybuda",
            "name": "reshape_970",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_969"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 970
        },
        "reshape_972": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_973"
            ],
            "ir": "pybuda",
            "name": "reshape_972",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 972
        },
        "reshape_974": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_975"
            ],
            "ir": "pybuda",
            "name": "reshape_974",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_973"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 974
        },
        "reshape_976": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_977"
            ],
            "ir": "pybuda",
            "name": "reshape_976",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_975"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 976
        },
        "reshape_978": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_979"
            ],
            "ir": "pybuda",
            "name": "reshape_978",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_977",
                "nn.dense_1524",
                "nn.dense_1536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 978
        },
        "reshape_983": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_984"
            ],
            "ir": "pybuda",
            "name": "reshape_983",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_982"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 983
        },
        "reshape_985": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_986"
            ],
            "ir": "pybuda",
            "name": "reshape_985",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_984"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 985
        },
        "reshape_988": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_989"
            ],
            "ir": "pybuda",
            "name": "reshape_988",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 988
        },
        "reshape_990": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_991"
            ],
            "ir": "pybuda",
            "name": "reshape_990",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_989"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 990
        },
        "reshape_995": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_996"
            ],
            "ir": "pybuda",
            "name": "reshape_995",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_994"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 995
        },
        "reshape_997": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_998"
            ],
            "ir": "pybuda",
            "name": "reshape_997",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 997
        },
        "reshape_999": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1000"
            ],
            "ir": "pybuda",
            "name": "reshape_999",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_998"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 999
        },
        "strided_slice_1277": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_ids"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1277",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1276"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::slice, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x2fb4dde0), 0, 0, 0, 0)",
            "type": "strided_slice",
            "unique_id": 1277
        },
        "strided_slice_1982": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1982",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1981"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 1982
        },
        "strided_slice_1983": {
            "cache": {
                "shape": [
                    1
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1983",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_400"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 1983
        },
        "strided_slice_1989": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1989",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1988"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 1989
        },
        "strided_slice_1990": {
            "cache": {
                "shape": [
                    1
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1990",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1985"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 1990
        },
        "subtract_1292": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "input_nodes": [
                "constant_1293",
                "cast_1294"
            ],
            "ir": "pybuda",
            "name": "subtract_1292",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1291"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::rsub, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x918176a0), 0, 0, 0, 0)",
            "type": "subtract",
            "unique_id": 1292
        },
        "transpose_1009": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1010"
            ],
            "ir": "pybuda",
            "name": "transpose_1009",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1008"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1009
        },
        "transpose_1034": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1035"
            ],
            "ir": "pybuda",
            "name": "transpose_1034",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1033"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1034
        },
        "transpose_1045": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1046"
            ],
            "ir": "pybuda",
            "name": "transpose_1045",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1044"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1045
        },
        "transpose_1070": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1071"
            ],
            "ir": "pybuda",
            "name": "transpose_1070",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1069"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1070
        },
        "transpose_1081": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1082"
            ],
            "ir": "pybuda",
            "name": "transpose_1081",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1080"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1081
        },
        "transpose_1106": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1107"
            ],
            "ir": "pybuda",
            "name": "transpose_1106",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1105"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1106
        },
        "transpose_1117": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1118"
            ],
            "ir": "pybuda",
            "name": "transpose_1117",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1116"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1117
        },
        "transpose_1142": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1143"
            ],
            "ir": "pybuda",
            "name": "transpose_1142",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1141"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1142
        },
        "transpose_1153": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1154"
            ],
            "ir": "pybuda",
            "name": "transpose_1153",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1153
        },
        "transpose_1178": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1179"
            ],
            "ir": "pybuda",
            "name": "transpose_1178",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1178
        },
        "transpose_1189": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1190"
            ],
            "ir": "pybuda",
            "name": "transpose_1189",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1188"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1189
        },
        "transpose_1214": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1215"
            ],
            "ir": "pybuda",
            "name": "transpose_1214",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1213"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1214
        },
        "transpose_1225": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1226"
            ],
            "ir": "pybuda",
            "name": "transpose_1225",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1224"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1225
        },
        "transpose_1250": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1251"
            ],
            "ir": "pybuda",
            "name": "transpose_1250",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1249"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1250
        },
        "transpose_1261": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1262"
            ],
            "ir": "pybuda",
            "name": "transpose_1261",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1260"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1261
        },
        "transpose_1278": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1279"
            ],
            "ir": "pybuda",
            "name": "transpose_1278",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1265"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1278
        },
        "transpose_1279": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1279",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1278"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1279
        },
        "transpose_1280": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1281"
            ],
            "ir": "pybuda",
            "name": "transpose_1280",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1259"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1280
        },
        "transpose_1282": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1283"
            ],
            "ir": "pybuda",
            "name": "transpose_1282",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1281"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1282
        },
        "transpose_1287": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1288"
            ],
            "ir": "pybuda",
            "name": "transpose_1287",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1286"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1287
        },
        "transpose_1288": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1288",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1287"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1288
        },
        "transpose_1297": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1298"
            ],
            "ir": "pybuda",
            "name": "transpose_1297",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1252"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1297
        },
        "transpose_1299": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1300"
            ],
            "ir": "pybuda",
            "name": "transpose_1299",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1298"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1299
        },
        "transpose_1300": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1301"
            ],
            "ir": "pybuda",
            "name": "transpose_1300",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1299"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1300
        },
        "transpose_1305": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1306"
            ],
            "ir": "pybuda",
            "name": "transpose_1305",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1304"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1305
        },
        "transpose_1306": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1306",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1305"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1306
        },
        "transpose_1307": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1308"
            ],
            "ir": "pybuda",
            "name": "transpose_1307",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1248"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1307
        },
        "transpose_1308": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1308",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1307"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1308
        },
        "transpose_1309": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1310"
            ],
            "ir": "pybuda",
            "name": "transpose_1309",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1241"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1309
        },
        "transpose_1310": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1310",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1309"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1310
        },
        "transpose_1311": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1312"
            ],
            "ir": "pybuda",
            "name": "transpose_1311",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1236"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1311
        },
        "transpose_1312": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1312",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1311"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1312
        },
        "transpose_1313": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1314"
            ],
            "ir": "pybuda",
            "name": "transpose_1313",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1229"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1313
        },
        "transpose_1314": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1314",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1313"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1314
        },
        "transpose_1315": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1316"
            ],
            "ir": "pybuda",
            "name": "transpose_1315",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1223"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1315
        },
        "transpose_1317": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1318"
            ],
            "ir": "pybuda",
            "name": "transpose_1317",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1316"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1317
        },
        "transpose_1322": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1323"
            ],
            "ir": "pybuda",
            "name": "transpose_1322",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1321"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1322
        },
        "transpose_1323": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1323",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1322"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1323
        },
        "transpose_1326": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1327"
            ],
            "ir": "pybuda",
            "name": "transpose_1326",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1216"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1326
        },
        "transpose_1328": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1329"
            ],
            "ir": "pybuda",
            "name": "transpose_1328",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1327"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1328
        },
        "transpose_1329": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1330"
            ],
            "ir": "pybuda",
            "name": "transpose_1329",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1328"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1329
        },
        "transpose_1334": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1335"
            ],
            "ir": "pybuda",
            "name": "transpose_1334",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1333"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1334
        },
        "transpose_1335": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1335",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1334"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1335
        },
        "transpose_1336": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1337"
            ],
            "ir": "pybuda",
            "name": "transpose_1336",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1212"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1336
        },
        "transpose_1337": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1337",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1336"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1337
        },
        "transpose_1338": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1339"
            ],
            "ir": "pybuda",
            "name": "transpose_1338",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1205"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1338
        },
        "transpose_1339": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1339",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1338"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1339
        },
        "transpose_1340": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1341"
            ],
            "ir": "pybuda",
            "name": "transpose_1340",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1200"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1340
        },
        "transpose_1341": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1341",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1340"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1341
        },
        "transpose_1342": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1343"
            ],
            "ir": "pybuda",
            "name": "transpose_1342",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1193"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1342
        },
        "transpose_1343": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1343",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1342"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1343
        },
        "transpose_1344": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1345"
            ],
            "ir": "pybuda",
            "name": "transpose_1344",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1187"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1344
        },
        "transpose_1346": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1347"
            ],
            "ir": "pybuda",
            "name": "transpose_1346",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1345"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1346
        },
        "transpose_1351": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1352"
            ],
            "ir": "pybuda",
            "name": "transpose_1351",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1350"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1351
        },
        "transpose_1352": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1352",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1351"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1352
        },
        "transpose_1355": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1356"
            ],
            "ir": "pybuda",
            "name": "transpose_1355",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1180"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1355
        },
        "transpose_1357": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1358"
            ],
            "ir": "pybuda",
            "name": "transpose_1357",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1356"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1357
        },
        "transpose_1358": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1359"
            ],
            "ir": "pybuda",
            "name": "transpose_1358",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1357"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1358
        },
        "transpose_1363": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1364"
            ],
            "ir": "pybuda",
            "name": "transpose_1363",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1362"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1363
        },
        "transpose_1364": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1364",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1363"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1364
        },
        "transpose_1365": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1366"
            ],
            "ir": "pybuda",
            "name": "transpose_1365",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1176"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1365
        },
        "transpose_1366": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1366",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1365"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1366
        },
        "transpose_1367": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1368"
            ],
            "ir": "pybuda",
            "name": "transpose_1367",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1169"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1367
        },
        "transpose_1368": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1368",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1367"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1368
        },
        "transpose_1369": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1370"
            ],
            "ir": "pybuda",
            "name": "transpose_1369",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1164"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1369
        },
        "transpose_1370": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1370",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1369"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1370
        },
        "transpose_1371": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1372"
            ],
            "ir": "pybuda",
            "name": "transpose_1371",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1157"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1371
        },
        "transpose_1372": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1372",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1371"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1372
        },
        "transpose_1373": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1374"
            ],
            "ir": "pybuda",
            "name": "transpose_1373",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1151"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1373
        },
        "transpose_1375": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1376"
            ],
            "ir": "pybuda",
            "name": "transpose_1375",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1374"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1375
        },
        "transpose_1380": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1381"
            ],
            "ir": "pybuda",
            "name": "transpose_1380",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1379"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1380
        },
        "transpose_1381": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1381",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1380"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1381
        },
        "transpose_1384": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1385"
            ],
            "ir": "pybuda",
            "name": "transpose_1384",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1144"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1384
        },
        "transpose_1386": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1387"
            ],
            "ir": "pybuda",
            "name": "transpose_1386",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1385"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1386
        },
        "transpose_1387": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1388"
            ],
            "ir": "pybuda",
            "name": "transpose_1387",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1386"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1387
        },
        "transpose_1392": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1393"
            ],
            "ir": "pybuda",
            "name": "transpose_1392",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1391"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1392
        },
        "transpose_1393": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1393",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1392"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1393
        },
        "transpose_1394": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1395"
            ],
            "ir": "pybuda",
            "name": "transpose_1394",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1140"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1394
        },
        "transpose_1395": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1395",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1394"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1395
        },
        "transpose_1396": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1397"
            ],
            "ir": "pybuda",
            "name": "transpose_1396",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1133"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1396
        },
        "transpose_1397": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1397",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1396"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1397
        },
        "transpose_1398": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1399"
            ],
            "ir": "pybuda",
            "name": "transpose_1398",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1128"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1398
        },
        "transpose_1399": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1399",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1398"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1399
        },
        "transpose_1400": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1401"
            ],
            "ir": "pybuda",
            "name": "transpose_1400",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1121"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1400
        },
        "transpose_1401": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1401",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1400"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1401
        },
        "transpose_1402": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1403"
            ],
            "ir": "pybuda",
            "name": "transpose_1402",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1115"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1402
        },
        "transpose_1404": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1405"
            ],
            "ir": "pybuda",
            "name": "transpose_1404",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1403"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1404
        },
        "transpose_1409": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1410"
            ],
            "ir": "pybuda",
            "name": "transpose_1409",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1408"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1409
        },
        "transpose_1410": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1410",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1409"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1410
        },
        "transpose_1413": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1414"
            ],
            "ir": "pybuda",
            "name": "transpose_1413",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1108"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1413
        },
        "transpose_1415": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1416"
            ],
            "ir": "pybuda",
            "name": "transpose_1415",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1415
        },
        "transpose_1416": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1417"
            ],
            "ir": "pybuda",
            "name": "transpose_1416",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1416
        },
        "transpose_1421": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1422"
            ],
            "ir": "pybuda",
            "name": "transpose_1421",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1420"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1421
        },
        "transpose_1422": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1422",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1421"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1422
        },
        "transpose_1423": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1424"
            ],
            "ir": "pybuda",
            "name": "transpose_1423",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1104"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1423
        },
        "transpose_1424": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1424",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1423"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1424
        },
        "transpose_1425": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1426"
            ],
            "ir": "pybuda",
            "name": "transpose_1425",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1097"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1425
        },
        "transpose_1426": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1426",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1425"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1426
        },
        "transpose_1427": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1428"
            ],
            "ir": "pybuda",
            "name": "transpose_1427",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1092"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1427
        },
        "transpose_1428": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1428",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1427"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1428
        },
        "transpose_1429": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1430"
            ],
            "ir": "pybuda",
            "name": "transpose_1429",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1085"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1429
        },
        "transpose_1430": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1430",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1429"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1430
        },
        "transpose_1431": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1432"
            ],
            "ir": "pybuda",
            "name": "transpose_1431",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1079"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1431
        },
        "transpose_1433": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1434"
            ],
            "ir": "pybuda",
            "name": "transpose_1433",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1433
        },
        "transpose_1438": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1439"
            ],
            "ir": "pybuda",
            "name": "transpose_1438",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1437"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1438
        },
        "transpose_1439": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1439",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1438"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1439
        },
        "transpose_1442": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1443"
            ],
            "ir": "pybuda",
            "name": "transpose_1442",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1072"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1442
        },
        "transpose_1444": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1445"
            ],
            "ir": "pybuda",
            "name": "transpose_1444",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1444
        },
        "transpose_1445": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1446"
            ],
            "ir": "pybuda",
            "name": "transpose_1445",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1445
        },
        "transpose_1450": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1451"
            ],
            "ir": "pybuda",
            "name": "transpose_1450",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1449"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1450
        },
        "transpose_1451": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1451",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1450"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1451
        },
        "transpose_1452": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1453"
            ],
            "ir": "pybuda",
            "name": "transpose_1452",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1068"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1452
        },
        "transpose_1453": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1453",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1452"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1453
        },
        "transpose_1454": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1455"
            ],
            "ir": "pybuda",
            "name": "transpose_1454",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1061"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1454
        },
        "transpose_1455": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1455",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1454"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1455
        },
        "transpose_1456": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1457"
            ],
            "ir": "pybuda",
            "name": "transpose_1456",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1056"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1456
        },
        "transpose_1457": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1457",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1456"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1457
        },
        "transpose_1458": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1459"
            ],
            "ir": "pybuda",
            "name": "transpose_1458",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1049"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1458
        },
        "transpose_1459": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1459",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1458"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1459
        },
        "transpose_1460": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1461"
            ],
            "ir": "pybuda",
            "name": "transpose_1460",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1043"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1460
        },
        "transpose_1462": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1463"
            ],
            "ir": "pybuda",
            "name": "transpose_1462",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1462
        },
        "transpose_1467": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1468"
            ],
            "ir": "pybuda",
            "name": "transpose_1467",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1466"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1467
        },
        "transpose_1468": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1468",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1467"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1468
        },
        "transpose_1471": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1472"
            ],
            "ir": "pybuda",
            "name": "transpose_1471",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1036"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1471
        },
        "transpose_1473": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1474"
            ],
            "ir": "pybuda",
            "name": "transpose_1473",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1472"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1473
        },
        "transpose_1474": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1475"
            ],
            "ir": "pybuda",
            "name": "transpose_1474",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1473"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1474
        },
        "transpose_1479": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1480"
            ],
            "ir": "pybuda",
            "name": "transpose_1479",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1478"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1479
        },
        "transpose_1480": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1480",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1479"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1480
        },
        "transpose_1481": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1482"
            ],
            "ir": "pybuda",
            "name": "transpose_1481",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1032"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1481
        },
        "transpose_1482": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1482",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1481"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1482
        },
        "transpose_1483": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1484"
            ],
            "ir": "pybuda",
            "name": "transpose_1483",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1025"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1483
        },
        "transpose_1484": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1484",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1483"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1484
        },
        "transpose_1485": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1486"
            ],
            "ir": "pybuda",
            "name": "transpose_1485",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1020"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1485
        },
        "transpose_1486": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1486",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1485"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1486
        },
        "transpose_1487": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1488"
            ],
            "ir": "pybuda",
            "name": "transpose_1487",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1013"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1487
        },
        "transpose_1488": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1488",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1487"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1488
        },
        "transpose_1489": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1490"
            ],
            "ir": "pybuda",
            "name": "transpose_1489",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1007"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1489
        },
        "transpose_1491": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1492"
            ],
            "ir": "pybuda",
            "name": "transpose_1491",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1491
        },
        "transpose_1496": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1497"
            ],
            "ir": "pybuda",
            "name": "transpose_1496",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1495"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1496
        },
        "transpose_1497": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1497",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1496"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1497
        },
        "transpose_1500": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1501"
            ],
            "ir": "pybuda",
            "name": "transpose_1500",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1000"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1500
        },
        "transpose_1502": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1503"
            ],
            "ir": "pybuda",
            "name": "transpose_1502",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1502
        },
        "transpose_1503": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1504"
            ],
            "ir": "pybuda",
            "name": "transpose_1503",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1503
        },
        "transpose_1508": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1509"
            ],
            "ir": "pybuda",
            "name": "transpose_1508",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1507"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1508
        },
        "transpose_1509": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1509",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1508"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1509
        },
        "transpose_1510": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1511"
            ],
            "ir": "pybuda",
            "name": "transpose_1510",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_996"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1510
        },
        "transpose_1511": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1511",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1510"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1511
        },
        "transpose_1512": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1513"
            ],
            "ir": "pybuda",
            "name": "transpose_1512",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_989"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1512
        },
        "transpose_1513": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1513",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1512"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1513
        },
        "transpose_1514": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1515"
            ],
            "ir": "pybuda",
            "name": "transpose_1514",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_984"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1514
        },
        "transpose_1515": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1515",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1514"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1515
        },
        "transpose_1516": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1517"
            ],
            "ir": "pybuda",
            "name": "transpose_1516",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_977"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1516
        },
        "transpose_1517": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1517",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1516"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1517
        },
        "transpose_1518": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1519"
            ],
            "ir": "pybuda",
            "name": "transpose_1518",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_971"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1518
        },
        "transpose_1520": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1521"
            ],
            "ir": "pybuda",
            "name": "transpose_1520",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1520
        },
        "transpose_1525": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1526"
            ],
            "ir": "pybuda",
            "name": "transpose_1525",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1524"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1525
        },
        "transpose_1526": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1526",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1525"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1526
        },
        "transpose_1529": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1530"
            ],
            "ir": "pybuda",
            "name": "transpose_1529",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_964"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1529
        },
        "transpose_1531": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1532"
            ],
            "ir": "pybuda",
            "name": "transpose_1531",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1531
        },
        "transpose_1532": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1533"
            ],
            "ir": "pybuda",
            "name": "transpose_1532",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1532
        },
        "transpose_1537": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1538"
            ],
            "ir": "pybuda",
            "name": "transpose_1537",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1536"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1537
        },
        "transpose_1538": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1538",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1537"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1538
        },
        "transpose_1539": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1540"
            ],
            "ir": "pybuda",
            "name": "transpose_1539",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_960"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1539
        },
        "transpose_1540": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1540",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1539"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1540
        },
        "transpose_1541": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1542"
            ],
            "ir": "pybuda",
            "name": "transpose_1541",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_953"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1541
        },
        "transpose_1542": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1542",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1541"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1542
        },
        "transpose_1543": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1544"
            ],
            "ir": "pybuda",
            "name": "transpose_1543",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_948"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1543
        },
        "transpose_1544": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1544",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1543"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1544
        },
        "transpose_1545": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1546"
            ],
            "ir": "pybuda",
            "name": "transpose_1545",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_941"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1545
        },
        "transpose_1546": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1546",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1545"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1546
        },
        "transpose_1547": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1548"
            ],
            "ir": "pybuda",
            "name": "transpose_1547",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_935"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1547
        },
        "transpose_1549": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1550"
            ],
            "ir": "pybuda",
            "name": "transpose_1549",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1548"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1549
        },
        "transpose_1554": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1555"
            ],
            "ir": "pybuda",
            "name": "transpose_1554",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1553"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1554
        },
        "transpose_1555": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1555",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1554"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1555
        },
        "transpose_1558": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1559"
            ],
            "ir": "pybuda",
            "name": "transpose_1558",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_928"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1558
        },
        "transpose_1560": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1561"
            ],
            "ir": "pybuda",
            "name": "transpose_1560",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1559"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1560
        },
        "transpose_1561": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1562"
            ],
            "ir": "pybuda",
            "name": "transpose_1561",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1561
        },
        "transpose_1566": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1567"
            ],
            "ir": "pybuda",
            "name": "transpose_1566",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1565"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1566
        },
        "transpose_1567": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1567",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1566"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1567
        },
        "transpose_1568": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1569"
            ],
            "ir": "pybuda",
            "name": "transpose_1568",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_924"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1568
        },
        "transpose_1569": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1569",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1568"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1569
        },
        "transpose_1570": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1571"
            ],
            "ir": "pybuda",
            "name": "transpose_1570",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_917"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1570
        },
        "transpose_1571": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1571",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1570"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1571
        },
        "transpose_1572": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1573"
            ],
            "ir": "pybuda",
            "name": "transpose_1572",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_912"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1572
        },
        "transpose_1573": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1573",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1572"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1573
        },
        "transpose_1574": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1575"
            ],
            "ir": "pybuda",
            "name": "transpose_1574",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_905"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1574
        },
        "transpose_1575": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1575",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1574"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1575
        },
        "transpose_1576": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1577"
            ],
            "ir": "pybuda",
            "name": "transpose_1576",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_899"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1576
        },
        "transpose_1578": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1579"
            ],
            "ir": "pybuda",
            "name": "transpose_1578",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1577"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1578
        },
        "transpose_1583": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1584"
            ],
            "ir": "pybuda",
            "name": "transpose_1583",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1582"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1583
        },
        "transpose_1584": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1584",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1583"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1584
        },
        "transpose_1587": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1588"
            ],
            "ir": "pybuda",
            "name": "transpose_1587",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_892"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1587
        },
        "transpose_1589": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1590"
            ],
            "ir": "pybuda",
            "name": "transpose_1589",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1588"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1589
        },
        "transpose_1590": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1591"
            ],
            "ir": "pybuda",
            "name": "transpose_1590",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1590
        },
        "transpose_1595": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1596"
            ],
            "ir": "pybuda",
            "name": "transpose_1595",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1594"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1595
        },
        "transpose_1596": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1596",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1595"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1596
        },
        "transpose_1597": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1598"
            ],
            "ir": "pybuda",
            "name": "transpose_1597",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_888"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1597
        },
        "transpose_1598": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1598",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1597"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1598
        },
        "transpose_1599": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1600"
            ],
            "ir": "pybuda",
            "name": "transpose_1599",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_881"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1599
        },
        "transpose_1600": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1600",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1599"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1600
        },
        "transpose_1601": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1602"
            ],
            "ir": "pybuda",
            "name": "transpose_1601",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_876"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1601
        },
        "transpose_1602": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1602",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1601"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1602
        },
        "transpose_1603": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1604"
            ],
            "ir": "pybuda",
            "name": "transpose_1603",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_869"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1603
        },
        "transpose_1604": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1604",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1603"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1604
        },
        "transpose_1605": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1606"
            ],
            "ir": "pybuda",
            "name": "transpose_1605",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_863"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1605
        },
        "transpose_1607": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1608"
            ],
            "ir": "pybuda",
            "name": "transpose_1607",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1607
        },
        "transpose_1612": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1613"
            ],
            "ir": "pybuda",
            "name": "transpose_1612",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1611"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1612
        },
        "transpose_1613": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1613",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1612"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1613
        },
        "transpose_1616": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1617"
            ],
            "ir": "pybuda",
            "name": "transpose_1616",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_856"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1616
        },
        "transpose_1618": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1619"
            ],
            "ir": "pybuda",
            "name": "transpose_1618",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1618
        },
        "transpose_1619": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1620"
            ],
            "ir": "pybuda",
            "name": "transpose_1619",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1618"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1619
        },
        "transpose_1624": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1625"
            ],
            "ir": "pybuda",
            "name": "transpose_1624",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1623"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1624
        },
        "transpose_1625": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1625",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1624"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1625
        },
        "transpose_1626": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1627"
            ],
            "ir": "pybuda",
            "name": "transpose_1626",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_852"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1626
        },
        "transpose_1627": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1627",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1626"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1627
        },
        "transpose_1628": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1629"
            ],
            "ir": "pybuda",
            "name": "transpose_1628",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_845"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1628
        },
        "transpose_1629": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1629",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1628"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1629
        },
        "transpose_1630": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1631"
            ],
            "ir": "pybuda",
            "name": "transpose_1630",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_840"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1630
        },
        "transpose_1631": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1631",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1630"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1631
        },
        "transpose_1632": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1633"
            ],
            "ir": "pybuda",
            "name": "transpose_1632",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_833"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1632
        },
        "transpose_1633": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1633",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1632"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1633
        },
        "transpose_1634": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1635"
            ],
            "ir": "pybuda",
            "name": "transpose_1634",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_827"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1634
        },
        "transpose_1636": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1637"
            ],
            "ir": "pybuda",
            "name": "transpose_1636",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1636
        },
        "transpose_1641": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1642"
            ],
            "ir": "pybuda",
            "name": "transpose_1641",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1640"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1641
        },
        "transpose_1642": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1642",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1641"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1642
        },
        "transpose_1645": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1646"
            ],
            "ir": "pybuda",
            "name": "transpose_1645",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_820"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1645
        },
        "transpose_1647": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1648"
            ],
            "ir": "pybuda",
            "name": "transpose_1647",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1647
        },
        "transpose_1648": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1649"
            ],
            "ir": "pybuda",
            "name": "transpose_1648",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1648
        },
        "transpose_1653": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1654"
            ],
            "ir": "pybuda",
            "name": "transpose_1653",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1652"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1653
        },
        "transpose_1654": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1654",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1653"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1654
        },
        "transpose_1655": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1656"
            ],
            "ir": "pybuda",
            "name": "transpose_1655",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_816"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1655
        },
        "transpose_1656": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1656",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1655"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1656
        },
        "transpose_1657": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1658"
            ],
            "ir": "pybuda",
            "name": "transpose_1657",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_809"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1657
        },
        "transpose_1658": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1658",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1657"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1658
        },
        "transpose_1659": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1660"
            ],
            "ir": "pybuda",
            "name": "transpose_1659",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_804"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1659
        },
        "transpose_1660": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1660",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1659"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1660
        },
        "transpose_1661": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1662"
            ],
            "ir": "pybuda",
            "name": "transpose_1661",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_797"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1661
        },
        "transpose_1662": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1662",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1661"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1662
        },
        "transpose_1663": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1664"
            ],
            "ir": "pybuda",
            "name": "transpose_1663",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_791"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1663
        },
        "transpose_1665": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1666"
            ],
            "ir": "pybuda",
            "name": "transpose_1665",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1665
        },
        "transpose_1670": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1671"
            ],
            "ir": "pybuda",
            "name": "transpose_1670",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1669"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1670
        },
        "transpose_1671": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1671",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1670"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1671
        },
        "transpose_1674": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1675"
            ],
            "ir": "pybuda",
            "name": "transpose_1674",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_784"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1674
        },
        "transpose_1676": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1677"
            ],
            "ir": "pybuda",
            "name": "transpose_1676",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1676
        },
        "transpose_1677": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1678"
            ],
            "ir": "pybuda",
            "name": "transpose_1677",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1677
        },
        "transpose_1682": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1683"
            ],
            "ir": "pybuda",
            "name": "transpose_1682",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1681"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1682
        },
        "transpose_1683": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1683",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1682"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1683
        },
        "transpose_1684": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1685"
            ],
            "ir": "pybuda",
            "name": "transpose_1684",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_780"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1684
        },
        "transpose_1685": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1685",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1684"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1685
        },
        "transpose_1686": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1687"
            ],
            "ir": "pybuda",
            "name": "transpose_1686",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_773"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1686
        },
        "transpose_1687": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1687",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1686"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1687
        },
        "transpose_1688": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1689"
            ],
            "ir": "pybuda",
            "name": "transpose_1688",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_768"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1688
        },
        "transpose_1689": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1689",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1688"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1689
        },
        "transpose_1690": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1691"
            ],
            "ir": "pybuda",
            "name": "transpose_1690",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_761"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1690
        },
        "transpose_1691": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1691",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1690"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1691
        },
        "transpose_1692": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1693"
            ],
            "ir": "pybuda",
            "name": "transpose_1692",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_755"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1692
        },
        "transpose_1694": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1695"
            ],
            "ir": "pybuda",
            "name": "transpose_1694",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1693"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1694
        },
        "transpose_1699": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1700"
            ],
            "ir": "pybuda",
            "name": "transpose_1699",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1698"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1699
        },
        "transpose_1700": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1700",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1699"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1700
        },
        "transpose_1703": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1704"
            ],
            "ir": "pybuda",
            "name": "transpose_1703",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_748"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1703
        },
        "transpose_1705": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1706"
            ],
            "ir": "pybuda",
            "name": "transpose_1705",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1704"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1705
        },
        "transpose_1706": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1707"
            ],
            "ir": "pybuda",
            "name": "transpose_1706",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1705"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1706
        },
        "transpose_1711": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1712"
            ],
            "ir": "pybuda",
            "name": "transpose_1711",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1710"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1711
        },
        "transpose_1712": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1712",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1711"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1712
        },
        "transpose_1713": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1714"
            ],
            "ir": "pybuda",
            "name": "transpose_1713",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_744"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1713
        },
        "transpose_1714": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1714",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1713"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1714
        },
        "transpose_1715": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1716"
            ],
            "ir": "pybuda",
            "name": "transpose_1715",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_737"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1715
        },
        "transpose_1716": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1716",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1715"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1716
        },
        "transpose_1717": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1718"
            ],
            "ir": "pybuda",
            "name": "transpose_1717",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_732"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1717
        },
        "transpose_1718": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1718",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1717"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1718
        },
        "transpose_1719": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1720"
            ],
            "ir": "pybuda",
            "name": "transpose_1719",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_725"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1719
        },
        "transpose_1720": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1720",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1719"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1720
        },
        "transpose_1721": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1722"
            ],
            "ir": "pybuda",
            "name": "transpose_1721",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_719"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1721
        },
        "transpose_1723": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1724"
            ],
            "ir": "pybuda",
            "name": "transpose_1723",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1722"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1723
        },
        "transpose_1728": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1729"
            ],
            "ir": "pybuda",
            "name": "transpose_1728",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1727"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1728
        },
        "transpose_1729": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1729",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1728"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1729
        },
        "transpose_1732": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1733"
            ],
            "ir": "pybuda",
            "name": "transpose_1732",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_712"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1732
        },
        "transpose_1734": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1735"
            ],
            "ir": "pybuda",
            "name": "transpose_1734",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1734
        },
        "transpose_1735": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1736"
            ],
            "ir": "pybuda",
            "name": "transpose_1735",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1734"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1735
        },
        "transpose_1740": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1741"
            ],
            "ir": "pybuda",
            "name": "transpose_1740",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1739"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1740
        },
        "transpose_1741": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1741",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1740"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1741
        },
        "transpose_1742": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1743"
            ],
            "ir": "pybuda",
            "name": "transpose_1742",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_708"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1742
        },
        "transpose_1743": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1743",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1742"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1743
        },
        "transpose_1744": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1745"
            ],
            "ir": "pybuda",
            "name": "transpose_1744",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_701"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1744
        },
        "transpose_1745": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1745",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1744"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1745
        },
        "transpose_1746": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1747"
            ],
            "ir": "pybuda",
            "name": "transpose_1746",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_696"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1746
        },
        "transpose_1747": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1747",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1746"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1747
        },
        "transpose_1748": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1749"
            ],
            "ir": "pybuda",
            "name": "transpose_1748",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_689"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1748
        },
        "transpose_1749": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1749",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1748"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1749
        },
        "transpose_1750": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1751"
            ],
            "ir": "pybuda",
            "name": "transpose_1750",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_683"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1750
        },
        "transpose_1752": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1753"
            ],
            "ir": "pybuda",
            "name": "transpose_1752",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1752
        },
        "transpose_1757": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1758"
            ],
            "ir": "pybuda",
            "name": "transpose_1757",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1756"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1757
        },
        "transpose_1758": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1758",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1757"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1758
        },
        "transpose_1761": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1762"
            ],
            "ir": "pybuda",
            "name": "transpose_1761",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_676"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1761
        },
        "transpose_1763": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1764"
            ],
            "ir": "pybuda",
            "name": "transpose_1763",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1763
        },
        "transpose_1764": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1765"
            ],
            "ir": "pybuda",
            "name": "transpose_1764",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1764
        },
        "transpose_1769": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1770"
            ],
            "ir": "pybuda",
            "name": "transpose_1769",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1768"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1769
        },
        "transpose_1770": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1770",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1769"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1770
        },
        "transpose_1771": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1772"
            ],
            "ir": "pybuda",
            "name": "transpose_1771",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_672"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1771
        },
        "transpose_1772": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1772",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1771"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1772
        },
        "transpose_1773": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1774"
            ],
            "ir": "pybuda",
            "name": "transpose_1773",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_665"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1773
        },
        "transpose_1774": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1774",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1773"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1774
        },
        "transpose_1775": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1776"
            ],
            "ir": "pybuda",
            "name": "transpose_1775",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_660"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1775
        },
        "transpose_1776": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1776",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1775"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1776
        },
        "transpose_1777": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1778"
            ],
            "ir": "pybuda",
            "name": "transpose_1777",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_653"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1777
        },
        "transpose_1778": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1778",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1777"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1778
        },
        "transpose_1779": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1780"
            ],
            "ir": "pybuda",
            "name": "transpose_1779",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_647"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1779
        },
        "transpose_1781": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1782"
            ],
            "ir": "pybuda",
            "name": "transpose_1781",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1781
        },
        "transpose_1786": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1787"
            ],
            "ir": "pybuda",
            "name": "transpose_1786",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1785"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1786
        },
        "transpose_1787": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1787",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1786"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1787
        },
        "transpose_1790": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1791"
            ],
            "ir": "pybuda",
            "name": "transpose_1790",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_640"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1790
        },
        "transpose_1792": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1793"
            ],
            "ir": "pybuda",
            "name": "transpose_1792",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1792
        },
        "transpose_1793": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1794"
            ],
            "ir": "pybuda",
            "name": "transpose_1793",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1792"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1793
        },
        "transpose_1798": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1799"
            ],
            "ir": "pybuda",
            "name": "transpose_1798",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1797"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1798
        },
        "transpose_1799": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1799",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1798"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1799
        },
        "transpose_1800": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1801"
            ],
            "ir": "pybuda",
            "name": "transpose_1800",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_636"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1800
        },
        "transpose_1801": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1801",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1800"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1801
        },
        "transpose_1802": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1803"
            ],
            "ir": "pybuda",
            "name": "transpose_1802",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_629"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1802
        },
        "transpose_1803": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1803",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1802"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1803
        },
        "transpose_1804": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1805"
            ],
            "ir": "pybuda",
            "name": "transpose_1804",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_624"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1804
        },
        "transpose_1805": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1805",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1804"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1805
        },
        "transpose_1806": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1807"
            ],
            "ir": "pybuda",
            "name": "transpose_1806",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_617"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1806
        },
        "transpose_1807": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1807",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1806"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1807
        },
        "transpose_1808": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1809"
            ],
            "ir": "pybuda",
            "name": "transpose_1808",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_611"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1808
        },
        "transpose_1810": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1811"
            ],
            "ir": "pybuda",
            "name": "transpose_1810",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1810
        },
        "transpose_1815": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1816"
            ],
            "ir": "pybuda",
            "name": "transpose_1815",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1814"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1815
        },
        "transpose_1816": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1816",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1815"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1816
        },
        "transpose_1819": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1820"
            ],
            "ir": "pybuda",
            "name": "transpose_1819",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_604"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1819
        },
        "transpose_1821": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1822"
            ],
            "ir": "pybuda",
            "name": "transpose_1821",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1820"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1821
        },
        "transpose_1822": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1823"
            ],
            "ir": "pybuda",
            "name": "transpose_1822",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1821"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1822
        },
        "transpose_1827": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1828"
            ],
            "ir": "pybuda",
            "name": "transpose_1827",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1826"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1827
        },
        "transpose_1828": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1828",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1827"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1828
        },
        "transpose_1829": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1830"
            ],
            "ir": "pybuda",
            "name": "transpose_1829",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_600"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1829
        },
        "transpose_1830": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1830",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1829"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1830
        },
        "transpose_1831": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1832"
            ],
            "ir": "pybuda",
            "name": "transpose_1831",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_593"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1831
        },
        "transpose_1832": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1832",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1831"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1832
        },
        "transpose_1833": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1834"
            ],
            "ir": "pybuda",
            "name": "transpose_1833",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_588"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1833
        },
        "transpose_1834": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1834",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1833"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1834
        },
        "transpose_1835": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1836"
            ],
            "ir": "pybuda",
            "name": "transpose_1835",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_581"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1835
        },
        "transpose_1836": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1836",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1835"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1836
        },
        "transpose_1837": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1838"
            ],
            "ir": "pybuda",
            "name": "transpose_1837",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_575"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1837
        },
        "transpose_1839": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1840"
            ],
            "ir": "pybuda",
            "name": "transpose_1839",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1839
        },
        "transpose_1844": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1845"
            ],
            "ir": "pybuda",
            "name": "transpose_1844",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1843"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1844
        },
        "transpose_1845": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1845",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1844"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1845
        },
        "transpose_1848": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1849"
            ],
            "ir": "pybuda",
            "name": "transpose_1848",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_568"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1848
        },
        "transpose_1850": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1851"
            ],
            "ir": "pybuda",
            "name": "transpose_1850",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1850
        },
        "transpose_1851": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1852"
            ],
            "ir": "pybuda",
            "name": "transpose_1851",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1851
        },
        "transpose_1856": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1857"
            ],
            "ir": "pybuda",
            "name": "transpose_1856",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1855"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1856
        },
        "transpose_1857": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1857",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1856"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1857
        },
        "transpose_1858": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1859"
            ],
            "ir": "pybuda",
            "name": "transpose_1858",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_564"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1858
        },
        "transpose_1859": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1859",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1858"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1859
        },
        "transpose_1860": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1861"
            ],
            "ir": "pybuda",
            "name": "transpose_1860",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_557"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1860
        },
        "transpose_1861": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1861",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1860"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1861
        },
        "transpose_1862": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1863"
            ],
            "ir": "pybuda",
            "name": "transpose_1862",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_552"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1862
        },
        "transpose_1863": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1863",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1862"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1863
        },
        "transpose_1864": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1865"
            ],
            "ir": "pybuda",
            "name": "transpose_1864",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_545"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1864
        },
        "transpose_1865": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1865",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1864"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1865
        },
        "transpose_1866": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1867"
            ],
            "ir": "pybuda",
            "name": "transpose_1866",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_539"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1866
        },
        "transpose_1868": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1869"
            ],
            "ir": "pybuda",
            "name": "transpose_1868",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1868
        },
        "transpose_1873": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1874"
            ],
            "ir": "pybuda",
            "name": "transpose_1873",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1872"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1873
        },
        "transpose_1874": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1874",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1873"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1874
        },
        "transpose_1877": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1878"
            ],
            "ir": "pybuda",
            "name": "transpose_1877",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_532"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1877
        },
        "transpose_1879": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1880"
            ],
            "ir": "pybuda",
            "name": "transpose_1879",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1878"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1879
        },
        "transpose_1880": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1881"
            ],
            "ir": "pybuda",
            "name": "transpose_1880",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1880
        },
        "transpose_1885": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1886"
            ],
            "ir": "pybuda",
            "name": "transpose_1885",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1884"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1885
        },
        "transpose_1886": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1886",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1885"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1886
        },
        "transpose_1887": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1888"
            ],
            "ir": "pybuda",
            "name": "transpose_1887",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_528"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1887
        },
        "transpose_1888": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1888",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1887"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1888
        },
        "transpose_1889": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1890"
            ],
            "ir": "pybuda",
            "name": "transpose_1889",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_521"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1889
        },
        "transpose_1890": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1890",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1889"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1890
        },
        "transpose_1891": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1892"
            ],
            "ir": "pybuda",
            "name": "transpose_1891",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_516"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1891
        },
        "transpose_1892": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1892",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1891"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1892
        },
        "transpose_1893": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1894"
            ],
            "ir": "pybuda",
            "name": "transpose_1893",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_509"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1893
        },
        "transpose_1894": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1894",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1893"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1894
        },
        "transpose_1895": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1896"
            ],
            "ir": "pybuda",
            "name": "transpose_1895",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_503"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1895
        },
        "transpose_1897": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1898"
            ],
            "ir": "pybuda",
            "name": "transpose_1897",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1896"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1897
        },
        "transpose_1902": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1903"
            ],
            "ir": "pybuda",
            "name": "transpose_1902",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1901"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1902
        },
        "transpose_1903": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1903",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1902"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1903
        },
        "transpose_1906": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1907"
            ],
            "ir": "pybuda",
            "name": "transpose_1906",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_496"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1906
        },
        "transpose_1908": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1909"
            ],
            "ir": "pybuda",
            "name": "transpose_1908",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1907"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1908
        },
        "transpose_1909": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1910"
            ],
            "ir": "pybuda",
            "name": "transpose_1909",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1908"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1909
        },
        "transpose_1914": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1915"
            ],
            "ir": "pybuda",
            "name": "transpose_1914",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1913"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1914
        },
        "transpose_1915": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1915",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1914"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1915
        },
        "transpose_1916": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1917"
            ],
            "ir": "pybuda",
            "name": "transpose_1916",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_492"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1916
        },
        "transpose_1917": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1917",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1916"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1917
        },
        "transpose_1918": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1919"
            ],
            "ir": "pybuda",
            "name": "transpose_1918",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_485"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1918
        },
        "transpose_1919": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1919",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1918"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1919
        },
        "transpose_1920": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1921"
            ],
            "ir": "pybuda",
            "name": "transpose_1920",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_480"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1920
        },
        "transpose_1921": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1921",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1920"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1921
        },
        "transpose_1922": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1923"
            ],
            "ir": "pybuda",
            "name": "transpose_1922",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_473"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1922
        },
        "transpose_1923": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1923",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1922"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1923
        },
        "transpose_1924": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1925"
            ],
            "ir": "pybuda",
            "name": "transpose_1924",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_467"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1924
        },
        "transpose_1926": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1927"
            ],
            "ir": "pybuda",
            "name": "transpose_1926",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1926
        },
        "transpose_1931": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1932"
            ],
            "ir": "pybuda",
            "name": "transpose_1931",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1930"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1931
        },
        "transpose_1932": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1932",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1931"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1932
        },
        "transpose_1935": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1936"
            ],
            "ir": "pybuda",
            "name": "transpose_1935",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_460"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1935
        },
        "transpose_1937": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1938"
            ],
            "ir": "pybuda",
            "name": "transpose_1937",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1936"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1937
        },
        "transpose_1938": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1939"
            ],
            "ir": "pybuda",
            "name": "transpose_1938",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1938
        },
        "transpose_1943": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1944"
            ],
            "ir": "pybuda",
            "name": "transpose_1943",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1942"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1943
        },
        "transpose_1944": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1944",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1943"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1944
        },
        "transpose_1945": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1946"
            ],
            "ir": "pybuda",
            "name": "transpose_1945",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_456"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1945
        },
        "transpose_1946": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1946",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1945"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1946
        },
        "transpose_1947": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1948"
            ],
            "ir": "pybuda",
            "name": "transpose_1947",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_449"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1947
        },
        "transpose_1948": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1948",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1947"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1948
        },
        "transpose_1949": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1950"
            ],
            "ir": "pybuda",
            "name": "transpose_1949",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_444"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1949
        },
        "transpose_1950": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1950",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1949"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1950
        },
        "transpose_1951": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1952"
            ],
            "ir": "pybuda",
            "name": "transpose_1951",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_437"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1951
        },
        "transpose_1952": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1952",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1951"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1952
        },
        "transpose_1953": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1954"
            ],
            "ir": "pybuda",
            "name": "transpose_1953",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_431"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1953
        },
        "transpose_1955": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1956"
            ],
            "ir": "pybuda",
            "name": "transpose_1955",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1954"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1955
        },
        "transpose_1960": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1961"
            ],
            "ir": "pybuda",
            "name": "transpose_1960",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1959"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1960
        },
        "transpose_1961": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1961",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1960"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1961
        },
        "transpose_1964": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1965"
            ],
            "ir": "pybuda",
            "name": "transpose_1964",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_424"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1964
        },
        "transpose_1966": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1967"
            ],
            "ir": "pybuda",
            "name": "transpose_1966",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1965"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1966
        },
        "transpose_1967": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1968"
            ],
            "ir": "pybuda",
            "name": "transpose_1967",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1966"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1967
        },
        "transpose_1972": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1973"
            ],
            "ir": "pybuda",
            "name": "transpose_1972",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1971"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1972
        },
        "transpose_1973": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1973",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1972"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1973
        },
        "transpose_1974": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1975"
            ],
            "ir": "pybuda",
            "name": "transpose_1974",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_420"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1974
        },
        "transpose_1975": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1975",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1974"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1975
        },
        "transpose_1976": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1977"
            ],
            "ir": "pybuda",
            "name": "transpose_1976",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_413"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1976
        },
        "transpose_1977": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1977",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1976"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1977
        },
        "transpose_1978": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1979"
            ],
            "ir": "pybuda",
            "name": "transpose_1978",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_408"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1978
        },
        "transpose_1979": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1979",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1978"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1979
        },
        "transpose_1980": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1981"
            ],
            "ir": "pybuda",
            "name": "transpose_1980",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_401"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1980
        },
        "transpose_1981": {
            "cache": {
                "shape": [
                    1024,
                    1
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_1982"
            ],
            "ir": "pybuda",
            "name": "transpose_1981",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1980"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1981
        },
        "transpose_1987": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1988"
            ],
            "ir": "pybuda",
            "name": "transpose_1987",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1986"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1987
        },
        "transpose_1988": {
            "cache": {
                "shape": [
                    1024,
                    1
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_1989"
            ],
            "ir": "pybuda",
            "name": "transpose_1988",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1987"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1988
        },
        "transpose_422": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_423"
            ],
            "ir": "pybuda",
            "name": "transpose_422",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 422
        },
        "transpose_433": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_434"
            ],
            "ir": "pybuda",
            "name": "transpose_433",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 433
        },
        "transpose_458": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_459"
            ],
            "ir": "pybuda",
            "name": "transpose_458",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_457"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 458
        },
        "transpose_469": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_470"
            ],
            "ir": "pybuda",
            "name": "transpose_469",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 469
        },
        "transpose_494": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_495"
            ],
            "ir": "pybuda",
            "name": "transpose_494",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 494
        },
        "transpose_505": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_506"
            ],
            "ir": "pybuda",
            "name": "transpose_505",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_504"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 505
        },
        "transpose_530": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_531"
            ],
            "ir": "pybuda",
            "name": "transpose_530",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 530
        },
        "transpose_541": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_542"
            ],
            "ir": "pybuda",
            "name": "transpose_541",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 541
        },
        "transpose_566": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_567"
            ],
            "ir": "pybuda",
            "name": "transpose_566",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 566
        },
        "transpose_577": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_578"
            ],
            "ir": "pybuda",
            "name": "transpose_577",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 577
        },
        "transpose_602": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_603"
            ],
            "ir": "pybuda",
            "name": "transpose_602",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 602
        },
        "transpose_613": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_614"
            ],
            "ir": "pybuda",
            "name": "transpose_613",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 613
        },
        "transpose_638": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_639"
            ],
            "ir": "pybuda",
            "name": "transpose_638",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_637"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 638
        },
        "transpose_649": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_650"
            ],
            "ir": "pybuda",
            "name": "transpose_649",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 649
        },
        "transpose_674": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_675"
            ],
            "ir": "pybuda",
            "name": "transpose_674",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_673"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 674
        },
        "transpose_685": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_686"
            ],
            "ir": "pybuda",
            "name": "transpose_685",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 685
        },
        "transpose_710": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_711"
            ],
            "ir": "pybuda",
            "name": "transpose_710",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 710
        },
        "transpose_721": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_722"
            ],
            "ir": "pybuda",
            "name": "transpose_721",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 721
        },
        "transpose_746": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_747"
            ],
            "ir": "pybuda",
            "name": "transpose_746",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_745"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 746
        },
        "transpose_757": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_758"
            ],
            "ir": "pybuda",
            "name": "transpose_757",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 757
        },
        "transpose_782": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_783"
            ],
            "ir": "pybuda",
            "name": "transpose_782",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_781"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 782
        },
        "transpose_793": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_794"
            ],
            "ir": "pybuda",
            "name": "transpose_793",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_792"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 793
        },
        "transpose_818": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_819"
            ],
            "ir": "pybuda",
            "name": "transpose_818",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_817"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 818
        },
        "transpose_829": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_830"
            ],
            "ir": "pybuda",
            "name": "transpose_829",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_828"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 829
        },
        "transpose_854": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_855"
            ],
            "ir": "pybuda",
            "name": "transpose_854",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_853"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 854
        },
        "transpose_865": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_866"
            ],
            "ir": "pybuda",
            "name": "transpose_865",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_864"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 865
        },
        "transpose_890": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_891"
            ],
            "ir": "pybuda",
            "name": "transpose_890",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_889"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 890
        },
        "transpose_901": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_902"
            ],
            "ir": "pybuda",
            "name": "transpose_901",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 901
        },
        "transpose_926": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_927"
            ],
            "ir": "pybuda",
            "name": "transpose_926",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 926
        },
        "transpose_937": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_938"
            ],
            "ir": "pybuda",
            "name": "transpose_937",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_936"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 937
        },
        "transpose_962": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_963"
            ],
            "ir": "pybuda",
            "name": "transpose_962",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_961"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 962
        },
        "transpose_973": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_974"
            ],
            "ir": "pybuda",
            "name": "transpose_973",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_972"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 973
        },
        "transpose_998": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_999"
            ],
            "ir": "pybuda",
            "name": "transpose_998",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_997"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 998
        },
        "tuple_395": {
            "cache": {
                "shape": [
                    [
                        "1",
                        "384"
                    ],
                    [
                        "1",
                        "384"
                    ]
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "reshape_396",
                "reshape_1991"
            ],
            "ir": "pybuda",
            "name": "tuple_395",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 395
        },
        "tuple_397": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "reshape_1984",
                "reshape_399",
                "reshape_1984"
            ],
            "ir": "pybuda",
            "name": "tuple_397",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_396",
                "reshape_1991"
            ],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 397
        },
        "tuple_398": {
            "cache": {
                "shape": [
                    [
                        "1",
                        "384",
                        "1"
                    ],
                    [
                        "1",
                        "384",
                        "1"
                    ]
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "reshape_1984"
            ],
            "ir": "pybuda",
            "name": "tuple_398",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 398
        }
    }
}