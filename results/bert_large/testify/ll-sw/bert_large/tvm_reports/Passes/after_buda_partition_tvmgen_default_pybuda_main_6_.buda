{
    "graph": {},
    "nodes": {
        "FunctionVar_0_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_0_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_404",
                "transpose_437",
                "nn.dense_2723"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2721
        },
        "FunctionVar_0_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_0_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2722
        },
        "FunctionVar_100_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_100_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1424"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1422
        },
        "FunctionVar_100_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_100_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1425"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1423
        },
        "FunctionVar_101_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_101_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_2022",
                "nn.dense_2164"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2162
        },
        "FunctionVar_101_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_101_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2165"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2163
        },
        "FunctionVar_102_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_102_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2148"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2146
        },
        "FunctionVar_102_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_102_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2149"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2147
        },
        "FunctionVar_103_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_103_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1451",
                "reshape_2006"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2004
        },
        "FunctionVar_103_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_103_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1452"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1450
        },
        "FunctionVar_104_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_104_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1464",
                "reshape_1693"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1691
        },
        "FunctionVar_104_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_104_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1465"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1463
        },
        "FunctionVar_105_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_105_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1473"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1471
        },
        "FunctionVar_105_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_105_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1474"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1472
        },
        "FunctionVar_106_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_106_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1486",
                "reshape_1988"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1986
        },
        "FunctionVar_106_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_106_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1487"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1485
        },
        "FunctionVar_107_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_107_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2130"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2128
        },
        "FunctionVar_107_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_107_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2131"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2129
        },
        "FunctionVar_108_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_108_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1972",
                "nn.dense_2114"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2112
        },
        "FunctionVar_108_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_108_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2115"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2113
        },
        "FunctionVar_109_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_109_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1513",
                "reshape_1755"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1753
        },
        "FunctionVar_109_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_109_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1514"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1512
        },
        "FunctionVar_10_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_10_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_494",
                "nn.dropout_612"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 611
        },
        "FunctionVar_10_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_10_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_495"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 493
        },
        "FunctionVar_110_0": {
            "cache": {
                "shape": [
                    "384",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_110_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1526"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1524
        },
        "FunctionVar_110_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_110_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1527"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1525
        },
        "FunctionVar_111_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_111_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1535",
                "reshape_1954"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1952
        },
        "FunctionVar_111_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_111_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1536"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1534
        },
        "FunctionVar_112_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_112_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1548"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1546
        },
        "FunctionVar_112_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_112_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1549"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1547
        },
        "FunctionVar_113_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_113_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1938",
                "nn.dense_2096"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2094
        },
        "FunctionVar_113_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_113_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2097"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2095
        },
        "FunctionVar_114_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_114_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1817",
                "nn.dense_2080"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2078
        },
        "FunctionVar_114_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_114_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2081"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2079
        },
        "FunctionVar_115_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_115_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1575"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1573
        },
        "FunctionVar_115_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_115_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1576"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1574
        },
        "FunctionVar_116_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_116_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1588",
                "reshape_1920"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1918
        },
        "FunctionVar_116_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_116_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1589"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1587
        },
        "FunctionVar_117_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_117_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1597"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1595
        },
        "FunctionVar_117_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_117_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1598"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1596
        },
        "FunctionVar_118_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_118_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1610",
                "reshape_1898"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1896
        },
        "FunctionVar_118_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_118_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1611"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1609
        },
        "FunctionVar_119_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_119_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1879",
                "nn.dense_2062"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2060
        },
        "FunctionVar_119_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_119_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2063"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2061
        },
        "FunctionVar_11_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_11_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_629",
                "reshape_2634",
                "nn.dense_2674"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2672
        },
        "FunctionVar_11_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_11_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2675"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2673
        },
        "FunctionVar_120_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_120_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2046"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2044
        },
        "FunctionVar_120_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_120_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2047"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2045
        },
        "FunctionVar_121_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_121_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1637"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1635
        },
        "FunctionVar_121_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_121_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1638"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1636
        },
        "FunctionVar_122_0": {
            "cache": {
                "shape": [
                    "384",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_122_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1650"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1648
        },
        "FunctionVar_122_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_122_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1651"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1649
        },
        "FunctionVar_123_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_123_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1659"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1657
        },
        "FunctionVar_123_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_123_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1660"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1658
        },
        "FunctionVar_124_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_124_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1672"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1670
        },
        "FunctionVar_124_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_124_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1673"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1671
        },
        "FunctionVar_125_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_125_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2028"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2026
        },
        "FunctionVar_125_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_125_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2029"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2027
        },
        "FunctionVar_126_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_126_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2012"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2010
        },
        "FunctionVar_126_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_126_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2013"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2011
        },
        "FunctionVar_127_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_127_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1699"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1697
        },
        "FunctionVar_127_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_127_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1700"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1698
        },
        "FunctionVar_128_0": {
            "cache": {
                "shape": [
                    "384",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_128_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1712"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1710
        },
        "FunctionVar_128_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_128_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1713"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1711
        },
        "FunctionVar_129_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_129_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1721"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1719
        },
        "FunctionVar_129_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_129_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1722"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1720
        },
        "FunctionVar_12_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_12_0",
            "opcode": "Input",
            "output_nodes": [
                "transpose_623",
                "nn.dropout_652",
                "nn.dense_2658"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2656
        },
        "FunctionVar_12_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_12_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2659"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2657
        },
        "FunctionVar_130_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_130_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1734"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1732
        },
        "FunctionVar_130_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_130_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1735"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1733
        },
        "FunctionVar_131_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_131_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1994"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1992
        },
        "FunctionVar_131_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_131_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1995"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1993
        },
        "FunctionVar_132_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_132_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1978"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1976
        },
        "FunctionVar_132_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_132_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1979"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1977
        },
        "FunctionVar_133_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_133_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1761"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1759
        },
        "FunctionVar_133_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_133_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1762"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1760
        },
        "FunctionVar_134_0": {
            "cache": {
                "shape": [
                    "384",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_134_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1774"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1772
        },
        "FunctionVar_134_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_134_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1775"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1773
        },
        "FunctionVar_135_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_135_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1783"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1781
        },
        "FunctionVar_135_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_135_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1784"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1782
        },
        "FunctionVar_136_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_136_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1796"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1794
        },
        "FunctionVar_136_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_136_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1797"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1795
        },
        "FunctionVar_137_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_137_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1960"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1958
        },
        "FunctionVar_137_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_137_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1961"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1959
        },
        "FunctionVar_138_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_138_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1944"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1942
        },
        "FunctionVar_138_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_138_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1945"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1943
        },
        "FunctionVar_139_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_139_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1823"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1821
        },
        "FunctionVar_139_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_139_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1824"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1822
        },
        "FunctionVar_13_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_13_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_521",
                "nn.dropout_674",
                "reshape_2618"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2616
        },
        "FunctionVar_13_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_13_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 520
        },
        "FunctionVar_140_0": {
            "cache": {
                "shape": [
                    "384",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_140_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1836"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1834
        },
        "FunctionVar_140_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_140_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1837"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1835
        },
        "FunctionVar_141_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_141_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1845"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1843
        },
        "FunctionVar_141_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_141_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1844
        },
        "FunctionVar_142_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_142_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1858"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1856
        },
        "FunctionVar_142_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_142_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1859"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1857
        },
        "FunctionVar_143_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_143_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1926"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1924
        },
        "FunctionVar_143_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_143_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1927"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1925
        },
        "FunctionVar_144_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_144_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1904"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1902
        },
        "FunctionVar_144_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_144_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1905"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1903
        },
        "FunctionVar_145_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_145_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1885"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1883
        },
        "FunctionVar_145_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_145_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1886"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1884
        },
        "FunctionVar_14_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_14_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_534",
                "reshape_577",
                "nn.dropout_691"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 690
        },
        "FunctionVar_14_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_14_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_535"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 533
        },
        "FunctionVar_15_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_15_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_543",
                "nn.dropout_714"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 713
        },
        "FunctionVar_15_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_15_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_544"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 542
        },
        "FunctionVar_16_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_16_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_556",
                "transpose_685",
                "nn.dropout_736",
                "reshape_2600"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2598
        },
        "FunctionVar_16_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_16_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_557"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 555
        },
        "FunctionVar_17_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_17_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_753",
                "nn.dense_2640"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2638
        },
        "FunctionVar_17_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_17_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2641"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2639
        },
        "FunctionVar_18_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_18_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_776",
                "reshape_2584",
                "nn.dense_2624"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2622
        },
        "FunctionVar_18_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_18_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2625"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2623
        },
        "FunctionVar_19_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_19_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_583",
                "reshape_639",
                "nn.dropout_798"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 797
        },
        "FunctionVar_19_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_19_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_584"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 582
        },
        "FunctionVar_1_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_1_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_397",
                "nn.dropout_426",
                "reshape_2702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2700
        },
        "FunctionVar_1_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_1_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_398"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 396
        },
        "FunctionVar_20_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_20_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_596",
                "transpose_747",
                "nn.dropout_815"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 814
        },
        "FunctionVar_20_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_20_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_597"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 595
        },
        "FunctionVar_21_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_21_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_605",
                "nn.dropout_838",
                "reshape_2566"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2564
        },
        "FunctionVar_21_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_21_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_606"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 604
        },
        "FunctionVar_22_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_22_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_618",
                "nn.dropout_860"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 859
        },
        "FunctionVar_22_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_22_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_619"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 617
        },
        "FunctionVar_23_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_23_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_877",
                "reshape_2550",
                "nn.dense_2606"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2604
        },
        "FunctionVar_23_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_23_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2607"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2605
        },
        "FunctionVar_24_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_24_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_701",
                "transpose_809",
                "nn.dropout_900",
                "nn.dense_2590"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2588
        },
        "FunctionVar_24_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_24_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2591"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2589
        },
        "FunctionVar_25_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_25_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_645",
                "nn.dropout_922"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 921
        },
        "FunctionVar_25_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_25_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_646"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 644
        },
        "FunctionVar_26_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_26_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_658",
                "nn.dropout_939",
                "reshape_2532"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2530
        },
        "FunctionVar_26_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_26_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_659"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 657
        },
        "FunctionVar_27_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_27_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_667",
                "nn.dropout_962"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 961
        },
        "FunctionVar_27_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_27_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_668"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 666
        },
        "FunctionVar_28_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_28_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_680",
                "transpose_871",
                "nn.dropout_984",
                "reshape_2516"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2514
        },
        "FunctionVar_28_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_28_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_681"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 679
        },
        "FunctionVar_29_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_29_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_763",
                "nn.dropout_1001",
                "nn.dense_2572"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2570
        },
        "FunctionVar_29_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_29_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2573"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2571
        },
        "FunctionVar_2_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_2_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_410",
                "nn.dropout_443"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 442
        },
        "FunctionVar_2_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_2_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_411"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 409
        },
        "FunctionVar_30_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_30_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1024",
                "nn.dense_2556"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2554
        },
        "FunctionVar_30_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_30_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2557"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2555
        },
        "FunctionVar_31_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_31_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_707",
                "nn.dropout_1046",
                "reshape_2498"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2496
        },
        "FunctionVar_31_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_31_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_708"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 706
        },
        "FunctionVar_32_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_32_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_720",
                "transpose_933",
                "nn.dropout_1063"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1062
        },
        "FunctionVar_32_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_32_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_721"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 719
        },
        "FunctionVar_33_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_33_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_729",
                "nn.dropout_1086",
                "reshape_2482"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2480
        },
        "FunctionVar_33_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_33_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_730"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 728
        },
        "FunctionVar_34_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_34_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_742",
                "reshape_825",
                "nn.dropout_1108"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1107
        },
        "FunctionVar_34_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_34_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_743"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 741
        },
        "FunctionVar_35_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_35_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1125",
                "nn.dense_2538"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2536
        },
        "FunctionVar_35_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_35_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2539"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2537
        },
        "FunctionVar_36_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_36_0",
            "opcode": "Input",
            "output_nodes": [
                "transpose_995",
                "nn.dropout_1148",
                "reshape_2464",
                "nn.dense_2522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2520
        },
        "FunctionVar_36_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_36_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2523"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2521
        },
        "FunctionVar_37_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_37_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_769",
                "nn.dropout_1170"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1169
        },
        "FunctionVar_37_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_37_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_770"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 768
        },
        "FunctionVar_38_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_38_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_782",
                "nn.dropout_1187",
                "reshape_2448"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2446
        },
        "FunctionVar_38_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_38_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_783"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 781
        },
        "FunctionVar_39_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_39_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_791",
                "reshape_887",
                "nn.dropout_1210"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1209
        },
        "FunctionVar_39_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_39_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_792"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 790
        },
        "FunctionVar_3_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_3_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_419",
                "nn.dropout_466",
                "reshape_2686"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2684
        },
        "FunctionVar_3_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_3_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_420"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 418
        },
        "FunctionVar_40_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_40_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_804",
                "transpose_1057",
                "nn.dropout_1232"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1231
        },
        "FunctionVar_40_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_40_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_805"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 803
        },
        "FunctionVar_41_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_41_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1249",
                "reshape_2430",
                "nn.dense_2504"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2502
        },
        "FunctionVar_41_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_41_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2505"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2503
        },
        "FunctionVar_42_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_42_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1272",
                "nn.dense_2488"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2486
        },
        "FunctionVar_42_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_42_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2489"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2487
        },
        "FunctionVar_43_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_43_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_831",
                "nn.dropout_1294",
                "reshape_2414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2412
        },
        "FunctionVar_43_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_43_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_832"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 830
        },
        "FunctionVar_44_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_44_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_844",
                "reshape_949",
                "transpose_1119",
                "nn.dropout_1311"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1310
        },
        "FunctionVar_44_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_44_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_845"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 843
        },
        "FunctionVar_45_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_45_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_853",
                "nn.dropout_1334"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1333
        },
        "FunctionVar_45_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_45_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_854"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 852
        },
        "FunctionVar_46_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_46_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_866",
                "nn.dropout_1356",
                "reshape_2396"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2394
        },
        "FunctionVar_46_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_46_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_867"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 865
        },
        "FunctionVar_47_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_47_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1373",
                "nn.dense_2470"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2468
        },
        "FunctionVar_47_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_47_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2471"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2469
        },
        "FunctionVar_48_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_48_0",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1181",
                "nn.dropout_1396",
                "reshape_2380",
                "nn.dense_2454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2452
        },
        "FunctionVar_48_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_48_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2455"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2453
        },
        "FunctionVar_49_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_49_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_893",
                "reshape_1011",
                "nn.dropout_1418"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1417
        },
        "FunctionVar_49_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_49_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_894"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 892
        },
        "FunctionVar_4_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "64"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_4_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_432",
                "reshape_453",
                "nn.dropout_488",
                "transpose_499"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 497
        },
        "FunctionVar_4_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_4_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_433"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 431
        },
        "FunctionVar_50_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_50_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_906",
                "nn.dropout_1435"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1434
        },
        "FunctionVar_50_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_50_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_907"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 905
        },
        "FunctionVar_51_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_51_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_915",
                "nn.dropout_1458",
                "reshape_2362"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2360
        },
        "FunctionVar_51_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_51_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_916"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 914
        },
        "FunctionVar_52_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_52_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_928",
                "transpose_1243",
                "nn.dropout_1480"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1479
        },
        "FunctionVar_52_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_52_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_929"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 927
        },
        "FunctionVar_53_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_53_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1497",
                "reshape_2346",
                "nn.dense_2436"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2434
        },
        "FunctionVar_53_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_53_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2437"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2435
        },
        "FunctionVar_54_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_54_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1073",
                "nn.dropout_1520",
                "nn.dense_2420"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2418
        },
        "FunctionVar_54_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_54_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2421"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2419
        },
        "FunctionVar_55_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_55_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_955",
                "nn.dropout_1542"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1541
        },
        "FunctionVar_55_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_55_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_956"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 954
        },
        "FunctionVar_56_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_56_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_968",
                "transpose_1305",
                "nn.dropout_1559",
                "reshape_2328"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2326
        },
        "FunctionVar_56_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_56_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_969"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 967
        },
        "FunctionVar_57_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_57_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_977",
                "nn.dropout_1582"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1581
        },
        "FunctionVar_57_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_57_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_978"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 976
        },
        "FunctionVar_58_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_58_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_990",
                "nn.dropout_1604",
                "reshape_2312"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2310
        },
        "FunctionVar_58_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_58_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_991"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 989
        },
        "FunctionVar_59_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_59_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1135",
                "nn.dropout_1621",
                "nn.dense_2402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2400
        },
        "FunctionVar_59_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_59_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2403"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2401
        },
        "FunctionVar_5_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_5_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_505",
                "nn.dense_2708"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2706
        },
        "FunctionVar_5_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_5_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2709"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2707
        },
        "FunctionVar_60_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_60_0",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1367",
                "nn.dropout_1644",
                "nn.dense_2386"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2384
        },
        "FunctionVar_60_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_60_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2387"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2385
        },
        "FunctionVar_61_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_61_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1017",
                "nn.dropout_1666",
                "reshape_2294"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2292
        },
        "FunctionVar_61_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_61_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1018"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1016
        },
        "FunctionVar_62_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_62_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1030",
                "nn.dropout_1683"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1682
        },
        "FunctionVar_62_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_62_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1029
        },
        "FunctionVar_63_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_63_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1039",
                "nn.dropout_1706",
                "reshape_2278"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2276
        },
        "FunctionVar_63_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_63_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1040"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1038
        },
        "FunctionVar_64_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_64_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1052",
                "reshape_1197",
                "transpose_1429",
                "nn.dropout_1728"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1727
        },
        "FunctionVar_64_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_64_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1053"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1051
        },
        "FunctionVar_65_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_65_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1745",
                "nn.dense_2368"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2366
        },
        "FunctionVar_65_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_65_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2369"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2367
        },
        "FunctionVar_66_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_66_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1768",
                "reshape_2260",
                "nn.dense_2352"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2350
        },
        "FunctionVar_66_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_66_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2353"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2351
        },
        "FunctionVar_67_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_67_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1079",
                "nn.dropout_1790"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1789
        },
        "FunctionVar_67_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_67_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1080"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1078
        },
        "FunctionVar_68_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_68_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1092",
                "transpose_1491",
                "nn.dropout_1807",
                "reshape_2244"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2242
        },
        "FunctionVar_68_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_68_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1093"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1091
        },
        "FunctionVar_69_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_69_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1101",
                "reshape_1259",
                "nn.dropout_1830"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1829
        },
        "FunctionVar_69_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_69_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1102"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1100
        },
        "FunctionVar_6_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_6_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_528",
                "reshape_2668",
                "nn.dense_2692"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2690
        },
        "FunctionVar_6_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_6_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2693"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2691
        },
        "FunctionVar_70_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_70_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1114",
                "nn.dropout_1852"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1851
        },
        "FunctionVar_70_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_70_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1115"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1113
        },
        "FunctionVar_71_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_71_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dropout_1869",
                "reshape_2226",
                "nn.dense_2334"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2332
        },
        "FunctionVar_71_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_71_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2335"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2333
        },
        "FunctionVar_72_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_72_0",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1553",
                "nn.dropout_1890",
                "nn.dense_2318"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2316
        },
        "FunctionVar_72_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_72_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2319"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2317
        },
        "FunctionVar_73_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_73_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1141",
                "reshape_2210"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2208
        },
        "FunctionVar_73_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_73_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1142"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1140
        },
        "FunctionVar_74_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_74_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1154",
                "reshape_1321"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1319
        },
        "FunctionVar_74_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_74_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1155"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1153
        },
        "FunctionVar_75_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_75_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1163"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1161
        },
        "FunctionVar_75_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_75_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1164"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1162
        },
        "FunctionVar_76_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_76_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1176",
                "transpose_1615",
                "reshape_2192"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2190
        },
        "FunctionVar_76_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_76_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1177"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1175
        },
        "FunctionVar_77_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_77_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2300"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2298
        },
        "FunctionVar_77_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_77_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2301"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2299
        },
        "FunctionVar_78_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_78_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_2176",
                "nn.dense_2284"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2282
        },
        "FunctionVar_78_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_78_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2285"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2283
        },
        "FunctionVar_79_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_79_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1203",
                "reshape_1383"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1381
        },
        "FunctionVar_79_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_79_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1204"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1202
        },
        "FunctionVar_7_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_7_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_459",
                "nn.dropout_550"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 549
        },
        "FunctionVar_7_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_7_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_460"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 458
        },
        "FunctionVar_80_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "64"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_80_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1216",
                "transpose_1677"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1675
        },
        "FunctionVar_80_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_80_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1217"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1215
        },
        "FunctionVar_81_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_81_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1225",
                "reshape_2158"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2156
        },
        "FunctionVar_81_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_81_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1226"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1224
        },
        "FunctionVar_82_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_82_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1238"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1236
        },
        "FunctionVar_82_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_82_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1239"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1237
        },
        "FunctionVar_83_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_83_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_2142",
                "nn.dense_2266"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2264
        },
        "FunctionVar_83_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_83_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2267"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2265
        },
        "FunctionVar_84_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_84_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1445",
                "transpose_1739",
                "nn.dense_2250"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2248
        },
        "FunctionVar_84_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_84_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2251"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2249
        },
        "FunctionVar_85_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_85_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1265"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1263
        },
        "FunctionVar_85_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_85_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1266"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1264
        },
        "FunctionVar_86_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_86_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1278",
                "reshape_2124"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2122
        },
        "FunctionVar_86_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_86_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1279"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1277
        },
        "FunctionVar_87_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_87_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1287"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1285
        },
        "FunctionVar_87_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_87_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1288"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1286
        },
        "FunctionVar_88_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_88_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1300",
                "transpose_1801",
                "reshape_2108"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2106
        },
        "FunctionVar_88_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_88_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1301"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1299
        },
        "FunctionVar_89_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_89_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1507",
                "nn.dense_2232"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2230
        },
        "FunctionVar_89_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_89_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2233"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2231
        },
        "FunctionVar_8_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_8_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_472",
                "transpose_561",
                "nn.dropout_567",
                "reshape_2652"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2650
        },
        "FunctionVar_8_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_8_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_473"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 471
        },
        "FunctionVar_90_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_90_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2216"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2214
        },
        "FunctionVar_90_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_90_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2217"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2215
        },
        "FunctionVar_91_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_91_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1327",
                "reshape_2090"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2088
        },
        "FunctionVar_91_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_91_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1328"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1326
        },
        "FunctionVar_92_0": {
            "cache": {
                "shape": [
                    "1",
                    "16",
                    "384",
                    "64"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_92_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1340",
                "transpose_1863"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1861
        },
        "FunctionVar_92_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_92_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1341"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1339
        },
        "FunctionVar_93_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_93_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1349",
                "reshape_2074"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2072
        },
        "FunctionVar_93_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_93_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1350"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1348
        },
        "FunctionVar_94_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_94_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1362",
                "reshape_1569"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1567
        },
        "FunctionVar_94_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_94_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1363"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1361
        },
        "FunctionVar_95_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_95_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_2198"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2196
        },
        "FunctionVar_95_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_95_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2199"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2197
        },
        "FunctionVar_96_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_96_0",
            "opcode": "Input",
            "output_nodes": [
                "reshape_2056",
                "nn.dense_2182"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2180
        },
        "FunctionVar_96_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_96_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2183"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2181
        },
        "FunctionVar_97_0": {
            "cache": {
                "shape": [
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_97_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1389"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1387
        },
        "FunctionVar_97_1": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_97_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1390"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1388
        },
        "FunctionVar_98_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_98_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1402",
                "reshape_2040"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2038
        },
        "FunctionVar_98_1": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_98_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1403"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1401
        },
        "FunctionVar_99_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_99_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1411",
                "reshape_1631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1629
        },
        "FunctionVar_99_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_99_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1412"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1410
        },
        "FunctionVar_9_0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_9_0",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_481",
                "reshape_515",
                "nn.dropout_590"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 589
        },
        "FunctionVar_9_1": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "FunctionVar_9_1",
            "opcode": "Input",
            "output_nodes": [
                "transpose_482"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 480
        },
        "add_1003": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1004",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1003",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fa7ca0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1003
        },
        "add_1012": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1013",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1012",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1008"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1012
        },
        "add_1021": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1022",
                "layernorm_1042"
            ],
            "ir": "pybuda",
            "name": "add_1021",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1020"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e53a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1021
        },
        "add_1025": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1026",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1025",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1022"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1025
        },
        "add_1034": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1035",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1034",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1033"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1034
        },
        "add_1043": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1044",
                "layernorm_1082"
            ],
            "ir": "pybuda",
            "name": "add_1043",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf826d40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1043
        },
        "add_1047": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1048",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1047",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1044"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1047
        },
        "add_1065": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1066",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1065",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1064"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19be8370), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1065
        },
        "add_1074": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1075",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1074",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1070"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1074
        },
        "add_1083": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1084",
                "layernorm_1104"
            ],
            "ir": "pybuda",
            "name": "add_1083",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1082"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output, 0x31bc3c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1083
        },
        "add_1087": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1088",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1087",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1084"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1087
        },
        "add_1096": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1097",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1096",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1095"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1096
        },
        "add_1105": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1106",
                "layernorm_1144"
            ],
            "ir": "pybuda",
            "name": "add_1105",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1104"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b3d300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1105
        },
        "add_1109": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1110",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1109",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1106"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1109
        },
        "add_1127": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1128",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1127",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824de0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1127
        },
        "add_1136": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1137",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1136",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1132"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1136
        },
        "add_1145": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1146",
                "layernorm_1166"
            ],
            "ir": "pybuda",
            "name": "add_1145",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output, 0xf76f920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1145
        },
        "add_1149": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1150",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1149",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1146"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1149
        },
        "add_1158": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1159",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1158",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1157"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1158
        },
        "add_1167": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1168",
                "layernorm_1206"
            ],
            "ir": "pybuda",
            "name": "add_1167",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1166"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b40c10), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1167
        },
        "add_1171": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1172",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1171",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1168"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1171
        },
        "add_1189": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1190",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1189",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1188"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a503c30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1189
        },
        "add_1198": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1199",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1198",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1194"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1198
        },
        "add_1207": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1208",
                "layernorm_1228"
            ],
            "ir": "pybuda",
            "name": "add_1207",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output, 0xda20c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1207
        },
        "add_1211": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1212",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1211",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1208"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1211
        },
        "add_1220": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1221",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1220",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1219"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1220
        },
        "add_1229": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1230",
                "layernorm_1268"
            ],
            "ir": "pybuda",
            "name": "add_1229",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a518f60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1229
        },
        "add_1233": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1234",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1233",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1230"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1233
        },
        "add_1251": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1252",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1251",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1250"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3648ed50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1251
        },
        "add_1260": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1261",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1260",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1256"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1260
        },
        "add_1269": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1270",
                "layernorm_1290"
            ],
            "ir": "pybuda",
            "name": "add_1269",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e4190), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1269
        },
        "add_1273": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1274",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1273",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1270"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1273
        },
        "add_1282": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1283",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1282",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1281"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1282
        },
        "add_1291": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1292",
                "layernorm_1330"
            ],
            "ir": "pybuda",
            "name": "add_1291",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1290"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a4cfa80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1291
        },
        "add_1295": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1296",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1295",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1292"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1295
        },
        "add_1313": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1314",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1313",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1312"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36458280), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1313
        },
        "add_1322": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1323",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1322",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1318"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1322
        },
        "add_1331": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1332",
                "layernorm_1352"
            ],
            "ir": "pybuda",
            "name": "add_1331",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1330"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output, 0x36446a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1331
        },
        "add_1335": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1336",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1335",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1332"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1335
        },
        "add_1344": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1345",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1344",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1343"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1344
        },
        "add_1353": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1354",
                "layernorm_1392"
            ],
            "ir": "pybuda",
            "name": "add_1353",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1352"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xda20440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1353
        },
        "add_1357": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1358",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1357",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1354"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1357
        },
        "add_1375": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1376",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1375",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1374"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b6cff0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1375
        },
        "add_1384": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1385",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1384",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1380"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1384
        },
        "add_1393": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1394",
                "layernorm_1414"
            ],
            "ir": "pybuda",
            "name": "add_1393",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1392"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output, 0x31b556d0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1393
        },
        "add_1397": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1398",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1397",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1394"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1397
        },
        "add_1406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1407",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1406",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1405"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1406
        },
        "add_1415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1416",
                "layernorm_1454"
            ],
            "ir": "pybuda",
            "name": "add_1415",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a505020), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1415
        },
        "add_1419": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1420",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1419",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1416"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1419
        },
        "add_1437": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1438",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1437",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31ba9a90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1437
        },
        "add_1446": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1447",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1446",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1442"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1446
        },
        "add_1455": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1456",
                "layernorm_1476"
            ],
            "ir": "pybuda",
            "name": "add_1455",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1454"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output, 0x19bb3910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1455
        },
        "add_1459": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1460",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1459",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1456"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1459
        },
        "add_1468": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1469",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1468",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1467"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1468
        },
        "add_1477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1478",
                "layernorm_1516"
            ],
            "ir": "pybuda",
            "name": "add_1477",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a5206a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1477
        },
        "add_1481": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1482",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1481",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1478"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1481
        },
        "add_1499": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1500",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1499",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a509a40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1499
        },
        "add_1508": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1509",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1508",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1504"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1508
        },
        "add_1517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1518",
                "layernorm_1538"
            ],
            "ir": "pybuda",
            "name": "add_1517",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9c3520), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1517
        },
        "add_1521": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1522",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1521",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1518"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1521
        },
        "add_1530": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1531",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1530",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1529"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1530
        },
        "add_1539": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1540",
                "layernorm_1578"
            ],
            "ir": "pybuda",
            "name": "add_1539",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a500890), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1539
        },
        "add_1543": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1544",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1543",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1540"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1543
        },
        "add_1561": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1562",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1561",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91823d90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1561
        },
        "add_1570": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1571",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1570",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1566"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1570
        },
        "add_1579": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1580",
                "layernorm_1600"
            ],
            "ir": "pybuda",
            "name": "add_1579",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output, 0x2fb49910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1579
        },
        "add_1583": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1584",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1583",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1580"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1583
        },
        "add_1592": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1593",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1592",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1591"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1592
        },
        "add_1601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1602",
                "layernorm_1640"
            ],
            "ir": "pybuda",
            "name": "add_1601",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a45ddb0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1601
        },
        "add_1605": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1606",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1605",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1602"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1605
        },
        "add_1623": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1624",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1623",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4890c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1623
        },
        "add_1632": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1633",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1632",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1628"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1632
        },
        "add_1641": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1642",
                "layernorm_1662"
            ],
            "ir": "pybuda",
            "name": "add_1641",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1640"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output, 0x8ab077c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1641
        },
        "add_1645": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1646",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1645",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1642"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1645
        },
        "add_1654": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1655",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1654",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1653"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1654
        },
        "add_1663": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1664",
                "layernorm_1702"
            ],
            "ir": "pybuda",
            "name": "add_1663",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba60c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1663
        },
        "add_1667": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1668",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1667",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1664"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1667
        },
        "add_1685": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1686",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1685",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bbfab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1685
        },
        "add_1694": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1695",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1694",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1690"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1694
        },
        "add_1703": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1704",
                "layernorm_1724"
            ],
            "ir": "pybuda",
            "name": "add_1703",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output, 0x917a5e00), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1703
        },
        "add_1707": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1708",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1707",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1704"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1707
        },
        "add_1716": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1717",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1716",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1715"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1716
        },
        "add_1725": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1726",
                "layernorm_1764"
            ],
            "ir": "pybuda",
            "name": "add_1725",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1724"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba7070), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1725
        },
        "add_1729": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1730",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1729",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1726"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1729
        },
        "add_1747": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1748",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1747",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b5bbd0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1747
        },
        "add_1756": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1757",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1756",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1752"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1756
        },
        "add_1765": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1766",
                "layernorm_1786"
            ],
            "ir": "pybuda",
            "name": "add_1765",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1764"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9be180), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1765
        },
        "add_1769": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1770",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1769",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1766"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1769
        },
        "add_1778": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1779",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1778",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1777"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1778
        },
        "add_1787": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1788",
                "layernorm_1826"
            ],
            "ir": "pybuda",
            "name": "add_1787",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x8ab53930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1787
        },
        "add_1791": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1792",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1791",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1788"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1791
        },
        "add_1809": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1810",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1809",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9e4730), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1809
        },
        "add_1818": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1819",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1818",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1814"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1818
        },
        "add_1827": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1828",
                "layernorm_1848"
            ],
            "ir": "pybuda",
            "name": "add_1827",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output, 0xd950e20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1827
        },
        "add_1831": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1832",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1831",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1828"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1831
        },
        "add_1840": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1841",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1840",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_1839"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1840
        },
        "add_1849": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1850",
                "pybuda.dropout_1888"
            ],
            "ir": "pybuda",
            "name": "add_1849",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xd96bf40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1849
        },
        "add_1853": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1854",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1853",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1850"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1853
        },
        "add_1871": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_1872",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_1871",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9182dc30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1871
        },
        "add_1880": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1881",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1880",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1876"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1880
        },
        "add_1899": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1900",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1899",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1895"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1899
        },
        "add_1921": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1922",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1921",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1917"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1921
        },
        "add_1939": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1940",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1939",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1935"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1939
        },
        "add_1955": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1956",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1955",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1951"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1955
        },
        "add_1973": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1974",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1973",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1969"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1973
        },
        "add_1989": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1990",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1989",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_1985"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1989
        },
        "add_2007": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2008",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2007",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2003"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2007
        },
        "add_2023": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2024",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2023",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2019"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2023
        },
        "add_2041": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2042",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2041",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2037"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2041
        },
        "add_2057": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2058",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2057",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2053"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2057
        },
        "add_2075": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2076",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2075",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2071"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2075
        },
        "add_2091": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2092",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2091",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2087"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2091
        },
        "add_2109": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2110",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2109",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2105"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2109
        },
        "add_2125": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2126",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2125",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2121"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2125
        },
        "add_2143": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2144",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2143",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2139"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2143
        },
        "add_2159": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2160",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2159",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2155"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2159
        },
        "add_2177": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2178",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2177",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2173"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2177
        },
        "add_2193": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2194",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2193",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2189"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2193
        },
        "add_2211": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2212",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2211",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2207"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2211
        },
        "add_2227": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2228",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2227",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2223"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2227
        },
        "add_2245": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2246",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2245",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2241"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2245
        },
        "add_2261": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2262",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2261",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2257"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2261
        },
        "add_2279": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2280",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2279",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2275"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2279
        },
        "add_2295": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2296",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2295",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2291"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2295
        },
        "add_2313": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2314",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2313",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2309"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2313
        },
        "add_2329": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2330",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2329",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2325"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2329
        },
        "add_2347": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2348",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2347",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2343"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2347
        },
        "add_2363": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2364",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2363",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2359"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2363
        },
        "add_2381": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2382",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2381",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2377"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2381
        },
        "add_2397": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2398",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2397",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2393"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2397
        },
        "add_2415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2416",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2415",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2411"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2415
        },
        "add_2431": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2432",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2431",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2427"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2431
        },
        "add_2449": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2450",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2449",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2445"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2449
        },
        "add_2465": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2466",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2465",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2461"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2465
        },
        "add_2483": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2484",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2483",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2479"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2483
        },
        "add_2499": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2500",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2499",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2495"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2499
        },
        "add_2517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2518",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2517",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2513"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2517
        },
        "add_2533": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2534",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2533",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2529"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2533
        },
        "add_2551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2552",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2551",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2547"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2551
        },
        "add_2567": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2568",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2567",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2563"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2567
        },
        "add_2585": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2586",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2585",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2581"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2585
        },
        "add_2601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2602",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2601",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2597"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2601
        },
        "add_2619": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2620",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2619",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2615"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2619
        },
        "add_2635": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2636",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2635",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2631"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2635
        },
        "add_2653": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2654",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2653",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2649"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2653
        },
        "add_2669": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2670",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2669",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2665"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2669
        },
        "add_2687": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2688",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_2687",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2683"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2687
        },
        "add_2703": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2704",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_2703",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_2699"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2703
        },
        "add_2719": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2720",
                "strided_slice_2727"
            ],
            "ir": "pybuda",
            "name": "add_2719",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2718"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 2719
        },
        "add_393": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_394",
                "strided_slice_2716"
            ],
            "ir": "pybuda",
            "name": "add_393",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_392"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 393
        },
        "add_401": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_402",
                "layernorm_422"
            ],
            "ir": "pybuda",
            "name": "add_401",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output, 0x94142930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 401
        },
        "add_405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_406",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_405",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_402"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 405
        },
        "add_414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_415",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_414",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_413"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 414
        },
        "add_423": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_424",
                "layernorm_462"
            ],
            "ir": "pybuda",
            "name": "add_423",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_422"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x126d55e0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 423
        },
        "add_427": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_428",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_427",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_424"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 427
        },
        "add_445": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_446",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_445",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94190e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 445
        },
        "add_454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_455",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_454",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_450"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 454
        },
        "add_463": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_464",
                "layernorm_484"
            ],
            "ir": "pybuda",
            "name": "add_463",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_462"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output, 0x126a7350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 463
        },
        "add_467": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_468",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_467",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_464"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 467
        },
        "add_476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_477",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_476",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_475"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 476
        },
        "add_485": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_486",
                "layernorm_524"
            ],
            "ir": "pybuda",
            "name": "add_485",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x917b0210), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 485
        },
        "add_489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_490",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_489",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_486"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 489
        },
        "add_507": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_508",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_507",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f668f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 507
        },
        "add_516": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_517",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_516",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_512"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 516
        },
        "add_525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_526",
                "layernorm_546"
            ],
            "ir": "pybuda",
            "name": "add_525",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_524"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output, 0x941d25a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 525
        },
        "add_529": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_530",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_529",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_526"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 529
        },
        "add_538": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_539",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_538",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_537"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 538
        },
        "add_547": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_548",
                "layernorm_586"
            ],
            "ir": "pybuda",
            "name": "add_547",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x94179fa0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 547
        },
        "add_551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_552",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_551",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_548"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 551
        },
        "add_569": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_570",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_569",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126af900), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 569
        },
        "add_578": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_579",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_578",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_574"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 578
        },
        "add_587": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_588",
                "layernorm_608"
            ],
            "ir": "pybuda",
            "name": "add_587",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a445480), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 587
        },
        "add_591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_592",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_591",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_588"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 591
        },
        "add_600": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_601",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_600",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_599"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 600
        },
        "add_609": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_610",
                "layernorm_648"
            ],
            "ir": "pybuda",
            "name": "add_609",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf78a620), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 609
        },
        "add_613": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_614",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_613",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_610"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 613
        },
        "add_631": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_632",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_631",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049c80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 631
        },
        "add_640": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_641",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_640",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_636"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 640
        },
        "add_649": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_650",
                "layernorm_670"
            ],
            "ir": "pybuda",
            "name": "add_649",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output, 0xf739860), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 649
        },
        "add_653": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_654",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_653",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_650"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 653
        },
        "add_662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_663",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_662",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_661"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 662
        },
        "add_671": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_672",
                "layernorm_710"
            ],
            "ir": "pybuda",
            "name": "add_671",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b39bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 671
        },
        "add_675": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_676",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_675",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_672"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 675
        },
        "add_693": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_694",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_693",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_692"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3652b260), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 693
        },
        "add_702": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_703",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_702",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_698"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 702
        },
        "add_711": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_712",
                "layernorm_732"
            ],
            "ir": "pybuda",
            "name": "add_711",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output, 0x27f39310), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 711
        },
        "add_715": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_716",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_715",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_712"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 715
        },
        "add_724": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_725",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_724",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_723"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 724
        },
        "add_733": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_734",
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "add_733",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf76bc40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 733
        },
        "add_737": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_738",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_737",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_734"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 737
        },
        "add_755": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_756",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_755",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fecf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 755
        },
        "add_764": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_765",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_764",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_760"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 764
        },
        "add_773": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_774",
                "layernorm_794"
            ],
            "ir": "pybuda",
            "name": "add_773",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9d6cf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 773
        },
        "add_777": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_778",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_777",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_774"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 777
        },
        "add_786": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_787",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_786",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_785"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 786
        },
        "add_795": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_796",
                "layernorm_834"
            ],
            "ir": "pybuda",
            "name": "add_795",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_794"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x150b3e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 795
        },
        "add_799": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_800",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_799",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_796"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 799
        },
        "add_817": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_818",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_817",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_816"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf81bf50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 817
        },
        "add_826": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_827",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_826",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_822"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 826
        },
        "add_835": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_836",
                "layernorm_856"
            ],
            "ir": "pybuda",
            "name": "add_835",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output, 0x3645c290), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 835
        },
        "add_839": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_840",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_839",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_836"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 839
        },
        "add_848": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_849",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_848",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_847"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 848
        },
        "add_857": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_858",
                "layernorm_896"
            ],
            "ir": "pybuda",
            "name": "add_857",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_856"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x280244f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 857
        },
        "add_861": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_862",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_861",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_858"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 861
        },
        "add_879": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_880",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_879",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_878"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3643dac0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 879
        },
        "add_888": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_889",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_888",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_884"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 888
        },
        "add_897": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_898",
                "layernorm_918"
            ],
            "ir": "pybuda",
            "name": "add_897",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_896"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output, 0x27fce810), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 897
        },
        "add_901": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_902",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_901",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_898"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 901
        },
        "add_910": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_911",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_910",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_909"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 910
        },
        "add_919": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_920",
                "layernorm_958"
            ],
            "ir": "pybuda",
            "name": "add_919",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x15061a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 919
        },
        "add_923": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_924",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_923",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_920"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 923
        },
        "add_941": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "multiply_942",
                "multiply_1908"
            ],
            "ir": "pybuda",
            "name": "add_941",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_940"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c9850), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 941
        },
        "add_950": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_951",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_950",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hslice_946"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 950
        },
        "add_959": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_960",
                "layernorm_980"
            ],
            "ir": "pybuda",
            "name": "add_959",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_958"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a4d73f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 959
        },
        "add_963": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_964",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_963",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_960"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 963
        },
        "add_972": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_973",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_972",
            "opcode": "RelayOp",
            "output_nodes": [
                "gelu_971"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 972
        },
        "add_981": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_982",
                "layernorm_1020"
            ],
            "ir": "pybuda",
            "name": "add_981",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_980"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x27f42770), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 981
        },
        "add_985": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_986",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_985",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_982"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 985
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "attention_mask_1",
            "opcode": "Input",
            "output_nodes": [
                "reshape_1912"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1891"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1891"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 7
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1848"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 13
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1848"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 12
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1853"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 11
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1929"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 10
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1899"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 6
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1906"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 5
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1880"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 4
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1892"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 3
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1921"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 9
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1928"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 8
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1840"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 15
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1930"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 14
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1826"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 19
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1826"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 18
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1831"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 17
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1931"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 16
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1786"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 29
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1786"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 28
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1791"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 27
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1963"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 26
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1939"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 23
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1946"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 22
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1818"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 21
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1932"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 20
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1955"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 25
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1962"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 24
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1778"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 31
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1964"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 30
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1764"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 35
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1764"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 34
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1769"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 33
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1965"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 32
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 173
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 172
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1233"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 171
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2269"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 170
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2245"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 167
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2252"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 166
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1260"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 165
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2238"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 164
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2261"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 169
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 168
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1220"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 175
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2270"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 174
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 179
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 178
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1211"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 177
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2271"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 176
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1166"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 189
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1166"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 188
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1171"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 187
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2303"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 186
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2279"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 183
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2286"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 182
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1198"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 181
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2272"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 180
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2295"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 185
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2302"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 184
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1158"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 191
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2304"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 190
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1144"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 195
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1144"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 194
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1149"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 193
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2305"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 192
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1104"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 205
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1104"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 204
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1109"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 203
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2337"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 202
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2313"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 199
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2320"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 198
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1136"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 197
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2306"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 196
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2329"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 201
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2336"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 200
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1096"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 207
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2338"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 206
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1082"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 211
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1082"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 210
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1087"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 209
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2339"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 208
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1042"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 221
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1042"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 220
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1047"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 219
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2371"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 218
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2347"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 215
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2354"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 214
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1074"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 213
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2340"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 212
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2363"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 217
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2370"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 216
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1034"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 223
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2372"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 222
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1020"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 227
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1020"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 226
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1025"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 225
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2373"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 224
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_980"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 237
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_980"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 236
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_985"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 235
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2405"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 234
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2381"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 231
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2388"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 230
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1012"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 229
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2374"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 228
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2397"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 233
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2404"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 232
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_972"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 239
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2406"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 238
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_958"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 243
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_958"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 242
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_963"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 241
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2407"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 240
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 253
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 252
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_923"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 251
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 250
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2415"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 247
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2422"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 246
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_950"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 245
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2408"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 244
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2431"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 249
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2438"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 248
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_910"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 255
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2440"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 254
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_896"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 259
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_896"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 258
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_901"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 257
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2441"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 256
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_856"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 269
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_856"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 268
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_861"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 267
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2473"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 266
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2449"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 263
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2456"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 262
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_888"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 261
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2442"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 260
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2465"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 265
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2472"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 264
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_848"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 271
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2474"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 270
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 275
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 274
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_839"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 273
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2475"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 272
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_794"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 285
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_794"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 284
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_799"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 283
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2507"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 282
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2483"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 279
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2490"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 278
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_826"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 277
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 276
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2499"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 281
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2506"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 280
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_786"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 287
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2508"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 286
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 291
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 290
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_777"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 289
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2509"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 288
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_732"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 301
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_732"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 300
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_737"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 299
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2541"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 298
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2517"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 295
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2524"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 294
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_764"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 293
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2510"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 292
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2533"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 297
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2540"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 296
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 303
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2542"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 302
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 307
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 306
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_715"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 305
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2543"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 304
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_670"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 317
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_670"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 316
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_675"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 315
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2575"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 314
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2551"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 311
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2558"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 310
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 309
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2544"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 308
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2567"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 313
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2574"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 312
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_662"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 319
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2576"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 318
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_648"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 323
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_648"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 322
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_653"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 321
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2577"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 320
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 45
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 44
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1729"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 43
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1997"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 42
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1973"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 39
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1980"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 38
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1756"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 37
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1966"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 36
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1989"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 41
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1996"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 40
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1716"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 47
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1998"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 46
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 51
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 50
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1707"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 49
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1999"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 48
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_608"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 333
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_608"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 332
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_613"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 331
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2609"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 330
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2585"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 327
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2592"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 326
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_640"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 325
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2578"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 324
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2601"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 329
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2608"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 328
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_600"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 335
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2610"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 334
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_586"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 339
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_586"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 338
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_591"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 337
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2611"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 336
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 349
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 348
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_551"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 347
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2643"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 346
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2619"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 343
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2626"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 342
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_578"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 341
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2612"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 340
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2635"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 345
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2642"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 344
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_538"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 351
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2644"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 350
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_524"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 355
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_524"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 354
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_529"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 353
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2645"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 352
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 365
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 364
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_489"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 363
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2677"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 362
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2653"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 359
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2660"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 358
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_516"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 357
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2646"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 356
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2669"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 361
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2676"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 360
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 367
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2678"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 366
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_462"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 371
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_462"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 370
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_467"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 369
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2679"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 368
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_422"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 381
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_422"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 380
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_427"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 379
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2711"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 378
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2687"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 375
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2694"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 374
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 373
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2680"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 372
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2703"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 377
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2710"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 376
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 383
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2712"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 382
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_400"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 387
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_400"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 386
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_405"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 385
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2713"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 384
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1662"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 61
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1662"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 60
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1667"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 59
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 58
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2007"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 55
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2014"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 54
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1694"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 53
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2000"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 52
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2023"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 57
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2030"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 56
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1654"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 63
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2032"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 62
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1640"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 67
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1640"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 66
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1645"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 65
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2033"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 64
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1600"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 77
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1600"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 76
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1605"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 75
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2065"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 74
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2041"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 71
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2048"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 70
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1632"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 69
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2034"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 68
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2057"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 73
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2064"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 72
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 79
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2066"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 78
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1578"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 83
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1578"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 82
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1583"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 81
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2067"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 80
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1538"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 93
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1538"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 92
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1543"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 91
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2099"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 90
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2075"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 87
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2082"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 86
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1570"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 85
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2068"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 84
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2091"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 89
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2098"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 88
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1530"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 95
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2100"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 94
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1516"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 99
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1516"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 98
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1521"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 97
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2101"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 96
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 109
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 108
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1481"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 107
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2133"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 106
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2109"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 103
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2116"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 102
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1508"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 101
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2102"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 100
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2125"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 105
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2132"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 104
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1468"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 111
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2134"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 110
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 115
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 114
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1459"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 113
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2135"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 112
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 125
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 124
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1419"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 123
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2167"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 122
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2143"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 119
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2150"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 118
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1446"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 117
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2136"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 116
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2159"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 121
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2166"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 120
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1406"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 127
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2168"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 126
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1392"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 131
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1392"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 130
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1397"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 129
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2169"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 128
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1352"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 141
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1352"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 140
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1357"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 139
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2201"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 138
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2177"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 135
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2184"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 134
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1384"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 133
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2170"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 132
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2193"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 137
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2200"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 136
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1344"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 143
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2202"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 142
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1330"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 147
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1330"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 146
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1335"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 145
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2203"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 144
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1290"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 157
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1290"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 156
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1295"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 155
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2235"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 154
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2211"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 151
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2218"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 150
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1322"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 149
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2204"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 148
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_2227"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 153
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2234"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 152
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1282"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 159
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2236"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 158
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 163
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 162
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1273"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 161
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2237"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 160
        },
        "cast_1911": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "reshape_1912"
            ],
            "ir": "pybuda",
            "name": "cast_1911",
            "opcode": "RelayOp",
            "output_nodes": [
                "subtract_1909"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::to, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917a3500), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1911
        },
        "constant_1907": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1907",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1872"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1907
        },
        "constant_1910": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1910",
            "opcode": "Input",
            "output_nodes": [
                "subtract_1909"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1910
        },
        "constant_1913": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1913",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1908"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1913
        },
        "constant_1947": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1947",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1810"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1947
        },
        "constant_1981": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1981",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1748"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1981
        },
        "constant_2015": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2015",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1686"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2015
        },
        "constant_2049": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2049",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1624"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2049
        },
        "constant_2083": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2083",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1562"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2083
        },
        "constant_2117": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2117",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1500"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2117
        },
        "constant_2151": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2151",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1438"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2151
        },
        "constant_2185": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2185",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1376"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2185
        },
        "constant_2219": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2219",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1314"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2219
        },
        "constant_2253": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2253",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1252"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2253
        },
        "constant_2287": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2287",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1190"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2287
        },
        "constant_2321": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2321",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1128"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2321
        },
        "constant_2355": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2355",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1066"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2355
        },
        "constant_2389": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2389",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1004"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2389
        },
        "constant_2423": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2423",
            "opcode": "Input",
            "output_nodes": [
                "multiply_942"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2423
        },
        "constant_2457": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2457",
            "opcode": "Input",
            "output_nodes": [
                "multiply_880"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2457
        },
        "constant_2491": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2491",
            "opcode": "Input",
            "output_nodes": [
                "multiply_818"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2491
        },
        "constant_2525": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2525",
            "opcode": "Input",
            "output_nodes": [
                "multiply_756"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2525
        },
        "constant_2559": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2559",
            "opcode": "Input",
            "output_nodes": [
                "multiply_694"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2559
        },
        "constant_2593": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2593",
            "opcode": "Input",
            "output_nodes": [
                "multiply_632"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2593
        },
        "constant_2627": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2627",
            "opcode": "Input",
            "output_nodes": [
                "multiply_570"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2627
        },
        "constant_2661": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2661",
            "opcode": "Input",
            "output_nodes": [
                "multiply_508"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2661
        },
        "constant_2695": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2695",
            "opcode": "Input",
            "output_nodes": [
                "multiply_446"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2695
        },
        "gelu_1033": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1034"
            ],
            "ir": "pybuda",
            "name": "gelu_1033",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1032"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1033
        },
        "gelu_1095": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1096"
            ],
            "ir": "pybuda",
            "name": "gelu_1095",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1094"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1095
        },
        "gelu_1157": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1158"
            ],
            "ir": "pybuda",
            "name": "gelu_1157",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1156"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1157
        },
        "gelu_1219": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1220"
            ],
            "ir": "pybuda",
            "name": "gelu_1219",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1218"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1219
        },
        "gelu_1281": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1282"
            ],
            "ir": "pybuda",
            "name": "gelu_1281",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1280"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1281
        },
        "gelu_1343": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1344"
            ],
            "ir": "pybuda",
            "name": "gelu_1343",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1342"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1343
        },
        "gelu_1405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1406"
            ],
            "ir": "pybuda",
            "name": "gelu_1405",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1404"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1405
        },
        "gelu_1467": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1468"
            ],
            "ir": "pybuda",
            "name": "gelu_1467",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1467
        },
        "gelu_1529": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1530"
            ],
            "ir": "pybuda",
            "name": "gelu_1529",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1529
        },
        "gelu_1591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1592"
            ],
            "ir": "pybuda",
            "name": "gelu_1591",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1591
        },
        "gelu_1653": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1654"
            ],
            "ir": "pybuda",
            "name": "gelu_1653",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1653
        },
        "gelu_1715": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1716"
            ],
            "ir": "pybuda",
            "name": "gelu_1715",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1714"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1715
        },
        "gelu_1777": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1778"
            ],
            "ir": "pybuda",
            "name": "gelu_1777",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1776"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1777
        },
        "gelu_1839": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_1840"
            ],
            "ir": "pybuda",
            "name": "gelu_1839",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 1839
        },
        "gelu_413": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_414"
            ],
            "ir": "pybuda",
            "name": "gelu_413",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 413
        },
        "gelu_475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_476"
            ],
            "ir": "pybuda",
            "name": "gelu_475",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 475
        },
        "gelu_537": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_538"
            ],
            "ir": "pybuda",
            "name": "gelu_537",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 537
        },
        "gelu_599": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_600"
            ],
            "ir": "pybuda",
            "name": "gelu_599",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_598"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 599
        },
        "gelu_661": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_662"
            ],
            "ir": "pybuda",
            "name": "gelu_661",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_660"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 661
        },
        "gelu_723": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_724"
            ],
            "ir": "pybuda",
            "name": "gelu_723",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_722"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 723
        },
        "gelu_785": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_786"
            ],
            "ir": "pybuda",
            "name": "gelu_785",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 785
        },
        "gelu_847": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_848"
            ],
            "ir": "pybuda",
            "name": "gelu_847",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_846"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 847
        },
        "gelu_909": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_910"
            ],
            "ir": "pybuda",
            "name": "gelu_909",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_908"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 909
        },
        "gelu_971": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "gelu",
            "epoch": 0,
            "input_nodes": [
                "add_972"
            ],
            "ir": "pybuda",
            "name": "gelu_971",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "gelu",
            "unique_id": 971
        },
        "layernorm_1020": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1021",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1020",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_981",
                "reshape_1019"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf749490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1020
        },
        "layernorm_1042": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1043",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1042",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1021",
                "reshape_1041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x365122e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1042
        },
        "layernorm_1082": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1083",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1082",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1043",
                "reshape_1081"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d91c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1082
        },
        "layernorm_1104": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1105",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1104",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1083",
                "reshape_1103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4fc5e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1104
        },
        "layernorm_1144": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1145",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1144",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1105",
                "reshape_1143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd974ae0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1144
        },
        "layernorm_1166": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1167",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1166",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1145",
                "reshape_1165"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b455d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1166
        },
        "layernorm_1206": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1207",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1206",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1167",
                "reshape_1205"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd98ab70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1206
        },
        "layernorm_1228": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1229",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1228",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1207",
                "reshape_1227"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x364f4230), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1228
        },
        "layernorm_1268": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1269",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1268",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1229",
                "reshape_1267"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a472c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1268
        },
        "layernorm_1290": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1291",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1290",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269",
                "reshape_1289"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a48aee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1290
        },
        "layernorm_1330": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1331",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1330",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1291",
                "reshape_1329"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31c24e00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1330
        },
        "layernorm_1352": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1353",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1352",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1331",
                "reshape_1351"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd99a490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1352
        },
        "layernorm_1392": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1393",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1392",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1353",
                "reshape_1391"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd95cb50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1392
        },
        "layernorm_1414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1415",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1414",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1393",
                "reshape_1413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b8d0c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1414
        },
        "layernorm_1454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1455",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1454",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1415",
                "reshape_1453"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a456e70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1454
        },
        "layernorm_1476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1477",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1476",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1455",
                "reshape_1475"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19c0dd00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1476
        },
        "layernorm_1516": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1517",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1516",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1477",
                "reshape_1515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4d52d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1516
        },
        "layernorm_1538": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1539",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1538",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1517",
                "reshape_1537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b49cb0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1538
        },
        "layernorm_1578": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1579",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1578",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1539",
                "reshape_1577"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19bc47e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1578
        },
        "layernorm_1600": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1601",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1600",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1579",
                "reshape_1599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9bd4d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1600
        },
        "layernorm_1640": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1641",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1640",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1601",
                "reshape_1639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b96410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1640
        },
        "layernorm_1662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1663",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1662",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1641",
                "reshape_1661"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xda08cd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1662
        },
        "layernorm_1702": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1703",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1702",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1663",
                "reshape_1701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b59000), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1702
        },
        "layernorm_1724": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1725",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1724",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1703",
                "reshape_1723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917ab600), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1724
        },
        "layernorm_1764": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1765",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1764",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1725",
                "reshape_1763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9e7790), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1764
        },
        "layernorm_1786": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1787",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1786",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1765",
                "reshape_1785"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x91832300), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1786
        },
        "layernorm_1826": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1827",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1826",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1787",
                "reshape_1825"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9182e6e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1826
        },
        "layernorm_1848": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1849",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1848",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1827",
                "reshape_1847"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917a5390), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1848
        },
        "layernorm_1891": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "pybuda_6_i0",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1891",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x918210f0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1891
        },
        "layernorm_400": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_401",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_400",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fd6f10), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 400
        },
        "layernorm_422": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_423",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_422",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_401",
                "reshape_421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x37bd6810), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 422
        },
        "layernorm_462": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_463",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_462",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_423",
                "reshape_461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x126ea410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 462
        },
        "layernorm_484": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_485",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_484",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_463",
                "reshape_483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf75bdf0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 484
        },
        "layernorm_524": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_525",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_524",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_485",
                "reshape_523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x12643c20), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 524
        },
        "layernorm_546": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_547",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_546",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_525",
                "reshape_545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150af8e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 546
        },
        "layernorm_586": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_587",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_586",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_547",
                "reshape_585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7f9e90), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 586
        },
        "layernorm_608": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_609",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_608",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_587",
                "reshape_607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b4f460), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 608
        },
        "layernorm_648": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_649",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_648",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_609",
                "reshape_647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9420f530), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 648
        },
        "layernorm_670": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_671",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_670",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_649",
                "reshape_669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941de800), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 670
        },
        "layernorm_710": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_711",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_710",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_671",
                "reshape_709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150a6c60), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 710
        },
        "layernorm_732": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_733",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_732",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_711",
                "reshape_731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941f5c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 732
        },
        "layernorm_772": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_773",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_772",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_733",
                "reshape_771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150e9f80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 772
        },
        "layernorm_794": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_795",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_794",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_773",
                "reshape_793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d5c70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 794
        },
        "layernorm_834": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_835",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_834",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_795",
                "reshape_833"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf774ee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 834
        },
        "layernorm_856": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_857",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_856",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_835",
                "reshape_855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4bcfd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 856
        },
        "layernorm_896": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_897",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_896",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_857",
                "reshape_895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9fb7d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 896
        },
        "layernorm_918": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_919",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_918",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_897",
                "reshape_917"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fe2d50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 918
        },
        "layernorm_958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_959",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_958",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_919",
                "reshape_957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4996b0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 958
        },
        "layernorm_980": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_981",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_980",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_959",
                "reshape_979"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7674e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 980
        },
        "multiply_1004": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1005",
                "constant_2389"
            ],
            "ir": "pybuda",
            "name": "multiply_1004",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1003"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f45150), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1004
        },
        "multiply_1066": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1067",
                "constant_2355"
            ],
            "ir": "pybuda",
            "name": "multiply_1066",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1065"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82ecd0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1066
        },
        "multiply_1128": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1129",
                "constant_2321"
            ],
            "ir": "pybuda",
            "name": "multiply_1128",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda30d90), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1128
        },
        "multiply_1190": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1191",
                "constant_2287"
            ],
            "ir": "pybuda",
            "name": "multiply_1190",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1189"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364688e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1190
        },
        "multiply_1252": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1253",
                "constant_2253"
            ],
            "ir": "pybuda",
            "name": "multiply_1252",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36433ac0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1252
        },
        "multiply_1314": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1315",
                "constant_2219"
            ],
            "ir": "pybuda",
            "name": "multiply_1314",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1313"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bfe2e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1314
        },
        "multiply_1376": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1377",
                "constant_2185"
            ],
            "ir": "pybuda",
            "name": "multiply_1376",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1375"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf19c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1376
        },
        "multiply_1438": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1439",
                "constant_2151"
            ],
            "ir": "pybuda",
            "name": "multiply_1438",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1437"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49cbc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1438
        },
        "multiply_1500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1501",
                "constant_2117"
            ],
            "ir": "pybuda",
            "name": "multiply_1500",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1499"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511f40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1500
        },
        "multiply_1562": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1563",
                "constant_2083"
            ],
            "ir": "pybuda",
            "name": "multiply_1562",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c22f20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1562
        },
        "multiply_1624": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1625",
                "constant_2049"
            ],
            "ir": "pybuda",
            "name": "multiply_1624",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917b72e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1624
        },
        "multiply_1686": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1687",
                "constant_2015"
            ],
            "ir": "pybuda",
            "name": "multiply_1686",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1685"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91820730), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1686
        },
        "multiply_1748": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1749",
                "constant_1981"
            ],
            "ir": "pybuda",
            "name": "multiply_1748",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd960e90), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1748
        },
        "multiply_1810": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1811",
                "constant_1947"
            ],
            "ir": "pybuda",
            "name": "multiply_1810",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8abc4710), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1810
        },
        "multiply_1872": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_1873",
                "constant_1907"
            ],
            "ir": "pybuda",
            "name": "multiply_1872",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91826840), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1872
        },
        "multiply_1908": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "subtract_1909",
                "constant_1913"
            ],
            "ir": "pybuda",
            "name": "multiply_1908",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_445",
                "add_507",
                "add_569",
                "add_631",
                "add_693",
                "add_755",
                "add_817",
                "add_879",
                "add_941",
                "add_1003",
                "add_1065",
                "add_1127",
                "add_1189",
                "add_1251",
                "add_1313",
                "add_1375",
                "add_1437",
                "add_1499",
                "add_1561",
                "add_1623",
                "add_1685",
                "add_1747",
                "add_1809",
                "add_1871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::mul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x8ab56a50), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1908
        },
        "multiply_446": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_447",
                "constant_2695"
            ],
            "ir": "pybuda",
            "name": "multiply_446",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ec890), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 446
        },
        "multiply_508": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_509",
                "constant_2661"
            ],
            "ir": "pybuda",
            "name": "multiply_508",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94171620), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 508
        },
        "multiply_570": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_571",
                "constant_2627"
            ],
            "ir": "pybuda",
            "name": "multiply_570",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28007220), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 570
        },
        "multiply_632": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_633",
                "constant_2593"
            ],
            "ir": "pybuda",
            "name": "multiply_632",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_631"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf805110), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 632
        },
        "multiply_694": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_695",
                "constant_2559"
            ],
            "ir": "pybuda",
            "name": "multiply_694",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_693"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb4f1e0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 694
        },
        "multiply_756": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_757",
                "constant_2525"
            ],
            "ir": "pybuda",
            "name": "multiply_756",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27ff1540), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 756
        },
        "multiply_818": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_819",
                "constant_2491"
            ],
            "ir": "pybuda",
            "name": "multiply_818",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_817"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fcd060), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 818
        },
        "multiply_880": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_881",
                "constant_2457"
            ],
            "ir": "pybuda",
            "name": "multiply_880",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f69850), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 880
        },
        "multiply_942": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "reshape_943",
                "constant_2423"
            ],
            "ir": "pybuda",
            "name": "multiply_942",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_941"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d3100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 942
        },
        "nn.batch_matmul_1006": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1007",
                "transpose_2375"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1006",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1005"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1006
        },
        "nn.batch_matmul_1059": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1060",
                "transpose_2356"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1059",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1058"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1059
        },
        "nn.batch_matmul_1068": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1069",
                "transpose_2341"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1068",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1067"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1068
        },
        "nn.batch_matmul_1121": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1122",
                "transpose_2322"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1121",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1120"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1121
        },
        "nn.batch_matmul_1130": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1131",
                "transpose_2307"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1130",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1129"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1130
        },
        "nn.batch_matmul_1183": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1184",
                "transpose_2288"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1183",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1182"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1183
        },
        "nn.batch_matmul_1192": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1193",
                "transpose_2273"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1192",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1192
        },
        "nn.batch_matmul_1245": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1246",
                "transpose_2254"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1245",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1244"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1245
        },
        "nn.batch_matmul_1254": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1255",
                "transpose_2239"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1254",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1253"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1254
        },
        "nn.batch_matmul_1307": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1308",
                "transpose_2220"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1307",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1306"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1307
        },
        "nn.batch_matmul_1316": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1317",
                "transpose_2205"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1316",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1315"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1316
        },
        "nn.batch_matmul_1369": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1370",
                "transpose_2186"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1369",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1368"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1369
        },
        "nn.batch_matmul_1378": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1379",
                "transpose_2171"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1378",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1377"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1378
        },
        "nn.batch_matmul_1431": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1432",
                "transpose_2152"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1431",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1431
        },
        "nn.batch_matmul_1440": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1441",
                "transpose_2137"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1440",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1440
        },
        "nn.batch_matmul_1493": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1494",
                "transpose_2118"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1493",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1492"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1493
        },
        "nn.batch_matmul_1502": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1503",
                "transpose_2103"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1502",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1502
        },
        "nn.batch_matmul_1555": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1556",
                "transpose_2084"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1555",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1554"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1555
        },
        "nn.batch_matmul_1564": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1565",
                "transpose_2069"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1564",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1564
        },
        "nn.batch_matmul_1617": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1618",
                "transpose_2050"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1617",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1617
        },
        "nn.batch_matmul_1626": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1627",
                "transpose_2035"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1626",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1625"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1626
        },
        "nn.batch_matmul_1679": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1680",
                "transpose_2016"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1679",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1679
        },
        "nn.batch_matmul_1688": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1689",
                "transpose_2001"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1688",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1688
        },
        "nn.batch_matmul_1741": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1742",
                "transpose_1982"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1741",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1740"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1741
        },
        "nn.batch_matmul_1750": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1751",
                "transpose_1967"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1750",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1750
        },
        "nn.batch_matmul_1803": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1804",
                "transpose_1948"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1803",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1802"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1803
        },
        "nn.batch_matmul_1812": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1813",
                "transpose_1933"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1812",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1812
        },
        "nn.batch_matmul_1865": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1866",
                "transpose_1914"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1865",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1864"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1865
        },
        "nn.batch_matmul_1874": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1875",
                "transpose_1893"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1874",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1873"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1874
        },
        "nn.batch_matmul_439": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_440",
                "transpose_2696"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_439",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 439
        },
        "nn.batch_matmul_448": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_449",
                "transpose_2681"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_448",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 448
        },
        "nn.batch_matmul_501": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_502",
                "transpose_2662"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_501",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 501
        },
        "nn.batch_matmul_510": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_511",
                "transpose_2647"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_510",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_509"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 510
        },
        "nn.batch_matmul_563": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_564",
                "transpose_2628"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_563",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 563
        },
        "nn.batch_matmul_572": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_573",
                "transpose_2613"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_572",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 572
        },
        "nn.batch_matmul_625": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_626",
                "transpose_2594"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_625",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 625
        },
        "nn.batch_matmul_634": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_635",
                "transpose_2579"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_634",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 634
        },
        "nn.batch_matmul_687": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_688",
                "transpose_2560"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_687",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 687
        },
        "nn.batch_matmul_696": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_697",
                "transpose_2545"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 696
        },
        "nn.batch_matmul_749": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_750",
                "transpose_2526"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_749",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_748"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 749
        },
        "nn.batch_matmul_758": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_759",
                "transpose_2511"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_758",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 758
        },
        "nn.batch_matmul_811": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_812",
                "transpose_2492"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_811",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 811
        },
        "nn.batch_matmul_820": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_821",
                "transpose_2477"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_820",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 820
        },
        "nn.batch_matmul_873": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_874",
                "transpose_2458"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_873",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_872"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 873
        },
        "nn.batch_matmul_882": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_883",
                "transpose_2443"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_882",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 882
        },
        "nn.batch_matmul_935": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_936",
                "transpose_2424"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_935",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 935
        },
        "nn.batch_matmul_944": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_945",
                "transpose_2409"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_944",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_943"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 944
        },
        "nn.batch_matmul_997": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_998",
                "transpose_2390"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_997",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 997
        },
        "nn.dense_1017": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_61_0",
                "transpose_1018"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1017",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1017
        },
        "nn.dense_1030": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_62_0",
                "transpose_1031"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1030",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1030
        },
        "nn.dense_1039": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_63_0",
                "transpose_1040"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1039",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1039
        },
        "nn.dense_1052": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_64_0",
                "transpose_1053"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1052",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1052
        },
        "nn.dense_1079": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_67_0",
                "transpose_1080"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1079",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1079
        },
        "nn.dense_1092": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_68_0",
                "transpose_1093"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1092",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1092
        },
        "nn.dense_1101": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_69_0",
                "transpose_1102"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1101",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1101
        },
        "nn.dense_1114": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_70_0",
                "transpose_1115"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1114",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1114
        },
        "nn.dense_1141": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_73_0",
                "transpose_1142"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1141",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1141
        },
        "nn.dense_1154": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_74_0",
                "transpose_1155"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1154",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1154
        },
        "nn.dense_1163": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_75_0",
                "transpose_1164"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1163",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1163
        },
        "nn.dense_1176": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_76_0",
                "transpose_1177"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1176",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1176
        },
        "nn.dense_1203": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_79_0",
                "transpose_1204"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1203",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1203
        },
        "nn.dense_1216": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_80_0",
                "transpose_1217"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1216",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1216
        },
        "nn.dense_1225": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_81_0",
                "transpose_1226"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1225",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1225
        },
        "nn.dense_1238": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_82_0",
                "transpose_1239"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1238",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1238
        },
        "nn.dense_1265": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_85_0",
                "transpose_1266"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1265",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1265
        },
        "nn.dense_1278": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_86_0",
                "transpose_1279"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1278",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1278
        },
        "nn.dense_1287": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_87_0",
                "transpose_1288"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1287",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1287
        },
        "nn.dense_1300": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_88_0",
                "transpose_1301"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1300",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1300
        },
        "nn.dense_1327": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_91_0",
                "transpose_1328"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1327",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1327
        },
        "nn.dense_1340": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_92_0",
                "transpose_1341"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1340",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1340
        },
        "nn.dense_1349": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_93_0",
                "transpose_1350"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1349",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1349
        },
        "nn.dense_1362": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_94_0",
                "transpose_1363"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1362",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1362
        },
        "nn.dense_1389": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_97_0",
                "transpose_1390"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1389",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1389
        },
        "nn.dense_1402": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_98_0",
                "transpose_1403"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1402",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1402
        },
        "nn.dense_1411": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_99_0",
                "transpose_1412"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1411",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1411
        },
        "nn.dense_1424": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_100_0",
                "transpose_1425"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1424",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1424
        },
        "nn.dense_1451": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_103_0",
                "transpose_1452"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1451",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1451
        },
        "nn.dense_1464": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_104_0",
                "transpose_1465"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1464",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1464
        },
        "nn.dense_1473": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_105_0",
                "transpose_1474"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1473",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1473
        },
        "nn.dense_1486": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_106_0",
                "transpose_1487"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1486",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1486
        },
        "nn.dense_1513": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_109_0",
                "transpose_1514"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1513",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1513
        },
        "nn.dense_1526": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_110_0",
                "transpose_1527"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1526",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1526
        },
        "nn.dense_1535": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_111_0",
                "transpose_1536"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1535",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1535
        },
        "nn.dense_1548": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_112_0",
                "transpose_1549"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1548",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1548
        },
        "nn.dense_1575": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_115_0",
                "transpose_1576"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1575",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1575
        },
        "nn.dense_1588": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_116_0",
                "transpose_1589"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1588",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1588
        },
        "nn.dense_1597": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_117_0",
                "transpose_1598"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1597",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1597
        },
        "nn.dense_1610": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_118_0",
                "transpose_1611"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1610",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1610
        },
        "nn.dense_1637": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_121_0",
                "transpose_1638"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1637",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1637
        },
        "nn.dense_1650": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_122_0",
                "transpose_1651"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1650",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1650
        },
        "nn.dense_1659": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_123_0",
                "transpose_1660"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1659",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1659
        },
        "nn.dense_1672": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_124_0",
                "transpose_1673"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1672",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1672
        },
        "nn.dense_1699": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_127_0",
                "transpose_1700"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1699",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1699
        },
        "nn.dense_1712": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_128_0",
                "transpose_1713"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1712",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1712
        },
        "nn.dense_1721": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_129_0",
                "transpose_1722"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1721",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1721
        },
        "nn.dense_1734": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_130_0",
                "transpose_1735"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1734",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1734
        },
        "nn.dense_1761": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_133_0",
                "transpose_1762"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1761",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1761
        },
        "nn.dense_1774": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_134_0",
                "transpose_1775"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1774",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1774
        },
        "nn.dense_1783": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_135_0",
                "transpose_1784"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1783",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1783
        },
        "nn.dense_1796": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_136_0",
                "transpose_1797"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1796",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1796
        },
        "nn.dense_1823": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_139_0",
                "transpose_1824"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1823",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1823
        },
        "nn.dense_1836": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_140_0",
                "transpose_1837"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1836",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1836
        },
        "nn.dense_1845": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_141_0",
                "transpose_1846"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1845",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1845
        },
        "nn.dense_1858": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_142_0",
                "transpose_1859"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1858",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1858
        },
        "nn.dense_1885": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_145_0",
                "transpose_1886"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1885",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1885
        },
        "nn.dense_1904": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_144_0",
                "transpose_1905"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1904",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1904
        },
        "nn.dense_1926": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_143_0",
                "transpose_1927"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1926",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1926
        },
        "nn.dense_1944": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_138_0",
                "transpose_1945"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1944",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1944
        },
        "nn.dense_1960": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_137_0",
                "transpose_1961"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1960",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1960
        },
        "nn.dense_1978": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_132_0",
                "transpose_1979"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1978",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1978
        },
        "nn.dense_1994": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_131_0",
                "transpose_1995"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1994",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1994
        },
        "nn.dense_2012": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_126_0",
                "transpose_2013"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2012",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2012
        },
        "nn.dense_2028": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_125_0",
                "transpose_2029"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2028",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2028
        },
        "nn.dense_2046": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_120_0",
                "transpose_2047"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2046",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2046
        },
        "nn.dense_2062": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_119_0",
                "transpose_2063"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2062",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2062
        },
        "nn.dense_2080": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_114_0",
                "transpose_2081"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2080",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2080
        },
        "nn.dense_2096": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_113_0",
                "transpose_2097"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2096",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2096
        },
        "nn.dense_2114": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_108_0",
                "transpose_2115"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2114",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2114
        },
        "nn.dense_2130": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_107_0",
                "transpose_2131"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2130",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2130
        },
        "nn.dense_2148": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_102_0",
                "transpose_2149"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2148",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2148
        },
        "nn.dense_2164": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_101_0",
                "transpose_2165"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2164",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2164
        },
        "nn.dense_2182": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_96_0",
                "transpose_2183"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2182",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2182
        },
        "nn.dense_2198": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_95_0",
                "transpose_2199"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2198",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2198
        },
        "nn.dense_2216": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_90_0",
                "transpose_2217"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2216",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2216
        },
        "nn.dense_2232": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_89_0",
                "transpose_2233"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2232",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2232
        },
        "nn.dense_2250": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_84_0",
                "transpose_2251"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2250",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2250
        },
        "nn.dense_2266": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_83_0",
                "transpose_2267"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2266",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2266
        },
        "nn.dense_2284": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_78_0",
                "transpose_2285"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2284",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2284
        },
        "nn.dense_2300": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_77_0",
                "transpose_2301"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2300",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2300
        },
        "nn.dense_2318": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_72_0",
                "transpose_2319"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2318",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2318
        },
        "nn.dense_2334": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_71_0",
                "transpose_2335"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2334",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2334
        },
        "nn.dense_2352": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_66_0",
                "transpose_2353"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2352",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2352
        },
        "nn.dense_2368": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_65_0",
                "transpose_2369"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2368",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2368
        },
        "nn.dense_2386": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_60_0",
                "transpose_2387"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2386",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2386
        },
        "nn.dense_2402": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_59_0",
                "transpose_2403"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2402",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2402
        },
        "nn.dense_2420": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_54_0",
                "transpose_2421"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2420",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2420
        },
        "nn.dense_2436": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_53_0",
                "transpose_2437"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2436",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2436
        },
        "nn.dense_2454": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_48_0",
                "transpose_2455"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2454",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2454
        },
        "nn.dense_2470": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_47_0",
                "transpose_2471"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2470",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2470
        },
        "nn.dense_2488": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_42_0",
                "transpose_2489"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2488",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2488
        },
        "nn.dense_2504": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_41_0",
                "transpose_2505"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2504",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2504
        },
        "nn.dense_2522": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_36_0",
                "transpose_2523"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2522",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2522
        },
        "nn.dense_2538": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_35_0",
                "transpose_2539"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2538",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2538
        },
        "nn.dense_2556": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_30_0",
                "transpose_2557"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2556",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2556
        },
        "nn.dense_2572": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_29_0",
                "transpose_2573"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2572",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2572
        },
        "nn.dense_2590": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_24_0",
                "transpose_2591"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2590",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2590
        },
        "nn.dense_2606": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_23_0",
                "transpose_2607"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2606",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2606
        },
        "nn.dense_2624": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_18_0",
                "transpose_2625"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2624",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2624
        },
        "nn.dense_2640": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_17_0",
                "transpose_2641"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2640",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2640
        },
        "nn.dense_2658": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_12_0",
                "transpose_2659"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2658",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2658
        },
        "nn.dense_2674": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_11_0",
                "transpose_2675"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2674",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2674
        },
        "nn.dense_2692": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_6_0",
                "transpose_2693"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2692",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2692
        },
        "nn.dense_2708": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_5_0",
                "transpose_2709"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2708",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2708
        },
        "nn.dense_2723": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_0_0",
                "transpose_2724"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2723",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "None",
            "type": "nn.dense",
            "unique_id": 2723
        },
        "nn.dense_397": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_1_0",
                "transpose_398"
            ],
            "ir": "pybuda",
            "name": "nn.dense_397",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "None",
            "type": "nn.dense",
            "unique_id": 397
        },
        "nn.dense_410": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_2_0",
                "transpose_411"
            ],
            "ir": "pybuda",
            "name": "nn.dense_410",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 410
        },
        "nn.dense_419": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_3_0",
                "transpose_420"
            ],
            "ir": "pybuda",
            "name": "nn.dense_419",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 419
        },
        "nn.dense_432": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_4_0",
                "transpose_433"
            ],
            "ir": "pybuda",
            "name": "nn.dense_432",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 432
        },
        "nn.dense_459": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_7_0",
                "transpose_460"
            ],
            "ir": "pybuda",
            "name": "nn.dense_459",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 459
        },
        "nn.dense_472": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_8_0",
                "transpose_473"
            ],
            "ir": "pybuda",
            "name": "nn.dense_472",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 472
        },
        "nn.dense_481": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_9_0",
                "transpose_482"
            ],
            "ir": "pybuda",
            "name": "nn.dense_481",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 481
        },
        "nn.dense_494": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_10_0",
                "transpose_495"
            ],
            "ir": "pybuda",
            "name": "nn.dense_494",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 494
        },
        "nn.dense_521": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_13_0",
                "transpose_522"
            ],
            "ir": "pybuda",
            "name": "nn.dense_521",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 521
        },
        "nn.dense_534": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_14_0",
                "transpose_535"
            ],
            "ir": "pybuda",
            "name": "nn.dense_534",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 534
        },
        "nn.dense_543": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_15_0",
                "transpose_544"
            ],
            "ir": "pybuda",
            "name": "nn.dense_543",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 543
        },
        "nn.dense_556": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_16_0",
                "transpose_557"
            ],
            "ir": "pybuda",
            "name": "nn.dense_556",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 556
        },
        "nn.dense_583": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_19_0",
                "transpose_584"
            ],
            "ir": "pybuda",
            "name": "nn.dense_583",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 583
        },
        "nn.dense_596": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_20_0",
                "transpose_597"
            ],
            "ir": "pybuda",
            "name": "nn.dense_596",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 596
        },
        "nn.dense_605": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_21_0",
                "transpose_606"
            ],
            "ir": "pybuda",
            "name": "nn.dense_605",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 605
        },
        "nn.dense_618": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_22_0",
                "transpose_619"
            ],
            "ir": "pybuda",
            "name": "nn.dense_618",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 618
        },
        "nn.dense_645": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_25_0",
                "transpose_646"
            ],
            "ir": "pybuda",
            "name": "nn.dense_645",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 645
        },
        "nn.dense_658": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_26_0",
                "transpose_659"
            ],
            "ir": "pybuda",
            "name": "nn.dense_658",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 658
        },
        "nn.dense_667": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_27_0",
                "transpose_668"
            ],
            "ir": "pybuda",
            "name": "nn.dense_667",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 667
        },
        "nn.dense_680": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_28_0",
                "transpose_681"
            ],
            "ir": "pybuda",
            "name": "nn.dense_680",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 680
        },
        "nn.dense_707": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_31_0",
                "transpose_708"
            ],
            "ir": "pybuda",
            "name": "nn.dense_707",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 707
        },
        "nn.dense_720": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_32_0",
                "transpose_721"
            ],
            "ir": "pybuda",
            "name": "nn.dense_720",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 720
        },
        "nn.dense_729": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_33_0",
                "transpose_730"
            ],
            "ir": "pybuda",
            "name": "nn.dense_729",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 729
        },
        "nn.dense_742": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_34_0",
                "transpose_743"
            ],
            "ir": "pybuda",
            "name": "nn.dense_742",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 742
        },
        "nn.dense_769": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_37_0",
                "transpose_770"
            ],
            "ir": "pybuda",
            "name": "nn.dense_769",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 769
        },
        "nn.dense_782": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_38_0",
                "transpose_783"
            ],
            "ir": "pybuda",
            "name": "nn.dense_782",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 782
        },
        "nn.dense_791": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_39_0",
                "transpose_792"
            ],
            "ir": "pybuda",
            "name": "nn.dense_791",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 791
        },
        "nn.dense_804": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_40_0",
                "transpose_805"
            ],
            "ir": "pybuda",
            "name": "nn.dense_804",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 804
        },
        "nn.dense_831": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_43_0",
                "transpose_832"
            ],
            "ir": "pybuda",
            "name": "nn.dense_831",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 831
        },
        "nn.dense_844": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_44_0",
                "transpose_845"
            ],
            "ir": "pybuda",
            "name": "nn.dense_844",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 844
        },
        "nn.dense_853": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_45_0",
                "transpose_854"
            ],
            "ir": "pybuda",
            "name": "nn.dense_853",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 853
        },
        "nn.dense_866": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_46_0",
                "transpose_867"
            ],
            "ir": "pybuda",
            "name": "nn.dense_866",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 866
        },
        "nn.dense_893": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_49_0",
                "transpose_894"
            ],
            "ir": "pybuda",
            "name": "nn.dense_893",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 893
        },
        "nn.dense_906": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_50_0",
                "transpose_907"
            ],
            "ir": "pybuda",
            "name": "nn.dense_906",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 906
        },
        "nn.dense_915": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_51_0",
                "transpose_916"
            ],
            "ir": "pybuda",
            "name": "nn.dense_915",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 915
        },
        "nn.dense_928": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_52_0",
                "transpose_929"
            ],
            "ir": "pybuda",
            "name": "nn.dense_928",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 928
        },
        "nn.dense_955": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_55_0",
                "transpose_956"
            ],
            "ir": "pybuda",
            "name": "nn.dense_955",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 955
        },
        "nn.dense_968": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_56_0",
                "transpose_969"
            ],
            "ir": "pybuda",
            "name": "nn.dense_968",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 968
        },
        "nn.dense_977": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_57_0",
                "transpose_978"
            ],
            "ir": "pybuda",
            "name": "nn.dense_977",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 977
        },
        "nn.dense_990": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_58_0",
                "transpose_991"
            ],
            "ir": "pybuda",
            "name": "nn.dense_990",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 990
        },
        "nn.dropout_1001": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_29_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1001",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1001
        },
        "nn.dropout_1024": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_30_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1024",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1024
        },
        "nn.dropout_1046": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_31_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1046",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1046
        },
        "nn.dropout_1063": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_32_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1063",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1063
        },
        "nn.dropout_1086": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_33_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1086",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1086
        },
        "nn.dropout_1108": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_34_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1108",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1108
        },
        "nn.dropout_1125": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_35_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1125",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1125
        },
        "nn.dropout_1148": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_36_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1148",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1148
        },
        "nn.dropout_1170": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_37_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1170",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1170
        },
        "nn.dropout_1187": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_38_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1187",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1187
        },
        "nn.dropout_1210": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_39_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1210",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1210
        },
        "nn.dropout_1232": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_40_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1232",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1232
        },
        "nn.dropout_1249": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_41_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1249",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1249
        },
        "nn.dropout_1272": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_42_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1272",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1272
        },
        "nn.dropout_1294": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_43_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1294",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1294
        },
        "nn.dropout_1311": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_44_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1311",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1311
        },
        "nn.dropout_1334": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_45_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1334",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1334
        },
        "nn.dropout_1356": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_46_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1356",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1356
        },
        "nn.dropout_1373": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_47_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1373",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1373
        },
        "nn.dropout_1396": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_48_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1396",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1396
        },
        "nn.dropout_1418": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_49_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1418",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1418
        },
        "nn.dropout_1435": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_50_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1435",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1435
        },
        "nn.dropout_1458": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_51_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1458",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1458
        },
        "nn.dropout_1480": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_52_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1480",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1480
        },
        "nn.dropout_1497": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_53_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1497",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1497
        },
        "nn.dropout_1520": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_54_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1520",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1520
        },
        "nn.dropout_1542": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_55_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1542",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1542
        },
        "nn.dropout_1559": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_56_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1559",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1559
        },
        "nn.dropout_1582": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_57_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1582",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1582
        },
        "nn.dropout_1604": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_58_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1604",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1604
        },
        "nn.dropout_1621": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_59_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1621",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1621
        },
        "nn.dropout_1644": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_60_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1644",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1644
        },
        "nn.dropout_1666": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_61_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1666",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1666
        },
        "nn.dropout_1683": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_62_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1683",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1683
        },
        "nn.dropout_1706": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_63_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1706",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1706
        },
        "nn.dropout_1728": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_64_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1728",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1728
        },
        "nn.dropout_1745": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_65_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1745",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1745
        },
        "nn.dropout_1768": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_66_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1768",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1768
        },
        "nn.dropout_1790": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_67_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1790",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1790
        },
        "nn.dropout_1807": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_68_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1807",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1807
        },
        "nn.dropout_1830": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_69_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1830",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1830
        },
        "nn.dropout_1852": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_70_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1852",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1852
        },
        "nn.dropout_1869": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_71_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1869",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1869
        },
        "nn.dropout_1890": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_72_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1890",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1890
        },
        "nn.dropout_404": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_0_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_404",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 404
        },
        "nn.dropout_426": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_1_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_426",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 426
        },
        "nn.dropout_443": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_2_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_443",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 443
        },
        "nn.dropout_466": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_3_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_466",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 466
        },
        "nn.dropout_488": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_4_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_488",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 488
        },
        "nn.dropout_505": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_5_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_505",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 505
        },
        "nn.dropout_528": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_6_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_528",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 528
        },
        "nn.dropout_550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_7_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_550",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 550
        },
        "nn.dropout_567": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_8_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_567",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 567
        },
        "nn.dropout_590": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_9_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_590",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 590
        },
        "nn.dropout_612": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_10_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_612",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 612
        },
        "nn.dropout_629": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_11_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_629",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 629
        },
        "nn.dropout_652": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_12_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_652",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 652
        },
        "nn.dropout_674": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_13_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_674",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 674
        },
        "nn.dropout_691": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_14_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_691",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 691
        },
        "nn.dropout_714": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_15_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_714",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 714
        },
        "nn.dropout_736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_16_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_736",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 736
        },
        "nn.dropout_753": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_17_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_753",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 753
        },
        "nn.dropout_776": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_18_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_776",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 776
        },
        "nn.dropout_798": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_19_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_798",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 798
        },
        "nn.dropout_815": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_20_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_815",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 815
        },
        "nn.dropout_838": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_21_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_838",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 838
        },
        "nn.dropout_860": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_22_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_860",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 860
        },
        "nn.dropout_877": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_23_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_877",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 877
        },
        "nn.dropout_900": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_24_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_900",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 900
        },
        "nn.dropout_922": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_25_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_922",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 922
        },
        "nn.dropout_939": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_26_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_939",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 939
        },
        "nn.dropout_962": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_27_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_962",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 962
        },
        "nn.dropout_984": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_28_0"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_984",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 984
        },
        "nn.softmax_1002": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1003"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1002",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x280119a0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1002
        },
        "nn.softmax_1064": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1065"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1064",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1061"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f55ff0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1064
        },
        "nn.softmax_1126": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1127"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1126",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1123"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98d0b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1126
        },
        "nn.softmax_1188": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1189"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1188",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1185"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf778820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1188
        },
        "nn.softmax_1250": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1251"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1250",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1247"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364e52c0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1250
        },
        "nn.softmax_1312": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1313"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1312",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1309"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36479bd0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1312
        },
        "nn.softmax_1374": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1375"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1374",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1371"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c23820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1374
        },
        "nn.softmax_1436": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1437"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1436",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1433"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bdeb50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1436
        },
        "nn.softmax_1498": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1499"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1498",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511de0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1498
        },
        "nn.softmax_1560": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1561"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1560",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1557"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49d340), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1560
        },
        "nn.softmax_1622": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1623"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1622",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1619"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c25db0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1622
        },
        "nn.softmax_1684": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1685"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1684",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c1d990), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1684
        },
        "nn.softmax_1746": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1747"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1746",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1743"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b65130), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1746
        },
        "nn.softmax_1808": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1809"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1808",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1805"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98a870), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1808
        },
        "nn.softmax_1870": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1871"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1870",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_1867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9af750), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1870
        },
        "nn.softmax_444": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_445"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_444",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37bd2dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 444
        },
        "nn.softmax_506": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_507"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_506",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9422d960), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 506
        },
        "nn.softmax_568": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_569"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_568",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7b0540), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 568
        },
        "nn.softmax_630": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_631"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_630",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126863e0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 630
        },
        "nn.softmax_692": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_693"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_692",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1270), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 692
        },
        "nn.softmax_754": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_755"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_754",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9723b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 754
        },
        "nn.softmax_816": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_817"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_816",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28027dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 816
        },
        "nn.softmax_878": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_879"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_878",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150e2880), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 878
        },
        "nn.softmax_940": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_941"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_940",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.dropout_937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15044f50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 940
        },
        "pybuda.dropout_1022": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1025"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1022",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xf76cd20), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1022
        },
        "pybuda.dropout_1044": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1047"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1044",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1043"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xf78e3a0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1044
        },
        "pybuda.dropout_1061": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1064"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1061",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1060"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x27f4bd60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1061
        },
        "pybuda.dropout_1084": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1087"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1084",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1083"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x3652b110), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1084
        },
        "pybuda.dropout_1106": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1109"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1106",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1105"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xd990740), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1106
        },
        "pybuda.dropout_1123": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1126"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1123",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0xf82ef80), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1123
        },
        "pybuda.dropout_1146": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1149"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1146",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1145"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a4d71b0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1146
        },
        "pybuda.dropout_1168": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1171"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1168",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1167"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xd960ce0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1168
        },
        "pybuda.dropout_1185": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1188"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1185",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1184"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0xd955810), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1185
        },
        "pybuda.dropout_1208": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1211"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1208",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1207"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x31bcda60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1208
        },
        "pybuda.dropout_1230": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1233"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1230",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1229"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19b4f1e0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1230
        },
        "pybuda.dropout_1247": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1250"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1247",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1246"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x364d3580), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1247
        },
        "pybuda.dropout_1270": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1273"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1270",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a4ce690), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1270
        },
        "pybuda.dropout_1292": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1295"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1292",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1291"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x3649de10), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1292
        },
        "pybuda.dropout_1309": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1312"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1309",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1308"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x364995c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1309
        },
        "pybuda.dropout_1332": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1335"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1332",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1331"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19bfdda0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1332
        },
        "pybuda.dropout_1354": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1357"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1354",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1353"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19ba6410), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1354
        },
        "pybuda.dropout_1371": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1374"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1371",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1370"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x36453c60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1371
        },
        "pybuda.dropout_1394": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1397"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1394",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1393"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a463730), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1394
        },
        "pybuda.dropout_1416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1419"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1416",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a501f60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1416
        },
        "pybuda.dropout_1433": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1436"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1433",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x31b776c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1433
        },
        "pybuda.dropout_1456": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1459"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1456",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a4d50c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1456
        },
        "pybuda.dropout_1478": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1481"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1478",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19bc4850), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1478
        },
        "pybuda.dropout_1495": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1498"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1495",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x31b62330), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1495
        },
        "pybuda.dropout_1518": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1521"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1518",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a4372e0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1518
        },
        "pybuda.dropout_1540": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1543"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1540",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a4b3070), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1540
        },
        "pybuda.dropout_1557": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1560"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1557",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1556"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x2a4eb630), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1557
        },
        "pybuda.dropout_1580": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1583"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1580",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19be8ca0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1580
        },
        "pybuda.dropout_1602": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1605"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1602",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x2a482990), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1602
        },
        "pybuda.dropout_1619": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1622"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1619",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1618"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x2a468520), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1619
        },
        "pybuda.dropout_1642": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1645"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1642",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xda1c010), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1642
        },
        "pybuda.dropout_1664": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1667"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1664",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x19b66fb0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1664
        },
        "pybuda.dropout_1681": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1684"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1681",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x19b5dc00), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1681
        },
        "pybuda.dropout_1704": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1707"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1704",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x917e55c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1704
        },
        "pybuda.dropout_1726": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1729"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1726",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xd9c5630), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1726
        },
        "pybuda.dropout_1743": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1746"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1743",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1742"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0xd99b320), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1743
        },
        "pybuda.dropout_1766": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1769"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1766",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1765"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x917b2ca0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1766
        },
        "pybuda.dropout_1788": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1791"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1788",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1787"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xda0e7c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1788
        },
        "pybuda.dropout_1805": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1808"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1805",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1804"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0xda28150), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1805
        },
        "pybuda.dropout_1828": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1831"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1828",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1827"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xd9874c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1828
        },
        "pybuda.dropout_1850": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1853"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1850",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x9182d6e0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1850
        },
        "pybuda.dropout_1867": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1870"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1867",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1866"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0xd94c130), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1867
        },
        "pybuda.dropout_1888": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1891"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_1888",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1849",
                "reshape_1887"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.dropout.Dropout::dropout, 0x91828080), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 1888
        },
        "pybuda.dropout_402": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_405"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_402",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_401"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0xf74ccb0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 402
        },
        "pybuda.dropout_424": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_427"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_424",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x37ba65c0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 424
        },
        "pybuda.dropout_441": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_444"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_441",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_440"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x37ba3c60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 441
        },
        "pybuda.dropout_464": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_467"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_464",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x942364d0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 464
        },
        "pybuda.dropout_486": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_489"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_486",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_485"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x94226b30), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 486
        },
        "pybuda.dropout_503": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_506"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_503",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x3645fa60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 503
        },
        "pybuda.dropout_526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_529"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_526",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_525"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x1269ec20), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 526
        },
        "pybuda.dropout_548": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_551"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_548",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x941aeab0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 548
        },
        "pybuda.dropout_565": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_568"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_565",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x151275a0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 565
        },
        "pybuda.dropout_588": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_591"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_588",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x1262f750), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 588
        },
        "pybuda.dropout_610": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_613"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_610",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x941543f0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 610
        },
        "pybuda.dropout_627": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_630"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_627",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x12632f80), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 627
        },
        "pybuda.dropout_650": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_653"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_650",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_649"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x28012130), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 650
        },
        "pybuda.dropout_672": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_675"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_672",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x1504e1e0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 672
        },
        "pybuda.dropout_689": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_692"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_689",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x12645ff0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 689
        },
        "pybuda.dropout_712": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_715"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_712",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x1507bad0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 712
        },
        "pybuda.dropout_734": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_737"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_734",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x36497de0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 734
        },
        "pybuda.dropout_751": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_754"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_751",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x941fcdd0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 751
        },
        "pybuda.dropout_774": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_777"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_774",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_773"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x151239a0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 774
        },
        "pybuda.dropout_796": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_799"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_796",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_795"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x91826640), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 796
        },
        "pybuda.dropout_813": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_816"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_813",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_812"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x94156de0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 813
        },
        "pybuda.dropout_836": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_839"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_836",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_835"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x27f7c5d0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 836
        },
        "pybuda.dropout_858": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_861"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_858",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_857"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x365099d0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 858
        },
        "pybuda.dropout_875": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_878"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_875",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x31bd7bf0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 875
        },
        "pybuda.dropout_898": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_901"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_898",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x3650d0d0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 898
        },
        "pybuda.dropout_920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_923"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_920",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_919"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x15068530), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 920
        },
        "pybuda.dropout_937": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_940"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_937",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_936"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x2801e1f0), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 937
        },
        "pybuda.dropout_960": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_963"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_960",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x27f57590), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 960
        },
        "pybuda.dropout_982": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_985"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_982",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_981"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.dropout.Dropout::dropout, 0x31c2f530), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 982
        },
        "pybuda.dropout_999": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "pybuda.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1002"
            ],
            "ir": "pybuda",
            "name": "pybuda.dropout_999",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_998"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::dropout, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.dropout.Dropout::dropout, 0x27f8ff60), 0, 0, 0, 0)",
            "type": "pybuda.dropout",
            "unique_id": 999
        },
        "pybuda.hslice_1008": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1012"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1008",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1007"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1008
        },
        "pybuda.hslice_1070": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1074"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1070",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1069"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1070
        },
        "pybuda.hslice_1132": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1136"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1132",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1131"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1132
        },
        "pybuda.hslice_1194": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1198"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1194",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1193"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1194
        },
        "pybuda.hslice_1256": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1260"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1256",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1256
        },
        "pybuda.hslice_1318": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1322"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1318",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1317"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1318
        },
        "pybuda.hslice_1380": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1384"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1380",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1379"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1380
        },
        "pybuda.hslice_1442": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1446"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1442",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1442
        },
        "pybuda.hslice_1504": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1508"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1504",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1504
        },
        "pybuda.hslice_1566": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1570"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1566",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1566
        },
        "pybuda.hslice_1628": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1632"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1628",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1628
        },
        "pybuda.hslice_1690": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1694"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1690",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1690
        },
        "pybuda.hslice_1752": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1756"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1752",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1752
        },
        "pybuda.hslice_1814": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1818"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1814",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1814
        },
        "pybuda.hslice_1876": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1880"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1876",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1876
        },
        "pybuda.hslice_1895": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1899"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1895",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1894"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1895
        },
        "pybuda.hslice_1917": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1921"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1917",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1916"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1917
        },
        "pybuda.hslice_1935": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1939"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1935",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1935
        },
        "pybuda.hslice_1951": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1955"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1951",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1950"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1951
        },
        "pybuda.hslice_1969": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1973"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1969",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1968"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1969
        },
        "pybuda.hslice_1985": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_1989"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_1985",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1984"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 1985
        },
        "pybuda.hslice_2003": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2007"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2003",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2003
        },
        "pybuda.hslice_2019": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2023"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2019",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2018"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2019
        },
        "pybuda.hslice_2037": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2041"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2037",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2036"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2037
        },
        "pybuda.hslice_2053": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2057"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2053",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2052"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2053
        },
        "pybuda.hslice_2071": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2075"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2071",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2071
        },
        "pybuda.hslice_2087": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2091"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2087",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2086"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2087
        },
        "pybuda.hslice_2105": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2109"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2105",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2104"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2105
        },
        "pybuda.hslice_2121": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2125"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2121",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2120"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2121
        },
        "pybuda.hslice_2139": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2143"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2139",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2138"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2139
        },
        "pybuda.hslice_2155": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2159"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2155",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2154"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2155
        },
        "pybuda.hslice_2173": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2177"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2173",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2172"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2173
        },
        "pybuda.hslice_2189": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2193"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2189",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2188"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2189
        },
        "pybuda.hslice_2207": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2211"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2207",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2206"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2207
        },
        "pybuda.hslice_2223": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2227"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2223",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2223
        },
        "pybuda.hslice_2241": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2245"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2241",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2240"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2241
        },
        "pybuda.hslice_2257": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2261"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2257",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2256"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2257
        },
        "pybuda.hslice_2275": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2279"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2275",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2274"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2275
        },
        "pybuda.hslice_2291": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2295"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2291",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2290"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2291
        },
        "pybuda.hslice_2309": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2313"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2309",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2308"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2309
        },
        "pybuda.hslice_2325": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2329"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2325",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2324"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2325
        },
        "pybuda.hslice_2343": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2347"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2343",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2342"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2343
        },
        "pybuda.hslice_2359": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2363"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2359",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2358"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2359
        },
        "pybuda.hslice_2377": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2381"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2377",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2376"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2377
        },
        "pybuda.hslice_2393": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2397"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2393",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2392"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2393
        },
        "pybuda.hslice_2411": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2415"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2411",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2410"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2411
        },
        "pybuda.hslice_2427": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2431"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2427",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2427
        },
        "pybuda.hslice_2445": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2449"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2445",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2445
        },
        "pybuda.hslice_2461": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2465"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2461",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2461
        },
        "pybuda.hslice_2479": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2483"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2479",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2479
        },
        "pybuda.hslice_2495": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2499"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2495",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2495
        },
        "pybuda.hslice_2513": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2517"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2513",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2512"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2513
        },
        "pybuda.hslice_2529": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2533"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2529",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2529
        },
        "pybuda.hslice_2547": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2551"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2547",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2547
        },
        "pybuda.hslice_2563": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2567"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2563",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2563
        },
        "pybuda.hslice_2581": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2585"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2581",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2580"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2581
        },
        "pybuda.hslice_2597": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2601"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2597",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2596"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2597
        },
        "pybuda.hslice_2615": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2619"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2615",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2615
        },
        "pybuda.hslice_2631": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2635"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2631",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2631
        },
        "pybuda.hslice_2649": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2653"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2649",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2649
        },
        "pybuda.hslice_2665": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2669"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2665",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2665
        },
        "pybuda.hslice_2683": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2687"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2683",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2683
        },
        "pybuda.hslice_2699": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_2703"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_2699",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2698"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 2699
        },
        "pybuda.hslice_450": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_454"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_450",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 450
        },
        "pybuda.hslice_512": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_516"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_512",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 512
        },
        "pybuda.hslice_574": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_578"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_574",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_573"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 574
        },
        "pybuda.hslice_636": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_640"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_636",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 636
        },
        "pybuda.hslice_698": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_702"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_698",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 698
        },
        "pybuda.hslice_760": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_764"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_760",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 760
        },
        "pybuda.hslice_822": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_826"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_822",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_821"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 822
        },
        "pybuda.hslice_884": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_888"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_884",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_883"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 884
        },
        "pybuda.hslice_946": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "pybuda.hslice",
            "epoch": 0,
            "input_nodes": [
                "add_950"
            ],
            "ir": "pybuda",
            "name": "pybuda.hslice_946",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_945"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "pybuda.hslice",
            "unique_id": 946
        },
        "pybuda.hstack_1054": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1058"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1054",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1049"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1054
        },
        "pybuda.hstack_1116": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1120"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1116",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1111"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1116
        },
        "pybuda.hstack_1178": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1182"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1178",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1173"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1178
        },
        "pybuda.hstack_1240": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1244"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1240",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1235"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1240
        },
        "pybuda.hstack_1302": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1306"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1302",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1297"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1302
        },
        "pybuda.hstack_1364": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1368"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1364",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1359"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1364
        },
        "pybuda.hstack_1426": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1430"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1426",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1426
        },
        "pybuda.hstack_1488": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1492"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1488",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1488
        },
        "pybuda.hstack_1550": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1554"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1550",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1550
        },
        "pybuda.hstack_1612": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1616"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1612",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1612
        },
        "pybuda.hstack_1674": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1678"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1674",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1674
        },
        "pybuda.hstack_1736": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1740"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1736",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1736
        },
        "pybuda.hstack_1798": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1802"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1798",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1798
        },
        "pybuda.hstack_1860": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_1864"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_1860",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 1860
        },
        "pybuda.hstack_434": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_438"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_434",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 434
        },
        "pybuda.hstack_496": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_500"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_496",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_491"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 496
        },
        "pybuda.hstack_558": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_562"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_558",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 558
        },
        "pybuda.hstack_620": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_624"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_620",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 620
        },
        "pybuda.hstack_682": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_686"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_682",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_677"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 682
        },
        "pybuda.hstack_744": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_748"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_744",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 744
        },
        "pybuda.hstack_806": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_810"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_806",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_801"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 806
        },
        "pybuda.hstack_868": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_872"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_868",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 868
        },
        "pybuda.hstack_930": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_934"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_930",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 930
        },
        "pybuda.hstack_992": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.hstack",
            "epoch": 0,
            "input_nodes": [
                "reshape_996"
            ],
            "ir": "pybuda",
            "name": "pybuda.hstack_992",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "pybuda.hstack",
            "unique_id": 992
        },
        "pybuda.matmul_1014": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1019",
                "transpose_2374"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1014",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1013"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1014
        },
        "pybuda.matmul_1027": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1032",
                "transpose_2373"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1027",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1026"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1027
        },
        "pybuda.matmul_1036": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1041",
                "transpose_2372"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1036",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1036
        },
        "pybuda.matmul_1049": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1054",
                "transpose_2371"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1049",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1048"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1049
        },
        "pybuda.matmul_1076": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1081",
                "transpose_2340"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1076",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1075"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1076
        },
        "pybuda.matmul_1089": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1094",
                "transpose_2339"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1089",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1088"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1089
        },
        "pybuda.matmul_1098": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1103",
                "transpose_2338"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1098",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1097"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1098
        },
        "pybuda.matmul_1111": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1116",
                "transpose_2337"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1111",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1111
        },
        "pybuda.matmul_1138": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1143",
                "transpose_2306"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1138",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1137"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1138
        },
        "pybuda.matmul_1151": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1156",
                "transpose_2305"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1151",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1151
        },
        "pybuda.matmul_1160": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1165",
                "transpose_2304"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1160",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1160
        },
        "pybuda.matmul_1173": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1178",
                "transpose_2303"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1173",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1172"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1173
        },
        "pybuda.matmul_1200": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1205",
                "transpose_2272"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1200",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1199"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1200
        },
        "pybuda.matmul_1213": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1218",
                "transpose_2271"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1213",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1212"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1213
        },
        "pybuda.matmul_1222": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1227",
                "transpose_2270"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1222",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1222
        },
        "pybuda.matmul_1235": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1240",
                "transpose_2269"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1235",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1234"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1235
        },
        "pybuda.matmul_1262": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1267",
                "transpose_2238"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1262",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1261"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1262
        },
        "pybuda.matmul_1275": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1280",
                "transpose_2237"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1275",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1274"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1275
        },
        "pybuda.matmul_1284": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1289",
                "transpose_2236"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1284",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1283"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1284
        },
        "pybuda.matmul_1297": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1302",
                "transpose_2235"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1297",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1296"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1297
        },
        "pybuda.matmul_1324": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1329",
                "transpose_2204"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1324",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1323"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1324
        },
        "pybuda.matmul_1337": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1342",
                "transpose_2203"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1337",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1336"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1337
        },
        "pybuda.matmul_1346": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1351",
                "transpose_2202"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1346",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1345"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1346
        },
        "pybuda.matmul_1359": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1364",
                "transpose_2201"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1359",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1358"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1359
        },
        "pybuda.matmul_1386": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1391",
                "transpose_2170"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1386",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1385"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1386
        },
        "pybuda.matmul_1399": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1404",
                "transpose_2169"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1399",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1399
        },
        "pybuda.matmul_1408": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1413",
                "transpose_2168"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1408",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1408
        },
        "pybuda.matmul_1421": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1426",
                "transpose_2167"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1421",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1420"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1421
        },
        "pybuda.matmul_1448": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1453",
                "transpose_2136"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1448",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1448
        },
        "pybuda.matmul_1461": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1466",
                "transpose_2135"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1461",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1461
        },
        "pybuda.matmul_1470": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1475",
                "transpose_2134"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1470",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1470
        },
        "pybuda.matmul_1483": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1488",
                "transpose_2133"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1483",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1482"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1483
        },
        "pybuda.matmul_1510": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1515",
                "transpose_2102"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1510",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1509"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1510
        },
        "pybuda.matmul_1523": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1528",
                "transpose_2101"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1523",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1523
        },
        "pybuda.matmul_1532": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1537",
                "transpose_2100"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1532",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1532
        },
        "pybuda.matmul_1545": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1550",
                "transpose_2099"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1545",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1544"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1545
        },
        "pybuda.matmul_1572": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1577",
                "transpose_2068"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1572",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1572
        },
        "pybuda.matmul_1585": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1590",
                "transpose_2067"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1585",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1584"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1585
        },
        "pybuda.matmul_1594": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1599",
                "transpose_2066"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1594",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1594
        },
        "pybuda.matmul_1607": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1612",
                "transpose_2065"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1607",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1607
        },
        "pybuda.matmul_1634": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1639",
                "transpose_2034"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1634",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1634
        },
        "pybuda.matmul_1647": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1652",
                "transpose_2033"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1647",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1647
        },
        "pybuda.matmul_1656": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1661",
                "transpose_2032"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1656",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1655"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1656
        },
        "pybuda.matmul_1669": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1674",
                "transpose_2031"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1669",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1668"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1669
        },
        "pybuda.matmul_1696": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1701",
                "transpose_2000"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1696
        },
        "pybuda.matmul_1709": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1714",
                "transpose_1999"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1709",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1709
        },
        "pybuda.matmul_1718": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1723",
                "transpose_1998"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1718",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1718
        },
        "pybuda.matmul_1731": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1736",
                "transpose_1997"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1731",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1730"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1731
        },
        "pybuda.matmul_1758": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1763",
                "transpose_1966"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1758",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1758
        },
        "pybuda.matmul_1771": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1776",
                "transpose_1965"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1771",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1771
        },
        "pybuda.matmul_1780": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1785",
                "transpose_1964"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1780",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1780
        },
        "pybuda.matmul_1793": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1798",
                "transpose_1963"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1793",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1792"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1793
        },
        "pybuda.matmul_1820": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1825",
                "transpose_1932"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1820",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1820
        },
        "pybuda.matmul_1833": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1838",
                "transpose_1931"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1833",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1832"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1833
        },
        "pybuda.matmul_1842": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1847",
                "transpose_1930"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1842",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1842
        },
        "pybuda.matmul_1855": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_1860",
                "transpose_1929"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1855",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1855
        },
        "pybuda.matmul_1882": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1887",
                "transpose_1892"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1882",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1882
        },
        "pybuda.matmul_1901": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1887",
                "transpose_1906"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1901",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1901
        },
        "pybuda.matmul_1923": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1887",
                "transpose_1928"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1923",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1923
        },
        "pybuda.matmul_1941": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1825",
                "transpose_1946"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1941",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1940"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1941
        },
        "pybuda.matmul_1957": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1825",
                "transpose_1962"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1957",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1956"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1957
        },
        "pybuda.matmul_1975": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1763",
                "transpose_1980"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1975",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1975
        },
        "pybuda.matmul_1991": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1763",
                "transpose_1996"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_1991",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1990"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 1991
        },
        "pybuda.matmul_2009": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1701",
                "transpose_2014"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2009",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2008"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2009
        },
        "pybuda.matmul_2025": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1701",
                "transpose_2030"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2025",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2024"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2025
        },
        "pybuda.matmul_2043": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1639",
                "transpose_2048"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2043",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2043
        },
        "pybuda.matmul_2059": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1639",
                "transpose_2064"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2059",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2058"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2059
        },
        "pybuda.matmul_2077": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1577",
                "transpose_2082"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2077",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2076"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2077
        },
        "pybuda.matmul_2093": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1577",
                "transpose_2098"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2093",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2092"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2093
        },
        "pybuda.matmul_2111": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1515",
                "transpose_2116"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2111",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2111
        },
        "pybuda.matmul_2127": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1515",
                "transpose_2132"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2127",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2127
        },
        "pybuda.matmul_2145": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1453",
                "transpose_2150"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2145",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2145
        },
        "pybuda.matmul_2161": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1453",
                "transpose_2166"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2161",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2160"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2161
        },
        "pybuda.matmul_2179": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1391",
                "transpose_2184"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2179",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2178"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2179
        },
        "pybuda.matmul_2195": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1391",
                "transpose_2200"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2195",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2194"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2195
        },
        "pybuda.matmul_2213": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1329",
                "transpose_2218"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2213",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2212"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2213
        },
        "pybuda.matmul_2229": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1329",
                "transpose_2234"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2229",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2228"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2229
        },
        "pybuda.matmul_2247": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1267",
                "transpose_2252"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2247",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2246"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2247
        },
        "pybuda.matmul_2263": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1267",
                "transpose_2268"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2263",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2262"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2263
        },
        "pybuda.matmul_2281": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1205",
                "transpose_2286"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2281",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2280"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2281
        },
        "pybuda.matmul_2297": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1205",
                "transpose_2302"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2297",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2296"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2297
        },
        "pybuda.matmul_2315": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1143",
                "transpose_2320"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2315",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2314"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2315
        },
        "pybuda.matmul_2331": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1143",
                "transpose_2336"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2331",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2330"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2331
        },
        "pybuda.matmul_2349": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1081",
                "transpose_2354"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2349",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2348"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2349
        },
        "pybuda.matmul_2365": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1081",
                "transpose_2370"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2365",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2364"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2365
        },
        "pybuda.matmul_2383": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1019",
                "transpose_2388"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2383",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2382"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2383
        },
        "pybuda.matmul_2399": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1019",
                "transpose_2404"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2399",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2399
        },
        "pybuda.matmul_2417": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_957",
                "transpose_2422"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2417",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2416"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2417
        },
        "pybuda.matmul_2433": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_957",
                "transpose_2438"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2433",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2433
        },
        "pybuda.matmul_2451": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_895",
                "transpose_2456"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2451",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2450"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2451
        },
        "pybuda.matmul_2467": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_895",
                "transpose_2472"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2467",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2467
        },
        "pybuda.matmul_2485": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "transpose_2490"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2485",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2485
        },
        "pybuda.matmul_2501": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "transpose_2506"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2501",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2501
        },
        "pybuda.matmul_2519": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_771",
                "transpose_2524"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2519",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2519
        },
        "pybuda.matmul_2535": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_771",
                "transpose_2540"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2535",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2535
        },
        "pybuda.matmul_2553": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_709",
                "transpose_2558"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2553",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2553
        },
        "pybuda.matmul_2569": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_709",
                "transpose_2574"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2569",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2569
        },
        "pybuda.matmul_2587": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_647",
                "transpose_2592"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2587",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2587
        },
        "pybuda.matmul_2603": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_647",
                "transpose_2608"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2603",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2603
        },
        "pybuda.matmul_2621": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_585",
                "transpose_2626"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2621",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2620"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2621
        },
        "pybuda.matmul_2637": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_585",
                "transpose_2642"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2637",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2637
        },
        "pybuda.matmul_2655": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_523",
                "transpose_2660"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2655",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2655
        },
        "pybuda.matmul_2671": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_523",
                "transpose_2676"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2671",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2671
        },
        "pybuda.matmul_2689": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_461",
                "transpose_2694"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2689",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2689
        },
        "pybuda.matmul_2705": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_461",
                "transpose_2710"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2705",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2704"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 2705
        },
        "pybuda.matmul_2720": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "transpose_2725"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_2720",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2719"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "pybuda.matmul",
            "unique_id": 2720
        },
        "pybuda.matmul_394": {
            "cache": {
                "shape": [
                    384,
                    1
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "transpose_2714"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_394",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_393"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "pybuda.matmul",
            "unique_id": 394
        },
        "pybuda.matmul_407": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_412",
                "transpose_2713"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_407",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 407
        },
        "pybuda.matmul_416": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_421",
                "transpose_2712"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_416",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 416
        },
        "pybuda.matmul_429": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_434",
                "transpose_2711"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_429",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 429
        },
        "pybuda.matmul_456": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_461",
                "transpose_2680"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_456",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 456
        },
        "pybuda.matmul_469": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_474",
                "transpose_2679"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_469",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 469
        },
        "pybuda.matmul_478": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_483",
                "transpose_2678"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_478",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 478
        },
        "pybuda.matmul_491": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_496",
                "transpose_2677"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_491",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 491
        },
        "pybuda.matmul_518": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_523",
                "transpose_2646"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_518",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 518
        },
        "pybuda.matmul_531": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_536",
                "transpose_2645"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_531",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 531
        },
        "pybuda.matmul_540": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_545",
                "transpose_2644"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_540",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 540
        },
        "pybuda.matmul_553": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_558",
                "transpose_2643"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_553",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 553
        },
        "pybuda.matmul_580": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_585",
                "transpose_2612"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_580",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 580
        },
        "pybuda.matmul_593": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_598",
                "transpose_2611"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_593",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 593
        },
        "pybuda.matmul_602": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_607",
                "transpose_2610"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_602",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 602
        },
        "pybuda.matmul_615": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_620",
                "transpose_2609"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_615",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 615
        },
        "pybuda.matmul_642": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_647",
                "transpose_2578"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_642",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 642
        },
        "pybuda.matmul_655": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_660",
                "transpose_2577"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_655",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 655
        },
        "pybuda.matmul_664": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_669",
                "transpose_2576"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_664",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 664
        },
        "pybuda.matmul_677": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_682",
                "transpose_2575"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_677",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 677
        },
        "pybuda.matmul_704": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_709",
                "transpose_2544"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_704",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 704
        },
        "pybuda.matmul_717": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_722",
                "transpose_2543"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_717",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 717
        },
        "pybuda.matmul_726": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_731",
                "transpose_2542"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_726",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 726
        },
        "pybuda.matmul_739": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_744",
                "transpose_2541"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_739",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 739
        },
        "pybuda.matmul_766": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_771",
                "transpose_2510"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_766",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_765"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 766
        },
        "pybuda.matmul_779": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_784",
                "transpose_2509"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_779",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 779
        },
        "pybuda.matmul_788": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_793",
                "transpose_2508"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_788",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_787"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 788
        },
        "pybuda.matmul_801": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_806",
                "transpose_2507"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_801",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_800"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 801
        },
        "pybuda.matmul_828": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "transpose_2476"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_828",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_827"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 828
        },
        "pybuda.matmul_841": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_846",
                "transpose_2475"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_841",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_840"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 841
        },
        "pybuda.matmul_850": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_855",
                "transpose_2474"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_850",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 850
        },
        "pybuda.matmul_863": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_868",
                "transpose_2473"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_863",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 863
        },
        "pybuda.matmul_890": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_895",
                "transpose_2442"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_890",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_889"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 890
        },
        "pybuda.matmul_903": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_908",
                "transpose_2441"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_903",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_902"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 903
        },
        "pybuda.matmul_912": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_917",
                "transpose_2440"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_912",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 912
        },
        "pybuda.matmul_925": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_930",
                "transpose_2439"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_925",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 925
        },
        "pybuda.matmul_952": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_957",
                "transpose_2408"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_952",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_951"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 952
        },
        "pybuda.matmul_965": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_970",
                "transpose_2407"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_965",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_964"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 965
        },
        "pybuda.matmul_974": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_979",
                "transpose_2406"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_974",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_973"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 974
        },
        "pybuda.matmul_987": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "pybuda.matmul",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hstack_992",
                "transpose_2405"
            ],
            "ir": "pybuda",
            "name": "pybuda.matmul_987",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_986"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "pybuda.matmul",
            "unique_id": 987
        },
        "pybuda_6_i0": {
            "cache": {
                "shape": [
                    "1",
                    "384",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "pybuda_6_i0",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1891"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 0
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    "2"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_2716",
                "strided_slice_2727"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 389
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_2715",
                "strided_slice_2726"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 388
        },
        "reshape_1005": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1006"
            ],
            "ir": "pybuda",
            "name": "reshape_1005",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1005
        },
        "reshape_1007": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1008"
            ],
            "ir": "pybuda",
            "name": "reshape_1007",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1007
        },
        "reshape_1011": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_49_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1011",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1010"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1011
        },
        "reshape_1013": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1014"
            ],
            "ir": "pybuda",
            "name": "reshape_1013",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1012"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1013
        },
        "reshape_1019": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1020"
            ],
            "ir": "pybuda",
            "name": "reshape_1019",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1014",
                "pybuda.matmul_2383",
                "pybuda.matmul_2399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1019
        },
        "reshape_1026": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1027"
            ],
            "ir": "pybuda",
            "name": "reshape_1026",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1025"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1026
        },
        "reshape_1032": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1033"
            ],
            "ir": "pybuda",
            "name": "reshape_1032",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1027"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1032
        },
        "reshape_1035": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1036"
            ],
            "ir": "pybuda",
            "name": "reshape_1035",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1034"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1035
        },
        "reshape_1041": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1042"
            ],
            "ir": "pybuda",
            "name": "reshape_1041",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1036"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1041
        },
        "reshape_1048": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1049"
            ],
            "ir": "pybuda",
            "name": "reshape_1048",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1047"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1048
        },
        "reshape_1056": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1057"
            ],
            "ir": "pybuda",
            "name": "reshape_1056",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1056
        },
        "reshape_1058": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1059"
            ],
            "ir": "pybuda",
            "name": "reshape_1058",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1054"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1058
        },
        "reshape_1060": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1061"
            ],
            "ir": "pybuda",
            "name": "reshape_1060",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1060
        },
        "reshape_1067": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1068"
            ],
            "ir": "pybuda",
            "name": "reshape_1067",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1067
        },
        "reshape_1069": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1070"
            ],
            "ir": "pybuda",
            "name": "reshape_1069",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1068"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1069
        },
        "reshape_1073": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_54_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1073",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1072"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1073
        },
        "reshape_1075": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1076"
            ],
            "ir": "pybuda",
            "name": "reshape_1075",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1074"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1075
        },
        "reshape_1081": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1082"
            ],
            "ir": "pybuda",
            "name": "reshape_1081",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1076",
                "pybuda.matmul_2349",
                "pybuda.matmul_2365"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1081
        },
        "reshape_1088": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1089"
            ],
            "ir": "pybuda",
            "name": "reshape_1088",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1087"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1088
        },
        "reshape_1094": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1095"
            ],
            "ir": "pybuda",
            "name": "reshape_1094",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1089"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1094
        },
        "reshape_1097": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1098"
            ],
            "ir": "pybuda",
            "name": "reshape_1097",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1097
        },
        "reshape_1103": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1104"
            ],
            "ir": "pybuda",
            "name": "reshape_1103",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1098"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1103
        },
        "reshape_1110": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1111"
            ],
            "ir": "pybuda",
            "name": "reshape_1110",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1109"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1110
        },
        "reshape_1118": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1119"
            ],
            "ir": "pybuda",
            "name": "reshape_1118",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1118
        },
        "reshape_1120": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1121"
            ],
            "ir": "pybuda",
            "name": "reshape_1120",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1116"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1120
        },
        "reshape_1122": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1123"
            ],
            "ir": "pybuda",
            "name": "reshape_1122",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1121"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1122
        },
        "reshape_1129": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1130"
            ],
            "ir": "pybuda",
            "name": "reshape_1129",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1128"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1129
        },
        "reshape_1131": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1132"
            ],
            "ir": "pybuda",
            "name": "reshape_1131",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1130"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1131
        },
        "reshape_1135": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_59_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1135",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1134"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1135
        },
        "reshape_1137": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1138"
            ],
            "ir": "pybuda",
            "name": "reshape_1137",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1136"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1137
        },
        "reshape_1143": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1144"
            ],
            "ir": "pybuda",
            "name": "reshape_1143",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1138",
                "pybuda.matmul_2315",
                "pybuda.matmul_2331"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1143
        },
        "reshape_1150": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1151"
            ],
            "ir": "pybuda",
            "name": "reshape_1150",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1149"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1150
        },
        "reshape_1156": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1157"
            ],
            "ir": "pybuda",
            "name": "reshape_1156",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1151"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1156
        },
        "reshape_1159": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1160"
            ],
            "ir": "pybuda",
            "name": "reshape_1159",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1158"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1159
        },
        "reshape_1165": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1166"
            ],
            "ir": "pybuda",
            "name": "reshape_1165",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1160"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1165
        },
        "reshape_1172": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1173"
            ],
            "ir": "pybuda",
            "name": "reshape_1172",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1171"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1172
        },
        "reshape_1180": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1181"
            ],
            "ir": "pybuda",
            "name": "reshape_1180",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1180
        },
        "reshape_1182": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1183"
            ],
            "ir": "pybuda",
            "name": "reshape_1182",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1178"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1182
        },
        "reshape_1184": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1185"
            ],
            "ir": "pybuda",
            "name": "reshape_1184",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1183"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1184
        },
        "reshape_1191": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1192"
            ],
            "ir": "pybuda",
            "name": "reshape_1191",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1190"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1191
        },
        "reshape_1193": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1194"
            ],
            "ir": "pybuda",
            "name": "reshape_1193",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1192"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1193
        },
        "reshape_1197": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_64_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1197",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1196"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1197
        },
        "reshape_1199": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1200"
            ],
            "ir": "pybuda",
            "name": "reshape_1199",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1198"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1199
        },
        "reshape_1205": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1206"
            ],
            "ir": "pybuda",
            "name": "reshape_1205",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1200",
                "pybuda.matmul_2281",
                "pybuda.matmul_2297"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1205
        },
        "reshape_1212": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1213"
            ],
            "ir": "pybuda",
            "name": "reshape_1212",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1211"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1212
        },
        "reshape_1218": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1219"
            ],
            "ir": "pybuda",
            "name": "reshape_1218",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1213"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1218
        },
        "reshape_1221": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1222"
            ],
            "ir": "pybuda",
            "name": "reshape_1221",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1220"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1221
        },
        "reshape_1227": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1228"
            ],
            "ir": "pybuda",
            "name": "reshape_1227",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1227
        },
        "reshape_1234": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1235"
            ],
            "ir": "pybuda",
            "name": "reshape_1234",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1233"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1234
        },
        "reshape_1242": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1243"
            ],
            "ir": "pybuda",
            "name": "reshape_1242",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1242
        },
        "reshape_1244": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1245"
            ],
            "ir": "pybuda",
            "name": "reshape_1244",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1240"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1244
        },
        "reshape_1246": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1247"
            ],
            "ir": "pybuda",
            "name": "reshape_1246",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1245"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1246
        },
        "reshape_1253": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1254"
            ],
            "ir": "pybuda",
            "name": "reshape_1253",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1252"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1253
        },
        "reshape_1255": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1256"
            ],
            "ir": "pybuda",
            "name": "reshape_1255",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1254"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1255
        },
        "reshape_1259": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_69_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1259",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1259
        },
        "reshape_1261": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1262"
            ],
            "ir": "pybuda",
            "name": "reshape_1261",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1260"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1261
        },
        "reshape_1267": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1268"
            ],
            "ir": "pybuda",
            "name": "reshape_1267",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1262",
                "pybuda.matmul_2247",
                "pybuda.matmul_2263"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1267
        },
        "reshape_1274": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1275"
            ],
            "ir": "pybuda",
            "name": "reshape_1274",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1273"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1274
        },
        "reshape_1280": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1281"
            ],
            "ir": "pybuda",
            "name": "reshape_1280",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1275"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1280
        },
        "reshape_1283": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1284"
            ],
            "ir": "pybuda",
            "name": "reshape_1283",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1282"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1283
        },
        "reshape_1289": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1290"
            ],
            "ir": "pybuda",
            "name": "reshape_1289",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1284"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1289
        },
        "reshape_1296": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1297"
            ],
            "ir": "pybuda",
            "name": "reshape_1296",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1295"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1296
        },
        "reshape_1304": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1305"
            ],
            "ir": "pybuda",
            "name": "reshape_1304",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1304
        },
        "reshape_1306": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1307"
            ],
            "ir": "pybuda",
            "name": "reshape_1306",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1302"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1306
        },
        "reshape_1308": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1309"
            ],
            "ir": "pybuda",
            "name": "reshape_1308",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1307"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1308
        },
        "reshape_1315": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1316"
            ],
            "ir": "pybuda",
            "name": "reshape_1315",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1314"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1315
        },
        "reshape_1317": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1318"
            ],
            "ir": "pybuda",
            "name": "reshape_1317",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1316"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1317
        },
        "reshape_1321": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_74_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1321",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1320"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1321
        },
        "reshape_1323": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1324"
            ],
            "ir": "pybuda",
            "name": "reshape_1323",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1322"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1323
        },
        "reshape_1329": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1330"
            ],
            "ir": "pybuda",
            "name": "reshape_1329",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1324",
                "pybuda.matmul_2213",
                "pybuda.matmul_2229"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1329
        },
        "reshape_1336": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1337"
            ],
            "ir": "pybuda",
            "name": "reshape_1336",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1335"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1336
        },
        "reshape_1342": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1343"
            ],
            "ir": "pybuda",
            "name": "reshape_1342",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1337"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1342
        },
        "reshape_1345": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1346"
            ],
            "ir": "pybuda",
            "name": "reshape_1345",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1344"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1345
        },
        "reshape_1351": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1352"
            ],
            "ir": "pybuda",
            "name": "reshape_1351",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1346"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1351
        },
        "reshape_1358": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1359"
            ],
            "ir": "pybuda",
            "name": "reshape_1358",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1357"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1358
        },
        "reshape_1366": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1367"
            ],
            "ir": "pybuda",
            "name": "reshape_1366",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1366
        },
        "reshape_1368": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1369"
            ],
            "ir": "pybuda",
            "name": "reshape_1368",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1364"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1368
        },
        "reshape_1370": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1371"
            ],
            "ir": "pybuda",
            "name": "reshape_1370",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1369"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1370
        },
        "reshape_1377": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1378"
            ],
            "ir": "pybuda",
            "name": "reshape_1377",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1376"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1377
        },
        "reshape_1379": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1380"
            ],
            "ir": "pybuda",
            "name": "reshape_1379",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1378"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1379
        },
        "reshape_1383": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_79_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1383",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1382"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1383
        },
        "reshape_1385": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1386"
            ],
            "ir": "pybuda",
            "name": "reshape_1385",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1384"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1385
        },
        "reshape_1391": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1392"
            ],
            "ir": "pybuda",
            "name": "reshape_1391",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1386",
                "pybuda.matmul_2179",
                "pybuda.matmul_2195"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1391
        },
        "reshape_1398": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1399"
            ],
            "ir": "pybuda",
            "name": "reshape_1398",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1397"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1398
        },
        "reshape_1404": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1405"
            ],
            "ir": "pybuda",
            "name": "reshape_1404",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1404
        },
        "reshape_1407": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1408"
            ],
            "ir": "pybuda",
            "name": "reshape_1407",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1407
        },
        "reshape_1413": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1414"
            ],
            "ir": "pybuda",
            "name": "reshape_1413",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1408"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1413
        },
        "reshape_1420": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1421"
            ],
            "ir": "pybuda",
            "name": "reshape_1420",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1420
        },
        "reshape_1428": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1429"
            ],
            "ir": "pybuda",
            "name": "reshape_1428",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1428
        },
        "reshape_1430": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1431"
            ],
            "ir": "pybuda",
            "name": "reshape_1430",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1430
        },
        "reshape_1432": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1433"
            ],
            "ir": "pybuda",
            "name": "reshape_1432",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1432
        },
        "reshape_1439": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1440"
            ],
            "ir": "pybuda",
            "name": "reshape_1439",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1439
        },
        "reshape_1441": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1442"
            ],
            "ir": "pybuda",
            "name": "reshape_1441",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1440"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1441
        },
        "reshape_1445": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_84_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1445",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1445
        },
        "reshape_1447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1448"
            ],
            "ir": "pybuda",
            "name": "reshape_1447",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1446"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1447
        },
        "reshape_1453": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1454"
            ],
            "ir": "pybuda",
            "name": "reshape_1453",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1448",
                "pybuda.matmul_2145",
                "pybuda.matmul_2161"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1453
        },
        "reshape_1460": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1461"
            ],
            "ir": "pybuda",
            "name": "reshape_1460",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1460
        },
        "reshape_1466": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1467"
            ],
            "ir": "pybuda",
            "name": "reshape_1466",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1466
        },
        "reshape_1469": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1470"
            ],
            "ir": "pybuda",
            "name": "reshape_1469",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1469
        },
        "reshape_1475": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1476"
            ],
            "ir": "pybuda",
            "name": "reshape_1475",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1470"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1475
        },
        "reshape_1482": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1483"
            ],
            "ir": "pybuda",
            "name": "reshape_1482",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1482
        },
        "reshape_1490": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1491"
            ],
            "ir": "pybuda",
            "name": "reshape_1490",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1490
        },
        "reshape_1492": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1493"
            ],
            "ir": "pybuda",
            "name": "reshape_1492",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1488"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1492
        },
        "reshape_1494": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1495"
            ],
            "ir": "pybuda",
            "name": "reshape_1494",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1494
        },
        "reshape_1501": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1502"
            ],
            "ir": "pybuda",
            "name": "reshape_1501",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1501
        },
        "reshape_1503": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1504"
            ],
            "ir": "pybuda",
            "name": "reshape_1503",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1503
        },
        "reshape_1507": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_89_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1507",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1507
        },
        "reshape_1509": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1510"
            ],
            "ir": "pybuda",
            "name": "reshape_1509",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1508"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1509
        },
        "reshape_1515": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1516"
            ],
            "ir": "pybuda",
            "name": "reshape_1515",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1510",
                "pybuda.matmul_2111",
                "pybuda.matmul_2127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1515
        },
        "reshape_1522": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1523"
            ],
            "ir": "pybuda",
            "name": "reshape_1522",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1521"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1522
        },
        "reshape_1528": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1529"
            ],
            "ir": "pybuda",
            "name": "reshape_1528",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1528
        },
        "reshape_1531": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1532"
            ],
            "ir": "pybuda",
            "name": "reshape_1531",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1531
        },
        "reshape_1537": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1538"
            ],
            "ir": "pybuda",
            "name": "reshape_1537",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1537
        },
        "reshape_1544": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1545"
            ],
            "ir": "pybuda",
            "name": "reshape_1544",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1544
        },
        "reshape_1552": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1553"
            ],
            "ir": "pybuda",
            "name": "reshape_1552",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1552
        },
        "reshape_1554": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1555"
            ],
            "ir": "pybuda",
            "name": "reshape_1554",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1554
        },
        "reshape_1556": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1557"
            ],
            "ir": "pybuda",
            "name": "reshape_1556",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1555"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1556
        },
        "reshape_1563": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1564"
            ],
            "ir": "pybuda",
            "name": "reshape_1563",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1563
        },
        "reshape_1565": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1566"
            ],
            "ir": "pybuda",
            "name": "reshape_1565",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1565
        },
        "reshape_1569": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_94_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1569",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1569
        },
        "reshape_1571": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1572"
            ],
            "ir": "pybuda",
            "name": "reshape_1571",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1571
        },
        "reshape_1577": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1578"
            ],
            "ir": "pybuda",
            "name": "reshape_1577",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1572",
                "pybuda.matmul_2077",
                "pybuda.matmul_2093"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1577
        },
        "reshape_1584": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1585"
            ],
            "ir": "pybuda",
            "name": "reshape_1584",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1583"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1584
        },
        "reshape_1590": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1591"
            ],
            "ir": "pybuda",
            "name": "reshape_1590",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1590
        },
        "reshape_1593": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1594"
            ],
            "ir": "pybuda",
            "name": "reshape_1593",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1593
        },
        "reshape_1599": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1600"
            ],
            "ir": "pybuda",
            "name": "reshape_1599",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1599
        },
        "reshape_1606": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1607"
            ],
            "ir": "pybuda",
            "name": "reshape_1606",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1605"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1606
        },
        "reshape_1614": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1615"
            ],
            "ir": "pybuda",
            "name": "reshape_1614",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1614
        },
        "reshape_1616": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1617"
            ],
            "ir": "pybuda",
            "name": "reshape_1616",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1616
        },
        "reshape_1618": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1619"
            ],
            "ir": "pybuda",
            "name": "reshape_1618",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1618
        },
        "reshape_1625": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1626"
            ],
            "ir": "pybuda",
            "name": "reshape_1625",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1625
        },
        "reshape_1627": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1628"
            ],
            "ir": "pybuda",
            "name": "reshape_1627",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1627
        },
        "reshape_1631": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_99_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1631",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1631
        },
        "reshape_1633": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1634"
            ],
            "ir": "pybuda",
            "name": "reshape_1633",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1632"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1633
        },
        "reshape_1639": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1640"
            ],
            "ir": "pybuda",
            "name": "reshape_1639",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1634",
                "pybuda.matmul_2043",
                "pybuda.matmul_2059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1639
        },
        "reshape_1646": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1647"
            ],
            "ir": "pybuda",
            "name": "reshape_1646",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1646
        },
        "reshape_1652": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1653"
            ],
            "ir": "pybuda",
            "name": "reshape_1652",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1652
        },
        "reshape_1655": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1656"
            ],
            "ir": "pybuda",
            "name": "reshape_1655",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1655
        },
        "reshape_1661": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1662"
            ],
            "ir": "pybuda",
            "name": "reshape_1661",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1656"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1661
        },
        "reshape_1668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1669"
            ],
            "ir": "pybuda",
            "name": "reshape_1668",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1668
        },
        "reshape_1676": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1677"
            ],
            "ir": "pybuda",
            "name": "reshape_1676",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1676
        },
        "reshape_1678": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1679"
            ],
            "ir": "pybuda",
            "name": "reshape_1678",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1678
        },
        "reshape_1680": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1681"
            ],
            "ir": "pybuda",
            "name": "reshape_1680",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1680
        },
        "reshape_1687": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1688"
            ],
            "ir": "pybuda",
            "name": "reshape_1687",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1687
        },
        "reshape_1689": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1690"
            ],
            "ir": "pybuda",
            "name": "reshape_1689",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1689
        },
        "reshape_1693": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_104_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1693",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1692"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1693
        },
        "reshape_1695": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1696"
            ],
            "ir": "pybuda",
            "name": "reshape_1695",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1695
        },
        "reshape_1701": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1702"
            ],
            "ir": "pybuda",
            "name": "reshape_1701",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1696",
                "pybuda.matmul_2009",
                "pybuda.matmul_2025"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1701
        },
        "reshape_1708": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1709"
            ],
            "ir": "pybuda",
            "name": "reshape_1708",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1707"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1708
        },
        "reshape_1714": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1715"
            ],
            "ir": "pybuda",
            "name": "reshape_1714",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1714
        },
        "reshape_1717": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1718"
            ],
            "ir": "pybuda",
            "name": "reshape_1717",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1717
        },
        "reshape_1723": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1724"
            ],
            "ir": "pybuda",
            "name": "reshape_1723",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1723
        },
        "reshape_1730": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1731"
            ],
            "ir": "pybuda",
            "name": "reshape_1730",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1729"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1730
        },
        "reshape_1738": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1739"
            ],
            "ir": "pybuda",
            "name": "reshape_1738",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1738
        },
        "reshape_1740": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1741"
            ],
            "ir": "pybuda",
            "name": "reshape_1740",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1736"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1740
        },
        "reshape_1742": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1743"
            ],
            "ir": "pybuda",
            "name": "reshape_1742",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1741"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1742
        },
        "reshape_1749": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1750"
            ],
            "ir": "pybuda",
            "name": "reshape_1749",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1748"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1749
        },
        "reshape_1751": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1752"
            ],
            "ir": "pybuda",
            "name": "reshape_1751",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1751
        },
        "reshape_1755": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_109_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1755",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1755
        },
        "reshape_1757": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1758"
            ],
            "ir": "pybuda",
            "name": "reshape_1757",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1757
        },
        "reshape_1763": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1764"
            ],
            "ir": "pybuda",
            "name": "reshape_1763",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1758",
                "pybuda.matmul_1975",
                "pybuda.matmul_1991"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1763
        },
        "reshape_1770": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1771"
            ],
            "ir": "pybuda",
            "name": "reshape_1770",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1769"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1770
        },
        "reshape_1776": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1777"
            ],
            "ir": "pybuda",
            "name": "reshape_1776",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1776
        },
        "reshape_1779": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1780"
            ],
            "ir": "pybuda",
            "name": "reshape_1779",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1779
        },
        "reshape_1785": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1786"
            ],
            "ir": "pybuda",
            "name": "reshape_1785",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1785
        },
        "reshape_1792": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1793"
            ],
            "ir": "pybuda",
            "name": "reshape_1792",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1792
        },
        "reshape_1800": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1801"
            ],
            "ir": "pybuda",
            "name": "reshape_1800",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1800
        },
        "reshape_1802": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1803"
            ],
            "ir": "pybuda",
            "name": "reshape_1802",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1798"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1802
        },
        "reshape_1804": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1805"
            ],
            "ir": "pybuda",
            "name": "reshape_1804",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1803"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1804
        },
        "reshape_1811": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1812"
            ],
            "ir": "pybuda",
            "name": "reshape_1811",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1811
        },
        "reshape_1813": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1814"
            ],
            "ir": "pybuda",
            "name": "reshape_1813",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1812"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1813
        },
        "reshape_1817": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_114_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1817",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1816"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1817
        },
        "reshape_1819": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1820"
            ],
            "ir": "pybuda",
            "name": "reshape_1819",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1818"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1819
        },
        "reshape_1825": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1826"
            ],
            "ir": "pybuda",
            "name": "reshape_1825",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1820",
                "pybuda.matmul_1941",
                "pybuda.matmul_1957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1825
        },
        "reshape_1832": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1833"
            ],
            "ir": "pybuda",
            "name": "reshape_1832",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1832
        },
        "reshape_1838": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_1839"
            ],
            "ir": "pybuda",
            "name": "reshape_1838",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1833"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1838
        },
        "reshape_1841": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1842"
            ],
            "ir": "pybuda",
            "name": "reshape_1841",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1840"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1841
        },
        "reshape_1847": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1848"
            ],
            "ir": "pybuda",
            "name": "reshape_1847",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1842"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1847
        },
        "reshape_1854": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1855"
            ],
            "ir": "pybuda",
            "name": "reshape_1854",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1853"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1854
        },
        "reshape_1862": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1863"
            ],
            "ir": "pybuda",
            "name": "reshape_1862",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1862
        },
        "reshape_1864": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1865"
            ],
            "ir": "pybuda",
            "name": "reshape_1864",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_1860"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1864
        },
        "reshape_1866": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1867"
            ],
            "ir": "pybuda",
            "name": "reshape_1866",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1865"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1866
        },
        "reshape_1873": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1874"
            ],
            "ir": "pybuda",
            "name": "reshape_1873",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1872"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1873
        },
        "reshape_1875": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1876"
            ],
            "ir": "pybuda",
            "name": "reshape_1875",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1875
        },
        "reshape_1879": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_119_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1879",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1878"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1879
        },
        "reshape_1881": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1882"
            ],
            "ir": "pybuda",
            "name": "reshape_1881",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1881
        },
        "reshape_1887": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_1888"
            ],
            "ir": "pybuda",
            "name": "reshape_1887",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1882",
                "pybuda.matmul_1901",
                "pybuda.matmul_1923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1887
        },
        "reshape_1894": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1895"
            ],
            "ir": "pybuda",
            "name": "reshape_1894",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1893"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1894
        },
        "reshape_1898": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_118_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1898",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1898
        },
        "reshape_1900": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1901"
            ],
            "ir": "pybuda",
            "name": "reshape_1900",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1899"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1900
        },
        "reshape_1912": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "attention_mask_1"
            ],
            "ir": "pybuda",
            "name": "reshape_1912",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1912
        },
        "reshape_1915": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1916"
            ],
            "ir": "pybuda",
            "name": "reshape_1915",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1914"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1915
        },
        "reshape_1920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_116_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1920",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1919"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1920
        },
        "reshape_1922": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1923"
            ],
            "ir": "pybuda",
            "name": "reshape_1922",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1921"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1922
        },
        "reshape_1934": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1935"
            ],
            "ir": "pybuda",
            "name": "reshape_1934",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1933"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1934
        },
        "reshape_1938": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_113_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1938",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1938
        },
        "reshape_1940": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1941"
            ],
            "ir": "pybuda",
            "name": "reshape_1940",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1939"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1940
        },
        "reshape_1949": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1950"
            ],
            "ir": "pybuda",
            "name": "reshape_1949",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1949
        },
        "reshape_1954": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_111_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1954",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1954
        },
        "reshape_1956": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1957"
            ],
            "ir": "pybuda",
            "name": "reshape_1956",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1956
        },
        "reshape_1968": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1969"
            ],
            "ir": "pybuda",
            "name": "reshape_1968",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1968
        },
        "reshape_1972": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_108_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1972",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1972
        },
        "reshape_1974": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1975"
            ],
            "ir": "pybuda",
            "name": "reshape_1974",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1973"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1974
        },
        "reshape_1983": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1984"
            ],
            "ir": "pybuda",
            "name": "reshape_1983",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1982"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1983
        },
        "reshape_1988": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_106_0"
            ],
            "ir": "pybuda",
            "name": "reshape_1988",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1988
        },
        "reshape_1990": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_1991"
            ],
            "ir": "pybuda",
            "name": "reshape_1990",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1989"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1990
        },
        "reshape_2002": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2003"
            ],
            "ir": "pybuda",
            "name": "reshape_2002",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2001"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2002
        },
        "reshape_2006": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_103_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2006",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2005"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2006
        },
        "reshape_2008": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2009"
            ],
            "ir": "pybuda",
            "name": "reshape_2008",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2007"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2008
        },
        "reshape_2017": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2018"
            ],
            "ir": "pybuda",
            "name": "reshape_2017",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2016"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2017
        },
        "reshape_2022": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_101_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2022",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2022
        },
        "reshape_2024": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2025"
            ],
            "ir": "pybuda",
            "name": "reshape_2024",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2023"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2024
        },
        "reshape_2036": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2037"
            ],
            "ir": "pybuda",
            "name": "reshape_2036",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2036
        },
        "reshape_2040": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_98_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2040",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2039"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2040
        },
        "reshape_2042": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2043"
            ],
            "ir": "pybuda",
            "name": "reshape_2042",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2042
        },
        "reshape_2051": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2052"
            ],
            "ir": "pybuda",
            "name": "reshape_2051",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2050"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2051
        },
        "reshape_2056": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_96_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2056",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2055"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2056
        },
        "reshape_2058": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2059"
            ],
            "ir": "pybuda",
            "name": "reshape_2058",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2057"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2058
        },
        "reshape_2070": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2071"
            ],
            "ir": "pybuda",
            "name": "reshape_2070",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2069"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2070
        },
        "reshape_2074": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_93_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2074",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2073"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2074
        },
        "reshape_2076": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2077"
            ],
            "ir": "pybuda",
            "name": "reshape_2076",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2075"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2076
        },
        "reshape_2085": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2086"
            ],
            "ir": "pybuda",
            "name": "reshape_2085",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2084"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2085
        },
        "reshape_2090": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_91_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2090",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2089"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2090
        },
        "reshape_2092": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2093"
            ],
            "ir": "pybuda",
            "name": "reshape_2092",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2091"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2092
        },
        "reshape_2104": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2105"
            ],
            "ir": "pybuda",
            "name": "reshape_2104",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2104
        },
        "reshape_2108": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_88_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2108",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2108
        },
        "reshape_2110": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2111"
            ],
            "ir": "pybuda",
            "name": "reshape_2110",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2109"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2110
        },
        "reshape_2119": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2120"
            ],
            "ir": "pybuda",
            "name": "reshape_2119",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2118"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2119
        },
        "reshape_2124": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_86_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2124",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2123"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2124
        },
        "reshape_2126": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2127"
            ],
            "ir": "pybuda",
            "name": "reshape_2126",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2125"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2126
        },
        "reshape_2138": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2139"
            ],
            "ir": "pybuda",
            "name": "reshape_2138",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2137"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2138
        },
        "reshape_2142": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_83_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2142",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2141"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2142
        },
        "reshape_2144": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2145"
            ],
            "ir": "pybuda",
            "name": "reshape_2144",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2144
        },
        "reshape_2153": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2154"
            ],
            "ir": "pybuda",
            "name": "reshape_2153",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2153
        },
        "reshape_2158": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_81_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2158",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2157"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2158
        },
        "reshape_2160": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2161"
            ],
            "ir": "pybuda",
            "name": "reshape_2160",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2160
        },
        "reshape_2172": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2173"
            ],
            "ir": "pybuda",
            "name": "reshape_2172",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2171"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2172
        },
        "reshape_2176": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_78_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2176",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2175"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2176
        },
        "reshape_2178": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2179"
            ],
            "ir": "pybuda",
            "name": "reshape_2178",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2178
        },
        "reshape_2187": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2188"
            ],
            "ir": "pybuda",
            "name": "reshape_2187",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2186"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2187
        },
        "reshape_2192": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_76_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2192",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2192
        },
        "reshape_2194": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2195"
            ],
            "ir": "pybuda",
            "name": "reshape_2194",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2193"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2194
        },
        "reshape_2206": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2207"
            ],
            "ir": "pybuda",
            "name": "reshape_2206",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2205"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2206
        },
        "reshape_2210": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_73_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2210",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2209"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2210
        },
        "reshape_2212": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2213"
            ],
            "ir": "pybuda",
            "name": "reshape_2212",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2211"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2212
        },
        "reshape_2221": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2222"
            ],
            "ir": "pybuda",
            "name": "reshape_2221",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2220"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2221
        },
        "reshape_2226": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_71_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2226",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2225"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2226
        },
        "reshape_2228": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2229"
            ],
            "ir": "pybuda",
            "name": "reshape_2228",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2227"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2228
        },
        "reshape_2240": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2241"
            ],
            "ir": "pybuda",
            "name": "reshape_2240",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2239"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2240
        },
        "reshape_2244": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_68_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2244",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2243"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2244
        },
        "reshape_2246": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2247"
            ],
            "ir": "pybuda",
            "name": "reshape_2246",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2245"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2246
        },
        "reshape_2255": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2256"
            ],
            "ir": "pybuda",
            "name": "reshape_2255",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2254"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2255
        },
        "reshape_2260": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_66_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2260",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2259"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2260
        },
        "reshape_2262": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2263"
            ],
            "ir": "pybuda",
            "name": "reshape_2262",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2261"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2262
        },
        "reshape_2274": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2275"
            ],
            "ir": "pybuda",
            "name": "reshape_2274",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2273"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2274
        },
        "reshape_2278": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_63_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2278",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2277"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2278
        },
        "reshape_2280": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2281"
            ],
            "ir": "pybuda",
            "name": "reshape_2280",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2279"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2280
        },
        "reshape_2289": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2290"
            ],
            "ir": "pybuda",
            "name": "reshape_2289",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2288"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2289
        },
        "reshape_2294": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_61_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2294",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2293"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2294
        },
        "reshape_2296": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2297"
            ],
            "ir": "pybuda",
            "name": "reshape_2296",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2295"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2296
        },
        "reshape_2308": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2309"
            ],
            "ir": "pybuda",
            "name": "reshape_2308",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2307"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2308
        },
        "reshape_2312": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_58_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2312",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2311"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2312
        },
        "reshape_2314": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2315"
            ],
            "ir": "pybuda",
            "name": "reshape_2314",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2313"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2314
        },
        "reshape_2323": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2324"
            ],
            "ir": "pybuda",
            "name": "reshape_2323",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2322"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2323
        },
        "reshape_2328": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_56_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2328",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2327"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2328
        },
        "reshape_2330": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2331"
            ],
            "ir": "pybuda",
            "name": "reshape_2330",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2329"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2330
        },
        "reshape_2342": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2343"
            ],
            "ir": "pybuda",
            "name": "reshape_2342",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2341"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2342
        },
        "reshape_2346": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_53_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2346",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2345"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2346
        },
        "reshape_2348": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2349"
            ],
            "ir": "pybuda",
            "name": "reshape_2348",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2347"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2348
        },
        "reshape_2357": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2358"
            ],
            "ir": "pybuda",
            "name": "reshape_2357",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2356"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2357
        },
        "reshape_2362": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_51_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2362",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2361"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2362
        },
        "reshape_2364": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2365"
            ],
            "ir": "pybuda",
            "name": "reshape_2364",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2363"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2364
        },
        "reshape_2376": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2377"
            ],
            "ir": "pybuda",
            "name": "reshape_2376",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2375"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2376
        },
        "reshape_2380": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_48_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2380",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2379"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2380
        },
        "reshape_2382": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2383"
            ],
            "ir": "pybuda",
            "name": "reshape_2382",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2381"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2382
        },
        "reshape_2391": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2392"
            ],
            "ir": "pybuda",
            "name": "reshape_2391",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2391
        },
        "reshape_2396": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_46_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2396",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2396
        },
        "reshape_2398": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2399"
            ],
            "ir": "pybuda",
            "name": "reshape_2398",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2397"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2398
        },
        "reshape_2410": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2411"
            ],
            "ir": "pybuda",
            "name": "reshape_2410",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2409"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2410
        },
        "reshape_2414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_43_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2414",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2414
        },
        "reshape_2416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2417"
            ],
            "ir": "pybuda",
            "name": "reshape_2416",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2416
        },
        "reshape_2425": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2426"
            ],
            "ir": "pybuda",
            "name": "reshape_2425",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2425
        },
        "reshape_2430": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_41_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2430",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2430
        },
        "reshape_2432": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2433"
            ],
            "ir": "pybuda",
            "name": "reshape_2432",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2432
        },
        "reshape_2444": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2445"
            ],
            "ir": "pybuda",
            "name": "reshape_2444",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2444
        },
        "reshape_2448": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_38_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2448",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2448
        },
        "reshape_2450": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2451"
            ],
            "ir": "pybuda",
            "name": "reshape_2450",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2450
        },
        "reshape_2459": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2460"
            ],
            "ir": "pybuda",
            "name": "reshape_2459",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2458"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2459
        },
        "reshape_2464": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_36_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2464",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2464
        },
        "reshape_2466": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2467"
            ],
            "ir": "pybuda",
            "name": "reshape_2466",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2466
        },
        "reshape_2478": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2479"
            ],
            "ir": "pybuda",
            "name": "reshape_2478",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2478
        },
        "reshape_2482": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_33_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2482",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2482
        },
        "reshape_2484": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2485"
            ],
            "ir": "pybuda",
            "name": "reshape_2484",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2484
        },
        "reshape_2493": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2494"
            ],
            "ir": "pybuda",
            "name": "reshape_2493",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2492"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2493
        },
        "reshape_2498": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_31_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2498",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2497"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2498
        },
        "reshape_2500": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2501"
            ],
            "ir": "pybuda",
            "name": "reshape_2500",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2499"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2500
        },
        "reshape_2512": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2513"
            ],
            "ir": "pybuda",
            "name": "reshape_2512",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2512
        },
        "reshape_2516": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_28_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2516",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2516
        },
        "reshape_2518": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2519"
            ],
            "ir": "pybuda",
            "name": "reshape_2518",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2518
        },
        "reshape_2527": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2528"
            ],
            "ir": "pybuda",
            "name": "reshape_2527",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2526"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2527
        },
        "reshape_2532": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_26_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2532",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2532
        },
        "reshape_2534": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2535"
            ],
            "ir": "pybuda",
            "name": "reshape_2534",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2533"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2534
        },
        "reshape_2546": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2547"
            ],
            "ir": "pybuda",
            "name": "reshape_2546",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2546
        },
        "reshape_2550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_23_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2550",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2549"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2550
        },
        "reshape_2552": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2553"
            ],
            "ir": "pybuda",
            "name": "reshape_2552",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2552
        },
        "reshape_2561": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2562"
            ],
            "ir": "pybuda",
            "name": "reshape_2561",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2561
        },
        "reshape_2566": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_21_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2566",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2566
        },
        "reshape_2568": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2569"
            ],
            "ir": "pybuda",
            "name": "reshape_2568",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2568
        },
        "reshape_2580": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2581"
            ],
            "ir": "pybuda",
            "name": "reshape_2580",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2580
        },
        "reshape_2584": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_18_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2584",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2583"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2584
        },
        "reshape_2586": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2587"
            ],
            "ir": "pybuda",
            "name": "reshape_2586",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2586
        },
        "reshape_2595": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2596"
            ],
            "ir": "pybuda",
            "name": "reshape_2595",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2595
        },
        "reshape_2600": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_16_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2600",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2600
        },
        "reshape_2602": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2603"
            ],
            "ir": "pybuda",
            "name": "reshape_2602",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2602
        },
        "reshape_2614": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2615"
            ],
            "ir": "pybuda",
            "name": "reshape_2614",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2614
        },
        "reshape_2618": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_13_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2618",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2618
        },
        "reshape_2620": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2621"
            ],
            "ir": "pybuda",
            "name": "reshape_2620",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2619"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2620
        },
        "reshape_2629": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2630"
            ],
            "ir": "pybuda",
            "name": "reshape_2629",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2629
        },
        "reshape_2634": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_11_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2634",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2634
        },
        "reshape_2636": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2637"
            ],
            "ir": "pybuda",
            "name": "reshape_2636",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2636
        },
        "reshape_2648": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2649"
            ],
            "ir": "pybuda",
            "name": "reshape_2648",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2648
        },
        "reshape_2652": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_8_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2652",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2652
        },
        "reshape_2654": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2655"
            ],
            "ir": "pybuda",
            "name": "reshape_2654",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2654
        },
        "reshape_2663": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2664"
            ],
            "ir": "pybuda",
            "name": "reshape_2663",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2663
        },
        "reshape_2668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_6_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2668",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2668
        },
        "reshape_2670": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2671"
            ],
            "ir": "pybuda",
            "name": "reshape_2670",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2670
        },
        "reshape_2682": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2683"
            ],
            "ir": "pybuda",
            "name": "reshape_2682",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2682
        },
        "reshape_2686": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_3_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2686",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2685"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2686
        },
        "reshape_2688": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2689"
            ],
            "ir": "pybuda",
            "name": "reshape_2688",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2688
        },
        "reshape_2697": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2698"
            ],
            "ir": "pybuda",
            "name": "reshape_2697",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2697
        },
        "reshape_2702": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_1_0"
            ],
            "ir": "pybuda",
            "name": "reshape_2702",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2702
        },
        "reshape_2704": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_2705"
            ],
            "ir": "pybuda",
            "name": "reshape_2704",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2704
        },
        "reshape_2717": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_2718"
            ],
            "ir": "pybuda",
            "name": "reshape_2717",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2717
        },
        "reshape_2718": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_2719"
            ],
            "ir": "pybuda",
            "name": "reshape_2718",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2717"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reshape",
            "unique_id": 2718
        },
        "reshape_391": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_392"
            ],
            "ir": "pybuda",
            "name": "reshape_391",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 391
        },
        "reshape_392": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_393"
            ],
            "ir": "pybuda",
            "name": "reshape_392",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_391"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "reshape",
            "unique_id": 392
        },
        "reshape_399": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_400"
            ],
            "ir": "pybuda",
            "name": "reshape_399",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_394",
                "pybuda.matmul_2720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 399
        },
        "reshape_406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_407"
            ],
            "ir": "pybuda",
            "name": "reshape_406",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_405"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 406
        },
        "reshape_412": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_413"
            ],
            "ir": "pybuda",
            "name": "reshape_412",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 412
        },
        "reshape_415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_416"
            ],
            "ir": "pybuda",
            "name": "reshape_415",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 415
        },
        "reshape_421": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_422"
            ],
            "ir": "pybuda",
            "name": "reshape_421",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_416"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 421
        },
        "reshape_428": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_429"
            ],
            "ir": "pybuda",
            "name": "reshape_428",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 428
        },
        "reshape_436": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_437"
            ],
            "ir": "pybuda",
            "name": "reshape_436",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 436
        },
        "reshape_438": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_439"
            ],
            "ir": "pybuda",
            "name": "reshape_438",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_434"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 438
        },
        "reshape_440": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_441"
            ],
            "ir": "pybuda",
            "name": "reshape_440",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 440
        },
        "reshape_447": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_448"
            ],
            "ir": "pybuda",
            "name": "reshape_447",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_446"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 447
        },
        "reshape_449": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_450"
            ],
            "ir": "pybuda",
            "name": "reshape_449",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 449
        },
        "reshape_453": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_4_0"
            ],
            "ir": "pybuda",
            "name": "reshape_453",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_452"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 453
        },
        "reshape_455": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_456"
            ],
            "ir": "pybuda",
            "name": "reshape_455",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_454"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 455
        },
        "reshape_461": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_462"
            ],
            "ir": "pybuda",
            "name": "reshape_461",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_456",
                "pybuda.matmul_2689",
                "pybuda.matmul_2705"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 461
        },
        "reshape_468": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_469"
            ],
            "ir": "pybuda",
            "name": "reshape_468",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 468
        },
        "reshape_474": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_475"
            ],
            "ir": "pybuda",
            "name": "reshape_474",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 474
        },
        "reshape_477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_478"
            ],
            "ir": "pybuda",
            "name": "reshape_477",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 477
        },
        "reshape_483": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_484"
            ],
            "ir": "pybuda",
            "name": "reshape_483",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 483
        },
        "reshape_490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_491"
            ],
            "ir": "pybuda",
            "name": "reshape_490",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_489"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 490
        },
        "reshape_498": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_499"
            ],
            "ir": "pybuda",
            "name": "reshape_498",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 498
        },
        "reshape_500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_501"
            ],
            "ir": "pybuda",
            "name": "reshape_500",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_496"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 500
        },
        "reshape_502": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_503"
            ],
            "ir": "pybuda",
            "name": "reshape_502",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 502
        },
        "reshape_509": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_510"
            ],
            "ir": "pybuda",
            "name": "reshape_509",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_508"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 509
        },
        "reshape_511": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_512"
            ],
            "ir": "pybuda",
            "name": "reshape_511",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 511
        },
        "reshape_515": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_9_0"
            ],
            "ir": "pybuda",
            "name": "reshape_515",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_514"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 515
        },
        "reshape_517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_518"
            ],
            "ir": "pybuda",
            "name": "reshape_517",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 517
        },
        "reshape_523": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_524"
            ],
            "ir": "pybuda",
            "name": "reshape_523",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_518",
                "pybuda.matmul_2655",
                "pybuda.matmul_2671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 523
        },
        "reshape_530": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_531"
            ],
            "ir": "pybuda",
            "name": "reshape_530",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 530
        },
        "reshape_536": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_537"
            ],
            "ir": "pybuda",
            "name": "reshape_536",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 536
        },
        "reshape_539": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_540"
            ],
            "ir": "pybuda",
            "name": "reshape_539",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 539
        },
        "reshape_545": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_546"
            ],
            "ir": "pybuda",
            "name": "reshape_545",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 545
        },
        "reshape_552": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_553"
            ],
            "ir": "pybuda",
            "name": "reshape_552",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 552
        },
        "reshape_560": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_561"
            ],
            "ir": "pybuda",
            "name": "reshape_560",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 560
        },
        "reshape_562": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_563"
            ],
            "ir": "pybuda",
            "name": "reshape_562",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 562
        },
        "reshape_564": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_565"
            ],
            "ir": "pybuda",
            "name": "reshape_564",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 564
        },
        "reshape_571": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_572"
            ],
            "ir": "pybuda",
            "name": "reshape_571",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 571
        },
        "reshape_573": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_574"
            ],
            "ir": "pybuda",
            "name": "reshape_573",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 573
        },
        "reshape_577": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_14_0"
            ],
            "ir": "pybuda",
            "name": "reshape_577",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 577
        },
        "reshape_579": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_580"
            ],
            "ir": "pybuda",
            "name": "reshape_579",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 579
        },
        "reshape_585": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_586"
            ],
            "ir": "pybuda",
            "name": "reshape_585",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_580",
                "pybuda.matmul_2621",
                "pybuda.matmul_2637"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 585
        },
        "reshape_592": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_593"
            ],
            "ir": "pybuda",
            "name": "reshape_592",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 592
        },
        "reshape_598": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_599"
            ],
            "ir": "pybuda",
            "name": "reshape_598",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 598
        },
        "reshape_601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_602"
            ],
            "ir": "pybuda",
            "name": "reshape_601",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 601
        },
        "reshape_607": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_608"
            ],
            "ir": "pybuda",
            "name": "reshape_607",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 607
        },
        "reshape_614": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_615"
            ],
            "ir": "pybuda",
            "name": "reshape_614",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 614
        },
        "reshape_622": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_623"
            ],
            "ir": "pybuda",
            "name": "reshape_622",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 622
        },
        "reshape_624": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_625"
            ],
            "ir": "pybuda",
            "name": "reshape_624",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_620"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 624
        },
        "reshape_626": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_627"
            ],
            "ir": "pybuda",
            "name": "reshape_626",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_625"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 626
        },
        "reshape_633": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_634"
            ],
            "ir": "pybuda",
            "name": "reshape_633",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_632"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 633
        },
        "reshape_635": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_636"
            ],
            "ir": "pybuda",
            "name": "reshape_635",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 635
        },
        "reshape_639": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_19_0"
            ],
            "ir": "pybuda",
            "name": "reshape_639",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 639
        },
        "reshape_641": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_642"
            ],
            "ir": "pybuda",
            "name": "reshape_641",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_640"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 641
        },
        "reshape_647": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_648"
            ],
            "ir": "pybuda",
            "name": "reshape_647",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_642",
                "pybuda.matmul_2587",
                "pybuda.matmul_2603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 647
        },
        "reshape_654": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_655"
            ],
            "ir": "pybuda",
            "name": "reshape_654",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 654
        },
        "reshape_660": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_661"
            ],
            "ir": "pybuda",
            "name": "reshape_660",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_655"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 660
        },
        "reshape_663": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_664"
            ],
            "ir": "pybuda",
            "name": "reshape_663",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 663
        },
        "reshape_669": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_670"
            ],
            "ir": "pybuda",
            "name": "reshape_669",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 669
        },
        "reshape_676": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_677"
            ],
            "ir": "pybuda",
            "name": "reshape_676",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 676
        },
        "reshape_684": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_685"
            ],
            "ir": "pybuda",
            "name": "reshape_684",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 684
        },
        "reshape_686": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_687"
            ],
            "ir": "pybuda",
            "name": "reshape_686",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 686
        },
        "reshape_688": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_689"
            ],
            "ir": "pybuda",
            "name": "reshape_688",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 688
        },
        "reshape_695": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_696"
            ],
            "ir": "pybuda",
            "name": "reshape_695",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 695
        },
        "reshape_697": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_698"
            ],
            "ir": "pybuda",
            "name": "reshape_697",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 697
        },
        "reshape_701": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_24_0"
            ],
            "ir": "pybuda",
            "name": "reshape_701",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 701
        },
        "reshape_703": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_704"
            ],
            "ir": "pybuda",
            "name": "reshape_703",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 703
        },
        "reshape_709": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_710"
            ],
            "ir": "pybuda",
            "name": "reshape_709",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_704",
                "pybuda.matmul_2553",
                "pybuda.matmul_2569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 709
        },
        "reshape_716": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_717"
            ],
            "ir": "pybuda",
            "name": "reshape_716",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 716
        },
        "reshape_722": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_723"
            ],
            "ir": "pybuda",
            "name": "reshape_722",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 722
        },
        "reshape_725": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_726"
            ],
            "ir": "pybuda",
            "name": "reshape_725",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_724"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 725
        },
        "reshape_731": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_732"
            ],
            "ir": "pybuda",
            "name": "reshape_731",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 731
        },
        "reshape_738": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_739"
            ],
            "ir": "pybuda",
            "name": "reshape_738",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 738
        },
        "reshape_746": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_747"
            ],
            "ir": "pybuda",
            "name": "reshape_746",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 746
        },
        "reshape_748": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_749"
            ],
            "ir": "pybuda",
            "name": "reshape_748",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_744"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 748
        },
        "reshape_750": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_751"
            ],
            "ir": "pybuda",
            "name": "reshape_750",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 750
        },
        "reshape_757": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_758"
            ],
            "ir": "pybuda",
            "name": "reshape_757",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 757
        },
        "reshape_759": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_760"
            ],
            "ir": "pybuda",
            "name": "reshape_759",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_758"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 759
        },
        "reshape_763": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_29_0"
            ],
            "ir": "pybuda",
            "name": "reshape_763",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 763
        },
        "reshape_765": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_766"
            ],
            "ir": "pybuda",
            "name": "reshape_765",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_764"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 765
        },
        "reshape_771": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "reshape_771",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_766",
                "pybuda.matmul_2519",
                "pybuda.matmul_2535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 771
        },
        "reshape_778": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_779"
            ],
            "ir": "pybuda",
            "name": "reshape_778",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_777"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 778
        },
        "reshape_784": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_785"
            ],
            "ir": "pybuda",
            "name": "reshape_784",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 784
        },
        "reshape_787": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_788"
            ],
            "ir": "pybuda",
            "name": "reshape_787",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 787
        },
        "reshape_793": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_794"
            ],
            "ir": "pybuda",
            "name": "reshape_793",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_788"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 793
        },
        "reshape_800": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_801"
            ],
            "ir": "pybuda",
            "name": "reshape_800",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_799"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 800
        },
        "reshape_808": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_809"
            ],
            "ir": "pybuda",
            "name": "reshape_808",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 808
        },
        "reshape_810": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_811"
            ],
            "ir": "pybuda",
            "name": "reshape_810",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_806"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 810
        },
        "reshape_812": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_813"
            ],
            "ir": "pybuda",
            "name": "reshape_812",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 812
        },
        "reshape_819": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_820"
            ],
            "ir": "pybuda",
            "name": "reshape_819",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_818"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 819
        },
        "reshape_821": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_822"
            ],
            "ir": "pybuda",
            "name": "reshape_821",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_820"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 821
        },
        "reshape_825": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_34_0"
            ],
            "ir": "pybuda",
            "name": "reshape_825",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_824"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 825
        },
        "reshape_827": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_828"
            ],
            "ir": "pybuda",
            "name": "reshape_827",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 827
        },
        "reshape_833": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_834"
            ],
            "ir": "pybuda",
            "name": "reshape_833",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_828",
                "pybuda.matmul_2485",
                "pybuda.matmul_2501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 833
        },
        "reshape_840": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_841"
            ],
            "ir": "pybuda",
            "name": "reshape_840",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 840
        },
        "reshape_846": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_847"
            ],
            "ir": "pybuda",
            "name": "reshape_846",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 846
        },
        "reshape_849": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_850"
            ],
            "ir": "pybuda",
            "name": "reshape_849",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 849
        },
        "reshape_855": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_856"
            ],
            "ir": "pybuda",
            "name": "reshape_855",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 855
        },
        "reshape_862": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_863"
            ],
            "ir": "pybuda",
            "name": "reshape_862",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_861"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 862
        },
        "reshape_870": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_871"
            ],
            "ir": "pybuda",
            "name": "reshape_870",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 870
        },
        "reshape_872": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_873"
            ],
            "ir": "pybuda",
            "name": "reshape_872",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 872
        },
        "reshape_874": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_875"
            ],
            "ir": "pybuda",
            "name": "reshape_874",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_873"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 874
        },
        "reshape_881": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_882"
            ],
            "ir": "pybuda",
            "name": "reshape_881",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 881
        },
        "reshape_883": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_884"
            ],
            "ir": "pybuda",
            "name": "reshape_883",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_882"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 883
        },
        "reshape_887": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_39_0"
            ],
            "ir": "pybuda",
            "name": "reshape_887",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_886"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 887
        },
        "reshape_889": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_890"
            ],
            "ir": "pybuda",
            "name": "reshape_889",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 889
        },
        "reshape_895": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_896"
            ],
            "ir": "pybuda",
            "name": "reshape_895",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_890",
                "pybuda.matmul_2451",
                "pybuda.matmul_2467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 895
        },
        "reshape_902": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_903"
            ],
            "ir": "pybuda",
            "name": "reshape_902",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_901"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 902
        },
        "reshape_908": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_909"
            ],
            "ir": "pybuda",
            "name": "reshape_908",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_903"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 908
        },
        "reshape_911": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_912"
            ],
            "ir": "pybuda",
            "name": "reshape_911",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_910"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 911
        },
        "reshape_917": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_918"
            ],
            "ir": "pybuda",
            "name": "reshape_917",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 917
        },
        "reshape_924": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_925"
            ],
            "ir": "pybuda",
            "name": "reshape_924",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 924
        },
        "reshape_932": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_933"
            ],
            "ir": "pybuda",
            "name": "reshape_932",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 932
        },
        "reshape_934": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_935"
            ],
            "ir": "pybuda",
            "name": "reshape_934",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 934
        },
        "reshape_936": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_937"
            ],
            "ir": "pybuda",
            "name": "reshape_936",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_935"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 936
        },
        "reshape_943": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_944"
            ],
            "ir": "pybuda",
            "name": "reshape_943",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 943
        },
        "reshape_945": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_946"
            ],
            "ir": "pybuda",
            "name": "reshape_945",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_944"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 945
        },
        "reshape_949": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_44_0"
            ],
            "ir": "pybuda",
            "name": "reshape_949",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 949
        },
        "reshape_951": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_952"
            ],
            "ir": "pybuda",
            "name": "reshape_951",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_950"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 951
        },
        "reshape_957": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_958"
            ],
            "ir": "pybuda",
            "name": "reshape_957",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_952",
                "pybuda.matmul_2417",
                "pybuda.matmul_2433"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 957
        },
        "reshape_964": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_965"
            ],
            "ir": "pybuda",
            "name": "reshape_964",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 964
        },
        "reshape_970": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "gelu_971"
            ],
            "ir": "pybuda",
            "name": "reshape_970",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_965"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 970
        },
        "reshape_973": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_974"
            ],
            "ir": "pybuda",
            "name": "reshape_973",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_972"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 973
        },
        "reshape_979": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_980"
            ],
            "ir": "pybuda",
            "name": "reshape_979",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 979
        },
        "reshape_986": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.matmul_987"
            ],
            "ir": "pybuda",
            "name": "reshape_986",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 986
        },
        "reshape_994": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_995"
            ],
            "ir": "pybuda",
            "name": "reshape_994",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 994
        },
        "reshape_996": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_997"
            ],
            "ir": "pybuda",
            "name": "reshape_996",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.hstack_992"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 996
        },
        "reshape_998": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "pybuda.dropout_999"
            ],
            "ir": "pybuda",
            "name": "reshape_998",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_997"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 998
        },
        "strided_slice_2715": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "strided_slice_2715",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2714"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 2715
        },
        "strided_slice_2716": {
            "cache": {
                "shape": [
                    1
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "strided_slice_2716",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_393"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 2716
        },
        "strided_slice_2726": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "strided_slice_2726",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2725"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 2726
        },
        "strided_slice_2727": {
            "cache": {
                "shape": [
                    1
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "strided_slice_2727",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2719"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "strided_slice",
            "unique_id": 2727
        },
        "subtract_1909": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "input_nodes": [
                "constant_1910",
                "cast_1911"
            ],
            "ir": "pybuda",
            "name": "subtract_1909",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1908"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::rsub, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x918176a0), 0, 0, 0, 0)",
            "type": "subtract",
            "unique_id": 1909
        },
        "transpose_1010": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1011"
            ],
            "ir": "pybuda",
            "name": "transpose_1010",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1010
        },
        "transpose_1018": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_61_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1018",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1017"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1018
        },
        "transpose_1031": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_62_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1031",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1030"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1031
        },
        "transpose_1040": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_63_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1040",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1039"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1040
        },
        "transpose_1053": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_64_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1053",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1052"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1053
        },
        "transpose_1057": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_40_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1057",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1056"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1057
        },
        "transpose_1072": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1073"
            ],
            "ir": "pybuda",
            "name": "transpose_1072",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1072
        },
        "transpose_1080": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_67_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1080",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1079"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1080
        },
        "transpose_1093": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_68_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1093",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1092"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1093
        },
        "transpose_1102": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_69_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1102",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1101"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1102
        },
        "transpose_1115": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_70_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1115",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1114"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1115
        },
        "transpose_1119": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_44_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1119",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1118"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1119
        },
        "transpose_1134": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1135"
            ],
            "ir": "pybuda",
            "name": "transpose_1134",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1134
        },
        "transpose_1142": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_73_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1142",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1141"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1142
        },
        "transpose_1155": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_74_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1155",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1154"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1155
        },
        "transpose_1164": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_75_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1164",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1163"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1164
        },
        "transpose_1177": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_76_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1177",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1176"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1177
        },
        "transpose_1181": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_48_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1181",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1180"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1181
        },
        "transpose_1196": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1197"
            ],
            "ir": "pybuda",
            "name": "transpose_1196",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1196
        },
        "transpose_1204": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_79_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1204",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1203"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1204
        },
        "transpose_1217": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_80_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1217",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1216"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1217
        },
        "transpose_1226": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_81_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1226",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1225"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1226
        },
        "transpose_1239": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_82_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1239",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1238"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1239
        },
        "transpose_1243": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_52_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1243",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1242"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1243
        },
        "transpose_1258": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1259"
            ],
            "ir": "pybuda",
            "name": "transpose_1258",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1258
        },
        "transpose_1266": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_85_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1266",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1265"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1266
        },
        "transpose_1279": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_86_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1279",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1278"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1279
        },
        "transpose_1288": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_87_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1288",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1287"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1288
        },
        "transpose_1301": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_88_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1301",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1300"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1301
        },
        "transpose_1305": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_56_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1305",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1304"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1305
        },
        "transpose_1320": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1321"
            ],
            "ir": "pybuda",
            "name": "transpose_1320",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1320
        },
        "transpose_1328": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_91_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1328",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1327"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1328
        },
        "transpose_1341": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_92_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1341",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1340"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1341
        },
        "transpose_1350": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_93_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1350",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1349"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1350
        },
        "transpose_1363": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_94_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1363",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1362"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1363
        },
        "transpose_1367": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_60_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1367",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1366"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1367
        },
        "transpose_1382": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1383"
            ],
            "ir": "pybuda",
            "name": "transpose_1382",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1382
        },
        "transpose_1390": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_97_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1390",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1389"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1390
        },
        "transpose_1403": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_98_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1403",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1402"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1403
        },
        "transpose_1412": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_99_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1412",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1411"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1412
        },
        "transpose_1425": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_100_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1425",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1424"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1425
        },
        "transpose_1429": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_64_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1429",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1429
        },
        "transpose_1444": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1445"
            ],
            "ir": "pybuda",
            "name": "transpose_1444",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1444
        },
        "transpose_1452": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_103_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1452",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1451"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1452
        },
        "transpose_1465": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_104_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1465",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1464"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1465
        },
        "transpose_1474": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_105_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1474",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1473"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1474
        },
        "transpose_1487": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_106_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1487",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1486"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1487
        },
        "transpose_1491": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_68_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1491",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1491
        },
        "transpose_1506": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1507"
            ],
            "ir": "pybuda",
            "name": "transpose_1506",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1506
        },
        "transpose_1514": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_109_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1514",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1513"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1514
        },
        "transpose_1527": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_110_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1527",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1526"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1527
        },
        "transpose_1536": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_111_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1536",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1535"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1536
        },
        "transpose_1549": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_112_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1549",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1548"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1549
        },
        "transpose_1553": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_72_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1553",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1553
        },
        "transpose_1568": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1569"
            ],
            "ir": "pybuda",
            "name": "transpose_1568",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1568
        },
        "transpose_1576": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_115_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1576",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1575"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1576
        },
        "transpose_1589": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_116_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1589",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1588"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1589
        },
        "transpose_1598": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_117_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1598",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1597"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1598
        },
        "transpose_1611": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_118_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1611",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1610"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1611
        },
        "transpose_1615": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_76_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1615",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1615
        },
        "transpose_1630": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1631"
            ],
            "ir": "pybuda",
            "name": "transpose_1630",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1630
        },
        "transpose_1638": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_121_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1638",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1637"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1638
        },
        "transpose_1651": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_122_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1651",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1650"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1651
        },
        "transpose_1660": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_123_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1660",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1659"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1660
        },
        "transpose_1673": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_124_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1673",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1672"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1673
        },
        "transpose_1677": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_80_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1677",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1677
        },
        "transpose_1692": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1693"
            ],
            "ir": "pybuda",
            "name": "transpose_1692",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1692
        },
        "transpose_1700": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_127_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1700",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1699"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1700
        },
        "transpose_1713": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_128_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1713",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1712"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1713
        },
        "transpose_1722": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_129_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1722",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1721"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1722
        },
        "transpose_1735": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_130_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1735",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1734"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1735
        },
        "transpose_1739": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_84_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1739",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1739
        },
        "transpose_1754": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1755"
            ],
            "ir": "pybuda",
            "name": "transpose_1754",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1754
        },
        "transpose_1762": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_133_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1762",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1761"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1762
        },
        "transpose_1775": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_134_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1775",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1774"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1775
        },
        "transpose_1784": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_135_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1784",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1783"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1784
        },
        "transpose_1797": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_136_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1797",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1796"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1797
        },
        "transpose_1801": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_88_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1801",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1800"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1801
        },
        "transpose_1816": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1817"
            ],
            "ir": "pybuda",
            "name": "transpose_1816",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1816
        },
        "transpose_1824": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_139_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1824",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1823"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1824
        },
        "transpose_1837": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_140_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1837",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1836"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1837
        },
        "transpose_1846": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_141_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1846",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1845"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1846
        },
        "transpose_1859": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_142_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1859",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1858"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1859
        },
        "transpose_1863": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_92_0"
            ],
            "ir": "pybuda",
            "name": "transpose_1863",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1863
        },
        "transpose_1878": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1879"
            ],
            "ir": "pybuda",
            "name": "transpose_1878",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1878
        },
        "transpose_1886": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_145_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1886",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1885"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1886
        },
        "transpose_1892": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1892",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1882"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1892
        },
        "transpose_1893": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1894"
            ],
            "ir": "pybuda",
            "name": "transpose_1893",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1874"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1893
        },
        "transpose_1897": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1898"
            ],
            "ir": "pybuda",
            "name": "transpose_1897",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1897
        },
        "transpose_1905": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_144_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1905",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1904"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1905
        },
        "transpose_1906": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1906",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1901"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1906
        },
        "transpose_1914": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1915"
            ],
            "ir": "pybuda",
            "name": "transpose_1914",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1865"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1914
        },
        "transpose_1916": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1917"
            ],
            "ir": "pybuda",
            "name": "transpose_1916",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1915"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1916
        },
        "transpose_1919": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1920"
            ],
            "ir": "pybuda",
            "name": "transpose_1919",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1919
        },
        "transpose_1927": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_143_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1927",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1926"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1927
        },
        "transpose_1928": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1928",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1923"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1928
        },
        "transpose_1929": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1929",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1855"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1929
        },
        "transpose_1930": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1930",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1842"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1930
        },
        "transpose_1931": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1931",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1833"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1931
        },
        "transpose_1932": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1932",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1820"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1932
        },
        "transpose_1933": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1934"
            ],
            "ir": "pybuda",
            "name": "transpose_1933",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1812"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1933
        },
        "transpose_1937": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1938"
            ],
            "ir": "pybuda",
            "name": "transpose_1937",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1937
        },
        "transpose_1945": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_138_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1945",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1944"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1945
        },
        "transpose_1946": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1946",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1941"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1946
        },
        "transpose_1948": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1949"
            ],
            "ir": "pybuda",
            "name": "transpose_1948",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1803"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1948
        },
        "transpose_1950": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1951"
            ],
            "ir": "pybuda",
            "name": "transpose_1950",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1949"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1950
        },
        "transpose_1953": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1954"
            ],
            "ir": "pybuda",
            "name": "transpose_1953",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1953
        },
        "transpose_1961": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_137_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1961",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1960"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1961
        },
        "transpose_1962": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1962",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1957"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1962
        },
        "transpose_1963": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1963",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1793"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1963
        },
        "transpose_1964": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1964",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1780"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1964
        },
        "transpose_1965": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1965",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1771"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1965
        },
        "transpose_1966": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1966",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1758"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1966
        },
        "transpose_1967": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1968"
            ],
            "ir": "pybuda",
            "name": "transpose_1967",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1750"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1967
        },
        "transpose_1971": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1972"
            ],
            "ir": "pybuda",
            "name": "transpose_1971",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1971
        },
        "transpose_1979": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_132_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1979",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1978"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1979
        },
        "transpose_1980": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1980",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1975"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1980
        },
        "transpose_1982": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1983"
            ],
            "ir": "pybuda",
            "name": "transpose_1982",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1741"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1982
        },
        "transpose_1984": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_1985"
            ],
            "ir": "pybuda",
            "name": "transpose_1984",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1983"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1984
        },
        "transpose_1987": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1988"
            ],
            "ir": "pybuda",
            "name": "transpose_1987",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1987
        },
        "transpose_1995": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_131_1"
            ],
            "ir": "pybuda",
            "name": "transpose_1995",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1994"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1995
        },
        "transpose_1996": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1996",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1991"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1996
        },
        "transpose_1997": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1997",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1731"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1997
        },
        "transpose_1998": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1998",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1718"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1998
        },
        "transpose_1999": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1999",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1709"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 1999
        },
        "transpose_2000": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2000",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1696"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2000
        },
        "transpose_2001": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2002"
            ],
            "ir": "pybuda",
            "name": "transpose_2001",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1688"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2001
        },
        "transpose_2005": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2006"
            ],
            "ir": "pybuda",
            "name": "transpose_2005",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2005
        },
        "transpose_2013": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_126_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2013",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2012"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2013
        },
        "transpose_2014": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2014",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2009"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2014
        },
        "transpose_2016": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2017"
            ],
            "ir": "pybuda",
            "name": "transpose_2016",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1679"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2016
        },
        "transpose_2018": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2019"
            ],
            "ir": "pybuda",
            "name": "transpose_2018",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2017"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2018
        },
        "transpose_2021": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2022"
            ],
            "ir": "pybuda",
            "name": "transpose_2021",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2021
        },
        "transpose_2029": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_125_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2029",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2028"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2029
        },
        "transpose_2030": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2030",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2025"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2030
        },
        "transpose_2031": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2031",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1669"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2031
        },
        "transpose_2032": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2032",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1656"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2032
        },
        "transpose_2033": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2033",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1647"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2033
        },
        "transpose_2034": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2034",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1634"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2034
        },
        "transpose_2035": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2036"
            ],
            "ir": "pybuda",
            "name": "transpose_2035",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1626"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2035
        },
        "transpose_2039": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2040"
            ],
            "ir": "pybuda",
            "name": "transpose_2039",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2039
        },
        "transpose_2047": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_120_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2047",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2046"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2047
        },
        "transpose_2048": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2048",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2043"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2048
        },
        "transpose_2050": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2051"
            ],
            "ir": "pybuda",
            "name": "transpose_2050",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1617"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2050
        },
        "transpose_2052": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2053"
            ],
            "ir": "pybuda",
            "name": "transpose_2052",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2051"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2052
        },
        "transpose_2055": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2056"
            ],
            "ir": "pybuda",
            "name": "transpose_2055",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2055
        },
        "transpose_2063": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_119_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2063",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2062"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2063
        },
        "transpose_2064": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2064",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2059"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2064
        },
        "transpose_2065": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2065",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1607"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2065
        },
        "transpose_2066": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2066",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1594"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2066
        },
        "transpose_2067": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2067",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1585"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2067
        },
        "transpose_2068": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2068",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1572"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2068
        },
        "transpose_2069": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2070"
            ],
            "ir": "pybuda",
            "name": "transpose_2069",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1564"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2069
        },
        "transpose_2073": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2074"
            ],
            "ir": "pybuda",
            "name": "transpose_2073",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2073
        },
        "transpose_2081": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_114_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2081",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2080"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2081
        },
        "transpose_2082": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2082",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2077"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2082
        },
        "transpose_2084": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2085"
            ],
            "ir": "pybuda",
            "name": "transpose_2084",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1555"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2084
        },
        "transpose_2086": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2087"
            ],
            "ir": "pybuda",
            "name": "transpose_2086",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2085"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2086
        },
        "transpose_2089": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2090"
            ],
            "ir": "pybuda",
            "name": "transpose_2089",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2089
        },
        "transpose_2097": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_113_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2097",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2096"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2097
        },
        "transpose_2098": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2098",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2093"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2098
        },
        "transpose_2099": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2099",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1545"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2099
        },
        "transpose_2100": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2100",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1532"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2100
        },
        "transpose_2101": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2101",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1523"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2101
        },
        "transpose_2102": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2102",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1510"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2102
        },
        "transpose_2103": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2104"
            ],
            "ir": "pybuda",
            "name": "transpose_2103",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1502"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2103
        },
        "transpose_2107": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2108"
            ],
            "ir": "pybuda",
            "name": "transpose_2107",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2107
        },
        "transpose_2115": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_108_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2115",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2114"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2115
        },
        "transpose_2116": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2116",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2111"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2116
        },
        "transpose_2118": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2119"
            ],
            "ir": "pybuda",
            "name": "transpose_2118",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1493"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2118
        },
        "transpose_2120": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2121"
            ],
            "ir": "pybuda",
            "name": "transpose_2120",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2119"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2120
        },
        "transpose_2123": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2124"
            ],
            "ir": "pybuda",
            "name": "transpose_2123",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2123
        },
        "transpose_2131": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_107_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2131",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2130"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2131
        },
        "transpose_2132": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2132",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2127"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2132
        },
        "transpose_2133": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2133",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1483"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2133
        },
        "transpose_2134": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2134",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1470"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2134
        },
        "transpose_2135": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2135",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1461"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2135
        },
        "transpose_2136": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2136",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1448"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2136
        },
        "transpose_2137": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2138"
            ],
            "ir": "pybuda",
            "name": "transpose_2137",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1440"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2137
        },
        "transpose_2141": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2142"
            ],
            "ir": "pybuda",
            "name": "transpose_2141",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2141
        },
        "transpose_2149": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_102_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2149",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2148"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2149
        },
        "transpose_2150": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2150",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2145"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2150
        },
        "transpose_2152": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2153"
            ],
            "ir": "pybuda",
            "name": "transpose_2152",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1431"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2152
        },
        "transpose_2154": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2155"
            ],
            "ir": "pybuda",
            "name": "transpose_2154",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2153"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2154
        },
        "transpose_2157": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2158"
            ],
            "ir": "pybuda",
            "name": "transpose_2157",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2157
        },
        "transpose_2165": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_101_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2165",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2164"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2165
        },
        "transpose_2166": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2166",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2161"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2166
        },
        "transpose_2167": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2167",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1421"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2167
        },
        "transpose_2168": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2168",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1408"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2168
        },
        "transpose_2169": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2169",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1399"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2169
        },
        "transpose_2170": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2170",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1386"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2170
        },
        "transpose_2171": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2172"
            ],
            "ir": "pybuda",
            "name": "transpose_2171",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1378"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2171
        },
        "transpose_2175": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2176"
            ],
            "ir": "pybuda",
            "name": "transpose_2175",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2175
        },
        "transpose_2183": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_96_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2183",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2182"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2183
        },
        "transpose_2184": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2184",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2179"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2184
        },
        "transpose_2186": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2187"
            ],
            "ir": "pybuda",
            "name": "transpose_2186",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1369"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2186
        },
        "transpose_2188": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2189"
            ],
            "ir": "pybuda",
            "name": "transpose_2188",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2187"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2188
        },
        "transpose_2191": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2192"
            ],
            "ir": "pybuda",
            "name": "transpose_2191",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2191
        },
        "transpose_2199": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_95_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2199",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2198"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2199
        },
        "transpose_2200": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2200",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2195"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2200
        },
        "transpose_2201": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2201",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1359"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2201
        },
        "transpose_2202": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2202",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1346"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2202
        },
        "transpose_2203": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2203",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1337"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2203
        },
        "transpose_2204": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2204",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1324"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2204
        },
        "transpose_2205": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2206"
            ],
            "ir": "pybuda",
            "name": "transpose_2205",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1316"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2205
        },
        "transpose_2209": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2210"
            ],
            "ir": "pybuda",
            "name": "transpose_2209",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2209
        },
        "transpose_2217": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_90_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2217",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2216"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2217
        },
        "transpose_2218": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2218",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2213"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2218
        },
        "transpose_2220": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2221"
            ],
            "ir": "pybuda",
            "name": "transpose_2220",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1307"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2220
        },
        "transpose_2222": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2223"
            ],
            "ir": "pybuda",
            "name": "transpose_2222",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2222
        },
        "transpose_2225": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2226"
            ],
            "ir": "pybuda",
            "name": "transpose_2225",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2225
        },
        "transpose_2233": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_89_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2233",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2232"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2233
        },
        "transpose_2234": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2234",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2229"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2234
        },
        "transpose_2235": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2235",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1297"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2235
        },
        "transpose_2236": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2236",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1284"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2236
        },
        "transpose_2237": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2237",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1275"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2237
        },
        "transpose_2238": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2238",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1262"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2238
        },
        "transpose_2239": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2240"
            ],
            "ir": "pybuda",
            "name": "transpose_2239",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1254"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2239
        },
        "transpose_2243": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2244"
            ],
            "ir": "pybuda",
            "name": "transpose_2243",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2243
        },
        "transpose_2251": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_84_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2251",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2250"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2251
        },
        "transpose_2252": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2252",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2247"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2252
        },
        "transpose_2254": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2255"
            ],
            "ir": "pybuda",
            "name": "transpose_2254",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1245"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2254
        },
        "transpose_2256": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2257"
            ],
            "ir": "pybuda",
            "name": "transpose_2256",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2256
        },
        "transpose_2259": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2260"
            ],
            "ir": "pybuda",
            "name": "transpose_2259",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2259
        },
        "transpose_2267": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_83_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2267",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2266"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2267
        },
        "transpose_2268": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2268",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2263"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2268
        },
        "transpose_2269": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2269",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1235"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2269
        },
        "transpose_2270": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2270",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1222"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2270
        },
        "transpose_2271": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2271",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1213"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2271
        },
        "transpose_2272": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2272",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1200"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2272
        },
        "transpose_2273": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2274"
            ],
            "ir": "pybuda",
            "name": "transpose_2273",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1192"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2273
        },
        "transpose_2277": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2278"
            ],
            "ir": "pybuda",
            "name": "transpose_2277",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2277
        },
        "transpose_2285": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_78_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2285",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2284"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2285
        },
        "transpose_2286": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2286",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2281"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2286
        },
        "transpose_2288": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2289"
            ],
            "ir": "pybuda",
            "name": "transpose_2288",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1183"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2288
        },
        "transpose_2290": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2291"
            ],
            "ir": "pybuda",
            "name": "transpose_2290",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2289"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2290
        },
        "transpose_2293": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2294"
            ],
            "ir": "pybuda",
            "name": "transpose_2293",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2293
        },
        "transpose_2301": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_77_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2301",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2300"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2301
        },
        "transpose_2302": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2302",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2297"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2302
        },
        "transpose_2303": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2303",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1173"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2303
        },
        "transpose_2304": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2304",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1160"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2304
        },
        "transpose_2305": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2305",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1151"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2305
        },
        "transpose_2306": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2306",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1138"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2306
        },
        "transpose_2307": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2308"
            ],
            "ir": "pybuda",
            "name": "transpose_2307",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1130"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2307
        },
        "transpose_2311": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2312"
            ],
            "ir": "pybuda",
            "name": "transpose_2311",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2311
        },
        "transpose_2319": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_72_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2319",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2318"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2319
        },
        "transpose_2320": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2320",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2315"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2320
        },
        "transpose_2322": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2323"
            ],
            "ir": "pybuda",
            "name": "transpose_2322",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1121"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2322
        },
        "transpose_2324": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2325"
            ],
            "ir": "pybuda",
            "name": "transpose_2324",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2323"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2324
        },
        "transpose_2327": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2328"
            ],
            "ir": "pybuda",
            "name": "transpose_2327",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2327
        },
        "transpose_2335": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_71_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2335",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2334"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2335
        },
        "transpose_2336": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2336",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2331"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2336
        },
        "transpose_2337": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2337",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1111"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2337
        },
        "transpose_2338": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2338",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1098"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2338
        },
        "transpose_2339": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2339",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1089"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2339
        },
        "transpose_2340": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2340",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1076"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2340
        },
        "transpose_2341": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2342"
            ],
            "ir": "pybuda",
            "name": "transpose_2341",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1068"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2341
        },
        "transpose_2345": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2346"
            ],
            "ir": "pybuda",
            "name": "transpose_2345",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2345
        },
        "transpose_2353": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_66_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2353",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2352"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2353
        },
        "transpose_2354": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2354",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2349"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2354
        },
        "transpose_2356": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2357"
            ],
            "ir": "pybuda",
            "name": "transpose_2356",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1059"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2356
        },
        "transpose_2358": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2359"
            ],
            "ir": "pybuda",
            "name": "transpose_2358",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2357"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2358
        },
        "transpose_2361": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2362"
            ],
            "ir": "pybuda",
            "name": "transpose_2361",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2361
        },
        "transpose_2369": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_65_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2369",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2368"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2369
        },
        "transpose_2370": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2370",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2365"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2370
        },
        "transpose_2371": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2371",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1049"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2371
        },
        "transpose_2372": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2372",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1036"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2372
        },
        "transpose_2373": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2373",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1027"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2373
        },
        "transpose_2374": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2374",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_1014"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2374
        },
        "transpose_2375": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2376"
            ],
            "ir": "pybuda",
            "name": "transpose_2375",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1006"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2375
        },
        "transpose_2379": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2380"
            ],
            "ir": "pybuda",
            "name": "transpose_2379",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2379
        },
        "transpose_2387": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_60_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2387",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2386"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2387
        },
        "transpose_2388": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2388",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2383"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2388
        },
        "transpose_2390": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2391"
            ],
            "ir": "pybuda",
            "name": "transpose_2390",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_997"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2390
        },
        "transpose_2392": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2393"
            ],
            "ir": "pybuda",
            "name": "transpose_2392",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2391"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2392
        },
        "transpose_2395": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2396"
            ],
            "ir": "pybuda",
            "name": "transpose_2395",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2395
        },
        "transpose_2403": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_59_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2403",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2402"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2403
        },
        "transpose_2404": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2404",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2399"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2404
        },
        "transpose_2405": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2405",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_987"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2405
        },
        "transpose_2406": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2406",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_974"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2406
        },
        "transpose_2407": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2407",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_965"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2407
        },
        "transpose_2408": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2408",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_952"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2408
        },
        "transpose_2409": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2410"
            ],
            "ir": "pybuda",
            "name": "transpose_2409",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_944"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2409
        },
        "transpose_2413": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2414"
            ],
            "ir": "pybuda",
            "name": "transpose_2413",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2413
        },
        "transpose_2421": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_54_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2421",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2420"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2421
        },
        "transpose_2422": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2422",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2417"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2422
        },
        "transpose_2424": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2425"
            ],
            "ir": "pybuda",
            "name": "transpose_2424",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_935"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2424
        },
        "transpose_2426": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2427"
            ],
            "ir": "pybuda",
            "name": "transpose_2426",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2425"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2426
        },
        "transpose_2429": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2430"
            ],
            "ir": "pybuda",
            "name": "transpose_2429",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2429
        },
        "transpose_2437": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_53_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2437",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2436"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2437
        },
        "transpose_2438": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2438",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2433"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2438
        },
        "transpose_2439": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2439",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_925"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2439
        },
        "transpose_2440": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2440",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_912"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2440
        },
        "transpose_2441": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2441",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_903"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2441
        },
        "transpose_2442": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2442",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_890"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2442
        },
        "transpose_2443": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2444"
            ],
            "ir": "pybuda",
            "name": "transpose_2443",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_882"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2443
        },
        "transpose_2447": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2448"
            ],
            "ir": "pybuda",
            "name": "transpose_2447",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2447
        },
        "transpose_2455": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_48_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2455",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2454"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2455
        },
        "transpose_2456": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2456",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2451"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2456
        },
        "transpose_2458": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2459"
            ],
            "ir": "pybuda",
            "name": "transpose_2458",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_873"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2458
        },
        "transpose_2460": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2461"
            ],
            "ir": "pybuda",
            "name": "transpose_2460",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2460
        },
        "transpose_2463": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2464"
            ],
            "ir": "pybuda",
            "name": "transpose_2463",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2463
        },
        "transpose_2471": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_47_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2471",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2470"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2471
        },
        "transpose_2472": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2472",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2467"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2472
        },
        "transpose_2473": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2473",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_863"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2473
        },
        "transpose_2474": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2474",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_850"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2474
        },
        "transpose_2475": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2475",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_841"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2475
        },
        "transpose_2476": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2476",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_828"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2476
        },
        "transpose_2477": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2478"
            ],
            "ir": "pybuda",
            "name": "transpose_2477",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_820"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2477
        },
        "transpose_2481": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2482"
            ],
            "ir": "pybuda",
            "name": "transpose_2481",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2481
        },
        "transpose_2489": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_42_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2489",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2488"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2489
        },
        "transpose_2490": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2490",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2485"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2490
        },
        "transpose_2492": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2493"
            ],
            "ir": "pybuda",
            "name": "transpose_2492",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_811"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2492
        },
        "transpose_2494": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2495"
            ],
            "ir": "pybuda",
            "name": "transpose_2494",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2494
        },
        "transpose_2497": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2498"
            ],
            "ir": "pybuda",
            "name": "transpose_2497",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2497
        },
        "transpose_2505": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_41_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2505",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2504"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2505
        },
        "transpose_2506": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2506",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2501"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2506
        },
        "transpose_2507": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2507",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_801"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2507
        },
        "transpose_2508": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2508",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_788"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2508
        },
        "transpose_2509": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2509",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_779"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2509
        },
        "transpose_2510": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2510",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_766"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2510
        },
        "transpose_2511": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2512"
            ],
            "ir": "pybuda",
            "name": "transpose_2511",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_758"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2511
        },
        "transpose_2515": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2516"
            ],
            "ir": "pybuda",
            "name": "transpose_2515",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2515
        },
        "transpose_2523": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_36_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2523",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2522"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2523
        },
        "transpose_2524": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2524",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2519"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2524
        },
        "transpose_2526": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2527"
            ],
            "ir": "pybuda",
            "name": "transpose_2526",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_749"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2526
        },
        "transpose_2528": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2529"
            ],
            "ir": "pybuda",
            "name": "transpose_2528",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2528
        },
        "transpose_2531": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2532"
            ],
            "ir": "pybuda",
            "name": "transpose_2531",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2531
        },
        "transpose_2539": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_35_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2539",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2538"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2539
        },
        "transpose_2540": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2540",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2535"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2540
        },
        "transpose_2541": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2541",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_739"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2541
        },
        "transpose_2542": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2542",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_726"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2542
        },
        "transpose_2543": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2543",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_717"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2543
        },
        "transpose_2544": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2544",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_704"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2544
        },
        "transpose_2545": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2546"
            ],
            "ir": "pybuda",
            "name": "transpose_2545",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_696"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2545
        },
        "transpose_2549": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2550"
            ],
            "ir": "pybuda",
            "name": "transpose_2549",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2549
        },
        "transpose_2557": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_30_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2557",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2556"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2557
        },
        "transpose_2558": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2558",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2553"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2558
        },
        "transpose_2560": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2561"
            ],
            "ir": "pybuda",
            "name": "transpose_2560",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_687"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2560
        },
        "transpose_2562": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2563"
            ],
            "ir": "pybuda",
            "name": "transpose_2562",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2562
        },
        "transpose_2565": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2566"
            ],
            "ir": "pybuda",
            "name": "transpose_2565",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2565
        },
        "transpose_2573": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_29_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2573",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2572"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2573
        },
        "transpose_2574": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2574",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2569"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2574
        },
        "transpose_2575": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2575",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_677"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2575
        },
        "transpose_2576": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2576",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_664"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2576
        },
        "transpose_2577": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2577",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_655"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2577
        },
        "transpose_2578": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2578",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_642"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2578
        },
        "transpose_2579": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2580"
            ],
            "ir": "pybuda",
            "name": "transpose_2579",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_634"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2579
        },
        "transpose_2583": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2584"
            ],
            "ir": "pybuda",
            "name": "transpose_2583",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2583
        },
        "transpose_2591": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_24_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2591",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2590"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2591
        },
        "transpose_2592": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2592",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2587"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2592
        },
        "transpose_2594": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2595"
            ],
            "ir": "pybuda",
            "name": "transpose_2594",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_625"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2594
        },
        "transpose_2596": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2597"
            ],
            "ir": "pybuda",
            "name": "transpose_2596",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2595"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2596
        },
        "transpose_2599": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2600"
            ],
            "ir": "pybuda",
            "name": "transpose_2599",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2599
        },
        "transpose_2607": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_23_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2607",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2606"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2607
        },
        "transpose_2608": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2608",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2603"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2608
        },
        "transpose_2609": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2609",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_615"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2609
        },
        "transpose_2610": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2610",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_602"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2610
        },
        "transpose_2611": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2611",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_593"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2611
        },
        "transpose_2612": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2612",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_580"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2612
        },
        "transpose_2613": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2614"
            ],
            "ir": "pybuda",
            "name": "transpose_2613",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_572"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2613
        },
        "transpose_2617": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2618"
            ],
            "ir": "pybuda",
            "name": "transpose_2617",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2617
        },
        "transpose_2625": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_18_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2625",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2624"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2625
        },
        "transpose_2626": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2626",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2621"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2626
        },
        "transpose_2628": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2629"
            ],
            "ir": "pybuda",
            "name": "transpose_2628",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_563"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2628
        },
        "transpose_2630": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2631"
            ],
            "ir": "pybuda",
            "name": "transpose_2630",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2630
        },
        "transpose_2633": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2634"
            ],
            "ir": "pybuda",
            "name": "transpose_2633",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2633
        },
        "transpose_2641": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_17_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2641",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2640"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2641
        },
        "transpose_2642": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2642",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2637"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2642
        },
        "transpose_2643": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2643",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_553"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2643
        },
        "transpose_2644": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2644",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_540"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2644
        },
        "transpose_2645": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2645",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_531"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2645
        },
        "transpose_2646": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2646",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_518"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2646
        },
        "transpose_2647": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2648"
            ],
            "ir": "pybuda",
            "name": "transpose_2647",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_510"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2647
        },
        "transpose_2651": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2652"
            ],
            "ir": "pybuda",
            "name": "transpose_2651",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2651
        },
        "transpose_2659": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_12_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2659",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2658"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2659
        },
        "transpose_2660": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2660",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2655"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2660
        },
        "transpose_2662": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2663"
            ],
            "ir": "pybuda",
            "name": "transpose_2662",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_501"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2662
        },
        "transpose_2664": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2665"
            ],
            "ir": "pybuda",
            "name": "transpose_2664",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2664
        },
        "transpose_2667": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2668"
            ],
            "ir": "pybuda",
            "name": "transpose_2667",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2667
        },
        "transpose_2675": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_11_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2675",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2674"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2675
        },
        "transpose_2676": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2676",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2671"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2676
        },
        "transpose_2677": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2677",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_491"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2677
        },
        "transpose_2678": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2678",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_478"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2678
        },
        "transpose_2679": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2679",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_469"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2679
        },
        "transpose_2680": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2680",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_456"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2680
        },
        "transpose_2681": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2682"
            ],
            "ir": "pybuda",
            "name": "transpose_2681",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_448"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2681
        },
        "transpose_2685": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2686"
            ],
            "ir": "pybuda",
            "name": "transpose_2685",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2685
        },
        "transpose_2693": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_6_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2693",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2692"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2693
        },
        "transpose_2694": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2694",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2689"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2694
        },
        "transpose_2696": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2697"
            ],
            "ir": "pybuda",
            "name": "transpose_2696",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_439"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2696
        },
        "transpose_2698": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "pybuda.hslice_2699"
            ],
            "ir": "pybuda",
            "name": "transpose_2698",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2698
        },
        "transpose_2701": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2702"
            ],
            "ir": "pybuda",
            "name": "transpose_2701",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2701
        },
        "transpose_2709": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_5_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2709",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2708"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2709
        },
        "transpose_2710": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2710",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2705"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2710
        },
        "transpose_2711": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2711",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_429"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2711
        },
        "transpose_2712": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2712",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_416"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2712
        },
        "transpose_2713": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2713",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_407"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2713
        },
        "transpose_2714": {
            "cache": {
                "shape": [
                    1024,
                    1
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_2715"
            ],
            "ir": "pybuda",
            "name": "transpose_2714",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_394"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2714
        },
        "transpose_2724": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_0_1"
            ],
            "ir": "pybuda",
            "name": "transpose_2724",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2723"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2724
        },
        "transpose_2725": {
            "cache": {
                "shape": [
                    1024,
                    1
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_2726"
            ],
            "ir": "pybuda",
            "name": "transpose_2725",
            "opcode": "RelayOp",
            "output_nodes": [
                "pybuda.matmul_2720"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 2725
        },
        "transpose_398": {
            "cache": {
                "shape": [
                    1,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_1_1"
            ],
            "ir": "pybuda",
            "name": "transpose_398",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_397"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 398
        },
        "transpose_411": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_2_1"
            ],
            "ir": "pybuda",
            "name": "transpose_411",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_410"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 411
        },
        "transpose_420": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_3_1"
            ],
            "ir": "pybuda",
            "name": "transpose_420",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_419"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 420
        },
        "transpose_433": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_4_1"
            ],
            "ir": "pybuda",
            "name": "transpose_433",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_432"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 433
        },
        "transpose_437": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_0_0"
            ],
            "ir": "pybuda",
            "name": "transpose_437",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 437
        },
        "transpose_452": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_453"
            ],
            "ir": "pybuda",
            "name": "transpose_452",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 452
        },
        "transpose_460": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_7_1"
            ],
            "ir": "pybuda",
            "name": "transpose_460",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_459"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 460
        },
        "transpose_473": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_8_1"
            ],
            "ir": "pybuda",
            "name": "transpose_473",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_472"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 473
        },
        "transpose_482": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_9_1"
            ],
            "ir": "pybuda",
            "name": "transpose_482",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_481"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 482
        },
        "transpose_495": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_10_1"
            ],
            "ir": "pybuda",
            "name": "transpose_495",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_494"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 495
        },
        "transpose_499": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_4_0"
            ],
            "ir": "pybuda",
            "name": "transpose_499",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 499
        },
        "transpose_514": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_515"
            ],
            "ir": "pybuda",
            "name": "transpose_514",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 514
        },
        "transpose_522": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_13_1"
            ],
            "ir": "pybuda",
            "name": "transpose_522",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_521"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 522
        },
        "transpose_535": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_14_1"
            ],
            "ir": "pybuda",
            "name": "transpose_535",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_534"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 535
        },
        "transpose_544": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_15_1"
            ],
            "ir": "pybuda",
            "name": "transpose_544",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_543"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 544
        },
        "transpose_557": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_16_1"
            ],
            "ir": "pybuda",
            "name": "transpose_557",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_556"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 557
        },
        "transpose_561": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_8_0"
            ],
            "ir": "pybuda",
            "name": "transpose_561",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 561
        },
        "transpose_576": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_577"
            ],
            "ir": "pybuda",
            "name": "transpose_576",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 576
        },
        "transpose_584": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_19_1"
            ],
            "ir": "pybuda",
            "name": "transpose_584",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_583"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 584
        },
        "transpose_597": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_20_1"
            ],
            "ir": "pybuda",
            "name": "transpose_597",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_596"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 597
        },
        "transpose_606": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_21_1"
            ],
            "ir": "pybuda",
            "name": "transpose_606",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_605"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 606
        },
        "transpose_619": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_22_1"
            ],
            "ir": "pybuda",
            "name": "transpose_619",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_618"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 619
        },
        "transpose_623": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_12_0"
            ],
            "ir": "pybuda",
            "name": "transpose_623",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 623
        },
        "transpose_638": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_639"
            ],
            "ir": "pybuda",
            "name": "transpose_638",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 638
        },
        "transpose_646": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_25_1"
            ],
            "ir": "pybuda",
            "name": "transpose_646",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_645"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 646
        },
        "transpose_659": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_26_1"
            ],
            "ir": "pybuda",
            "name": "transpose_659",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_658"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 659
        },
        "transpose_668": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_27_1"
            ],
            "ir": "pybuda",
            "name": "transpose_668",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_667"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 668
        },
        "transpose_681": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_28_1"
            ],
            "ir": "pybuda",
            "name": "transpose_681",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_680"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 681
        },
        "transpose_685": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_16_0"
            ],
            "ir": "pybuda",
            "name": "transpose_685",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 685
        },
        "transpose_700": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_701"
            ],
            "ir": "pybuda",
            "name": "transpose_700",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 700
        },
        "transpose_708": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_31_1"
            ],
            "ir": "pybuda",
            "name": "transpose_708",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_707"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 708
        },
        "transpose_721": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_32_1"
            ],
            "ir": "pybuda",
            "name": "transpose_721",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_720"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 721
        },
        "transpose_730": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_33_1"
            ],
            "ir": "pybuda",
            "name": "transpose_730",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_729"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 730
        },
        "transpose_743": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_34_1"
            ],
            "ir": "pybuda",
            "name": "transpose_743",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_742"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 743
        },
        "transpose_747": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_20_0"
            ],
            "ir": "pybuda",
            "name": "transpose_747",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 747
        },
        "transpose_762": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_763"
            ],
            "ir": "pybuda",
            "name": "transpose_762",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 762
        },
        "transpose_770": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_37_1"
            ],
            "ir": "pybuda",
            "name": "transpose_770",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_769"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 770
        },
        "transpose_783": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_38_1"
            ],
            "ir": "pybuda",
            "name": "transpose_783",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_782"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 783
        },
        "transpose_792": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_39_1"
            ],
            "ir": "pybuda",
            "name": "transpose_792",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_791"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 792
        },
        "transpose_805": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_40_1"
            ],
            "ir": "pybuda",
            "name": "transpose_805",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_804"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 805
        },
        "transpose_809": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_24_0"
            ],
            "ir": "pybuda",
            "name": "transpose_809",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 809
        },
        "transpose_824": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_825"
            ],
            "ir": "pybuda",
            "name": "transpose_824",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 824
        },
        "transpose_832": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_43_1"
            ],
            "ir": "pybuda",
            "name": "transpose_832",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_831"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 832
        },
        "transpose_845": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_44_1"
            ],
            "ir": "pybuda",
            "name": "transpose_845",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_844"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 845
        },
        "transpose_854": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_45_1"
            ],
            "ir": "pybuda",
            "name": "transpose_854",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_853"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 854
        },
        "transpose_867": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_46_1"
            ],
            "ir": "pybuda",
            "name": "transpose_867",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_866"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 867
        },
        "transpose_871": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_28_0"
            ],
            "ir": "pybuda",
            "name": "transpose_871",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 871
        },
        "transpose_886": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_887"
            ],
            "ir": "pybuda",
            "name": "transpose_886",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 886
        },
        "transpose_894": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_49_1"
            ],
            "ir": "pybuda",
            "name": "transpose_894",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_893"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 894
        },
        "transpose_907": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_50_1"
            ],
            "ir": "pybuda",
            "name": "transpose_907",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_906"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 907
        },
        "transpose_916": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_51_1"
            ],
            "ir": "pybuda",
            "name": "transpose_916",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_915"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 916
        },
        "transpose_929": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_52_1"
            ],
            "ir": "pybuda",
            "name": "transpose_929",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_928"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 929
        },
        "transpose_933": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_32_0"
            ],
            "ir": "pybuda",
            "name": "transpose_933",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_932"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 933
        },
        "transpose_948": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_949"
            ],
            "ir": "pybuda",
            "name": "transpose_948",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 948
        },
        "transpose_956": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_55_1"
            ],
            "ir": "pybuda",
            "name": "transpose_956",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_955"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 956
        },
        "transpose_969": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_56_1"
            ],
            "ir": "pybuda",
            "name": "transpose_969",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_968"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 969
        },
        "transpose_978": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_57_1"
            ],
            "ir": "pybuda",
            "name": "transpose_978",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_977"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 978
        },
        "transpose_991": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_58_1"
            ],
            "ir": "pybuda",
            "name": "transpose_991",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_990"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "transpose",
            "unique_id": 991
        },
        "transpose_995": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "FunctionVar_36_0"
            ],
            "ir": "pybuda",
            "name": "transpose_995",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_994"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 995
        },
        "tuple_390": {
            "cache": {
                "shape": [
                    [
                        "1",
                        "384"
                    ],
                    [
                        "1",
                        "384"
                    ]
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "reshape_391",
                "reshape_2717"
            ],
            "ir": "pybuda",
            "name": "tuple_390",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 390
        }
    }
}