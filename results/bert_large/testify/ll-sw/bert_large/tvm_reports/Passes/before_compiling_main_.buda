{
    "graph": {},
    "nodes": {
        "add_1007": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1008",
                "layernorm_1031"
            ],
            "ir": "pybuda",
            "name": "add_1007",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a505020), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1007
        },
        "add_1020": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1021",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1020",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1019"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31ba9a90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1020
        },
        "add_1032": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1033",
                "layernorm_1043"
            ],
            "ir": "pybuda",
            "name": "add_1032",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1031"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output, 0x19bb3910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1032
        },
        "add_1044": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1045",
                "layernorm_1068"
            ],
            "ir": "pybuda",
            "name": "add_1044",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1043"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a5206a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1044
        },
        "add_1057": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1058",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1057",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1056"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a509a40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1057
        },
        "add_1069": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1070",
                "layernorm_1080"
            ],
            "ir": "pybuda",
            "name": "add_1069",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1068"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9c3520), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1069
        },
        "add_1081": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1082",
                "layernorm_1105"
            ],
            "ir": "pybuda",
            "name": "add_1081",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1080"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a500890), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1081
        },
        "add_1094": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1095",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1094",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1093"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91823d90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1094
        },
        "add_1106": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1107",
                "layernorm_1117"
            ],
            "ir": "pybuda",
            "name": "add_1106",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1105"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output, 0x2fb49910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1106
        },
        "add_1118": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1119",
                "layernorm_1142"
            ],
            "ir": "pybuda",
            "name": "add_1118",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1117"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a45ddb0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1118
        },
        "add_1131": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1132",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1131",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1130"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4890c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1131
        },
        "add_1143": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1144",
                "layernorm_1154"
            ],
            "ir": "pybuda",
            "name": "add_1143",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1142"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output, 0x8ab077c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1143
        },
        "add_1155": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1156",
                "layernorm_1179"
            ],
            "ir": "pybuda",
            "name": "add_1155",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1154"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba60c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1155
        },
        "add_1168": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1169",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1168",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1167"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bbfab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1168
        },
        "add_1180": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1181",
                "layernorm_1191"
            ],
            "ir": "pybuda",
            "name": "add_1180",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1179"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output, 0x917a5e00), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1180
        },
        "add_1192": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1193",
                "layernorm_1216"
            ],
            "ir": "pybuda",
            "name": "add_1192",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba7070), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1192
        },
        "add_1205": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1206",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1205",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1204"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b5bbd0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1205
        },
        "add_1217": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1218",
                "layernorm_1228"
            ],
            "ir": "pybuda",
            "name": "add_1217",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1216"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9be180), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1217
        },
        "add_1229": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1230",
                "layernorm_1253"
            ],
            "ir": "pybuda",
            "name": "add_1229",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x8ab53930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1229
        },
        "add_1242": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1243",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1242",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1241"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9e4730), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1242
        },
        "add_1254": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1255",
                "layernorm_1265"
            ],
            "ir": "pybuda",
            "name": "add_1254",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1253"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output, 0xd950e20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1254
        },
        "add_1266": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1267",
                "nn.dropout_1290"
            ],
            "ir": "pybuda",
            "name": "add_1266",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1265"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xd96bf40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1266
        },
        "add_1279": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1280",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_1279",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1278"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9182dc30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1279
        },
        "add_1292": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "add_1293",
                "embedding_1298"
            ],
            "ir": "pybuda",
            "name": "add_1292",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1291"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add_, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x8ab40e80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1292
        },
        "add_1293": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "embedding_1294",
                "embedding_1296"
            ],
            "ir": "pybuda",
            "name": "add_1293",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1292"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x79f6e300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1293
        },
        "add_1338": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1339",
                "multiply_1340"
            ],
            "ir": "pybuda",
            "name": "add_1338",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1260"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1338
        },
        "add_1375": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1376",
                "multiply_1377"
            ],
            "ir": "pybuda",
            "name": "add_1375",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1223"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1375
        },
        "add_1412": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1413",
                "multiply_1414"
            ],
            "ir": "pybuda",
            "name": "add_1412",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1186"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1412
        },
        "add_1449": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1450",
                "multiply_1451"
            ],
            "ir": "pybuda",
            "name": "add_1449",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1149"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1449
        },
        "add_1486": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1487",
                "multiply_1488"
            ],
            "ir": "pybuda",
            "name": "add_1486",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1112"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1486
        },
        "add_1523": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1524",
                "multiply_1525"
            ],
            "ir": "pybuda",
            "name": "add_1523",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1075"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1523
        },
        "add_1560": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1561",
                "multiply_1562"
            ],
            "ir": "pybuda",
            "name": "add_1560",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1038"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1560
        },
        "add_1597": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1598",
                "multiply_1599"
            ],
            "ir": "pybuda",
            "name": "add_1597",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1001"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1597
        },
        "add_1634": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1635",
                "multiply_1636"
            ],
            "ir": "pybuda",
            "name": "add_1634",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_964"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1634
        },
        "add_1671": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1672",
                "multiply_1673"
            ],
            "ir": "pybuda",
            "name": "add_1671",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_927"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1671
        },
        "add_1708": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1709",
                "multiply_1710"
            ],
            "ir": "pybuda",
            "name": "add_1708",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_890"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1708
        },
        "add_1745": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1746",
                "multiply_1747"
            ],
            "ir": "pybuda",
            "name": "add_1745",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_853"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1745
        },
        "add_1782": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1783",
                "multiply_1784"
            ],
            "ir": "pybuda",
            "name": "add_1782",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_816"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1782
        },
        "add_1819": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1820",
                "multiply_1821"
            ],
            "ir": "pybuda",
            "name": "add_1819",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1819
        },
        "add_1856": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1857",
                "multiply_1858"
            ],
            "ir": "pybuda",
            "name": "add_1856",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_742"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1856
        },
        "add_1893": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1894",
                "multiply_1895"
            ],
            "ir": "pybuda",
            "name": "add_1893",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_705"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1893
        },
        "add_1930": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1931",
                "multiply_1932"
            ],
            "ir": "pybuda",
            "name": "add_1930",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_668"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1930
        },
        "add_1967": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1968",
                "multiply_1969"
            ],
            "ir": "pybuda",
            "name": "add_1967",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_631"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1967
        },
        "add_2004": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2005",
                "multiply_2006"
            ],
            "ir": "pybuda",
            "name": "add_2004",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2004
        },
        "add_2041": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2042",
                "multiply_2043"
            ],
            "ir": "pybuda",
            "name": "add_2041",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_557"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2041
        },
        "add_2078": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2079",
                "multiply_2080"
            ],
            "ir": "pybuda",
            "name": "add_2078",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_520"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2078
        },
        "add_2115": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2116",
                "multiply_2117"
            ],
            "ir": "pybuda",
            "name": "add_2115",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2115
        },
        "add_2152": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2153",
                "multiply_2154"
            ],
            "ir": "pybuda",
            "name": "add_2152",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_446"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2152
        },
        "add_2189": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_2190",
                "multiply_2191"
            ],
            "ir": "pybuda",
            "name": "add_2189",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_409"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 2189
        },
        "add_403": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_404",
                "layernorm_414"
            ],
            "ir": "pybuda",
            "name": "add_403",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output, 0x94142930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 403
        },
        "add_415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_416",
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "add_415",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x126d55e0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 415
        },
        "add_428": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_429",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_428",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94190e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 428
        },
        "add_440": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_441",
                "layernorm_451"
            ],
            "ir": "pybuda",
            "name": "add_440",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output, 0x126a7350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 440
        },
        "add_452": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_453",
                "layernorm_476"
            ],
            "ir": "pybuda",
            "name": "add_452",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x917b0210), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 452
        },
        "add_465": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_466",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_465",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f668f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 465
        },
        "add_477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_478",
                "layernorm_488"
            ],
            "ir": "pybuda",
            "name": "add_477",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output, 0x941d25a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 477
        },
        "add_489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_490",
                "layernorm_513"
            ],
            "ir": "pybuda",
            "name": "add_489",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_488"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x94179fa0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 489
        },
        "add_502": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_503",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_502",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126af900), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 502
        },
        "add_514": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_515",
                "layernorm_525"
            ],
            "ir": "pybuda",
            "name": "add_514",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_513"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a445480), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 514
        },
        "add_526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_527",
                "layernorm_550"
            ],
            "ir": "pybuda",
            "name": "add_526",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_525"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf78a620), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 526
        },
        "add_539": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_540",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_539",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049c80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 539
        },
        "add_551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_552",
                "layernorm_562"
            ],
            "ir": "pybuda",
            "name": "add_551",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output, 0xf739860), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 551
        },
        "add_563": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_564",
                "layernorm_587"
            ],
            "ir": "pybuda",
            "name": "add_563",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b39bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 563
        },
        "add_576": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_577",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_576",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_575"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3652b260), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 576
        },
        "add_588": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_589",
                "layernorm_599"
            ],
            "ir": "pybuda",
            "name": "add_588",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output, 0x27f39310), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 588
        },
        "add_600": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_601",
                "layernorm_624"
            ],
            "ir": "pybuda",
            "name": "add_600",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf76bc40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 600
        },
        "add_613": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_614",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_613",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fecf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 613
        },
        "add_625": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_626",
                "layernorm_636"
            ],
            "ir": "pybuda",
            "name": "add_625",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9d6cf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 625
        },
        "add_637": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_638",
                "layernorm_661"
            ],
            "ir": "pybuda",
            "name": "add_637",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x150b3e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 637
        },
        "add_650": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_651",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_650",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_649"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf81bf50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 650
        },
        "add_662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_663",
                "layernorm_673"
            ],
            "ir": "pybuda",
            "name": "add_662",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_661"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output, 0x3645c290), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 662
        },
        "add_674": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_675",
                "layernorm_698"
            ],
            "ir": "pybuda",
            "name": "add_674",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_673"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x280244f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 674
        },
        "add_687": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_688",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_687",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3643dac0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 687
        },
        "add_699": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_700",
                "layernorm_710"
            ],
            "ir": "pybuda",
            "name": "add_699",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_698"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output, 0x27fce810), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 699
        },
        "add_711": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_712",
                "layernorm_735"
            ],
            "ir": "pybuda",
            "name": "add_711",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x15061a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 711
        },
        "add_724": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_725",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_724",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c9850), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 724
        },
        "add_736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_737",
                "layernorm_747"
            ],
            "ir": "pybuda",
            "name": "add_736",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_735"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a4d73f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 736
        },
        "add_748": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_749",
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "add_748",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x27f42770), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 748
        },
        "add_761": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_762",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_761",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_760"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fa7ca0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 761
        },
        "add_773": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_774",
                "layernorm_784"
            ],
            "ir": "pybuda",
            "name": "add_773",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e53a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 773
        },
        "add_785": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_786",
                "layernorm_809"
            ],
            "ir": "pybuda",
            "name": "add_785",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf826d40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 785
        },
        "add_798": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_799",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_798",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_797"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19be8370), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 798
        },
        "add_810": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_811",
                "layernorm_821"
            ],
            "ir": "pybuda",
            "name": "add_810",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output, 0x31bc3c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 810
        },
        "add_822": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_823",
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "add_822",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_821"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b3d300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 822
        },
        "add_835": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_836",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_835",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_834"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824de0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 835
        },
        "add_847": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_848",
                "layernorm_858"
            ],
            "ir": "pybuda",
            "name": "add_847",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output, 0xf76f920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 847
        },
        "add_859": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_860",
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "add_859",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_858"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b40c10), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 859
        },
        "add_872": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_873",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_872",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a503c30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 872
        },
        "add_884": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_885",
                "layernorm_895"
            ],
            "ir": "pybuda",
            "name": "add_884",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output, 0xda20c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 884
        },
        "add_896": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_897",
                "layernorm_920"
            ],
            "ir": "pybuda",
            "name": "add_896",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a518f60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 896
        },
        "add_909": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_910",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_909",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_908"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3648ed50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 909
        },
        "add_921": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_922",
                "layernorm_932"
            ],
            "ir": "pybuda",
            "name": "add_921",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_920"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e4190), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 921
        },
        "add_933": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_934",
                "layernorm_957"
            ],
            "ir": "pybuda",
            "name": "add_933",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_932"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a4cfa80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 933
        },
        "add_946": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_947",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_946",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_945"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36458280), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 946
        },
        "add_958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_959",
                "layernorm_969"
            ],
            "ir": "pybuda",
            "name": "add_958",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output, 0x36446a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 958
        },
        "add_970": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_971",
                "layernorm_994"
            ],
            "ir": "pybuda",
            "name": "add_970",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_969"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xda20440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 970
        },
        "add_983": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_984",
                "multiply_1315"
            ],
            "ir": "pybuda",
            "name": "add_983",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_982"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b6cff0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 983
        },
        "add_995": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_996",
                "layernorm_1006"
            ],
            "ir": "pybuda",
            "name": "add_995",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_994"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output, 0x31b556d0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 995
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "attention_mask_1",
            "opcode": "Input",
            "output_nodes": [
                "expand_dims_1322"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1291"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 8
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1291"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 7
        },
        "bert.embeddings.position_embeddings.weight": {
            "cache": {
                "shape": [
                    "512",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1298"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 5
        },
        "bert.embeddings.position_ids": {
            "cache": {
                "shape": [
                    "1",
                    "512"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_ids",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_1300"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 6
        },
        "bert.embeddings.token_type_embeddings.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.token_type_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1296"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 4
        },
        "bert.embeddings.word_embeddings.weight": {
            "cache": {
                "shape": [
                    "28996",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.word_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1294"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 3
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1265"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 18
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1265"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 17
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1268"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 16
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1335"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 15
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1308"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 12
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1313"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 11
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1286"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 10
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1302"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 9
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1328"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 14
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1333"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 13
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1261"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 20
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1337"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 19
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1253"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 24
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1253"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 23
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1256"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 22
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1346"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 21
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 34
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1228"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 33
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1231"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 32
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1372"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 31
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1354"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 28
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1359"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 27
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1249"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 26
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1348"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 25
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1365"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 30
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1370"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 29
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1224"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 36
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1374"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 35
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1216"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 40
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1216"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 39
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1219"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 38
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1383"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 37
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_895"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 178
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_895"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 177
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_898"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 176
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1705"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 175
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1687"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 172
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1692"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 171
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_916"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 170
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1681"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 169
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1698"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 174
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1703"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 173
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_891"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 180
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1707"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 179
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 184
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_883"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 183
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_886"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 182
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1716"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 181
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_858"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 194
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_858"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 193
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_861"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 192
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1742"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 191
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 188
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1729"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 187
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_879"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 186
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1718"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 185
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1735"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 190
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1740"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 189
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_854"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 196
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1744"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 195
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 200
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 199
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_849"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 198
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1753"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 197
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_821"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 210
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_821"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 209
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_824"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 208
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1779"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 207
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1761"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 204
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1766"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 203
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_842"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 202
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1755"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 201
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 206
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1777"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 205
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_817"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 212
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1781"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 211
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_809"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 216
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_809"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 215
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_812"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 214
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1790"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 213
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_784"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 226
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_784"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 225
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_787"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 224
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1816"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 223
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1798"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 220
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1803"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 219
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_805"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 218
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1792"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 217
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1809"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 222
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1814"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 221
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_780"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 228
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1818"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 227
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 232
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 231
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_775"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 230
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1827"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 229
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_747"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 242
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_747"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 241
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_750"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 240
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1853"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 239
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1835"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 236
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1840"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 235
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_768"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 234
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1829"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 233
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 238
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1851"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 237
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_743"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 244
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1855"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 243
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_735"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 248
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_735"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 247
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_738"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 246
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1864"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 245
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 258
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_710"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 257
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_713"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 256
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1890"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 255
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1872"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 252
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1877"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 251
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_731"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 250
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1866"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 249
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1883"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 254
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1888"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 253
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_706"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 260
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1892"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 259
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_698"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 264
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_698"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 263
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_701"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 262
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1901"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 261
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_673"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 274
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_673"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 273
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_676"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 272
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1927"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 271
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1909"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 268
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1914"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 267
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_694"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 266
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1903"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 265
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1920"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 270
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1925"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 269
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_669"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 276
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1929"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 275
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_661"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 280
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_661"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 279
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_664"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 278
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1938"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 277
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_636"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 290
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_636"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 289
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_639"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 288
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1964"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 287
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1946"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 284
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1951"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 283
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_657"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 282
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1940"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 281
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1957"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 286
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1962"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 285
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_632"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 292
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1966"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 291
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_624"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 296
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_624"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 295
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_627"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 294
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1975"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 293
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_599"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 306
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_599"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 305
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_602"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 304
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2001"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 303
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1983"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 300
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1988"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 299
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_620"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 298
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1977"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 297
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1994"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 302
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1999"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 301
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_595"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 308
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2003"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 307
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_587"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 312
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_587"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 311
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_590"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 310
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2012"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 309
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_562"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 322
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_562"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 321
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_565"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 320
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2038"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 319
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2020"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 316
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2025"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 315
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_583"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 314
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2014"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 313
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 318
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2036"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 317
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_558"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 324
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2040"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 323
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_550"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 328
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_550"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 327
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_553"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 326
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2049"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 325
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1191"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 50
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1191"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 49
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1194"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 48
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1409"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 47
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1391"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 44
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1396"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 43
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1212"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 42
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1385"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 41
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 46
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1407"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 45
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1187"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 52
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1411"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 51
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1179"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 56
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1179"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 55
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1182"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 54
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1420"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 53
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_525"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 338
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_525"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 337
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_528"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 336
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2075"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 335
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2057"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 332
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2062"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 331
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 330
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2051"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 329
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2068"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 334
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2073"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 333
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_521"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 340
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2077"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 339
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_513"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 344
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_513"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 343
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_516"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 342
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2086"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 341
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_488"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 354
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_488"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 353
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_491"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 352
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2112"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 351
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2094"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 348
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2099"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 347
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_509"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 346
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2088"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 345
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2105"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 350
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2110"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 349
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 356
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2114"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 355
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 360
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 359
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_479"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 358
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2123"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 357
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 370
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_451"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 369
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_454"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 368
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2149"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 367
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2131"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 364
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2136"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 363
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_472"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 362
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2125"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 361
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2142"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 366
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2147"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 365
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_447"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 372
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2151"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 371
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 376
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 375
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_442"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 374
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2160"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 373
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 386
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 385
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_417"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 384
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2186"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 383
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2168"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 380
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2173"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 379
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_435"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 378
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2162"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 377
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_2179"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 382
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2184"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 381
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_410"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 388
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2188"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 387
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 392
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 391
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_405"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 390
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2197"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 389
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1154"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 66
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1154"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 65
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1157"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 64
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1446"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 63
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1428"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 60
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1433"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 59
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1175"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 58
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1422"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 57
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1439"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 62
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1444"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 61
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1150"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 68
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1448"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 67
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1142"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 72
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1142"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 71
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1145"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 70
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1457"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 69
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1117"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 82
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1117"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 81
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1120"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 80
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1483"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 79
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1465"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 76
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1470"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 75
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1138"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 74
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1459"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 73
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 78
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1481"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 77
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1113"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 84
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1485"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 83
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1105"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 88
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1105"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 87
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1108"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 86
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1494"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 85
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1080"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 98
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1080"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 97
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1083"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 96
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1520"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 95
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1502"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 92
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1507"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 91
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1101"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 90
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1496"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 89
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1513"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 94
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1518"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 93
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1076"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 100
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 99
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1068"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 104
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1068"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 103
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1071"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 102
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1531"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 101
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1043"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 114
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1043"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 113
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1046"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 112
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1557"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 111
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1539"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 108
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1544"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 107
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1064"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 106
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1533"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 105
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1550"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 110
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1555"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 109
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1039"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 116
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1559"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 115
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 120
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 119
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1034"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 118
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1568"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 117
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1006"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 130
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1006"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 129
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1009"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 128
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1594"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 127
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1576"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 124
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1581"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 123
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1027"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 122
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1570"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 121
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1587"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 126
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1592"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 125
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1002"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 132
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1596"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 131
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_994"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 136
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_994"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 135
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_997"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 134
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1605"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 133
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_969"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 146
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_969"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 145
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_972"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 144
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 143
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1613"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 140
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1618"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 139
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_990"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 138
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1607"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 137
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1624"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 142
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1629"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 141
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_965"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 148
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1633"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 147
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_957"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 152
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_957"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 151
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_960"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 150
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1642"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 149
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_932"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 162
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_932"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 161
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_935"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 160
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1668"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 159
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1650"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 156
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1655"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 155
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_953"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 154
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1644"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 153
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_1661"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 158
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1666"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 157
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_928"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 164
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1670"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 163
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_920"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 168
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_920"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 167
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_923"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 166
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_1679"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 165
        },
        "cast_1295": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_ids"
            ],
            "ir": "pybuda",
            "name": "cast_1295",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1294"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1295
        },
        "cast_1297": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_1"
            ],
            "ir": "pybuda",
            "name": "cast_1297",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1296"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1297
        },
        "cast_1299": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_1300"
            ],
            "ir": "pybuda",
            "name": "cast_1299",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1298"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1299
        },
        "cast_1320": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "expand_dims_1321"
            ],
            "ir": "pybuda",
            "name": "cast_1320",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1318"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::to, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917a3500), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1320
        },
        "constant_1314": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1314",
            "opcode": "Input",
            "output_nodes": [
                "divide_1280"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1314
        },
        "constant_1317": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1317",
            "opcode": "Input",
            "output_nodes": [
                "subtract_1316"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1317
        },
        "constant_1319": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1319",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1318"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1319
        },
        "constant_1323": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1323",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1315"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1323
        },
        "constant_1339": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1339",
            "opcode": "Input",
            "output_nodes": [
                "add_1338"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1339
        },
        "constant_1343": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1343",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1342"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1343
        },
        "constant_1344": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1344",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1340"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1344
        },
        "constant_1360": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1360",
            "opcode": "Input",
            "output_nodes": [
                "divide_1243"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1360
        },
        "constant_1376": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1376",
            "opcode": "Input",
            "output_nodes": [
                "add_1375"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1376
        },
        "constant_1380": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1380",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1379"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1380
        },
        "constant_1381": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1381",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1377"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1381
        },
        "constant_1397": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1397",
            "opcode": "Input",
            "output_nodes": [
                "divide_1206"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1397
        },
        "constant_1413": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1413",
            "opcode": "Input",
            "output_nodes": [
                "add_1412"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1413
        },
        "constant_1417": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1417",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1416"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1417
        },
        "constant_1418": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1418",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1414"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1418
        },
        "constant_1434": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1434",
            "opcode": "Input",
            "output_nodes": [
                "divide_1169"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1434
        },
        "constant_1450": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1450",
            "opcode": "Input",
            "output_nodes": [
                "add_1449"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1450
        },
        "constant_1454": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1454",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1453"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1454
        },
        "constant_1455": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1455",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1451"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1455
        },
        "constant_1471": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1471",
            "opcode": "Input",
            "output_nodes": [
                "divide_1132"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1471
        },
        "constant_1487": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1487",
            "opcode": "Input",
            "output_nodes": [
                "add_1486"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1487
        },
        "constant_1491": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1491",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1490"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1491
        },
        "constant_1492": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1492",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1488"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1492
        },
        "constant_1508": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1508",
            "opcode": "Input",
            "output_nodes": [
                "divide_1095"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1508
        },
        "constant_1524": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1524",
            "opcode": "Input",
            "output_nodes": [
                "add_1523"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1524
        },
        "constant_1528": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1528",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1527"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1528
        },
        "constant_1529": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1529",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1525"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1529
        },
        "constant_1545": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1545",
            "opcode": "Input",
            "output_nodes": [
                "divide_1058"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1545
        },
        "constant_1561": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1561",
            "opcode": "Input",
            "output_nodes": [
                "add_1560"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1561
        },
        "constant_1565": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1565",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1564"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1565
        },
        "constant_1566": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1566",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1562"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1566
        },
        "constant_1582": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1582",
            "opcode": "Input",
            "output_nodes": [
                "divide_1021"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1582
        },
        "constant_1598": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1598",
            "opcode": "Input",
            "output_nodes": [
                "add_1597"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1598
        },
        "constant_1602": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1602",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1601"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1602
        },
        "constant_1603": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1603",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1599"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1603
        },
        "constant_1619": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1619",
            "opcode": "Input",
            "output_nodes": [
                "divide_984"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1619
        },
        "constant_1635": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1635",
            "opcode": "Input",
            "output_nodes": [
                "add_1634"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1635
        },
        "constant_1639": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1639",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1638"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1639
        },
        "constant_1640": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1640",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1636"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1640
        },
        "constant_1656": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1656",
            "opcode": "Input",
            "output_nodes": [
                "divide_947"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1656
        },
        "constant_1672": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1672",
            "opcode": "Input",
            "output_nodes": [
                "add_1671"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1672
        },
        "constant_1676": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1676",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1675"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1676
        },
        "constant_1677": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1677",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1673"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1677
        },
        "constant_1693": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1693",
            "opcode": "Input",
            "output_nodes": [
                "divide_910"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1693
        },
        "constant_1709": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1709",
            "opcode": "Input",
            "output_nodes": [
                "add_1708"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1709
        },
        "constant_1713": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1713",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1712"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1713
        },
        "constant_1714": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1714",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1710"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1714
        },
        "constant_1730": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1730",
            "opcode": "Input",
            "output_nodes": [
                "divide_873"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1730
        },
        "constant_1746": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1746",
            "opcode": "Input",
            "output_nodes": [
                "add_1745"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1746
        },
        "constant_1750": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1750",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1749"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1750
        },
        "constant_1751": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1751",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1747"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1751
        },
        "constant_1767": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1767",
            "opcode": "Input",
            "output_nodes": [
                "divide_836"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1767
        },
        "constant_1783": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1783",
            "opcode": "Input",
            "output_nodes": [
                "add_1782"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1783
        },
        "constant_1787": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1787",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1786"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1787
        },
        "constant_1788": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1788",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1784"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1788
        },
        "constant_1804": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1804",
            "opcode": "Input",
            "output_nodes": [
                "divide_799"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1804
        },
        "constant_1820": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1820",
            "opcode": "Input",
            "output_nodes": [
                "add_1819"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1820
        },
        "constant_1824": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1824",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1823"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1824
        },
        "constant_1825": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1825",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1821"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1825
        },
        "constant_1841": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1841",
            "opcode": "Input",
            "output_nodes": [
                "divide_762"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1841
        },
        "constant_1857": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1857",
            "opcode": "Input",
            "output_nodes": [
                "add_1856"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1857
        },
        "constant_1861": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1861",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1860"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1861
        },
        "constant_1862": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1862",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1858"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1862
        },
        "constant_1878": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1878",
            "opcode": "Input",
            "output_nodes": [
                "divide_725"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1878
        },
        "constant_1894": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1894",
            "opcode": "Input",
            "output_nodes": [
                "add_1893"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1894
        },
        "constant_1898": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1898",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1897"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1898
        },
        "constant_1899": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1899",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1895"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1899
        },
        "constant_1915": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1915",
            "opcode": "Input",
            "output_nodes": [
                "divide_688"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1915
        },
        "constant_1931": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1931",
            "opcode": "Input",
            "output_nodes": [
                "add_1930"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1931
        },
        "constant_1935": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1935",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1934"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1935
        },
        "constant_1936": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1936",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1932"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1936
        },
        "constant_1952": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1952",
            "opcode": "Input",
            "output_nodes": [
                "divide_651"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1952
        },
        "constant_1968": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1968",
            "opcode": "Input",
            "output_nodes": [
                "add_1967"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1968
        },
        "constant_1972": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1972",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1971"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1972
        },
        "constant_1973": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1973",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1969"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1973
        },
        "constant_1989": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1989",
            "opcode": "Input",
            "output_nodes": [
                "divide_614"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1989
        },
        "constant_2005": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2005",
            "opcode": "Input",
            "output_nodes": [
                "add_2004"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2005
        },
        "constant_2009": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2009",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2008"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2009
        },
        "constant_2010": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2010",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2006"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2010
        },
        "constant_2026": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2026",
            "opcode": "Input",
            "output_nodes": [
                "divide_577"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2026
        },
        "constant_2042": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2042",
            "opcode": "Input",
            "output_nodes": [
                "add_2041"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2042
        },
        "constant_2046": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2046",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2045"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2046
        },
        "constant_2047": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2047",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2043"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2047
        },
        "constant_2063": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2063",
            "opcode": "Input",
            "output_nodes": [
                "divide_540"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2063
        },
        "constant_2079": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2079",
            "opcode": "Input",
            "output_nodes": [
                "add_2078"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2079
        },
        "constant_2083": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2083",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2082"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2083
        },
        "constant_2084": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2084",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2080"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2084
        },
        "constant_2100": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2100",
            "opcode": "Input",
            "output_nodes": [
                "divide_503"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2100
        },
        "constant_2116": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2116",
            "opcode": "Input",
            "output_nodes": [
                "add_2115"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2116
        },
        "constant_2120": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2120",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2119"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2120
        },
        "constant_2121": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2121",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2117"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2121
        },
        "constant_2137": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2137",
            "opcode": "Input",
            "output_nodes": [
                "divide_466"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2137
        },
        "constant_2153": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2153",
            "opcode": "Input",
            "output_nodes": [
                "add_2152"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2153
        },
        "constant_2157": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2157",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2156"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2157
        },
        "constant_2158": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2158",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2154"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2158
        },
        "constant_2174": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2174",
            "opcode": "Input",
            "output_nodes": [
                "divide_429"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2174
        },
        "constant_2190": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2190",
            "opcode": "Input",
            "output_nodes": [
                "add_2189"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2190
        },
        "constant_2194": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2194",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2193"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2194
        },
        "constant_2195": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_2195",
            "opcode": "Input",
            "output_nodes": [
                "multiply_2191"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 2195
        },
        "divide_1021": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1022",
                "constant_1582"
            ],
            "ir": "pybuda",
            "name": "divide_1021",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1020"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49cbc0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1021
        },
        "divide_1058": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1059",
                "constant_1545"
            ],
            "ir": "pybuda",
            "name": "divide_1058",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1057"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511f40), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1058
        },
        "divide_1095": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1096",
                "constant_1508"
            ],
            "ir": "pybuda",
            "name": "divide_1095",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1094"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c22f20), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1095
        },
        "divide_1132": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1133",
                "constant_1471"
            ],
            "ir": "pybuda",
            "name": "divide_1132",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1131"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917b72e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1132
        },
        "divide_1169": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1170",
                "constant_1434"
            ],
            "ir": "pybuda",
            "name": "divide_1169",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1168"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91820730), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1169
        },
        "divide_1206": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1207",
                "constant_1397"
            ],
            "ir": "pybuda",
            "name": "divide_1206",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1205"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd960e90), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1206
        },
        "divide_1243": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1244",
                "constant_1360"
            ],
            "ir": "pybuda",
            "name": "divide_1243",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1242"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8abc4710), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1243
        },
        "divide_1280": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1281",
                "constant_1314"
            ],
            "ir": "pybuda",
            "name": "divide_1280",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1279"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91826840), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1280
        },
        "divide_429": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_430",
                "constant_2174"
            ],
            "ir": "pybuda",
            "name": "divide_429",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ec890), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 429
        },
        "divide_466": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_467",
                "constant_2137"
            ],
            "ir": "pybuda",
            "name": "divide_466",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94171620), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 466
        },
        "divide_503": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_504",
                "constant_2100"
            ],
            "ir": "pybuda",
            "name": "divide_503",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28007220), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 503
        },
        "divide_540": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_541",
                "constant_2063"
            ],
            "ir": "pybuda",
            "name": "divide_540",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf805110), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 540
        },
        "divide_577": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_578",
                "constant_2026"
            ],
            "ir": "pybuda",
            "name": "divide_577",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb4f1e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 577
        },
        "divide_614": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_615",
                "constant_1989"
            ],
            "ir": "pybuda",
            "name": "divide_614",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27ff1540), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 614
        },
        "divide_651": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_652",
                "constant_1952"
            ],
            "ir": "pybuda",
            "name": "divide_651",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_650"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fcd060), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 651
        },
        "divide_688": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_689",
                "constant_1915"
            ],
            "ir": "pybuda",
            "name": "divide_688",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f69850), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 688
        },
        "divide_725": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_726",
                "constant_1878"
            ],
            "ir": "pybuda",
            "name": "divide_725",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_724"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d3100), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 725
        },
        "divide_762": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_763",
                "constant_1841"
            ],
            "ir": "pybuda",
            "name": "divide_762",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_761"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f45150), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 762
        },
        "divide_799": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_800",
                "constant_1804"
            ],
            "ir": "pybuda",
            "name": "divide_799",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_798"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82ecd0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 799
        },
        "divide_836": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_837",
                "constant_1767"
            ],
            "ir": "pybuda",
            "name": "divide_836",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_835"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda30d90), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 836
        },
        "divide_873": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_874",
                "constant_1730"
            ],
            "ir": "pybuda",
            "name": "divide_873",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_872"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364688e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 873
        },
        "divide_910": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_911",
                "constant_1693"
            ],
            "ir": "pybuda",
            "name": "divide_910",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_909"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36433ac0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 910
        },
        "divide_947": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_948",
                "constant_1656"
            ],
            "ir": "pybuda",
            "name": "divide_947",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_946"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bfe2e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 947
        },
        "divide_984": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_985",
                "constant_1619"
            ],
            "ir": "pybuda",
            "name": "divide_984",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_983"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf19c0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 984
        },
        "embedding_1294": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.word_embeddings.weight",
                "cast_1295"
            ],
            "ir": "pybuda",
            "name": "embedding_1294",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1293"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1294
        },
        "embedding_1296": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.token_type_embeddings.weight",
                "cast_1297"
            ],
            "ir": "pybuda",
            "name": "embedding_1296",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1293"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1296
        },
        "embedding_1298": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_embeddings.weight",
                "cast_1299"
            ],
            "ir": "pybuda",
            "name": "embedding_1298",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1292"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1298
        },
        "erf_1341": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1342"
            ],
            "ir": "pybuda",
            "name": "erf_1341",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1340"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1341
        },
        "erf_1378": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1379"
            ],
            "ir": "pybuda",
            "name": "erf_1378",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1377"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1378
        },
        "erf_1415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1416"
            ],
            "ir": "pybuda",
            "name": "erf_1415",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1415
        },
        "erf_1452": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1453"
            ],
            "ir": "pybuda",
            "name": "erf_1452",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1451"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1452
        },
        "erf_1489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1490"
            ],
            "ir": "pybuda",
            "name": "erf_1489",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1488"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1489
        },
        "erf_1526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1527"
            ],
            "ir": "pybuda",
            "name": "erf_1526",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1525"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1526
        },
        "erf_1563": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1564"
            ],
            "ir": "pybuda",
            "name": "erf_1563",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1563
        },
        "erf_1600": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1601"
            ],
            "ir": "pybuda",
            "name": "erf_1600",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1600
        },
        "erf_1637": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1638"
            ],
            "ir": "pybuda",
            "name": "erf_1637",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1637
        },
        "erf_1674": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1675"
            ],
            "ir": "pybuda",
            "name": "erf_1674",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1673"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1674
        },
        "erf_1711": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1712"
            ],
            "ir": "pybuda",
            "name": "erf_1711",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1711
        },
        "erf_1748": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1749"
            ],
            "ir": "pybuda",
            "name": "erf_1748",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1748
        },
        "erf_1785": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1786"
            ],
            "ir": "pybuda",
            "name": "erf_1785",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1785
        },
        "erf_1822": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1823"
            ],
            "ir": "pybuda",
            "name": "erf_1822",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1821"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1822
        },
        "erf_1859": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1860"
            ],
            "ir": "pybuda",
            "name": "erf_1859",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1858"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1859
        },
        "erf_1896": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1897"
            ],
            "ir": "pybuda",
            "name": "erf_1896",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1896
        },
        "erf_1933": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1934"
            ],
            "ir": "pybuda",
            "name": "erf_1933",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1932"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1933
        },
        "erf_1970": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1971"
            ],
            "ir": "pybuda",
            "name": "erf_1970",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1969"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1970
        },
        "erf_2007": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2008"
            ],
            "ir": "pybuda",
            "name": "erf_2007",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2007
        },
        "erf_2044": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2045"
            ],
            "ir": "pybuda",
            "name": "erf_2044",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2043"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2044
        },
        "erf_2081": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2082"
            ],
            "ir": "pybuda",
            "name": "erf_2081",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2080"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2081
        },
        "erf_2118": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2119"
            ],
            "ir": "pybuda",
            "name": "erf_2118",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2117"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2118
        },
        "erf_2155": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2156"
            ],
            "ir": "pybuda",
            "name": "erf_2155",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2154"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2155
        },
        "erf_2192": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_2193"
            ],
            "ir": "pybuda",
            "name": "erf_2192",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_2191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 2192
        },
        "expand_dims_1321": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "expand_dims",
            "epoch": 0,
            "input_nodes": [
                "expand_dims_1322"
            ],
            "ir": "pybuda",
            "name": "expand_dims_1321",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1320"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "expand_dims",
            "unique_id": 1321
        },
        "expand_dims_1322": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384
                ]
            },
            "class": "expand_dims",
            "epoch": 0,
            "input_nodes": [
                "attention_mask_1"
            ],
            "ir": "pybuda",
            "name": "expand_dims_1322",
            "opcode": "RelayOp",
            "output_nodes": [
                "expand_dims_1321"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "expand_dims",
            "unique_id": 1322
        },
        "input_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_1",
            "opcode": "Input",
            "output_nodes": [
                "cast_1297"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1
        },
        "input_ids": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_ids",
            "opcode": "Input",
            "output_nodes": [
                "cast_1295"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 0
        },
        "layernorm_1006": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1007",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1006",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_995",
                "reshape_1005"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b8d0c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1006
        },
        "layernorm_1031": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1032",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1031",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1007",
                "reshape_1030",
                "reshape_1579",
                "reshape_1590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a456e70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1031
        },
        "layernorm_1043": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1044",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1043",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1032",
                "reshape_1042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19c0dd00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1043
        },
        "layernorm_1068": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1069",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1068",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1044",
                "reshape_1067",
                "reshape_1542",
                "reshape_1553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4d52d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1068
        },
        "layernorm_1080": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1081",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1080",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1069",
                "reshape_1079"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b49cb0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1080
        },
        "layernorm_1105": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1106",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1105",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1081",
                "reshape_1104",
                "reshape_1505",
                "reshape_1516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19bc47e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1105
        },
        "layernorm_1117": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1118",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1117",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1106",
                "reshape_1116"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9bd4d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1117
        },
        "layernorm_1142": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1143",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1142",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1118",
                "reshape_1141",
                "reshape_1468",
                "reshape_1479"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b96410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1142
        },
        "layernorm_1154": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1155",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1154",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1143",
                "reshape_1153"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xda08cd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1154
        },
        "layernorm_1179": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1180",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1179",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1155",
                "reshape_1178",
                "reshape_1431",
                "reshape_1442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b59000), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1179
        },
        "layernorm_1191": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1192",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1191",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1180",
                "reshape_1190"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917ab600), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1191
        },
        "layernorm_1216": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1217",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1216",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1192",
                "reshape_1215",
                "reshape_1394",
                "reshape_1405"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9e7790), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1216
        },
        "layernorm_1228": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1229",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1228",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1217",
                "reshape_1227"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x91832300), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1228
        },
        "layernorm_1253": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1254",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1253",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1229",
                "reshape_1252",
                "reshape_1357",
                "reshape_1368"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9182e6e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1253
        },
        "layernorm_1265": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1266",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1265",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1254",
                "reshape_1264"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917a5390), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1265
        },
        "layernorm_1291": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1292",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1291",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1290"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x918210f0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1291
        },
        "layernorm_402": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_403",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_402",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_401"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fd6f10), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 402
        },
        "layernorm_414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_415",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_414",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_403",
                "reshape_413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x37bd6810), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 414
        },
        "layernorm_439": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_440",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_439",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_415",
                "reshape_438",
                "reshape_2171",
                "reshape_2182"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x126ea410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 439
        },
        "layernorm_451": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_452",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_451",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_440",
                "reshape_450"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf75bdf0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 451
        },
        "layernorm_476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_477",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_476",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_452",
                "reshape_475",
                "reshape_2134",
                "reshape_2145"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x12643c20), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 476
        },
        "layernorm_488": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_489",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_488",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_477",
                "reshape_487"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150af8e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 488
        },
        "layernorm_513": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_514",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_513",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_489",
                "reshape_512",
                "reshape_2097",
                "reshape_2108"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7f9e90), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 513
        },
        "layernorm_525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_526",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_525",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_514",
                "reshape_524"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b4f460), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 525
        },
        "layernorm_550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_551",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_550",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_526",
                "reshape_549",
                "reshape_2060",
                "reshape_2071"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9420f530), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 550
        },
        "layernorm_562": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_563",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_562",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_551",
                "reshape_561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941de800), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 562
        },
        "layernorm_587": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_588",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_587",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_563",
                "reshape_586",
                "reshape_2023",
                "reshape_2034"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150a6c60), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 587
        },
        "layernorm_599": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_600",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_599",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_588",
                "reshape_598"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941f5c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 599
        },
        "layernorm_624": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_625",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_624",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_600",
                "reshape_623",
                "reshape_1986",
                "reshape_1997"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150e9f80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 624
        },
        "layernorm_636": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_637",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_636",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_625",
                "reshape_635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d5c70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 636
        },
        "layernorm_661": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_662",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_661",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_637",
                "reshape_660",
                "reshape_1949",
                "reshape_1960"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf774ee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 661
        },
        "layernorm_673": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_674",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_673",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_662",
                "reshape_672"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4bcfd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 673
        },
        "layernorm_698": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_699",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_698",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_674",
                "reshape_697",
                "reshape_1912",
                "reshape_1923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9fb7d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 698
        },
        "layernorm_710": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_711",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_710",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_699",
                "reshape_709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fe2d50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 710
        },
        "layernorm_735": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_736",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_735",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_711",
                "reshape_734",
                "reshape_1875",
                "reshape_1886"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4996b0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 735
        },
        "layernorm_747": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_748",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_747",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_736",
                "reshape_746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7674e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 747
        },
        "layernorm_772": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_773",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_772",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_748",
                "reshape_771",
                "reshape_1838",
                "reshape_1849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf749490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 772
        },
        "layernorm_784": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_785",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_784",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_773",
                "reshape_783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x365122e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 784
        },
        "layernorm_809": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_810",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_809",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_785",
                "reshape_808",
                "reshape_1801",
                "reshape_1812"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d91c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 809
        },
        "layernorm_821": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_822",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_821",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_810",
                "reshape_820"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4fc5e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 821
        },
        "layernorm_846": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_847",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_846",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_822",
                "reshape_845",
                "reshape_1764",
                "reshape_1775"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd974ae0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 846
        },
        "layernorm_858": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_859",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_858",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_847",
                "reshape_857"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b455d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 858
        },
        "layernorm_883": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_884",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_883",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_859",
                "reshape_882",
                "reshape_1727",
                "reshape_1738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd98ab70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 883
        },
        "layernorm_895": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_896",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_895",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_884",
                "reshape_894"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x364f4230), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 895
        },
        "layernorm_920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_921",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_920",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_896",
                "reshape_919",
                "reshape_1690",
                "reshape_1701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a472c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 920
        },
        "layernorm_932": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_933",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_932",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_921",
                "reshape_931"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a48aee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 932
        },
        "layernorm_957": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_958",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_957",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_933",
                "reshape_956",
                "reshape_1653",
                "reshape_1664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31c24e00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 957
        },
        "layernorm_969": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_970",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_969",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_958",
                "reshape_968"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd99a490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 969
        },
        "layernorm_994": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_995",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_994",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_970",
                "reshape_993",
                "reshape_1616",
                "reshape_1627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd95cb50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 994
        },
        "multiply_1001": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1002",
                "add_1597"
            ],
            "ir": "pybuda",
            "name": "multiply_1001",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1000"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1001
        },
        "multiply_1038": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1039",
                "add_1560"
            ],
            "ir": "pybuda",
            "name": "multiply_1038",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1037"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1038
        },
        "multiply_1075": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1076",
                "add_1523"
            ],
            "ir": "pybuda",
            "name": "multiply_1075",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1074"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1075
        },
        "multiply_1112": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1113",
                "add_1486"
            ],
            "ir": "pybuda",
            "name": "multiply_1112",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1111"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1112
        },
        "multiply_1149": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1150",
                "add_1449"
            ],
            "ir": "pybuda",
            "name": "multiply_1149",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1148"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1149
        },
        "multiply_1186": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1187",
                "add_1412"
            ],
            "ir": "pybuda",
            "name": "multiply_1186",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1185"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1186
        },
        "multiply_1223": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1224",
                "add_1375"
            ],
            "ir": "pybuda",
            "name": "multiply_1223",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1223
        },
        "multiply_1260": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1261",
                "add_1338"
            ],
            "ir": "pybuda",
            "name": "multiply_1260",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1259"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1260
        },
        "multiply_1315": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "subtract_1316",
                "constant_1323"
            ],
            "ir": "pybuda",
            "name": "multiply_1315",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_428",
                "add_465",
                "add_502",
                "add_539",
                "add_576",
                "add_613",
                "add_650",
                "add_687",
                "add_724",
                "add_761",
                "add_798",
                "add_835",
                "add_872",
                "add_909",
                "add_946",
                "add_983",
                "add_1020",
                "add_1057",
                "add_1094",
                "add_1131",
                "add_1168",
                "add_1205",
                "add_1242",
                "add_1279"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::mul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x8ab56a50), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1315
        },
        "multiply_1318": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "constant_1319",
                "cast_1320"
            ],
            "ir": "pybuda",
            "name": "multiply_1318",
            "opcode": "RelayOp",
            "output_nodes": [
                "subtract_1316"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::rsub, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x918176a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1318
        },
        "multiply_1340": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1341",
                "constant_1344"
            ],
            "ir": "pybuda",
            "name": "multiply_1340",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1338"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1340
        },
        "multiply_1342": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1261",
                "constant_1343"
            ],
            "ir": "pybuda",
            "name": "multiply_1342",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1341"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1342
        },
        "multiply_1377": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1378",
                "constant_1381"
            ],
            "ir": "pybuda",
            "name": "multiply_1377",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1375"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1377
        },
        "multiply_1379": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1224",
                "constant_1380"
            ],
            "ir": "pybuda",
            "name": "multiply_1379",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1378"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1379
        },
        "multiply_1414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1415",
                "constant_1418"
            ],
            "ir": "pybuda",
            "name": "multiply_1414",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1414
        },
        "multiply_1416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1187",
                "constant_1417"
            ],
            "ir": "pybuda",
            "name": "multiply_1416",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1415"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1416
        },
        "multiply_1451": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1452",
                "constant_1455"
            ],
            "ir": "pybuda",
            "name": "multiply_1451",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1451
        },
        "multiply_1453": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1150",
                "constant_1454"
            ],
            "ir": "pybuda",
            "name": "multiply_1453",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1452"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1453
        },
        "multiply_1488": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1489",
                "constant_1492"
            ],
            "ir": "pybuda",
            "name": "multiply_1488",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1488
        },
        "multiply_1490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1113",
                "constant_1491"
            ],
            "ir": "pybuda",
            "name": "multiply_1490",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1489"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1490
        },
        "multiply_1525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1526",
                "constant_1529"
            ],
            "ir": "pybuda",
            "name": "multiply_1525",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1525
        },
        "multiply_1527": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1076",
                "constant_1528"
            ],
            "ir": "pybuda",
            "name": "multiply_1527",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1526"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1527
        },
        "multiply_1562": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1563",
                "constant_1566"
            ],
            "ir": "pybuda",
            "name": "multiply_1562",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1562
        },
        "multiply_1564": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1039",
                "constant_1565"
            ],
            "ir": "pybuda",
            "name": "multiply_1564",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1564
        },
        "multiply_1599": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1600",
                "constant_1603"
            ],
            "ir": "pybuda",
            "name": "multiply_1599",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1597"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1599
        },
        "multiply_1601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1002",
                "constant_1602"
            ],
            "ir": "pybuda",
            "name": "multiply_1601",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1601
        },
        "multiply_1636": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1637",
                "constant_1640"
            ],
            "ir": "pybuda",
            "name": "multiply_1636",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1636
        },
        "multiply_1638": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_965",
                "constant_1639"
            ],
            "ir": "pybuda",
            "name": "multiply_1638",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1637"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1638
        },
        "multiply_1673": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1674",
                "constant_1677"
            ],
            "ir": "pybuda",
            "name": "multiply_1673",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1673
        },
        "multiply_1675": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_928",
                "constant_1676"
            ],
            "ir": "pybuda",
            "name": "multiply_1675",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1675
        },
        "multiply_1710": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1711",
                "constant_1714"
            ],
            "ir": "pybuda",
            "name": "multiply_1710",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1710
        },
        "multiply_1712": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_891",
                "constant_1713"
            ],
            "ir": "pybuda",
            "name": "multiply_1712",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1712
        },
        "multiply_1747": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1748",
                "constant_1751"
            ],
            "ir": "pybuda",
            "name": "multiply_1747",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1745"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1747
        },
        "multiply_1749": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_854",
                "constant_1750"
            ],
            "ir": "pybuda",
            "name": "multiply_1749",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1748"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1749
        },
        "multiply_1784": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1785",
                "constant_1788"
            ],
            "ir": "pybuda",
            "name": "multiply_1784",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1782"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1784
        },
        "multiply_1786": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_817",
                "constant_1787"
            ],
            "ir": "pybuda",
            "name": "multiply_1786",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1785"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1786
        },
        "multiply_1821": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1822",
                "constant_1825"
            ],
            "ir": "pybuda",
            "name": "multiply_1821",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1821
        },
        "multiply_1823": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_780",
                "constant_1824"
            ],
            "ir": "pybuda",
            "name": "multiply_1823",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1822"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1823
        },
        "multiply_1858": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1859",
                "constant_1862"
            ],
            "ir": "pybuda",
            "name": "multiply_1858",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1856"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1858
        },
        "multiply_1860": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_743",
                "constant_1861"
            ],
            "ir": "pybuda",
            "name": "multiply_1860",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1859"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1860
        },
        "multiply_1895": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1896",
                "constant_1899"
            ],
            "ir": "pybuda",
            "name": "multiply_1895",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1893"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1895
        },
        "multiply_1897": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_706",
                "constant_1898"
            ],
            "ir": "pybuda",
            "name": "multiply_1897",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1896"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1897
        },
        "multiply_1932": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1933",
                "constant_1936"
            ],
            "ir": "pybuda",
            "name": "multiply_1932",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1932
        },
        "multiply_1934": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_669",
                "constant_1935"
            ],
            "ir": "pybuda",
            "name": "multiply_1934",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1933"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1934
        },
        "multiply_1969": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1970",
                "constant_1973"
            ],
            "ir": "pybuda",
            "name": "multiply_1969",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1969
        },
        "multiply_1971": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_632",
                "constant_1972"
            ],
            "ir": "pybuda",
            "name": "multiply_1971",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1971
        },
        "multiply_2006": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2007",
                "constant_2010"
            ],
            "ir": "pybuda",
            "name": "multiply_2006",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2006
        },
        "multiply_2008": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_595",
                "constant_2009"
            ],
            "ir": "pybuda",
            "name": "multiply_2008",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2007"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2008
        },
        "multiply_2043": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2044",
                "constant_2047"
            ],
            "ir": "pybuda",
            "name": "multiply_2043",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2043
        },
        "multiply_2045": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_558",
                "constant_2046"
            ],
            "ir": "pybuda",
            "name": "multiply_2045",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2044"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2045
        },
        "multiply_2080": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2081",
                "constant_2084"
            ],
            "ir": "pybuda",
            "name": "multiply_2080",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2080
        },
        "multiply_2082": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_521",
                "constant_2083"
            ],
            "ir": "pybuda",
            "name": "multiply_2082",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2081"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2082
        },
        "multiply_2117": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2118",
                "constant_2121"
            ],
            "ir": "pybuda",
            "name": "multiply_2117",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2115"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2117
        },
        "multiply_2119": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_484",
                "constant_2120"
            ],
            "ir": "pybuda",
            "name": "multiply_2119",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2118"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2119
        },
        "multiply_2154": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2155",
                "constant_2158"
            ],
            "ir": "pybuda",
            "name": "multiply_2154",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2154
        },
        "multiply_2156": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_447",
                "constant_2157"
            ],
            "ir": "pybuda",
            "name": "multiply_2156",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2155"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2156
        },
        "multiply_2191": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_2192",
                "constant_2195"
            ],
            "ir": "pybuda",
            "name": "multiply_2191",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_2189"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2191
        },
        "multiply_2193": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_410",
                "constant_2194"
            ],
            "ir": "pybuda",
            "name": "multiply_2193",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_2192"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 2193
        },
        "multiply_409": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_410",
                "add_2189"
            ],
            "ir": "pybuda",
            "name": "multiply_409",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_408"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 409
        },
        "multiply_446": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_447",
                "add_2152"
            ],
            "ir": "pybuda",
            "name": "multiply_446",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 446
        },
        "multiply_483": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_484",
                "add_2115"
            ],
            "ir": "pybuda",
            "name": "multiply_483",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_482"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 483
        },
        "multiply_520": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_521",
                "add_2078"
            ],
            "ir": "pybuda",
            "name": "multiply_520",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 520
        },
        "multiply_557": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_558",
                "add_2041"
            ],
            "ir": "pybuda",
            "name": "multiply_557",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_556"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 557
        },
        "multiply_594": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_595",
                "add_2004"
            ],
            "ir": "pybuda",
            "name": "multiply_594",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 594
        },
        "multiply_631": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_632",
                "add_1967"
            ],
            "ir": "pybuda",
            "name": "multiply_631",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 631
        },
        "multiply_668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_669",
                "add_1930"
            ],
            "ir": "pybuda",
            "name": "multiply_668",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 668
        },
        "multiply_705": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_706",
                "add_1893"
            ],
            "ir": "pybuda",
            "name": "multiply_705",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_704"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 705
        },
        "multiply_742": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_743",
                "add_1856"
            ],
            "ir": "pybuda",
            "name": "multiply_742",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_741"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 742
        },
        "multiply_779": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_780",
                "add_1819"
            ],
            "ir": "pybuda",
            "name": "multiply_779",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 779
        },
        "multiply_816": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_817",
                "add_1782"
            ],
            "ir": "pybuda",
            "name": "multiply_816",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_815"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 816
        },
        "multiply_853": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_854",
                "add_1745"
            ],
            "ir": "pybuda",
            "name": "multiply_853",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_852"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 853
        },
        "multiply_890": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_891",
                "add_1708"
            ],
            "ir": "pybuda",
            "name": "multiply_890",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_889"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 890
        },
        "multiply_927": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_928",
                "add_1671"
            ],
            "ir": "pybuda",
            "name": "multiply_927",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_926"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 927
        },
        "multiply_964": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_965",
                "add_1634"
            ],
            "ir": "pybuda",
            "name": "multiply_964",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 964
        },
        "nn.batch_matmul_1016": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1017",
                "reshape_1583"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1016",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1015"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1016
        },
        "nn.batch_matmul_1023": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1024",
                "reshape_1571"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1023",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1022"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1023
        },
        "nn.batch_matmul_1053": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1054",
                "reshape_1546"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1053",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1052"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1053
        },
        "nn.batch_matmul_1060": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1061",
                "reshape_1534"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1060",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1060
        },
        "nn.batch_matmul_1090": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1091",
                "reshape_1509"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1090",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1089"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1090
        },
        "nn.batch_matmul_1097": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1098",
                "reshape_1497"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1097",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1097
        },
        "nn.batch_matmul_1127": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1128",
                "reshape_1472"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1127",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1127
        },
        "nn.batch_matmul_1134": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1135",
                "reshape_1460"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1134",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1133"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1134
        },
        "nn.batch_matmul_1164": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1165",
                "reshape_1435"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1164",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1163"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1164
        },
        "nn.batch_matmul_1171": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1172",
                "reshape_1423"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1171",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1170"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1171
        },
        "nn.batch_matmul_1201": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1202",
                "reshape_1398"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1201",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1200"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1201
        },
        "nn.batch_matmul_1208": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1209",
                "reshape_1386"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1208",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1207"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1208
        },
        "nn.batch_matmul_1238": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1239",
                "reshape_1361"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1238",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1237"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1238
        },
        "nn.batch_matmul_1245": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1246",
                "reshape_1349"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1245",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1244"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1245
        },
        "nn.batch_matmul_1275": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1276",
                "reshape_1324"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1275",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1274"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1275
        },
        "nn.batch_matmul_1282": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1283",
                "reshape_1303"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1282",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1281"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1282
        },
        "nn.batch_matmul_424": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_425",
                "reshape_2175"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_424",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 424
        },
        "nn.batch_matmul_431": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_432",
                "reshape_2163"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_431",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 431
        },
        "nn.batch_matmul_461": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_462",
                "reshape_2138"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_461",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 461
        },
        "nn.batch_matmul_468": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_469",
                "reshape_2126"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_468",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 468
        },
        "nn.batch_matmul_498": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_499",
                "reshape_2101"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_498",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_497"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 498
        },
        "nn.batch_matmul_505": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_506",
                "reshape_2089"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_505",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_504"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 505
        },
        "nn.batch_matmul_535": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_536",
                "reshape_2064"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_535",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 535
        },
        "nn.batch_matmul_542": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_543",
                "reshape_2052"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_542",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_541"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 542
        },
        "nn.batch_matmul_572": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_573",
                "reshape_2027"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_572",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 572
        },
        "nn.batch_matmul_579": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_580",
                "reshape_2015"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_579",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 579
        },
        "nn.batch_matmul_609": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_610",
                "reshape_1990"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_609",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 609
        },
        "nn.batch_matmul_616": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_617",
                "reshape_1978"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_616",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 616
        },
        "nn.batch_matmul_646": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_647",
                "reshape_1953"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_646",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 646
        },
        "nn.batch_matmul_653": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_654",
                "reshape_1941"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_653",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 653
        },
        "nn.batch_matmul_683": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_684",
                "reshape_1916"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_683",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 683
        },
        "nn.batch_matmul_690": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_691",
                "reshape_1904"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_690",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 690
        },
        "nn.batch_matmul_720": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_721",
                "reshape_1879"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_720",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_719"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 720
        },
        "nn.batch_matmul_727": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_728",
                "reshape_1867"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_727",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 727
        },
        "nn.batch_matmul_757": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_758",
                "reshape_1842"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_757",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 757
        },
        "nn.batch_matmul_764": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_765",
                "reshape_1830"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_764",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 764
        },
        "nn.batch_matmul_794": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_795",
                "reshape_1805"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_794",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 794
        },
        "nn.batch_matmul_801": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_802",
                "reshape_1793"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_801",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_800"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 801
        },
        "nn.batch_matmul_831": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_832",
                "reshape_1768"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_831",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_830"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 831
        },
        "nn.batch_matmul_838": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_839",
                "reshape_1756"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_838",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_837"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 838
        },
        "nn.batch_matmul_868": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_869",
                "reshape_1731"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_868",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 868
        },
        "nn.batch_matmul_875": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_876",
                "reshape_1719"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_875",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 875
        },
        "nn.batch_matmul_905": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_906",
                "reshape_1694"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_905",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_904"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 905
        },
        "nn.batch_matmul_912": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_913",
                "reshape_1682"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_912",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 912
        },
        "nn.batch_matmul_942": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_943",
                "reshape_1657"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_942",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_941"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 942
        },
        "nn.batch_matmul_949": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_950",
                "reshape_1645"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_949",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 949
        },
        "nn.batch_matmul_979": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_980",
                "reshape_1620"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_979",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_978"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 979
        },
        "nn.batch_matmul_986": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_987",
                "reshape_1608"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_986",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 986
        },
        "nn.bias_add_1002": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1003",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1002",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1001",
                "multiply_1601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1002
        },
        "nn.bias_add_1009": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1010",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1009",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1008"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1009
        },
        "nn.bias_add_1027": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1028",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1027",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1026"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1027
        },
        "nn.bias_add_1034": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1035",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1034",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1033"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1034
        },
        "nn.bias_add_1039": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1040",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1039",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1038",
                "multiply_1564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1039
        },
        "nn.bias_add_1046": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1047",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1046",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1045"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1046
        },
        "nn.bias_add_1064": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1065",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1064",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1063"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1064
        },
        "nn.bias_add_1071": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1072",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1071",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1071
        },
        "nn.bias_add_1076": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1077",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1076",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1075",
                "multiply_1527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1076
        },
        "nn.bias_add_1083": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1084",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1083",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1082"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1083
        },
        "nn.bias_add_1101": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1102",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1101",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1100"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1101
        },
        "nn.bias_add_1108": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1109",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1108",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1108
        },
        "nn.bias_add_1113": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1114",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1113",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1112",
                "multiply_1490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1113
        },
        "nn.bias_add_1120": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1121",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1120",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1119"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1120
        },
        "nn.bias_add_1138": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1139",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1138",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1137"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1138
        },
        "nn.bias_add_1145": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1146",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1145",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1145
        },
        "nn.bias_add_1150": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1151",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1150",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1149",
                "multiply_1453"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1150
        },
        "nn.bias_add_1157": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1158",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1157",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1156"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1157
        },
        "nn.bias_add_1175": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1176",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1175",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1174"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1175
        },
        "nn.bias_add_1182": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1183",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1182",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1181"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1182
        },
        "nn.bias_add_1187": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1188",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1187",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1186",
                "multiply_1416"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1187
        },
        "nn.bias_add_1194": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1195",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1194",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1193"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1194
        },
        "nn.bias_add_1212": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1213",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1212",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1211"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1212
        },
        "nn.bias_add_1219": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1220",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1219",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1218"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1219
        },
        "nn.bias_add_1224": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1225",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1224",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1223",
                "multiply_1379"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1224
        },
        "nn.bias_add_1231": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1232",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1231",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1230"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1231
        },
        "nn.bias_add_1249": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1250",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1249",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1248"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1249
        },
        "nn.bias_add_1256": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1257",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1256",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1256
        },
        "nn.bias_add_1261": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1262",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1261",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1260",
                "multiply_1342"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1261
        },
        "nn.bias_add_1268": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1269",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1268",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1267"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1268
        },
        "nn.bias_add_1286": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1287",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1286",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1285"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1286
        },
        "nn.bias_add_1308": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1309",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1308",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1307"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1308
        },
        "nn.bias_add_1328": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1329",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1328",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1327"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1328
        },
        "nn.bias_add_1354": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1355",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1354",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1353"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1354
        },
        "nn.bias_add_1365": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1366",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1365",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1364"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1365
        },
        "nn.bias_add_1391": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1392",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1391",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1391
        },
        "nn.bias_add_1402": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1403",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1402",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1401"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1402
        },
        "nn.bias_add_1428": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1429",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1428",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1428
        },
        "nn.bias_add_1439": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1440",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1439",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1439
        },
        "nn.bias_add_1465": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1466",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1465",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1465
        },
        "nn.bias_add_1476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1477",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1476",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1475"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1476
        },
        "nn.bias_add_1502": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1503",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1502",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1502
        },
        "nn.bias_add_1513": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1514",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1513",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1512"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1513
        },
        "nn.bias_add_1539": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1540",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1539",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1539
        },
        "nn.bias_add_1550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1551",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1550",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1549"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1550
        },
        "nn.bias_add_1576": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1577",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1576",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1575"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1576
        },
        "nn.bias_add_1587": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1588",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1587",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1587
        },
        "nn.bias_add_1613": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1614",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1613",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1613
        },
        "nn.bias_add_1624": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1625",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1624",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1624
        },
        "nn.bias_add_1650": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1651",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1650",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1649"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1650
        },
        "nn.bias_add_1661": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1662",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1661",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1660"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1661
        },
        "nn.bias_add_1687": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1688",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1687",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1687
        },
        "nn.bias_add_1698": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1699",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1698",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1698
        },
        "nn.bias_add_1724": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1725",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1724",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1724
        },
        "nn.bias_add_1735": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1736",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1735",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1734"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1735
        },
        "nn.bias_add_1761": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1762",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1761",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1760"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1761
        },
        "nn.bias_add_1772": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1773",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1772",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1772
        },
        "nn.bias_add_1798": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1799",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1798",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1797"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1798
        },
        "nn.bias_add_1809": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1810",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1809",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1809
        },
        "nn.bias_add_1835": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1836",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1835",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1834"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1835
        },
        "nn.bias_add_1846": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1847",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1846",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1845"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1846
        },
        "nn.bias_add_1872": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1873",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1872",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1871"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1872
        },
        "nn.bias_add_1883": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1884",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1883",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1882"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1883
        },
        "nn.bias_add_1909": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1910",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1909",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1908"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1909
        },
        "nn.bias_add_1920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1921",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1920",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1919"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1920
        },
        "nn.bias_add_1946": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1947",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1946",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1945"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1946
        },
        "nn.bias_add_1957": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1958",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1957",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1956"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1957
        },
        "nn.bias_add_1983": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1984",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1983",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1982"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1983
        },
        "nn.bias_add_1994": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1995",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_1994",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1993"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 1994
        },
        "nn.bias_add_2020": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2021",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2020",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2019"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2020
        },
        "nn.bias_add_2031": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2032",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2031",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2030"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2031
        },
        "nn.bias_add_2057": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2058",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2057",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2056"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2057
        },
        "nn.bias_add_2068": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2069",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2068",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2067"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2068
        },
        "nn.bias_add_2094": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2095",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2094",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2093"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2094
        },
        "nn.bias_add_2105": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2106",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2105",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2104"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2105
        },
        "nn.bias_add_2131": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2132",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2131",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2130"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2131
        },
        "nn.bias_add_2142": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2143",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2142",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2141"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2142
        },
        "nn.bias_add_2168": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2169",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2168",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2167"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2168
        },
        "nn.bias_add_2179": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_2180",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_2179",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2178"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 2179
        },
        "nn.bias_add_398": {
            "cache": {
                "shape": [
                    1,
                    384,
                    2
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_398",
            "opcode": "RelayOp",
            "output_nodes": [
                "split_397",
                "split_397"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 398
        },
        "nn.bias_add_405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_406",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_405",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_404"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 405
        },
        "nn.bias_add_410": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_411",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_410",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_409",
                "multiply_2193"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 410
        },
        "nn.bias_add_417": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_418",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_417",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_416"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 417
        },
        "nn.bias_add_435": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_436",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_435",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_434"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 435
        },
        "nn.bias_add_442": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_443",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_442",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 442
        },
        "nn.bias_add_447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_448",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_447",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_446",
                "multiply_2156"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 447
        },
        "nn.bias_add_454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_455",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_454",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_453"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 454
        },
        "nn.bias_add_472": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_473",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_472",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_471"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 472
        },
        "nn.bias_add_479": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_480",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_479",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 479
        },
        "nn.bias_add_484": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_485",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_484",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_483",
                "multiply_2119"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 484
        },
        "nn.bias_add_491": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_492",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_491",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 491
        },
        "nn.bias_add_509": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_510",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_509",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_508"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 509
        },
        "nn.bias_add_516": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_517",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_516",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 516
        },
        "nn.bias_add_521": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_522",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_521",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_520",
                "multiply_2082"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 521
        },
        "nn.bias_add_528": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_529",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_528",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 528
        },
        "nn.bias_add_546": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_547",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_546",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 546
        },
        "nn.bias_add_553": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_554",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_553",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 553
        },
        "nn.bias_add_558": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_559",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_558",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_557",
                "multiply_2045"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 558
        },
        "nn.bias_add_565": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_566",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_565",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 565
        },
        "nn.bias_add_583": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_584",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_583",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_582"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 583
        },
        "nn.bias_add_590": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_591",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_590",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 590
        },
        "nn.bias_add_595": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_596",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_595",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_594",
                "multiply_2008"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 595
        },
        "nn.bias_add_602": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_603",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_602",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 602
        },
        "nn.bias_add_620": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_621",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_620",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_619"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 620
        },
        "nn.bias_add_627": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_628",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_627",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 627
        },
        "nn.bias_add_632": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_633",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_632",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_631",
                "multiply_1971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 632
        },
        "nn.bias_add_639": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_640",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_639",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 639
        },
        "nn.bias_add_657": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_658",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_657",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_656"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 657
        },
        "nn.bias_add_664": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_665",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_664",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 664
        },
        "nn.bias_add_669": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_670",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_669",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_668",
                "multiply_1934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 669
        },
        "nn.bias_add_676": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_677",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_676",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 676
        },
        "nn.bias_add_694": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_695",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_694",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_693"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 694
        },
        "nn.bias_add_701": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_702",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_701",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 701
        },
        "nn.bias_add_706": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_707",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_706",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_705",
                "multiply_1897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 706
        },
        "nn.bias_add_713": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_714",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_713",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_712"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 713
        },
        "nn.bias_add_731": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_732",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_731",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_730"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 731
        },
        "nn.bias_add_738": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_739",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_738",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 738
        },
        "nn.bias_add_743": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_744",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_743",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_742",
                "multiply_1860"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 743
        },
        "nn.bias_add_750": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_751",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_750",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 750
        },
        "nn.bias_add_768": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_769",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_768",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_767"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 768
        },
        "nn.bias_add_775": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_776",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_775",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 775
        },
        "nn.bias_add_780": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_781",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_780",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_779",
                "multiply_1823"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 780
        },
        "nn.bias_add_787": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_788",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_787",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 787
        },
        "nn.bias_add_805": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_806",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_805",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_804"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 805
        },
        "nn.bias_add_812": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_813",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_812",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 812
        },
        "nn.bias_add_817": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_818",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_817",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_816",
                "multiply_1786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 817
        },
        "nn.bias_add_824": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_825",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_824",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_823"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 824
        },
        "nn.bias_add_842": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_843",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_842",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 842
        },
        "nn.bias_add_849": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_850",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_849",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 849
        },
        "nn.bias_add_854": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_855",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_854",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_853",
                "multiply_1749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 854
        },
        "nn.bias_add_861": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_862",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_861",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_860"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 861
        },
        "nn.bias_add_879": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_880",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_879",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_878"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 879
        },
        "nn.bias_add_886": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_887",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_886",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_885"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 886
        },
        "nn.bias_add_891": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_892",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_891",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_890",
                "multiply_1712"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 891
        },
        "nn.bias_add_898": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_899",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_898",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 898
        },
        "nn.bias_add_916": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_917",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_916",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_915"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 916
        },
        "nn.bias_add_923": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_924",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_923",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 923
        },
        "nn.bias_add_928": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_929",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_928",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_927",
                "multiply_1675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 928
        },
        "nn.bias_add_935": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_936",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_935",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 935
        },
        "nn.bias_add_953": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_954",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_953",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_952"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 953
        },
        "nn.bias_add_960": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_961",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_960",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 960
        },
        "nn.bias_add_965": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_966",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_965",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_964",
                "multiply_1638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 965
        },
        "nn.bias_add_972": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_973",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_972",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 972
        },
        "nn.bias_add_990": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_991",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_990",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_989"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 990
        },
        "nn.bias_add_997": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.bias_add",
            "epoch": 0,
            "input_nodes": [
                "reshape_998",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "nn.bias_add_997",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "nn.bias_add",
            "unique_id": 997
        },
        "nn.dense_1004": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1005",
                "transpose_1595"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1004",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1003"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1004
        },
        "nn.dense_1011": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1012",
                "transpose_1593"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1011",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1010"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1011
        },
        "nn.dense_1029": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1030",
                "transpose_1569"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1029",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1028"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1029
        },
        "nn.dense_1036": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1037",
                "transpose_1567"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1036",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1036
        },
        "nn.dense_1041": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1042",
                "transpose_1558"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1041",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1040"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1041
        },
        "nn.dense_1048": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1049",
                "transpose_1556"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1048",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1047"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1048
        },
        "nn.dense_1066": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1067",
                "transpose_1532"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1066",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1065"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1066
        },
        "nn.dense_1073": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1074",
                "transpose_1530"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1073",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1072"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1073
        },
        "nn.dense_1078": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1079",
                "transpose_1521"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1078",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1077"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1078
        },
        "nn.dense_1085": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1086",
                "transpose_1519"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1085",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1084"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1085
        },
        "nn.dense_1103": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1104",
                "transpose_1495"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1103",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1102"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1103
        },
        "nn.dense_1110": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1111",
                "transpose_1493"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1110",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1109"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1110
        },
        "nn.dense_1115": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1116",
                "transpose_1484"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1115",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1114"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1115
        },
        "nn.dense_1122": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1123",
                "transpose_1482"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1122",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1121"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1122
        },
        "nn.dense_1140": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1141",
                "transpose_1458"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1140",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1139"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1140
        },
        "nn.dense_1147": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1148",
                "transpose_1456"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1147",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1146"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1147
        },
        "nn.dense_1152": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1153",
                "transpose_1447"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1152",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1151"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1152
        },
        "nn.dense_1159": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1160",
                "transpose_1445"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1159",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1158"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1159
        },
        "nn.dense_1177": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1178",
                "transpose_1421"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1177",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1176"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1177
        },
        "nn.dense_1184": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1185",
                "transpose_1419"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1184",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1183"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1184
        },
        "nn.dense_1189": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1190",
                "transpose_1410"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1189",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1188"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1189
        },
        "nn.dense_1196": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1197",
                "transpose_1408"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1196",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1195"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1196
        },
        "nn.dense_1214": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1215",
                "transpose_1384"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1214",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1213"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1214
        },
        "nn.dense_1221": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1222",
                "transpose_1382"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1221",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1220"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1221
        },
        "nn.dense_1226": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1227",
                "transpose_1373"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1226",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1225"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1226
        },
        "nn.dense_1233": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1234",
                "transpose_1371"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1233",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1232"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1233
        },
        "nn.dense_1251": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1252",
                "transpose_1347"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1251",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1250"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1251
        },
        "nn.dense_1258": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1259",
                "transpose_1345"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1258",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1257"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1258
        },
        "nn.dense_1263": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1264",
                "transpose_1336"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1263",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1262"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1263
        },
        "nn.dense_1270": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1271",
                "transpose_1334"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1270",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1270
        },
        "nn.dense_1288": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1289",
                "transpose_1301"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1288",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1287"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1288
        },
        "nn.dense_1310": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1311",
                "transpose_1312"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1310",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1309"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1310
        },
        "nn.dense_1330": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1331",
                "transpose_1332"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1330",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1329"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1330
        },
        "nn.dense_1356": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1357",
                "transpose_1358"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1356",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1355"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1356
        },
        "nn.dense_1367": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1368",
                "transpose_1369"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1367",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1366"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1367
        },
        "nn.dense_1393": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1394",
                "transpose_1395"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1393",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1392"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1393
        },
        "nn.dense_1404": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1405",
                "transpose_1406"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1404",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1403"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1404
        },
        "nn.dense_1430": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1431",
                "transpose_1432"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1430",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1430
        },
        "nn.dense_1441": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1442",
                "transpose_1443"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1441",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1440"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1441
        },
        "nn.dense_1467": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1468",
                "transpose_1469"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1467",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1467
        },
        "nn.dense_1478": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1479",
                "transpose_1480"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1478",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1478
        },
        "nn.dense_1504": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1505",
                "transpose_1506"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1504",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1504
        },
        "nn.dense_1515": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1516",
                "transpose_1517"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1515",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1514"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1515
        },
        "nn.dense_1541": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1542",
                "transpose_1543"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1541",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1541
        },
        "nn.dense_1552": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1553",
                "transpose_1554"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1552",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1552
        },
        "nn.dense_1578": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1579",
                "transpose_1580"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1578",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1577"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1578
        },
        "nn.dense_1589": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1590",
                "transpose_1591"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1589",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1588"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1589
        },
        "nn.dense_1615": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1616",
                "transpose_1617"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1615",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1615
        },
        "nn.dense_1626": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1627",
                "transpose_1628"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1626",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1625"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1626
        },
        "nn.dense_1652": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1653",
                "transpose_1654"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1652",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1652
        },
        "nn.dense_1663": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1664",
                "transpose_1665"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1663",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1663
        },
        "nn.dense_1689": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1690",
                "transpose_1691"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1689",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1689
        },
        "nn.dense_1700": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1701",
                "transpose_1702"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1700",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1699"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1700
        },
        "nn.dense_1726": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1727",
                "transpose_1728"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1726",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1726
        },
        "nn.dense_1737": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1738",
                "transpose_1739"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1737",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1736"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1737
        },
        "nn.dense_1763": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1764",
                "transpose_1765"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1763",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1763
        },
        "nn.dense_1774": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1775",
                "transpose_1776"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1774",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1773"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1774
        },
        "nn.dense_1800": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1801",
                "transpose_1802"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1800",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1799"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1800
        },
        "nn.dense_1811": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1812",
                "transpose_1813"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1811",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1811
        },
        "nn.dense_1837": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1838",
                "transpose_1839"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1837",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1836"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1837
        },
        "nn.dense_1848": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1849",
                "transpose_1850"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1848",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1847"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1848
        },
        "nn.dense_1874": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1875",
                "transpose_1876"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1874",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1873"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1874
        },
        "nn.dense_1885": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1886",
                "transpose_1887"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1885",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1884"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1885
        },
        "nn.dense_1911": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1912",
                "transpose_1913"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1911",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1910"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1911
        },
        "nn.dense_1922": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1923",
                "transpose_1924"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1922",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1921"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1922
        },
        "nn.dense_1948": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1949",
                "transpose_1950"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1948",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1947"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1948
        },
        "nn.dense_1959": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1960",
                "transpose_1961"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1959",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1958"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1959
        },
        "nn.dense_1985": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1986",
                "transpose_1987"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1985",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1984"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1985
        },
        "nn.dense_1996": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1997",
                "transpose_1998"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1996",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1995"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1996
        },
        "nn.dense_2022": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2023",
                "transpose_2024"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2022",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2022
        },
        "nn.dense_2033": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2034",
                "transpose_2035"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2033",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2032"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2033
        },
        "nn.dense_2059": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2060",
                "transpose_2061"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2059",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2058"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2059
        },
        "nn.dense_2070": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2071",
                "transpose_2072"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2070",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2069"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2070
        },
        "nn.dense_2096": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2097",
                "transpose_2098"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2096",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2095"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2096
        },
        "nn.dense_2107": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2108",
                "transpose_2109"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2107",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2106"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2107
        },
        "nn.dense_2133": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2134",
                "transpose_2135"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2133",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2132"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2133
        },
        "nn.dense_2144": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2145",
                "transpose_2146"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2144",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2144
        },
        "nn.dense_2170": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2171",
                "transpose_2172"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2170",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2169"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2170
        },
        "nn.dense_2181": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_2182",
                "transpose_2183"
            ],
            "ir": "pybuda",
            "name": "nn.dense_2181",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2180"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 2181
        },
        "nn.dense_400": {
            "cache": {
                "shape": [
                    384,
                    2
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_401",
                "transpose_2198"
            ],
            "ir": "pybuda",
            "name": "nn.dense_400",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 400
        },
        "nn.dense_407": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_408",
                "transpose_2196"
            ],
            "ir": "pybuda",
            "name": "nn.dense_407",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 407
        },
        "nn.dense_412": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_413",
                "transpose_2187"
            ],
            "ir": "pybuda",
            "name": "nn.dense_412",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_411"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 412
        },
        "nn.dense_419": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_420",
                "transpose_2185"
            ],
            "ir": "pybuda",
            "name": "nn.dense_419",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_418"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 419
        },
        "nn.dense_437": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_438",
                "transpose_2161"
            ],
            "ir": "pybuda",
            "name": "nn.dense_437",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 437
        },
        "nn.dense_444": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_445",
                "transpose_2159"
            ],
            "ir": "pybuda",
            "name": "nn.dense_444",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 444
        },
        "nn.dense_449": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_450",
                "transpose_2150"
            ],
            "ir": "pybuda",
            "name": "nn.dense_449",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 449
        },
        "nn.dense_456": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_457",
                "transpose_2148"
            ],
            "ir": "pybuda",
            "name": "nn.dense_456",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 456
        },
        "nn.dense_474": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_475",
                "transpose_2124"
            ],
            "ir": "pybuda",
            "name": "nn.dense_474",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_473"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 474
        },
        "nn.dense_481": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_482",
                "transpose_2122"
            ],
            "ir": "pybuda",
            "name": "nn.dense_481",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_480"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 481
        },
        "nn.dense_486": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_487",
                "transpose_2113"
            ],
            "ir": "pybuda",
            "name": "nn.dense_486",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_485"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 486
        },
        "nn.dense_493": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_494",
                "transpose_2111"
            ],
            "ir": "pybuda",
            "name": "nn.dense_493",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_492"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 493
        },
        "nn.dense_511": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_512",
                "transpose_2087"
            ],
            "ir": "pybuda",
            "name": "nn.dense_511",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 511
        },
        "nn.dense_518": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_519",
                "transpose_2085"
            ],
            "ir": "pybuda",
            "name": "nn.dense_518",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 518
        },
        "nn.dense_523": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_524",
                "transpose_2076"
            ],
            "ir": "pybuda",
            "name": "nn.dense_523",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 523
        },
        "nn.dense_530": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_531",
                "transpose_2074"
            ],
            "ir": "pybuda",
            "name": "nn.dense_530",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 530
        },
        "nn.dense_548": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_549",
                "transpose_2050"
            ],
            "ir": "pybuda",
            "name": "nn.dense_548",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 548
        },
        "nn.dense_555": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_556",
                "transpose_2048"
            ],
            "ir": "pybuda",
            "name": "nn.dense_555",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_554"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 555
        },
        "nn.dense_560": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_561",
                "transpose_2039"
            ],
            "ir": "pybuda",
            "name": "nn.dense_560",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_559"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 560
        },
        "nn.dense_567": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_568",
                "transpose_2037"
            ],
            "ir": "pybuda",
            "name": "nn.dense_567",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_566"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 567
        },
        "nn.dense_585": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_586",
                "transpose_2013"
            ],
            "ir": "pybuda",
            "name": "nn.dense_585",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_584"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 585
        },
        "nn.dense_592": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_593",
                "transpose_2011"
            ],
            "ir": "pybuda",
            "name": "nn.dense_592",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 592
        },
        "nn.dense_597": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_598",
                "transpose_2002"
            ],
            "ir": "pybuda",
            "name": "nn.dense_597",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_596"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 597
        },
        "nn.dense_604": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_605",
                "transpose_2000"
            ],
            "ir": "pybuda",
            "name": "nn.dense_604",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 604
        },
        "nn.dense_622": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_623",
                "transpose_1976"
            ],
            "ir": "pybuda",
            "name": "nn.dense_622",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_621"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 622
        },
        "nn.dense_629": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_630",
                "transpose_1974"
            ],
            "ir": "pybuda",
            "name": "nn.dense_629",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 629
        },
        "nn.dense_634": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_635",
                "transpose_1965"
            ],
            "ir": "pybuda",
            "name": "nn.dense_634",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 634
        },
        "nn.dense_641": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_642",
                "transpose_1963"
            ],
            "ir": "pybuda",
            "name": "nn.dense_641",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_640"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 641
        },
        "nn.dense_659": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_660",
                "transpose_1939"
            ],
            "ir": "pybuda",
            "name": "nn.dense_659",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_658"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 659
        },
        "nn.dense_666": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_667",
                "transpose_1937"
            ],
            "ir": "pybuda",
            "name": "nn.dense_666",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 666
        },
        "nn.dense_671": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_672",
                "transpose_1928"
            ],
            "ir": "pybuda",
            "name": "nn.dense_671",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 671
        },
        "nn.dense_678": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_679",
                "transpose_1926"
            ],
            "ir": "pybuda",
            "name": "nn.dense_678",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_677"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 678
        },
        "nn.dense_696": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_697",
                "transpose_1902"
            ],
            "ir": "pybuda",
            "name": "nn.dense_696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 696
        },
        "nn.dense_703": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_704",
                "transpose_1900"
            ],
            "ir": "pybuda",
            "name": "nn.dense_703",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 703
        },
        "nn.dense_708": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_709",
                "transpose_1891"
            ],
            "ir": "pybuda",
            "name": "nn.dense_708",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_707"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 708
        },
        "nn.dense_715": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_716",
                "transpose_1889"
            ],
            "ir": "pybuda",
            "name": "nn.dense_715",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_714"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 715
        },
        "nn.dense_733": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_734",
                "transpose_1865"
            ],
            "ir": "pybuda",
            "name": "nn.dense_733",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 733
        },
        "nn.dense_740": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_741",
                "transpose_1863"
            ],
            "ir": "pybuda",
            "name": "nn.dense_740",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 740
        },
        "nn.dense_745": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_746",
                "transpose_1854"
            ],
            "ir": "pybuda",
            "name": "nn.dense_745",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_744"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 745
        },
        "nn.dense_752": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_753",
                "transpose_1852"
            ],
            "ir": "pybuda",
            "name": "nn.dense_752",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 752
        },
        "nn.dense_770": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_771",
                "transpose_1828"
            ],
            "ir": "pybuda",
            "name": "nn.dense_770",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_769"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 770
        },
        "nn.dense_777": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_778",
                "transpose_1826"
            ],
            "ir": "pybuda",
            "name": "nn.dense_777",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_776"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 777
        },
        "nn.dense_782": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_783",
                "transpose_1817"
            ],
            "ir": "pybuda",
            "name": "nn.dense_782",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_781"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 782
        },
        "nn.dense_789": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_790",
                "transpose_1815"
            ],
            "ir": "pybuda",
            "name": "nn.dense_789",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_788"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 789
        },
        "nn.dense_807": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_808",
                "transpose_1791"
            ],
            "ir": "pybuda",
            "name": "nn.dense_807",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_806"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 807
        },
        "nn.dense_814": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_815",
                "transpose_1789"
            ],
            "ir": "pybuda",
            "name": "nn.dense_814",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 814
        },
        "nn.dense_819": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_820",
                "transpose_1780"
            ],
            "ir": "pybuda",
            "name": "nn.dense_819",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_818"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 819
        },
        "nn.dense_826": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_827",
                "transpose_1778"
            ],
            "ir": "pybuda",
            "name": "nn.dense_826",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_825"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 826
        },
        "nn.dense_844": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_845",
                "transpose_1754"
            ],
            "ir": "pybuda",
            "name": "nn.dense_844",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_843"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 844
        },
        "nn.dense_851": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_852",
                "transpose_1752"
            ],
            "ir": "pybuda",
            "name": "nn.dense_851",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 851
        },
        "nn.dense_856": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_857",
                "transpose_1743"
            ],
            "ir": "pybuda",
            "name": "nn.dense_856",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 856
        },
        "nn.dense_863": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_864",
                "transpose_1741"
            ],
            "ir": "pybuda",
            "name": "nn.dense_863",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 863
        },
        "nn.dense_881": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_882",
                "transpose_1717"
            ],
            "ir": "pybuda",
            "name": "nn.dense_881",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 881
        },
        "nn.dense_888": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_889",
                "transpose_1715"
            ],
            "ir": "pybuda",
            "name": "nn.dense_888",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_887"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 888
        },
        "nn.dense_893": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_894",
                "transpose_1706"
            ],
            "ir": "pybuda",
            "name": "nn.dense_893",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_892"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 893
        },
        "nn.dense_900": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_901",
                "transpose_1704"
            ],
            "ir": "pybuda",
            "name": "nn.dense_900",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_899"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 900
        },
        "nn.dense_918": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_919",
                "transpose_1680"
            ],
            "ir": "pybuda",
            "name": "nn.dense_918",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_917"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 918
        },
        "nn.dense_925": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_926",
                "transpose_1678"
            ],
            "ir": "pybuda",
            "name": "nn.dense_925",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 925
        },
        "nn.dense_930": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_931",
                "transpose_1669"
            ],
            "ir": "pybuda",
            "name": "nn.dense_930",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_929"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 930
        },
        "nn.dense_937": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_938",
                "transpose_1667"
            ],
            "ir": "pybuda",
            "name": "nn.dense_937",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_936"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 937
        },
        "nn.dense_955": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_956",
                "transpose_1643"
            ],
            "ir": "pybuda",
            "name": "nn.dense_955",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_954"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 955
        },
        "nn.dense_962": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_963",
                "transpose_1641"
            ],
            "ir": "pybuda",
            "name": "nn.dense_962",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_961"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 962
        },
        "nn.dense_967": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_968",
                "transpose_1632"
            ],
            "ir": "pybuda",
            "name": "nn.dense_967",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_966"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 967
        },
        "nn.dense_974": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_975",
                "transpose_1630"
            ],
            "ir": "pybuda",
            "name": "nn.dense_974",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_973"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 974
        },
        "nn.dense_992": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_993",
                "transpose_1606"
            ],
            "ir": "pybuda",
            "name": "nn.dense_992",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_991"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 992
        },
        "nn.dense_999": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1000",
                "transpose_1604"
            ],
            "ir": "pybuda",
            "name": "nn.dense_999",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_998"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 999
        },
        "nn.dropout_1008": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1009"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1008",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1007"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1008
        },
        "nn.dropout_1018": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1019"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1018",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1017"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1018
        },
        "nn.dropout_1033": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1034"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1033",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1032"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1033
        },
        "nn.dropout_1045": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1046"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1045",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1044"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1045
        },
        "nn.dropout_1055": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1056"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1055",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1054"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1055
        },
        "nn.dropout_1070": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1071"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1070",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1069"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1070
        },
        "nn.dropout_1082": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1083"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1082",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1081"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1082
        },
        "nn.dropout_1092": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1093"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1092",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1091"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1092
        },
        "nn.dropout_1107": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1108"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1107",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1106"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1107
        },
        "nn.dropout_1119": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1120"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1119",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1118"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1119
        },
        "nn.dropout_1129": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1130"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1129",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1128"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1129
        },
        "nn.dropout_1144": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1145"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1144",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1143"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1144
        },
        "nn.dropout_1156": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1157"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1156",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1155"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1156
        },
        "nn.dropout_1166": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1167"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1166",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1165"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1166
        },
        "nn.dropout_1181": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1182"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1181",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1180"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1181
        },
        "nn.dropout_1193": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1194"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1193",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1192"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1193
        },
        "nn.dropout_1203": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1204"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1203",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1202"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1203
        },
        "nn.dropout_1218": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1219"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1218",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1217"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1218
        },
        "nn.dropout_1230": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1231"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1230",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1229"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1230
        },
        "nn.dropout_1240": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1241"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1240",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1239"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1240
        },
        "nn.dropout_1255": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1256"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1255",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1254"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1255
        },
        "nn.dropout_1267": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1268"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1267",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1266"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1267
        },
        "nn.dropout_1277": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1278"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1277",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1276"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1277
        },
        "nn.dropout_1290": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1291"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1290",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1266",
                "reshape_1289",
                "reshape_1311",
                "reshape_1331"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1290
        },
        "nn.dropout_404": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_405"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_404",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_403"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 404
        },
        "nn.dropout_416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_417"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_416",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_415"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 416
        },
        "nn.dropout_426": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_427"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_426",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_425"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 426
        },
        "nn.dropout_441": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_442"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_441",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_440"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 441
        },
        "nn.dropout_453": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_454"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_453",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_452"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 453
        },
        "nn.dropout_463": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_464"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_463",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_462"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 463
        },
        "nn.dropout_478": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_479"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_478",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_477"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 478
        },
        "nn.dropout_490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_491"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_490",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_489"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 490
        },
        "nn.dropout_500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_501"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_500",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_499"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 500
        },
        "nn.dropout_515": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_516"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_515",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_514"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 515
        },
        "nn.dropout_527": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_528"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_527",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_526"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 527
        },
        "nn.dropout_537": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_538"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_537",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_536"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 537
        },
        "nn.dropout_552": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_553"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_552",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_551"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 552
        },
        "nn.dropout_564": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_565"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_564",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_563"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 564
        },
        "nn.dropout_574": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_575"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_574",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_573"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 574
        },
        "nn.dropout_589": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_590"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_589",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_588"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 589
        },
        "nn.dropout_601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_602"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_601",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_600"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 601
        },
        "nn.dropout_611": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_612"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_611",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_610"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 611
        },
        "nn.dropout_626": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_627"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_626",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_625"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 626
        },
        "nn.dropout_638": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_639"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_638",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_637"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 638
        },
        "nn.dropout_648": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_649"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_648",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_647"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 648
        },
        "nn.dropout_663": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_664"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_663",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_662"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 663
        },
        "nn.dropout_675": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_676"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_675",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_674"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 675
        },
        "nn.dropout_685": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_686"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_685",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_684"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 685
        },
        "nn.dropout_700": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_701"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_700",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_699"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 700
        },
        "nn.dropout_712": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_713"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_712",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_711"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 712
        },
        "nn.dropout_722": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_723"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_722",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_721"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 722
        },
        "nn.dropout_737": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_738"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_737",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_736"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 737
        },
        "nn.dropout_749": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_750"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_749",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_748"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 749
        },
        "nn.dropout_759": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_760"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_759",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_758"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 759
        },
        "nn.dropout_774": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_775"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_774",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_773"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 774
        },
        "nn.dropout_786": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_787"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_786",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_785"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 786
        },
        "nn.dropout_796": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_797"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_796",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_795"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 796
        },
        "nn.dropout_811": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_812"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_811",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_810"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 811
        },
        "nn.dropout_823": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_824"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_823",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_822"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 823
        },
        "nn.dropout_833": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_834"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_833",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_832"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 833
        },
        "nn.dropout_848": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_849"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_848",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_847"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 848
        },
        "nn.dropout_860": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_861"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_860",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_859"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 860
        },
        "nn.dropout_870": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_871"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_870",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_869"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 870
        },
        "nn.dropout_885": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_886"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_885",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_884"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 885
        },
        "nn.dropout_897": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_898"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_897",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_896"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 897
        },
        "nn.dropout_907": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_908"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_907",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_906"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 907
        },
        "nn.dropout_922": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_923"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_922",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_921"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 922
        },
        "nn.dropout_934": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_935"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_934",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_933"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 934
        },
        "nn.dropout_944": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_945"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_944",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_943"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 944
        },
        "nn.dropout_959": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_960"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_959",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_958"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 959
        },
        "nn.dropout_971": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_972"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_971",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_970"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 971
        },
        "nn.dropout_981": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_982"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_981",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_980"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 981
        },
        "nn.dropout_996": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_997"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_996",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_995"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 996
        },
        "nn.softmax_1019": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1020"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1019",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1018"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bdeb50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1019
        },
        "nn.softmax_1056": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1057"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1056",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1055"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511de0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1056
        },
        "nn.softmax_1093": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1094"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1093",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1092"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49d340), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1093
        },
        "nn.softmax_1130": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1131"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1130",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1129"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c25db0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1130
        },
        "nn.softmax_1167": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1168"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1167",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1166"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c1d990), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1167
        },
        "nn.softmax_1204": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1205"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1204",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1203"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b65130), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1204
        },
        "nn.softmax_1241": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1242"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1241",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1240"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98a870), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1241
        },
        "nn.softmax_1278": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1279"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1278",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1277"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9af750), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1278
        },
        "nn.softmax_427": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_428"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_427",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37bd2dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 427
        },
        "nn.softmax_464": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_465"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_464",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9422d960), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 464
        },
        "nn.softmax_501": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_502"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_501",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7b0540), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 501
        },
        "nn.softmax_538": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_539"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_538",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126863e0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 538
        },
        "nn.softmax_575": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_576"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_575",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1270), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 575
        },
        "nn.softmax_612": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_613"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_612",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_611"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9723b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 612
        },
        "nn.softmax_649": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_650"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_649",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28027dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 649
        },
        "nn.softmax_686": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_687"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_686",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_685"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150e2880), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 686
        },
        "nn.softmax_723": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_724"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_723",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_722"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15044f50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 723
        },
        "nn.softmax_760": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_761"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_760",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x280119a0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 760
        },
        "nn.softmax_797": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_798"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_797",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_796"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f55ff0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 797
        },
        "nn.softmax_834": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_835"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_834",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_833"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98d0b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 834
        },
        "nn.softmax_871": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_872"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_871",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf778820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 871
        },
        "nn.softmax_908": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_909"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_908",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_907"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364e52c0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 908
        },
        "nn.softmax_945": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_946"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_945",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_944"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36479bd0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 945
        },
        "nn.softmax_982": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_983"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_982",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_981"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c23820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 982
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    "2"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "output_nodes": [
                "nn.bias_add_398"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 394
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "output_nodes": [
                "transpose_2199"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 393
        },
        "reshape_1000": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1001"
            ],
            "ir": "pybuda",
            "name": "reshape_1000",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1000
        },
        "reshape_1003": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1004"
            ],
            "ir": "pybuda",
            "name": "reshape_1003",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1003
        },
        "reshape_1005": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1006"
            ],
            "ir": "pybuda",
            "name": "reshape_1005",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1005
        },
        "reshape_1010": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1011"
            ],
            "ir": "pybuda",
            "name": "reshape_1010",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1009"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1010
        },
        "reshape_1012": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1013"
            ],
            "ir": "pybuda",
            "name": "reshape_1012",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1011"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1012
        },
        "reshape_1013": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1014"
            ],
            "ir": "pybuda",
            "name": "reshape_1013",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1012"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1013
        },
        "reshape_1015": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1016"
            ],
            "ir": "pybuda",
            "name": "reshape_1015",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1014"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1015
        },
        "reshape_1017": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1018"
            ],
            "ir": "pybuda",
            "name": "reshape_1017",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1016"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1017
        },
        "reshape_1022": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1023"
            ],
            "ir": "pybuda",
            "name": "reshape_1022",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1022
        },
        "reshape_1024": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1025"
            ],
            "ir": "pybuda",
            "name": "reshape_1024",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1023"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1024
        },
        "reshape_1026": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1027"
            ],
            "ir": "pybuda",
            "name": "reshape_1026",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1025"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1026
        },
        "reshape_1028": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1029"
            ],
            "ir": "pybuda",
            "name": "reshape_1028",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1027"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1028
        },
        "reshape_1030": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1031"
            ],
            "ir": "pybuda",
            "name": "reshape_1030",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1029"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1030
        },
        "reshape_1035": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1036"
            ],
            "ir": "pybuda",
            "name": "reshape_1035",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1034"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1035
        },
        "reshape_1037": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1038"
            ],
            "ir": "pybuda",
            "name": "reshape_1037",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1036"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1037
        },
        "reshape_1040": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1041"
            ],
            "ir": "pybuda",
            "name": "reshape_1040",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1039"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1040
        },
        "reshape_1042": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1043"
            ],
            "ir": "pybuda",
            "name": "reshape_1042",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1042
        },
        "reshape_1047": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1048"
            ],
            "ir": "pybuda",
            "name": "reshape_1047",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1046"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1047
        },
        "reshape_1049": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1050"
            ],
            "ir": "pybuda",
            "name": "reshape_1049",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1048"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1049
        },
        "reshape_1050": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1051"
            ],
            "ir": "pybuda",
            "name": "reshape_1050",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1049"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1050
        },
        "reshape_1052": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1053"
            ],
            "ir": "pybuda",
            "name": "reshape_1052",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1051"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1052
        },
        "reshape_1054": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1055"
            ],
            "ir": "pybuda",
            "name": "reshape_1054",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1053"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1054
        },
        "reshape_1059": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1060"
            ],
            "ir": "pybuda",
            "name": "reshape_1059",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1058"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1059
        },
        "reshape_1061": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1062"
            ],
            "ir": "pybuda",
            "name": "reshape_1061",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1060"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1061
        },
        "reshape_1063": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1064"
            ],
            "ir": "pybuda",
            "name": "reshape_1063",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1062"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1063
        },
        "reshape_1065": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1066"
            ],
            "ir": "pybuda",
            "name": "reshape_1065",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1064"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1065
        },
        "reshape_1067": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1068"
            ],
            "ir": "pybuda",
            "name": "reshape_1067",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1067
        },
        "reshape_1072": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1073"
            ],
            "ir": "pybuda",
            "name": "reshape_1072",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1071"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1072
        },
        "reshape_1074": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1075"
            ],
            "ir": "pybuda",
            "name": "reshape_1074",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1073"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1074
        },
        "reshape_1077": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1078"
            ],
            "ir": "pybuda",
            "name": "reshape_1077",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1076"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1077
        },
        "reshape_1079": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1080"
            ],
            "ir": "pybuda",
            "name": "reshape_1079",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1079
        },
        "reshape_1084": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1085"
            ],
            "ir": "pybuda",
            "name": "reshape_1084",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1083"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1084
        },
        "reshape_1086": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1087"
            ],
            "ir": "pybuda",
            "name": "reshape_1086",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1085"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1086
        },
        "reshape_1087": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1088"
            ],
            "ir": "pybuda",
            "name": "reshape_1087",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1086"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1087
        },
        "reshape_1089": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1090"
            ],
            "ir": "pybuda",
            "name": "reshape_1089",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1088"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1089
        },
        "reshape_1091": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1092"
            ],
            "ir": "pybuda",
            "name": "reshape_1091",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1090"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1091
        },
        "reshape_1096": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1097"
            ],
            "ir": "pybuda",
            "name": "reshape_1096",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1095"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1096
        },
        "reshape_1098": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1099"
            ],
            "ir": "pybuda",
            "name": "reshape_1098",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1097"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1098
        },
        "reshape_1100": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1101"
            ],
            "ir": "pybuda",
            "name": "reshape_1100",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1099"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1100
        },
        "reshape_1102": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1103"
            ],
            "ir": "pybuda",
            "name": "reshape_1102",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1101"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1102
        },
        "reshape_1104": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1105"
            ],
            "ir": "pybuda",
            "name": "reshape_1104",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1104
        },
        "reshape_1109": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1110"
            ],
            "ir": "pybuda",
            "name": "reshape_1109",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1108"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1109
        },
        "reshape_1111": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1112"
            ],
            "ir": "pybuda",
            "name": "reshape_1111",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1111
        },
        "reshape_1114": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1115"
            ],
            "ir": "pybuda",
            "name": "reshape_1114",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1113"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1114
        },
        "reshape_1116": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1117"
            ],
            "ir": "pybuda",
            "name": "reshape_1116",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1115"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1116
        },
        "reshape_1121": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1122"
            ],
            "ir": "pybuda",
            "name": "reshape_1121",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1120"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1121
        },
        "reshape_1123": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1124"
            ],
            "ir": "pybuda",
            "name": "reshape_1123",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1123
        },
        "reshape_1124": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1125"
            ],
            "ir": "pybuda",
            "name": "reshape_1124",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1123"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1124
        },
        "reshape_1126": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1127"
            ],
            "ir": "pybuda",
            "name": "reshape_1126",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1125"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1126
        },
        "reshape_1128": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1129"
            ],
            "ir": "pybuda",
            "name": "reshape_1128",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1128
        },
        "reshape_1133": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1134"
            ],
            "ir": "pybuda",
            "name": "reshape_1133",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1132"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1133
        },
        "reshape_1135": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1136"
            ],
            "ir": "pybuda",
            "name": "reshape_1135",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1134"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1135
        },
        "reshape_1137": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1138"
            ],
            "ir": "pybuda",
            "name": "reshape_1137",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1136"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1137
        },
        "reshape_1139": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1140"
            ],
            "ir": "pybuda",
            "name": "reshape_1139",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1138"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1139
        },
        "reshape_1141": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1142"
            ],
            "ir": "pybuda",
            "name": "reshape_1141",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1140"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1141
        },
        "reshape_1146": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1147"
            ],
            "ir": "pybuda",
            "name": "reshape_1146",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1145"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1146
        },
        "reshape_1148": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1149"
            ],
            "ir": "pybuda",
            "name": "reshape_1148",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1147"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1148
        },
        "reshape_1151": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1152"
            ],
            "ir": "pybuda",
            "name": "reshape_1151",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1151
        },
        "reshape_1153": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1154"
            ],
            "ir": "pybuda",
            "name": "reshape_1153",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1153
        },
        "reshape_1158": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1159"
            ],
            "ir": "pybuda",
            "name": "reshape_1158",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1157"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1158
        },
        "reshape_1160": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1161"
            ],
            "ir": "pybuda",
            "name": "reshape_1160",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1160
        },
        "reshape_1161": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1162"
            ],
            "ir": "pybuda",
            "name": "reshape_1161",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1160"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1161
        },
        "reshape_1163": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1164"
            ],
            "ir": "pybuda",
            "name": "reshape_1163",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1162"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1163
        },
        "reshape_1165": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1166"
            ],
            "ir": "pybuda",
            "name": "reshape_1165",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1164"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1165
        },
        "reshape_1170": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1171"
            ],
            "ir": "pybuda",
            "name": "reshape_1170",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1169"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1170
        },
        "reshape_1172": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1173"
            ],
            "ir": "pybuda",
            "name": "reshape_1172",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1171"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1172
        },
        "reshape_1174": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1175"
            ],
            "ir": "pybuda",
            "name": "reshape_1174",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1173"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1174
        },
        "reshape_1176": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1177"
            ],
            "ir": "pybuda",
            "name": "reshape_1176",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1175"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1176
        },
        "reshape_1178": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1179"
            ],
            "ir": "pybuda",
            "name": "reshape_1178",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1178
        },
        "reshape_1183": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1184"
            ],
            "ir": "pybuda",
            "name": "reshape_1183",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1182"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1183
        },
        "reshape_1185": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1186"
            ],
            "ir": "pybuda",
            "name": "reshape_1185",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1184"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1185
        },
        "reshape_1188": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1189"
            ],
            "ir": "pybuda",
            "name": "reshape_1188",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1187"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1188
        },
        "reshape_1190": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1191"
            ],
            "ir": "pybuda",
            "name": "reshape_1190",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1189"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1190
        },
        "reshape_1195": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1196"
            ],
            "ir": "pybuda",
            "name": "reshape_1195",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1194"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1195
        },
        "reshape_1197": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1198"
            ],
            "ir": "pybuda",
            "name": "reshape_1197",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1196"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1197
        },
        "reshape_1198": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1199"
            ],
            "ir": "pybuda",
            "name": "reshape_1198",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1197"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1198
        },
        "reshape_1200": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1201"
            ],
            "ir": "pybuda",
            "name": "reshape_1200",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1199"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1200
        },
        "reshape_1202": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1203"
            ],
            "ir": "pybuda",
            "name": "reshape_1202",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1201"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1202
        },
        "reshape_1207": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1208"
            ],
            "ir": "pybuda",
            "name": "reshape_1207",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1206"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1207
        },
        "reshape_1209": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1210"
            ],
            "ir": "pybuda",
            "name": "reshape_1209",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1208"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1209
        },
        "reshape_1211": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1212"
            ],
            "ir": "pybuda",
            "name": "reshape_1211",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1210"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1211
        },
        "reshape_1213": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1214"
            ],
            "ir": "pybuda",
            "name": "reshape_1213",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1212"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1213
        },
        "reshape_1215": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1216"
            ],
            "ir": "pybuda",
            "name": "reshape_1215",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1214"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1215
        },
        "reshape_1220": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1221"
            ],
            "ir": "pybuda",
            "name": "reshape_1220",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1219"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1220
        },
        "reshape_1222": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1223"
            ],
            "ir": "pybuda",
            "name": "reshape_1222",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1222
        },
        "reshape_1225": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1226"
            ],
            "ir": "pybuda",
            "name": "reshape_1225",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1224"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1225
        },
        "reshape_1227": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1228"
            ],
            "ir": "pybuda",
            "name": "reshape_1227",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1226"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1227
        },
        "reshape_1232": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1233"
            ],
            "ir": "pybuda",
            "name": "reshape_1232",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1231"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1232
        },
        "reshape_1234": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1235"
            ],
            "ir": "pybuda",
            "name": "reshape_1234",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1233"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1234
        },
        "reshape_1235": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1236"
            ],
            "ir": "pybuda",
            "name": "reshape_1235",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1234"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1235
        },
        "reshape_1237": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1238"
            ],
            "ir": "pybuda",
            "name": "reshape_1237",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1236"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1237
        },
        "reshape_1239": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1240"
            ],
            "ir": "pybuda",
            "name": "reshape_1239",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1238"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1239
        },
        "reshape_1244": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1245"
            ],
            "ir": "pybuda",
            "name": "reshape_1244",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1243"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1244
        },
        "reshape_1246": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1247"
            ],
            "ir": "pybuda",
            "name": "reshape_1246",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1245"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1246
        },
        "reshape_1248": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1249"
            ],
            "ir": "pybuda",
            "name": "reshape_1248",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1247"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1248
        },
        "reshape_1250": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1251"
            ],
            "ir": "pybuda",
            "name": "reshape_1250",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1249"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1250
        },
        "reshape_1252": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1253"
            ],
            "ir": "pybuda",
            "name": "reshape_1252",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1252
        },
        "reshape_1257": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1258"
            ],
            "ir": "pybuda",
            "name": "reshape_1257",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1256"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1257
        },
        "reshape_1259": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1260"
            ],
            "ir": "pybuda",
            "name": "reshape_1259",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1259
        },
        "reshape_1262": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1263"
            ],
            "ir": "pybuda",
            "name": "reshape_1262",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1261"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1262
        },
        "reshape_1264": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1265"
            ],
            "ir": "pybuda",
            "name": "reshape_1264",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1263"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1264
        },
        "reshape_1269": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1270"
            ],
            "ir": "pybuda",
            "name": "reshape_1269",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1268"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1269
        },
        "reshape_1271": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_1272"
            ],
            "ir": "pybuda",
            "name": "reshape_1271",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1270"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1271
        },
        "reshape_1272": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1273"
            ],
            "ir": "pybuda",
            "name": "reshape_1272",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1271"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1272
        },
        "reshape_1274": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1275"
            ],
            "ir": "pybuda",
            "name": "reshape_1274",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1273"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1274
        },
        "reshape_1276": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1277"
            ],
            "ir": "pybuda",
            "name": "reshape_1276",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1275"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1276
        },
        "reshape_1281": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1282"
            ],
            "ir": "pybuda",
            "name": "reshape_1281",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1280"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1281
        },
        "reshape_1283": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1284"
            ],
            "ir": "pybuda",
            "name": "reshape_1283",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1282"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1283
        },
        "reshape_1285": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1286"
            ],
            "ir": "pybuda",
            "name": "reshape_1285",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1284"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1285
        },
        "reshape_1287": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1288"
            ],
            "ir": "pybuda",
            "name": "reshape_1287",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1286"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1287
        },
        "reshape_1289": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1290"
            ],
            "ir": "pybuda",
            "name": "reshape_1289",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1288"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1289
        },
        "reshape_1303": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1304"
            ],
            "ir": "pybuda",
            "name": "reshape_1303",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1282"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1303
        },
        "reshape_1307": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1308"
            ],
            "ir": "pybuda",
            "name": "reshape_1307",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1306"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1307
        },
        "reshape_1309": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1310"
            ],
            "ir": "pybuda",
            "name": "reshape_1309",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1308"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1309
        },
        "reshape_1311": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1290"
            ],
            "ir": "pybuda",
            "name": "reshape_1311",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1310"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1311
        },
        "reshape_1324": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1325"
            ],
            "ir": "pybuda",
            "name": "reshape_1324",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1275"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1324
        },
        "reshape_1327": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1328"
            ],
            "ir": "pybuda",
            "name": "reshape_1327",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1326"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1327
        },
        "reshape_1329": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1330"
            ],
            "ir": "pybuda",
            "name": "reshape_1329",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1328"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1329
        },
        "reshape_1331": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1290"
            ],
            "ir": "pybuda",
            "name": "reshape_1331",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1330"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1331
        },
        "reshape_1349": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1350"
            ],
            "ir": "pybuda",
            "name": "reshape_1349",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1245"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1349
        },
        "reshape_1353": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1354"
            ],
            "ir": "pybuda",
            "name": "reshape_1353",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1352"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1353
        },
        "reshape_1355": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1356"
            ],
            "ir": "pybuda",
            "name": "reshape_1355",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1354"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1355
        },
        "reshape_1357": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1253"
            ],
            "ir": "pybuda",
            "name": "reshape_1357",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1356"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1357
        },
        "reshape_1361": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1362"
            ],
            "ir": "pybuda",
            "name": "reshape_1361",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1238"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1361
        },
        "reshape_1364": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1365"
            ],
            "ir": "pybuda",
            "name": "reshape_1364",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1363"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1364
        },
        "reshape_1366": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1367"
            ],
            "ir": "pybuda",
            "name": "reshape_1366",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1365"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1366
        },
        "reshape_1368": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1253"
            ],
            "ir": "pybuda",
            "name": "reshape_1368",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1367"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1368
        },
        "reshape_1386": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1387"
            ],
            "ir": "pybuda",
            "name": "reshape_1386",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1208"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1386
        },
        "reshape_1390": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1391"
            ],
            "ir": "pybuda",
            "name": "reshape_1390",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1389"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1390
        },
        "reshape_1392": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1393"
            ],
            "ir": "pybuda",
            "name": "reshape_1392",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1391"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1392
        },
        "reshape_1394": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1216"
            ],
            "ir": "pybuda",
            "name": "reshape_1394",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1393"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1394
        },
        "reshape_1398": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1399"
            ],
            "ir": "pybuda",
            "name": "reshape_1398",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1201"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1398
        },
        "reshape_1401": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1402"
            ],
            "ir": "pybuda",
            "name": "reshape_1401",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1401
        },
        "reshape_1403": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1404"
            ],
            "ir": "pybuda",
            "name": "reshape_1403",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1403
        },
        "reshape_1405": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1216"
            ],
            "ir": "pybuda",
            "name": "reshape_1405",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1404"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1405
        },
        "reshape_1423": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1424"
            ],
            "ir": "pybuda",
            "name": "reshape_1423",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1171"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1423
        },
        "reshape_1427": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1428"
            ],
            "ir": "pybuda",
            "name": "reshape_1427",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1427
        },
        "reshape_1429": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1430"
            ],
            "ir": "pybuda",
            "name": "reshape_1429",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1429
        },
        "reshape_1431": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1179"
            ],
            "ir": "pybuda",
            "name": "reshape_1431",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1431
        },
        "reshape_1435": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1436"
            ],
            "ir": "pybuda",
            "name": "reshape_1435",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1164"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1435
        },
        "reshape_1438": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1439"
            ],
            "ir": "pybuda",
            "name": "reshape_1438",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1437"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1438
        },
        "reshape_1440": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1441"
            ],
            "ir": "pybuda",
            "name": "reshape_1440",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1440
        },
        "reshape_1442": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1179"
            ],
            "ir": "pybuda",
            "name": "reshape_1442",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1442
        },
        "reshape_1460": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1461"
            ],
            "ir": "pybuda",
            "name": "reshape_1460",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1134"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1460
        },
        "reshape_1464": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1465"
            ],
            "ir": "pybuda",
            "name": "reshape_1464",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1464
        },
        "reshape_1466": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1467"
            ],
            "ir": "pybuda",
            "name": "reshape_1466",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1466
        },
        "reshape_1468": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1142"
            ],
            "ir": "pybuda",
            "name": "reshape_1468",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1468
        },
        "reshape_1472": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1473"
            ],
            "ir": "pybuda",
            "name": "reshape_1472",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1472
        },
        "reshape_1475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1476"
            ],
            "ir": "pybuda",
            "name": "reshape_1475",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1475
        },
        "reshape_1477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1478"
            ],
            "ir": "pybuda",
            "name": "reshape_1477",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1477
        },
        "reshape_1479": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1142"
            ],
            "ir": "pybuda",
            "name": "reshape_1479",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1479
        },
        "reshape_1497": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1498"
            ],
            "ir": "pybuda",
            "name": "reshape_1497",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1097"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1497
        },
        "reshape_1501": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1502"
            ],
            "ir": "pybuda",
            "name": "reshape_1501",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1501
        },
        "reshape_1503": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1504"
            ],
            "ir": "pybuda",
            "name": "reshape_1503",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1503
        },
        "reshape_1505": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1105"
            ],
            "ir": "pybuda",
            "name": "reshape_1505",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1504"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1505
        },
        "reshape_1509": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1510"
            ],
            "ir": "pybuda",
            "name": "reshape_1509",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1090"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1509
        },
        "reshape_1512": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1513"
            ],
            "ir": "pybuda",
            "name": "reshape_1512",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1512
        },
        "reshape_1514": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1515"
            ],
            "ir": "pybuda",
            "name": "reshape_1514",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1513"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1514
        },
        "reshape_1516": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1105"
            ],
            "ir": "pybuda",
            "name": "reshape_1516",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1516
        },
        "reshape_1534": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1535"
            ],
            "ir": "pybuda",
            "name": "reshape_1534",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1060"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1534
        },
        "reshape_1538": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1539"
            ],
            "ir": "pybuda",
            "name": "reshape_1538",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1538
        },
        "reshape_1540": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1541"
            ],
            "ir": "pybuda",
            "name": "reshape_1540",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1540
        },
        "reshape_1542": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1068"
            ],
            "ir": "pybuda",
            "name": "reshape_1542",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1541"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1542
        },
        "reshape_1546": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1547"
            ],
            "ir": "pybuda",
            "name": "reshape_1546",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1053"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1546
        },
        "reshape_1549": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1550"
            ],
            "ir": "pybuda",
            "name": "reshape_1549",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1548"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1549
        },
        "reshape_1551": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1552"
            ],
            "ir": "pybuda",
            "name": "reshape_1551",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1551
        },
        "reshape_1553": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1068"
            ],
            "ir": "pybuda",
            "name": "reshape_1553",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1553
        },
        "reshape_1571": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1572"
            ],
            "ir": "pybuda",
            "name": "reshape_1571",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1023"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1571
        },
        "reshape_1575": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1576"
            ],
            "ir": "pybuda",
            "name": "reshape_1575",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1575
        },
        "reshape_1577": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1578"
            ],
            "ir": "pybuda",
            "name": "reshape_1577",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1577
        },
        "reshape_1579": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1031"
            ],
            "ir": "pybuda",
            "name": "reshape_1579",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1579
        },
        "reshape_1583": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1584"
            ],
            "ir": "pybuda",
            "name": "reshape_1583",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1016"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1583
        },
        "reshape_1586": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1587"
            ],
            "ir": "pybuda",
            "name": "reshape_1586",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1586
        },
        "reshape_1588": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1589"
            ],
            "ir": "pybuda",
            "name": "reshape_1588",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1588
        },
        "reshape_1590": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1031"
            ],
            "ir": "pybuda",
            "name": "reshape_1590",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1590
        },
        "reshape_1608": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1609"
            ],
            "ir": "pybuda",
            "name": "reshape_1608",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_986"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1608
        },
        "reshape_1612": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1613"
            ],
            "ir": "pybuda",
            "name": "reshape_1612",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1611"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1612
        },
        "reshape_1614": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1615"
            ],
            "ir": "pybuda",
            "name": "reshape_1614",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1614
        },
        "reshape_1616": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_994"
            ],
            "ir": "pybuda",
            "name": "reshape_1616",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1616
        },
        "reshape_1620": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1621"
            ],
            "ir": "pybuda",
            "name": "reshape_1620",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_979"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1620
        },
        "reshape_1623": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1624"
            ],
            "ir": "pybuda",
            "name": "reshape_1623",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1623
        },
        "reshape_1625": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1626"
            ],
            "ir": "pybuda",
            "name": "reshape_1625",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1625
        },
        "reshape_1627": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_994"
            ],
            "ir": "pybuda",
            "name": "reshape_1627",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1627
        },
        "reshape_1645": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1646"
            ],
            "ir": "pybuda",
            "name": "reshape_1645",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_949"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1645
        },
        "reshape_1649": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1650"
            ],
            "ir": "pybuda",
            "name": "reshape_1649",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1649
        },
        "reshape_1651": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1652"
            ],
            "ir": "pybuda",
            "name": "reshape_1651",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1650"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1651
        },
        "reshape_1653": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_957"
            ],
            "ir": "pybuda",
            "name": "reshape_1653",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1653
        },
        "reshape_1657": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1658"
            ],
            "ir": "pybuda",
            "name": "reshape_1657",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1657
        },
        "reshape_1660": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1661"
            ],
            "ir": "pybuda",
            "name": "reshape_1660",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1659"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1660
        },
        "reshape_1662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1663"
            ],
            "ir": "pybuda",
            "name": "reshape_1662",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1661"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1662
        },
        "reshape_1664": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_957"
            ],
            "ir": "pybuda",
            "name": "reshape_1664",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1664
        },
        "reshape_1682": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1683"
            ],
            "ir": "pybuda",
            "name": "reshape_1682",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1682
        },
        "reshape_1686": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1687"
            ],
            "ir": "pybuda",
            "name": "reshape_1686",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1685"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1686
        },
        "reshape_1688": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1689"
            ],
            "ir": "pybuda",
            "name": "reshape_1688",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1688
        },
        "reshape_1690": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_920"
            ],
            "ir": "pybuda",
            "name": "reshape_1690",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1690
        },
        "reshape_1694": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1695"
            ],
            "ir": "pybuda",
            "name": "reshape_1694",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_905"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1694
        },
        "reshape_1697": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1698"
            ],
            "ir": "pybuda",
            "name": "reshape_1697",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1697
        },
        "reshape_1699": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1700"
            ],
            "ir": "pybuda",
            "name": "reshape_1699",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1698"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1699
        },
        "reshape_1701": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_920"
            ],
            "ir": "pybuda",
            "name": "reshape_1701",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1701
        },
        "reshape_1719": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1720"
            ],
            "ir": "pybuda",
            "name": "reshape_1719",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1719
        },
        "reshape_1723": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1724"
            ],
            "ir": "pybuda",
            "name": "reshape_1723",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1722"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1723
        },
        "reshape_1725": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1726"
            ],
            "ir": "pybuda",
            "name": "reshape_1725",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1724"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1725
        },
        "reshape_1727": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "reshape_1727",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1727
        },
        "reshape_1731": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1732"
            ],
            "ir": "pybuda",
            "name": "reshape_1731",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1731
        },
        "reshape_1734": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1735"
            ],
            "ir": "pybuda",
            "name": "reshape_1734",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1734
        },
        "reshape_1736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1737"
            ],
            "ir": "pybuda",
            "name": "reshape_1736",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1735"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1736
        },
        "reshape_1738": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "reshape_1738",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1738
        },
        "reshape_1756": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1757"
            ],
            "ir": "pybuda",
            "name": "reshape_1756",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1756
        },
        "reshape_1760": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1761"
            ],
            "ir": "pybuda",
            "name": "reshape_1760",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1760
        },
        "reshape_1762": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1763"
            ],
            "ir": "pybuda",
            "name": "reshape_1762",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1761"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1762
        },
        "reshape_1764": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "reshape_1764",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1764
        },
        "reshape_1768": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1769"
            ],
            "ir": "pybuda",
            "name": "reshape_1768",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1768
        },
        "reshape_1771": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1772"
            ],
            "ir": "pybuda",
            "name": "reshape_1771",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1771
        },
        "reshape_1773": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1774"
            ],
            "ir": "pybuda",
            "name": "reshape_1773",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1772"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1773
        },
        "reshape_1775": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "reshape_1775",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1775
        },
        "reshape_1793": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1794"
            ],
            "ir": "pybuda",
            "name": "reshape_1793",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_801"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1793
        },
        "reshape_1797": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1798"
            ],
            "ir": "pybuda",
            "name": "reshape_1797",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1796"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1797
        },
        "reshape_1799": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1800"
            ],
            "ir": "pybuda",
            "name": "reshape_1799",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1798"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1799
        },
        "reshape_1801": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_809"
            ],
            "ir": "pybuda",
            "name": "reshape_1801",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1800"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1801
        },
        "reshape_1805": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1806"
            ],
            "ir": "pybuda",
            "name": "reshape_1805",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_794"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1805
        },
        "reshape_1808": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1809"
            ],
            "ir": "pybuda",
            "name": "reshape_1808",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1807"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1808
        },
        "reshape_1810": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1811"
            ],
            "ir": "pybuda",
            "name": "reshape_1810",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1810
        },
        "reshape_1812": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_809"
            ],
            "ir": "pybuda",
            "name": "reshape_1812",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1812
        },
        "reshape_1830": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1831"
            ],
            "ir": "pybuda",
            "name": "reshape_1830",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_764"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1830
        },
        "reshape_1834": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1835"
            ],
            "ir": "pybuda",
            "name": "reshape_1834",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1833"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1834
        },
        "reshape_1836": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1837"
            ],
            "ir": "pybuda",
            "name": "reshape_1836",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1835"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1836
        },
        "reshape_1838": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "reshape_1838",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1837"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1838
        },
        "reshape_1842": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1843"
            ],
            "ir": "pybuda",
            "name": "reshape_1842",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1842
        },
        "reshape_1845": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1846"
            ],
            "ir": "pybuda",
            "name": "reshape_1845",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1844"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1845
        },
        "reshape_1847": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1848"
            ],
            "ir": "pybuda",
            "name": "reshape_1847",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1846"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1847
        },
        "reshape_1849": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "reshape_1849",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1849
        },
        "reshape_1867": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1868"
            ],
            "ir": "pybuda",
            "name": "reshape_1867",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_727"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1867
        },
        "reshape_1871": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1872"
            ],
            "ir": "pybuda",
            "name": "reshape_1871",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1871
        },
        "reshape_1873": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1874"
            ],
            "ir": "pybuda",
            "name": "reshape_1873",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1872"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1873
        },
        "reshape_1875": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_735"
            ],
            "ir": "pybuda",
            "name": "reshape_1875",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1875
        },
        "reshape_1879": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1880"
            ],
            "ir": "pybuda",
            "name": "reshape_1879",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1879
        },
        "reshape_1882": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1883"
            ],
            "ir": "pybuda",
            "name": "reshape_1882",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1882
        },
        "reshape_1884": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1885"
            ],
            "ir": "pybuda",
            "name": "reshape_1884",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1883"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1884
        },
        "reshape_1886": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_735"
            ],
            "ir": "pybuda",
            "name": "reshape_1886",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1885"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1886
        },
        "reshape_1904": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1905"
            ],
            "ir": "pybuda",
            "name": "reshape_1904",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_690"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1904
        },
        "reshape_1908": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1909"
            ],
            "ir": "pybuda",
            "name": "reshape_1908",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1907"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1908
        },
        "reshape_1910": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1911"
            ],
            "ir": "pybuda",
            "name": "reshape_1910",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1909"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1910
        },
        "reshape_1912": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_698"
            ],
            "ir": "pybuda",
            "name": "reshape_1912",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1912
        },
        "reshape_1916": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1917"
            ],
            "ir": "pybuda",
            "name": "reshape_1916",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1916
        },
        "reshape_1919": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1920"
            ],
            "ir": "pybuda",
            "name": "reshape_1919",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1919
        },
        "reshape_1921": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1922"
            ],
            "ir": "pybuda",
            "name": "reshape_1921",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1920"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1921
        },
        "reshape_1923": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_698"
            ],
            "ir": "pybuda",
            "name": "reshape_1923",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1923
        },
        "reshape_1941": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1942"
            ],
            "ir": "pybuda",
            "name": "reshape_1941",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1941
        },
        "reshape_1945": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1946"
            ],
            "ir": "pybuda",
            "name": "reshape_1945",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1944"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1945
        },
        "reshape_1947": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1948"
            ],
            "ir": "pybuda",
            "name": "reshape_1947",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1946"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1947
        },
        "reshape_1949": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_661"
            ],
            "ir": "pybuda",
            "name": "reshape_1949",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1949
        },
        "reshape_1953": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1954"
            ],
            "ir": "pybuda",
            "name": "reshape_1953",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1953
        },
        "reshape_1956": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1957"
            ],
            "ir": "pybuda",
            "name": "reshape_1956",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1956
        },
        "reshape_1958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1959"
            ],
            "ir": "pybuda",
            "name": "reshape_1958",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1958
        },
        "reshape_1960": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_661"
            ],
            "ir": "pybuda",
            "name": "reshape_1960",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1960
        },
        "reshape_1978": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1979"
            ],
            "ir": "pybuda",
            "name": "reshape_1978",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1978
        },
        "reshape_1982": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1983"
            ],
            "ir": "pybuda",
            "name": "reshape_1982",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1981"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1982
        },
        "reshape_1984": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1985"
            ],
            "ir": "pybuda",
            "name": "reshape_1984",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1983"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1984
        },
        "reshape_1986": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_624"
            ],
            "ir": "pybuda",
            "name": "reshape_1986",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1986
        },
        "reshape_1990": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1991"
            ],
            "ir": "pybuda",
            "name": "reshape_1990",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1990
        },
        "reshape_1993": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_1994"
            ],
            "ir": "pybuda",
            "name": "reshape_1993",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1992"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1993
        },
        "reshape_1995": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1996"
            ],
            "ir": "pybuda",
            "name": "reshape_1995",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_1994"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1995
        },
        "reshape_1997": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_624"
            ],
            "ir": "pybuda",
            "name": "reshape_1997",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1997
        },
        "reshape_2015": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2016"
            ],
            "ir": "pybuda",
            "name": "reshape_2015",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2015
        },
        "reshape_2019": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2020"
            ],
            "ir": "pybuda",
            "name": "reshape_2019",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2018"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2019
        },
        "reshape_2021": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2022"
            ],
            "ir": "pybuda",
            "name": "reshape_2021",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2020"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2021
        },
        "reshape_2023": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_587"
            ],
            "ir": "pybuda",
            "name": "reshape_2023",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2022"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2023
        },
        "reshape_2027": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2028"
            ],
            "ir": "pybuda",
            "name": "reshape_2027",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2027
        },
        "reshape_2030": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2031"
            ],
            "ir": "pybuda",
            "name": "reshape_2030",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2029"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2030
        },
        "reshape_2032": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2033"
            ],
            "ir": "pybuda",
            "name": "reshape_2032",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2031"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2032
        },
        "reshape_2034": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_587"
            ],
            "ir": "pybuda",
            "name": "reshape_2034",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2033"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2034
        },
        "reshape_2052": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2053"
            ],
            "ir": "pybuda",
            "name": "reshape_2052",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_542"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2052
        },
        "reshape_2056": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2057"
            ],
            "ir": "pybuda",
            "name": "reshape_2056",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2055"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2056
        },
        "reshape_2058": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2059"
            ],
            "ir": "pybuda",
            "name": "reshape_2058",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2057"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2058
        },
        "reshape_2060": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_550"
            ],
            "ir": "pybuda",
            "name": "reshape_2060",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2060
        },
        "reshape_2064": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2065"
            ],
            "ir": "pybuda",
            "name": "reshape_2064",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2064
        },
        "reshape_2067": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2068"
            ],
            "ir": "pybuda",
            "name": "reshape_2067",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2067
        },
        "reshape_2069": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2070"
            ],
            "ir": "pybuda",
            "name": "reshape_2069",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2068"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2069
        },
        "reshape_2071": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_550"
            ],
            "ir": "pybuda",
            "name": "reshape_2071",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2071
        },
        "reshape_2089": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2090"
            ],
            "ir": "pybuda",
            "name": "reshape_2089",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_505"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2089
        },
        "reshape_2093": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2094"
            ],
            "ir": "pybuda",
            "name": "reshape_2093",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2092"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2093
        },
        "reshape_2095": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2096"
            ],
            "ir": "pybuda",
            "name": "reshape_2095",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2094"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2095
        },
        "reshape_2097": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_513"
            ],
            "ir": "pybuda",
            "name": "reshape_2097",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2097
        },
        "reshape_2101": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2102"
            ],
            "ir": "pybuda",
            "name": "reshape_2101",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2101
        },
        "reshape_2104": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2105"
            ],
            "ir": "pybuda",
            "name": "reshape_2104",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2104
        },
        "reshape_2106": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2107"
            ],
            "ir": "pybuda",
            "name": "reshape_2106",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2105"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2106
        },
        "reshape_2108": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_513"
            ],
            "ir": "pybuda",
            "name": "reshape_2108",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2108
        },
        "reshape_2126": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2127"
            ],
            "ir": "pybuda",
            "name": "reshape_2126",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2126
        },
        "reshape_2130": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2131"
            ],
            "ir": "pybuda",
            "name": "reshape_2130",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2129"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2130
        },
        "reshape_2132": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2133"
            ],
            "ir": "pybuda",
            "name": "reshape_2132",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2131"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2132
        },
        "reshape_2134": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_476"
            ],
            "ir": "pybuda",
            "name": "reshape_2134",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2133"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2134
        },
        "reshape_2138": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2139"
            ],
            "ir": "pybuda",
            "name": "reshape_2138",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2138
        },
        "reshape_2141": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2142"
            ],
            "ir": "pybuda",
            "name": "reshape_2141",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2140"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2141
        },
        "reshape_2143": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2144"
            ],
            "ir": "pybuda",
            "name": "reshape_2143",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2142"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2143
        },
        "reshape_2145": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_476"
            ],
            "ir": "pybuda",
            "name": "reshape_2145",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2145
        },
        "reshape_2163": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2164"
            ],
            "ir": "pybuda",
            "name": "reshape_2163",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2163
        },
        "reshape_2167": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2168"
            ],
            "ir": "pybuda",
            "name": "reshape_2167",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2166"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2167
        },
        "reshape_2169": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2170"
            ],
            "ir": "pybuda",
            "name": "reshape_2169",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2168"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2169
        },
        "reshape_2171": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "reshape_2171",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2170"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2171
        },
        "reshape_2175": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_2176"
            ],
            "ir": "pybuda",
            "name": "reshape_2175",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2175
        },
        "reshape_2178": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_2179"
            ],
            "ir": "pybuda",
            "name": "reshape_2178",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2178
        },
        "reshape_2180": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_2181"
            ],
            "ir": "pybuda",
            "name": "reshape_2180",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_2179"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2180
        },
        "reshape_2182": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "reshape_2182",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2181"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 2182
        },
        "reshape_399": {
            "cache": {
                "shape": [
                    1,
                    384,
                    2
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_400"
            ],
            "ir": "pybuda",
            "name": "reshape_399",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 399
        },
        "reshape_401": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_402"
            ],
            "ir": "pybuda",
            "name": "reshape_401",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 401
        },
        "reshape_406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_407"
            ],
            "ir": "pybuda",
            "name": "reshape_406",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_405"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 406
        },
        "reshape_408": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_409"
            ],
            "ir": "pybuda",
            "name": "reshape_408",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 408
        },
        "reshape_411": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_412"
            ],
            "ir": "pybuda",
            "name": "reshape_411",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_410"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 411
        },
        "reshape_413": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_414"
            ],
            "ir": "pybuda",
            "name": "reshape_413",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 413
        },
        "reshape_418": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_419"
            ],
            "ir": "pybuda",
            "name": "reshape_418",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_417"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 418
        },
        "reshape_420": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_421"
            ],
            "ir": "pybuda",
            "name": "reshape_420",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 420
        },
        "reshape_421": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_422"
            ],
            "ir": "pybuda",
            "name": "reshape_421",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_420"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 421
        },
        "reshape_423": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_424"
            ],
            "ir": "pybuda",
            "name": "reshape_423",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_422"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 423
        },
        "reshape_425": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_426"
            ],
            "ir": "pybuda",
            "name": "reshape_425",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 425
        },
        "reshape_430": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_431"
            ],
            "ir": "pybuda",
            "name": "reshape_430",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 430
        },
        "reshape_432": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_433"
            ],
            "ir": "pybuda",
            "name": "reshape_432",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 432
        },
        "reshape_434": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_435"
            ],
            "ir": "pybuda",
            "name": "reshape_434",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_433"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 434
        },
        "reshape_436": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_437"
            ],
            "ir": "pybuda",
            "name": "reshape_436",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 436
        },
        "reshape_438": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_439"
            ],
            "ir": "pybuda",
            "name": "reshape_438",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_437"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 438
        },
        "reshape_443": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_444"
            ],
            "ir": "pybuda",
            "name": "reshape_443",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 443
        },
        "reshape_445": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_446"
            ],
            "ir": "pybuda",
            "name": "reshape_445",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 445
        },
        "reshape_448": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_449"
            ],
            "ir": "pybuda",
            "name": "reshape_448",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 448
        },
        "reshape_450": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_451"
            ],
            "ir": "pybuda",
            "name": "reshape_450",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 450
        },
        "reshape_455": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_456"
            ],
            "ir": "pybuda",
            "name": "reshape_455",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_454"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 455
        },
        "reshape_457": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_458"
            ],
            "ir": "pybuda",
            "name": "reshape_457",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 457
        },
        "reshape_458": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_459"
            ],
            "ir": "pybuda",
            "name": "reshape_458",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_457"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 458
        },
        "reshape_460": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_461"
            ],
            "ir": "pybuda",
            "name": "reshape_460",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 460
        },
        "reshape_462": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_463"
            ],
            "ir": "pybuda",
            "name": "reshape_462",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 462
        },
        "reshape_467": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_468"
            ],
            "ir": "pybuda",
            "name": "reshape_467",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 467
        },
        "reshape_469": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_470"
            ],
            "ir": "pybuda",
            "name": "reshape_469",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 469
        },
        "reshape_471": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_472"
            ],
            "ir": "pybuda",
            "name": "reshape_471",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_470"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 471
        },
        "reshape_473": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_474"
            ],
            "ir": "pybuda",
            "name": "reshape_473",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_472"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 473
        },
        "reshape_475": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_476"
            ],
            "ir": "pybuda",
            "name": "reshape_475",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 475
        },
        "reshape_480": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_481"
            ],
            "ir": "pybuda",
            "name": "reshape_480",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_479"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 480
        },
        "reshape_482": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_483"
            ],
            "ir": "pybuda",
            "name": "reshape_482",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 482
        },
        "reshape_485": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_486"
            ],
            "ir": "pybuda",
            "name": "reshape_485",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 485
        },
        "reshape_487": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_488"
            ],
            "ir": "pybuda",
            "name": "reshape_487",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 487
        },
        "reshape_492": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_493"
            ],
            "ir": "pybuda",
            "name": "reshape_492",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_491"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 492
        },
        "reshape_494": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_495"
            ],
            "ir": "pybuda",
            "name": "reshape_494",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 494
        },
        "reshape_495": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_496"
            ],
            "ir": "pybuda",
            "name": "reshape_495",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 495
        },
        "reshape_497": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_498"
            ],
            "ir": "pybuda",
            "name": "reshape_497",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_496"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 497
        },
        "reshape_499": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_500"
            ],
            "ir": "pybuda",
            "name": "reshape_499",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 499
        },
        "reshape_504": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_505"
            ],
            "ir": "pybuda",
            "name": "reshape_504",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 504
        },
        "reshape_506": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_507"
            ],
            "ir": "pybuda",
            "name": "reshape_506",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_505"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 506
        },
        "reshape_508": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_509"
            ],
            "ir": "pybuda",
            "name": "reshape_508",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 508
        },
        "reshape_510": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_511"
            ],
            "ir": "pybuda",
            "name": "reshape_510",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_509"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 510
        },
        "reshape_512": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_513"
            ],
            "ir": "pybuda",
            "name": "reshape_512",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 512
        },
        "reshape_517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_518"
            ],
            "ir": "pybuda",
            "name": "reshape_517",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 517
        },
        "reshape_519": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_520"
            ],
            "ir": "pybuda",
            "name": "reshape_519",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 519
        },
        "reshape_522": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_523"
            ],
            "ir": "pybuda",
            "name": "reshape_522",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_521"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 522
        },
        "reshape_524": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_525"
            ],
            "ir": "pybuda",
            "name": "reshape_524",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 524
        },
        "reshape_529": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_530"
            ],
            "ir": "pybuda",
            "name": "reshape_529",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 529
        },
        "reshape_531": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_532"
            ],
            "ir": "pybuda",
            "name": "reshape_531",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 531
        },
        "reshape_532": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_533"
            ],
            "ir": "pybuda",
            "name": "reshape_532",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 532
        },
        "reshape_534": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_535"
            ],
            "ir": "pybuda",
            "name": "reshape_534",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_533"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 534
        },
        "reshape_536": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_537"
            ],
            "ir": "pybuda",
            "name": "reshape_536",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 536
        },
        "reshape_541": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_542"
            ],
            "ir": "pybuda",
            "name": "reshape_541",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 541
        },
        "reshape_543": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_544"
            ],
            "ir": "pybuda",
            "name": "reshape_543",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_542"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 543
        },
        "reshape_545": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_546"
            ],
            "ir": "pybuda",
            "name": "reshape_545",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_544"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 545
        },
        "reshape_547": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_548"
            ],
            "ir": "pybuda",
            "name": "reshape_547",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 547
        },
        "reshape_549": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_550"
            ],
            "ir": "pybuda",
            "name": "reshape_549",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_548"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 549
        },
        "reshape_554": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_555"
            ],
            "ir": "pybuda",
            "name": "reshape_554",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 554
        },
        "reshape_556": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_557"
            ],
            "ir": "pybuda",
            "name": "reshape_556",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_555"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 556
        },
        "reshape_559": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_560"
            ],
            "ir": "pybuda",
            "name": "reshape_559",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 559
        },
        "reshape_561": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_562"
            ],
            "ir": "pybuda",
            "name": "reshape_561",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 561
        },
        "reshape_566": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_567"
            ],
            "ir": "pybuda",
            "name": "reshape_566",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 566
        },
        "reshape_568": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_569"
            ],
            "ir": "pybuda",
            "name": "reshape_568",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 568
        },
        "reshape_569": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_570"
            ],
            "ir": "pybuda",
            "name": "reshape_569",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 569
        },
        "reshape_571": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_572"
            ],
            "ir": "pybuda",
            "name": "reshape_571",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 571
        },
        "reshape_573": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_574"
            ],
            "ir": "pybuda",
            "name": "reshape_573",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 573
        },
        "reshape_578": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_579"
            ],
            "ir": "pybuda",
            "name": "reshape_578",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_577"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 578
        },
        "reshape_580": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_581"
            ],
            "ir": "pybuda",
            "name": "reshape_580",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 580
        },
        "reshape_582": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_583"
            ],
            "ir": "pybuda",
            "name": "reshape_582",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_581"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 582
        },
        "reshape_584": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_585"
            ],
            "ir": "pybuda",
            "name": "reshape_584",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_583"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 584
        },
        "reshape_586": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_587"
            ],
            "ir": "pybuda",
            "name": "reshape_586",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 586
        },
        "reshape_591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_592"
            ],
            "ir": "pybuda",
            "name": "reshape_591",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 591
        },
        "reshape_593": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_594"
            ],
            "ir": "pybuda",
            "name": "reshape_593",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 593
        },
        "reshape_596": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_597"
            ],
            "ir": "pybuda",
            "name": "reshape_596",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_595"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 596
        },
        "reshape_598": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_599"
            ],
            "ir": "pybuda",
            "name": "reshape_598",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_597"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 598
        },
        "reshape_603": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_604"
            ],
            "ir": "pybuda",
            "name": "reshape_603",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 603
        },
        "reshape_605": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_606"
            ],
            "ir": "pybuda",
            "name": "reshape_605",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_604"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 605
        },
        "reshape_606": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_607"
            ],
            "ir": "pybuda",
            "name": "reshape_606",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_605"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 606
        },
        "reshape_608": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_609"
            ],
            "ir": "pybuda",
            "name": "reshape_608",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 608
        },
        "reshape_610": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_611"
            ],
            "ir": "pybuda",
            "name": "reshape_610",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 610
        },
        "reshape_615": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_616"
            ],
            "ir": "pybuda",
            "name": "reshape_615",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 615
        },
        "reshape_617": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_618"
            ],
            "ir": "pybuda",
            "name": "reshape_617",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 617
        },
        "reshape_619": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_620"
            ],
            "ir": "pybuda",
            "name": "reshape_619",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_618"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 619
        },
        "reshape_621": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_622"
            ],
            "ir": "pybuda",
            "name": "reshape_621",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_620"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 621
        },
        "reshape_623": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_624"
            ],
            "ir": "pybuda",
            "name": "reshape_623",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 623
        },
        "reshape_628": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_629"
            ],
            "ir": "pybuda",
            "name": "reshape_628",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 628
        },
        "reshape_630": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_631"
            ],
            "ir": "pybuda",
            "name": "reshape_630",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 630
        },
        "reshape_633": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_634"
            ],
            "ir": "pybuda",
            "name": "reshape_633",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_632"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 633
        },
        "reshape_635": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_636"
            ],
            "ir": "pybuda",
            "name": "reshape_635",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 635
        },
        "reshape_640": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_641"
            ],
            "ir": "pybuda",
            "name": "reshape_640",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 640
        },
        "reshape_642": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_643"
            ],
            "ir": "pybuda",
            "name": "reshape_642",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 642
        },
        "reshape_643": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_644"
            ],
            "ir": "pybuda",
            "name": "reshape_643",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_642"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 643
        },
        "reshape_645": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_646"
            ],
            "ir": "pybuda",
            "name": "reshape_645",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_644"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 645
        },
        "reshape_647": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_648"
            ],
            "ir": "pybuda",
            "name": "reshape_647",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 647
        },
        "reshape_652": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_653"
            ],
            "ir": "pybuda",
            "name": "reshape_652",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 652
        },
        "reshape_654": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_655"
            ],
            "ir": "pybuda",
            "name": "reshape_654",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 654
        },
        "reshape_656": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_657"
            ],
            "ir": "pybuda",
            "name": "reshape_656",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_655"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 656
        },
        "reshape_658": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_659"
            ],
            "ir": "pybuda",
            "name": "reshape_658",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_657"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 658
        },
        "reshape_660": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_661"
            ],
            "ir": "pybuda",
            "name": "reshape_660",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_659"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 660
        },
        "reshape_665": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_666"
            ],
            "ir": "pybuda",
            "name": "reshape_665",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 665
        },
        "reshape_667": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_668"
            ],
            "ir": "pybuda",
            "name": "reshape_667",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_666"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 667
        },
        "reshape_670": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_671"
            ],
            "ir": "pybuda",
            "name": "reshape_670",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 670
        },
        "reshape_672": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_673"
            ],
            "ir": "pybuda",
            "name": "reshape_672",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 672
        },
        "reshape_677": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_678"
            ],
            "ir": "pybuda",
            "name": "reshape_677",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 677
        },
        "reshape_679": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_680"
            ],
            "ir": "pybuda",
            "name": "reshape_679",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 679
        },
        "reshape_680": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_681"
            ],
            "ir": "pybuda",
            "name": "reshape_680",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 680
        },
        "reshape_682": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_683"
            ],
            "ir": "pybuda",
            "name": "reshape_682",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 682
        },
        "reshape_684": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_685"
            ],
            "ir": "pybuda",
            "name": "reshape_684",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 684
        },
        "reshape_689": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_690"
            ],
            "ir": "pybuda",
            "name": "reshape_689",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_688"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 689
        },
        "reshape_691": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_692"
            ],
            "ir": "pybuda",
            "name": "reshape_691",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_690"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 691
        },
        "reshape_693": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_694"
            ],
            "ir": "pybuda",
            "name": "reshape_693",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_692"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 693
        },
        "reshape_695": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_696"
            ],
            "ir": "pybuda",
            "name": "reshape_695",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 695
        },
        "reshape_697": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_698"
            ],
            "ir": "pybuda",
            "name": "reshape_697",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 697
        },
        "reshape_702": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_703"
            ],
            "ir": "pybuda",
            "name": "reshape_702",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 702
        },
        "reshape_704": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_705"
            ],
            "ir": "pybuda",
            "name": "reshape_704",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 704
        },
        "reshape_707": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_708"
            ],
            "ir": "pybuda",
            "name": "reshape_707",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_706"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 707
        },
        "reshape_709": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_710"
            ],
            "ir": "pybuda",
            "name": "reshape_709",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 709
        },
        "reshape_714": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_715"
            ],
            "ir": "pybuda",
            "name": "reshape_714",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_713"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 714
        },
        "reshape_716": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_717"
            ],
            "ir": "pybuda",
            "name": "reshape_716",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 716
        },
        "reshape_717": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_718"
            ],
            "ir": "pybuda",
            "name": "reshape_717",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 717
        },
        "reshape_719": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_720"
            ],
            "ir": "pybuda",
            "name": "reshape_719",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 719
        },
        "reshape_721": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_722"
            ],
            "ir": "pybuda",
            "name": "reshape_721",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 721
        },
        "reshape_726": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_727"
            ],
            "ir": "pybuda",
            "name": "reshape_726",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 726
        },
        "reshape_728": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_729"
            ],
            "ir": "pybuda",
            "name": "reshape_728",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_727"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 728
        },
        "reshape_730": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_731"
            ],
            "ir": "pybuda",
            "name": "reshape_730",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_729"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 730
        },
        "reshape_732": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_733"
            ],
            "ir": "pybuda",
            "name": "reshape_732",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 732
        },
        "reshape_734": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_735"
            ],
            "ir": "pybuda",
            "name": "reshape_734",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 734
        },
        "reshape_739": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_740"
            ],
            "ir": "pybuda",
            "name": "reshape_739",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 739
        },
        "reshape_741": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_742"
            ],
            "ir": "pybuda",
            "name": "reshape_741",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_740"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 741
        },
        "reshape_744": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_745"
            ],
            "ir": "pybuda",
            "name": "reshape_744",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_743"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 744
        },
        "reshape_746": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_747"
            ],
            "ir": "pybuda",
            "name": "reshape_746",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_745"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 746
        },
        "reshape_751": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_752"
            ],
            "ir": "pybuda",
            "name": "reshape_751",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 751
        },
        "reshape_753": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_754"
            ],
            "ir": "pybuda",
            "name": "reshape_753",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 753
        },
        "reshape_754": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_755"
            ],
            "ir": "pybuda",
            "name": "reshape_754",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_753"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 754
        },
        "reshape_756": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_757"
            ],
            "ir": "pybuda",
            "name": "reshape_756",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 756
        },
        "reshape_758": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_759"
            ],
            "ir": "pybuda",
            "name": "reshape_758",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 758
        },
        "reshape_763": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_764"
            ],
            "ir": "pybuda",
            "name": "reshape_763",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 763
        },
        "reshape_765": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_766"
            ],
            "ir": "pybuda",
            "name": "reshape_765",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_764"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 765
        },
        "reshape_767": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_768"
            ],
            "ir": "pybuda",
            "name": "reshape_767",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_766"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 767
        },
        "reshape_769": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_770"
            ],
            "ir": "pybuda",
            "name": "reshape_769",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 769
        },
        "reshape_771": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_772"
            ],
            "ir": "pybuda",
            "name": "reshape_771",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 771
        },
        "reshape_776": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_777"
            ],
            "ir": "pybuda",
            "name": "reshape_776",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_775"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 776
        },
        "reshape_778": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_779"
            ],
            "ir": "pybuda",
            "name": "reshape_778",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_777"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 778
        },
        "reshape_781": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_782"
            ],
            "ir": "pybuda",
            "name": "reshape_781",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 781
        },
        "reshape_783": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_784"
            ],
            "ir": "pybuda",
            "name": "reshape_783",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_782"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 783
        },
        "reshape_788": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_789"
            ],
            "ir": "pybuda",
            "name": "reshape_788",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_787"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 788
        },
        "reshape_790": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_791"
            ],
            "ir": "pybuda",
            "name": "reshape_790",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_789"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 790
        },
        "reshape_791": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_792"
            ],
            "ir": "pybuda",
            "name": "reshape_791",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_790"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 791
        },
        "reshape_793": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_794"
            ],
            "ir": "pybuda",
            "name": "reshape_793",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_792"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 793
        },
        "reshape_795": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_796"
            ],
            "ir": "pybuda",
            "name": "reshape_795",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_794"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 795
        },
        "reshape_800": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_801"
            ],
            "ir": "pybuda",
            "name": "reshape_800",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_799"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 800
        },
        "reshape_802": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_803"
            ],
            "ir": "pybuda",
            "name": "reshape_802",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_801"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 802
        },
        "reshape_804": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_805"
            ],
            "ir": "pybuda",
            "name": "reshape_804",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_803"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 804
        },
        "reshape_806": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_807"
            ],
            "ir": "pybuda",
            "name": "reshape_806",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_805"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 806
        },
        "reshape_808": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_809"
            ],
            "ir": "pybuda",
            "name": "reshape_808",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_807"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 808
        },
        "reshape_813": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_814"
            ],
            "ir": "pybuda",
            "name": "reshape_813",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_812"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 813
        },
        "reshape_815": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_816"
            ],
            "ir": "pybuda",
            "name": "reshape_815",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_814"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 815
        },
        "reshape_818": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_819"
            ],
            "ir": "pybuda",
            "name": "reshape_818",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_817"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 818
        },
        "reshape_820": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_821"
            ],
            "ir": "pybuda",
            "name": "reshape_820",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 820
        },
        "reshape_825": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_826"
            ],
            "ir": "pybuda",
            "name": "reshape_825",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_824"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 825
        },
        "reshape_827": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_828"
            ],
            "ir": "pybuda",
            "name": "reshape_827",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 827
        },
        "reshape_828": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_829"
            ],
            "ir": "pybuda",
            "name": "reshape_828",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_827"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 828
        },
        "reshape_830": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_831"
            ],
            "ir": "pybuda",
            "name": "reshape_830",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_829"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 830
        },
        "reshape_832": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_833"
            ],
            "ir": "pybuda",
            "name": "reshape_832",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 832
        },
        "reshape_837": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_838"
            ],
            "ir": "pybuda",
            "name": "reshape_837",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_836"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 837
        },
        "reshape_839": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_840"
            ],
            "ir": "pybuda",
            "name": "reshape_839",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 839
        },
        "reshape_841": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_842"
            ],
            "ir": "pybuda",
            "name": "reshape_841",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_840"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 841
        },
        "reshape_843": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_844"
            ],
            "ir": "pybuda",
            "name": "reshape_843",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_842"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 843
        },
        "reshape_845": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "reshape_845",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_844"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 845
        },
        "reshape_850": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_851"
            ],
            "ir": "pybuda",
            "name": "reshape_850",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 850
        },
        "reshape_852": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_853"
            ],
            "ir": "pybuda",
            "name": "reshape_852",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_851"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 852
        },
        "reshape_855": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_856"
            ],
            "ir": "pybuda",
            "name": "reshape_855",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 855
        },
        "reshape_857": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_858"
            ],
            "ir": "pybuda",
            "name": "reshape_857",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_856"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 857
        },
        "reshape_862": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_863"
            ],
            "ir": "pybuda",
            "name": "reshape_862",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_861"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 862
        },
        "reshape_864": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_865"
            ],
            "ir": "pybuda",
            "name": "reshape_864",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 864
        },
        "reshape_865": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_866"
            ],
            "ir": "pybuda",
            "name": "reshape_865",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_864"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 865
        },
        "reshape_867": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_868"
            ],
            "ir": "pybuda",
            "name": "reshape_867",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_866"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 867
        },
        "reshape_869": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_870"
            ],
            "ir": "pybuda",
            "name": "reshape_869",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 869
        },
        "reshape_874": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_875"
            ],
            "ir": "pybuda",
            "name": "reshape_874",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_873"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 874
        },
        "reshape_876": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_877"
            ],
            "ir": "pybuda",
            "name": "reshape_876",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 876
        },
        "reshape_878": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_879"
            ],
            "ir": "pybuda",
            "name": "reshape_878",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_877"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 878
        },
        "reshape_880": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_881"
            ],
            "ir": "pybuda",
            "name": "reshape_880",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 880
        },
        "reshape_882": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_883"
            ],
            "ir": "pybuda",
            "name": "reshape_882",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 882
        },
        "reshape_887": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_888"
            ],
            "ir": "pybuda",
            "name": "reshape_887",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_886"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 887
        },
        "reshape_889": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_890"
            ],
            "ir": "pybuda",
            "name": "reshape_889",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 889
        },
        "reshape_892": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_893"
            ],
            "ir": "pybuda",
            "name": "reshape_892",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_891"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 892
        },
        "reshape_894": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_895"
            ],
            "ir": "pybuda",
            "name": "reshape_894",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_893"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 894
        },
        "reshape_899": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_900"
            ],
            "ir": "pybuda",
            "name": "reshape_899",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_898"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 899
        },
        "reshape_901": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_902"
            ],
            "ir": "pybuda",
            "name": "reshape_901",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 901
        },
        "reshape_902": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_903"
            ],
            "ir": "pybuda",
            "name": "reshape_902",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_901"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 902
        },
        "reshape_904": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_905"
            ],
            "ir": "pybuda",
            "name": "reshape_904",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_903"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 904
        },
        "reshape_906": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_907"
            ],
            "ir": "pybuda",
            "name": "reshape_906",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_905"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 906
        },
        "reshape_911": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_912"
            ],
            "ir": "pybuda",
            "name": "reshape_911",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_910"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 911
        },
        "reshape_913": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_914"
            ],
            "ir": "pybuda",
            "name": "reshape_913",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 913
        },
        "reshape_915": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_916"
            ],
            "ir": "pybuda",
            "name": "reshape_915",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_914"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 915
        },
        "reshape_917": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_918"
            ],
            "ir": "pybuda",
            "name": "reshape_917",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_916"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 917
        },
        "reshape_919": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_920"
            ],
            "ir": "pybuda",
            "name": "reshape_919",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 919
        },
        "reshape_924": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_925"
            ],
            "ir": "pybuda",
            "name": "reshape_924",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 924
        },
        "reshape_926": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_927"
            ],
            "ir": "pybuda",
            "name": "reshape_926",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 926
        },
        "reshape_929": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_930"
            ],
            "ir": "pybuda",
            "name": "reshape_929",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_928"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 929
        },
        "reshape_931": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_932"
            ],
            "ir": "pybuda",
            "name": "reshape_931",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 931
        },
        "reshape_936": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_937"
            ],
            "ir": "pybuda",
            "name": "reshape_936",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_935"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 936
        },
        "reshape_938": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_939"
            ],
            "ir": "pybuda",
            "name": "reshape_938",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 938
        },
        "reshape_939": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_940"
            ],
            "ir": "pybuda",
            "name": "reshape_939",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_938"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 939
        },
        "reshape_941": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_942"
            ],
            "ir": "pybuda",
            "name": "reshape_941",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_940"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 941
        },
        "reshape_943": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_944"
            ],
            "ir": "pybuda",
            "name": "reshape_943",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 943
        },
        "reshape_948": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_949"
            ],
            "ir": "pybuda",
            "name": "reshape_948",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_947"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 948
        },
        "reshape_950": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_951"
            ],
            "ir": "pybuda",
            "name": "reshape_950",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_949"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 950
        },
        "reshape_952": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_953"
            ],
            "ir": "pybuda",
            "name": "reshape_952",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_951"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 952
        },
        "reshape_954": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_955"
            ],
            "ir": "pybuda",
            "name": "reshape_954",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 954
        },
        "reshape_956": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_957"
            ],
            "ir": "pybuda",
            "name": "reshape_956",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 956
        },
        "reshape_961": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_962"
            ],
            "ir": "pybuda",
            "name": "reshape_961",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_960"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 961
        },
        "reshape_963": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_964"
            ],
            "ir": "pybuda",
            "name": "reshape_963",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_962"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 963
        },
        "reshape_966": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_967"
            ],
            "ir": "pybuda",
            "name": "reshape_966",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_965"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 966
        },
        "reshape_968": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_969"
            ],
            "ir": "pybuda",
            "name": "reshape_968",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 968
        },
        "reshape_973": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_974"
            ],
            "ir": "pybuda",
            "name": "reshape_973",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_972"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 973
        },
        "reshape_975": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "reshape_976"
            ],
            "ir": "pybuda",
            "name": "reshape_975",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 975
        },
        "reshape_976": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_977"
            ],
            "ir": "pybuda",
            "name": "reshape_976",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_975"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 976
        },
        "reshape_978": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_979"
            ],
            "ir": "pybuda",
            "name": "reshape_978",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_977"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 978
        },
        "reshape_980": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_981"
            ],
            "ir": "pybuda",
            "name": "reshape_980",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_979"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 980
        },
        "reshape_985": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_986"
            ],
            "ir": "pybuda",
            "name": "reshape_985",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_984"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 985
        },
        "reshape_987": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_988"
            ],
            "ir": "pybuda",
            "name": "reshape_987",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_986"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 987
        },
        "reshape_989": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_990"
            ],
            "ir": "pybuda",
            "name": "reshape_989",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_988"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 989
        },
        "reshape_991": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_992"
            ],
            "ir": "pybuda",
            "name": "reshape_991",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_990"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 991
        },
        "reshape_993": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_994"
            ],
            "ir": "pybuda",
            "name": "reshape_993",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_992"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 993
        },
        "reshape_998": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_999"
            ],
            "ir": "pybuda",
            "name": "reshape_998",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.bias_add_997"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 998
        },
        "split_397": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "split",
            "epoch": 0,
            "input_nodes": [
                "nn.bias_add_398",
                "nn.bias_add_398"
            ],
            "ir": "pybuda",
            "name": "split_397",
            "opcode": "RelayOp",
            "output_nodes": [
                "squeeze_396",
                "squeeze_2200"
            ],
            "pybuda": 1,
            "type": "split",
            "unique_id": 397
        },
        "squeeze_2200": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "squeeze",
            "epoch": 0,
            "input_nodes": [
                "split_397"
            ],
            "ir": "pybuda",
            "name": "squeeze_2200",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "squeeze",
            "unique_id": 2200
        },
        "squeeze_396": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "squeeze",
            "epoch": 0,
            "input_nodes": [
                "split_397"
            ],
            "ir": "pybuda",
            "name": "squeeze_396",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "squeeze",
            "unique_id": 396
        },
        "strided_slice_1300": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_ids"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1300",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1299"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::slice, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x2fb4dde0), 0, 0, 0, 0)",
            "type": "strided_slice",
            "unique_id": 1300
        },
        "subtract_1316": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "input_nodes": [
                "constant_1317",
                "multiply_1318"
            ],
            "ir": "pybuda",
            "name": "subtract_1316",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1315"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::rsub, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x918176a0), 0, 0, 0, 0)",
            "type": "subtract",
            "unique_id": 1316
        },
        "transpose_1014": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1015"
            ],
            "ir": "pybuda",
            "name": "transpose_1014",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1013"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1014
        },
        "transpose_1025": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1026"
            ],
            "ir": "pybuda",
            "name": "transpose_1025",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1024"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1025
        },
        "transpose_1051": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1052"
            ],
            "ir": "pybuda",
            "name": "transpose_1051",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1050"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1051
        },
        "transpose_1062": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1063"
            ],
            "ir": "pybuda",
            "name": "transpose_1062",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1061"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1062
        },
        "transpose_1088": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1089"
            ],
            "ir": "pybuda",
            "name": "transpose_1088",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1087"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1088
        },
        "transpose_1099": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1100"
            ],
            "ir": "pybuda",
            "name": "transpose_1099",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1098"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1099
        },
        "transpose_1125": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1126"
            ],
            "ir": "pybuda",
            "name": "transpose_1125",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1124"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1125
        },
        "transpose_1136": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1137"
            ],
            "ir": "pybuda",
            "name": "transpose_1136",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1135"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1136
        },
        "transpose_1162": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1163"
            ],
            "ir": "pybuda",
            "name": "transpose_1162",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1161"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1162
        },
        "transpose_1173": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1174"
            ],
            "ir": "pybuda",
            "name": "transpose_1173",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1172"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1173
        },
        "transpose_1199": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1200"
            ],
            "ir": "pybuda",
            "name": "transpose_1199",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1198"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1199
        },
        "transpose_1210": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1211"
            ],
            "ir": "pybuda",
            "name": "transpose_1210",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1209"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1210
        },
        "transpose_1236": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1237"
            ],
            "ir": "pybuda",
            "name": "transpose_1236",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1235"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1236
        },
        "transpose_1247": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1248"
            ],
            "ir": "pybuda",
            "name": "transpose_1247",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1246"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1247
        },
        "transpose_1273": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1274"
            ],
            "ir": "pybuda",
            "name": "transpose_1273",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1272"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1273
        },
        "transpose_1284": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1285"
            ],
            "ir": "pybuda",
            "name": "transpose_1284",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1283"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1284
        },
        "transpose_1301": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1302"
            ],
            "ir": "pybuda",
            "name": "transpose_1301",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1288"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1301
        },
        "transpose_1302": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1302",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1301"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1302
        },
        "transpose_1304": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1305"
            ],
            "ir": "pybuda",
            "name": "transpose_1304",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1303"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1304
        },
        "transpose_1305": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1306"
            ],
            "ir": "pybuda",
            "name": "transpose_1305",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1304"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917e1700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1305
        },
        "transpose_1306": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1307"
            ],
            "ir": "pybuda",
            "name": "transpose_1306",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1305"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1306
        },
        "transpose_1312": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1313"
            ],
            "ir": "pybuda",
            "name": "transpose_1312",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1310"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1312
        },
        "transpose_1313": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1313",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1312"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1313
        },
        "transpose_1325": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1326"
            ],
            "ir": "pybuda",
            "name": "transpose_1325",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1324"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1325
        },
        "transpose_1326": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1327"
            ],
            "ir": "pybuda",
            "name": "transpose_1326",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1325"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1326
        },
        "transpose_1332": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1333"
            ],
            "ir": "pybuda",
            "name": "transpose_1332",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1330"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1332
        },
        "transpose_1333": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1333",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1332"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1333
        },
        "transpose_1334": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1335"
            ],
            "ir": "pybuda",
            "name": "transpose_1334",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1270"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1334
        },
        "transpose_1335": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1335",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1334"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1335
        },
        "transpose_1336": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1337"
            ],
            "ir": "pybuda",
            "name": "transpose_1336",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1263"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1336
        },
        "transpose_1337": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1337",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1336"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1337
        },
        "transpose_1345": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1346"
            ],
            "ir": "pybuda",
            "name": "transpose_1345",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1345
        },
        "transpose_1346": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.0.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1346",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1345"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1346
        },
        "transpose_1347": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1348"
            ],
            "ir": "pybuda",
            "name": "transpose_1347",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1347
        },
        "transpose_1348": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1348",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1347"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1348
        },
        "transpose_1350": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1351"
            ],
            "ir": "pybuda",
            "name": "transpose_1350",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1349"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1350
        },
        "transpose_1351": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1352"
            ],
            "ir": "pybuda",
            "name": "transpose_1351",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1350"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91829d00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1351
        },
        "transpose_1352": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1353"
            ],
            "ir": "pybuda",
            "name": "transpose_1352",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1351"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1352
        },
        "transpose_1358": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1359"
            ],
            "ir": "pybuda",
            "name": "transpose_1358",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1356"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1358
        },
        "transpose_1359": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1359",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1358"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1359
        },
        "transpose_1362": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1363"
            ],
            "ir": "pybuda",
            "name": "transpose_1362",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1361"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1362
        },
        "transpose_1363": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1364"
            ],
            "ir": "pybuda",
            "name": "transpose_1363",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1362"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1363
        },
        "transpose_1369": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1370"
            ],
            "ir": "pybuda",
            "name": "transpose_1369",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1367"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1369
        },
        "transpose_1370": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1370",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1369"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1370
        },
        "transpose_1371": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1372"
            ],
            "ir": "pybuda",
            "name": "transpose_1371",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1233"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1371
        },
        "transpose_1372": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1372",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1371"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1372
        },
        "transpose_1373": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1374"
            ],
            "ir": "pybuda",
            "name": "transpose_1373",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1226"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1373
        },
        "transpose_1374": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1374",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1373"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1374
        },
        "transpose_1382": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1383"
            ],
            "ir": "pybuda",
            "name": "transpose_1382",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1382
        },
        "transpose_1383": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.1.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1383",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1382"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1383
        },
        "transpose_1384": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1385"
            ],
            "ir": "pybuda",
            "name": "transpose_1384",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1214"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1384
        },
        "transpose_1385": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1385",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1384"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1385
        },
        "transpose_1387": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1388"
            ],
            "ir": "pybuda",
            "name": "transpose_1387",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1386"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1387
        },
        "transpose_1388": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1389"
            ],
            "ir": "pybuda",
            "name": "transpose_1388",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1387"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9181f620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1388
        },
        "transpose_1389": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1390"
            ],
            "ir": "pybuda",
            "name": "transpose_1389",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1388"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1389
        },
        "transpose_1395": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1396"
            ],
            "ir": "pybuda",
            "name": "transpose_1395",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1393"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1395
        },
        "transpose_1396": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1396",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1396
        },
        "transpose_1399": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1400"
            ],
            "ir": "pybuda",
            "name": "transpose_1399",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1399
        },
        "transpose_1400": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1401"
            ],
            "ir": "pybuda",
            "name": "transpose_1400",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1400
        },
        "transpose_1406": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1407"
            ],
            "ir": "pybuda",
            "name": "transpose_1406",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1404"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1406
        },
        "transpose_1407": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1407",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1407
        },
        "transpose_1408": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1409"
            ],
            "ir": "pybuda",
            "name": "transpose_1408",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1196"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1408
        },
        "transpose_1409": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1409",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1408"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1409
        },
        "transpose_1410": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1411"
            ],
            "ir": "pybuda",
            "name": "transpose_1410",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1189"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1410
        },
        "transpose_1411": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1411",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1410"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1411
        },
        "transpose_1419": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1420"
            ],
            "ir": "pybuda",
            "name": "transpose_1419",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1184"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1419
        },
        "transpose_1420": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.2.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1420",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1420
        },
        "transpose_1421": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1422"
            ],
            "ir": "pybuda",
            "name": "transpose_1421",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1421
        },
        "transpose_1422": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1422",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1422
        },
        "transpose_1424": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1425"
            ],
            "ir": "pybuda",
            "name": "transpose_1424",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1424
        },
        "transpose_1425": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1426"
            ],
            "ir": "pybuda",
            "name": "transpose_1425",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917af4e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1425
        },
        "transpose_1426": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1427"
            ],
            "ir": "pybuda",
            "name": "transpose_1426",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1425"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1426
        },
        "transpose_1432": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1433"
            ],
            "ir": "pybuda",
            "name": "transpose_1432",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1432
        },
        "transpose_1433": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1433",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1433
        },
        "transpose_1436": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1437"
            ],
            "ir": "pybuda",
            "name": "transpose_1436",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1436
        },
        "transpose_1437": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1438"
            ],
            "ir": "pybuda",
            "name": "transpose_1437",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1436"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1437
        },
        "transpose_1443": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1444"
            ],
            "ir": "pybuda",
            "name": "transpose_1443",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1443
        },
        "transpose_1444": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1444",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1444
        },
        "transpose_1445": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1446"
            ],
            "ir": "pybuda",
            "name": "transpose_1445",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1445
        },
        "transpose_1446": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1446",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1446
        },
        "transpose_1447": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1448"
            ],
            "ir": "pybuda",
            "name": "transpose_1447",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1447
        },
        "transpose_1448": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1448",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1448
        },
        "transpose_1456": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1457"
            ],
            "ir": "pybuda",
            "name": "transpose_1456",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1147"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1456
        },
        "transpose_1457": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.3.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1457",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1457
        },
        "transpose_1458": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1459"
            ],
            "ir": "pybuda",
            "name": "transpose_1458",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1140"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1458
        },
        "transpose_1459": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1459",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1458"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1459
        },
        "transpose_1461": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1462"
            ],
            "ir": "pybuda",
            "name": "transpose_1461",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1461
        },
        "transpose_1462": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1463"
            ],
            "ir": "pybuda",
            "name": "transpose_1462",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b8b6b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1462
        },
        "transpose_1463": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1464"
            ],
            "ir": "pybuda",
            "name": "transpose_1463",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1462"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1463
        },
        "transpose_1469": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1470"
            ],
            "ir": "pybuda",
            "name": "transpose_1469",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1469
        },
        "transpose_1470": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1470",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1470
        },
        "transpose_1473": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1474"
            ],
            "ir": "pybuda",
            "name": "transpose_1473",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1472"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1473
        },
        "transpose_1474": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1475"
            ],
            "ir": "pybuda",
            "name": "transpose_1474",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1473"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1474
        },
        "transpose_1480": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1481"
            ],
            "ir": "pybuda",
            "name": "transpose_1480",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1480
        },
        "transpose_1481": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1481",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1480"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1481
        },
        "transpose_1482": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1483"
            ],
            "ir": "pybuda",
            "name": "transpose_1482",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1482
        },
        "transpose_1483": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1483",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1482"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1483
        },
        "transpose_1484": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1485"
            ],
            "ir": "pybuda",
            "name": "transpose_1484",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1115"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1484
        },
        "transpose_1485": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1485",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1485
        },
        "transpose_1493": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1494"
            ],
            "ir": "pybuda",
            "name": "transpose_1493",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1493
        },
        "transpose_1494": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.4.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1494",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1494
        },
        "transpose_1495": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1496"
            ],
            "ir": "pybuda",
            "name": "transpose_1495",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1495
        },
        "transpose_1496": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1496",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1496
        },
        "transpose_1498": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1499"
            ],
            "ir": "pybuda",
            "name": "transpose_1498",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1497"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1498
        },
        "transpose_1499": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1500"
            ],
            "ir": "pybuda",
            "name": "transpose_1499",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b97500), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1499
        },
        "transpose_1500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1501"
            ],
            "ir": "pybuda",
            "name": "transpose_1500",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1499"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1500
        },
        "transpose_1506": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1507"
            ],
            "ir": "pybuda",
            "name": "transpose_1506",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1504"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1506
        },
        "transpose_1507": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1507",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1507
        },
        "transpose_1510": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1511"
            ],
            "ir": "pybuda",
            "name": "transpose_1510",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1509"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1510
        },
        "transpose_1511": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1512"
            ],
            "ir": "pybuda",
            "name": "transpose_1511",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1511
        },
        "transpose_1517": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1518"
            ],
            "ir": "pybuda",
            "name": "transpose_1517",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1517
        },
        "transpose_1518": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1518",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1518
        },
        "transpose_1519": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1520"
            ],
            "ir": "pybuda",
            "name": "transpose_1519",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1085"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1519
        },
        "transpose_1520": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1520",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1520
        },
        "transpose_1521": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1522"
            ],
            "ir": "pybuda",
            "name": "transpose_1521",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1521
        },
        "transpose_1522": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1522",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1521"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1522
        },
        "transpose_1530": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1531"
            ],
            "ir": "pybuda",
            "name": "transpose_1530",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1073"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1530
        },
        "transpose_1531": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.5.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1531",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1531
        },
        "transpose_1532": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1533"
            ],
            "ir": "pybuda",
            "name": "transpose_1532",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1532
        },
        "transpose_1533": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1533",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1533
        },
        "transpose_1535": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1536"
            ],
            "ir": "pybuda",
            "name": "transpose_1535",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1535
        },
        "transpose_1536": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1537"
            ],
            "ir": "pybuda",
            "name": "transpose_1536",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b914e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1536
        },
        "transpose_1537": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1538"
            ],
            "ir": "pybuda",
            "name": "transpose_1537",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1537
        },
        "transpose_1543": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1544"
            ],
            "ir": "pybuda",
            "name": "transpose_1543",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1541"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1543
        },
        "transpose_1544": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1544",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1544
        },
        "transpose_1547": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1548"
            ],
            "ir": "pybuda",
            "name": "transpose_1547",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1547
        },
        "transpose_1548": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1549"
            ],
            "ir": "pybuda",
            "name": "transpose_1548",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1548
        },
        "transpose_1554": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1555"
            ],
            "ir": "pybuda",
            "name": "transpose_1554",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1554
        },
        "transpose_1555": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1555",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1554"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1555
        },
        "transpose_1556": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1557"
            ],
            "ir": "pybuda",
            "name": "transpose_1556",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1048"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1556
        },
        "transpose_1557": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1557",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1556"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1557
        },
        "transpose_1558": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1559"
            ],
            "ir": "pybuda",
            "name": "transpose_1558",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1558
        },
        "transpose_1559": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1559",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1559
        },
        "transpose_1567": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1568"
            ],
            "ir": "pybuda",
            "name": "transpose_1567",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1036"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1567
        },
        "transpose_1568": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.6.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1568",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1568
        },
        "transpose_1569": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1570"
            ],
            "ir": "pybuda",
            "name": "transpose_1569",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1029"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1569
        },
        "transpose_1570": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1570",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1570
        },
        "transpose_1572": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1573"
            ],
            "ir": "pybuda",
            "name": "transpose_1572",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1572
        },
        "transpose_1573": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1574"
            ],
            "ir": "pybuda",
            "name": "transpose_1573",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9f3360), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1573
        },
        "transpose_1574": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1575"
            ],
            "ir": "pybuda",
            "name": "transpose_1574",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1573"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1574
        },
        "transpose_1580": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1581"
            ],
            "ir": "pybuda",
            "name": "transpose_1580",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1580
        },
        "transpose_1581": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1581",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1580"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1581
        },
        "transpose_1584": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1585"
            ],
            "ir": "pybuda",
            "name": "transpose_1584",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1583"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1584
        },
        "transpose_1585": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1586"
            ],
            "ir": "pybuda",
            "name": "transpose_1585",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1584"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1585
        },
        "transpose_1591": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1592"
            ],
            "ir": "pybuda",
            "name": "transpose_1591",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1591
        },
        "transpose_1592": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1592",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1592
        },
        "transpose_1593": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1594"
            ],
            "ir": "pybuda",
            "name": "transpose_1593",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1011"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1593
        },
        "transpose_1594": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1594",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1594
        },
        "transpose_1595": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1596"
            ],
            "ir": "pybuda",
            "name": "transpose_1595",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1595
        },
        "transpose_1596": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1596",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1595"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1596
        },
        "transpose_1604": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1605"
            ],
            "ir": "pybuda",
            "name": "transpose_1604",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1604
        },
        "transpose_1605": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.7.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1605",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1604"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1605
        },
        "transpose_1606": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1607"
            ],
            "ir": "pybuda",
            "name": "transpose_1606",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_992"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1606
        },
        "transpose_1607": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1607",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1607
        },
        "transpose_1609": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1610"
            ],
            "ir": "pybuda",
            "name": "transpose_1609",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1609
        },
        "transpose_1610": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1611"
            ],
            "ir": "pybuda",
            "name": "transpose_1610",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a44ea40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1610
        },
        "transpose_1611": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1612"
            ],
            "ir": "pybuda",
            "name": "transpose_1611",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1611
        },
        "transpose_1617": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1618"
            ],
            "ir": "pybuda",
            "name": "transpose_1617",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1617
        },
        "transpose_1618": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1618",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1618
        },
        "transpose_1621": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1622"
            ],
            "ir": "pybuda",
            "name": "transpose_1621",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1620"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1621
        },
        "transpose_1622": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1623"
            ],
            "ir": "pybuda",
            "name": "transpose_1622",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1621"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1622
        },
        "transpose_1628": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1629"
            ],
            "ir": "pybuda",
            "name": "transpose_1628",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1628
        },
        "transpose_1629": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1629",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1629
        },
        "transpose_1630": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1631"
            ],
            "ir": "pybuda",
            "name": "transpose_1630",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1630
        },
        "transpose_1631": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1631",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1631
        },
        "transpose_1632": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1633"
            ],
            "ir": "pybuda",
            "name": "transpose_1632",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1632
        },
        "transpose_1633": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1633",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1632"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1633
        },
        "transpose_1641": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1642"
            ],
            "ir": "pybuda",
            "name": "transpose_1641",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_962"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1641
        },
        "transpose_1642": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.8.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1642",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1642
        },
        "transpose_1643": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1644"
            ],
            "ir": "pybuda",
            "name": "transpose_1643",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_955"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1643
        },
        "transpose_1644": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1644",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1643"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1644
        },
        "transpose_1646": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1647"
            ],
            "ir": "pybuda",
            "name": "transpose_1646",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1646
        },
        "transpose_1647": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1648"
            ],
            "ir": "pybuda",
            "name": "transpose_1647",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c07ac0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1647
        },
        "transpose_1648": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1649"
            ],
            "ir": "pybuda",
            "name": "transpose_1648",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1648
        },
        "transpose_1654": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1655"
            ],
            "ir": "pybuda",
            "name": "transpose_1654",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1654
        },
        "transpose_1655": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1655",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1655
        },
        "transpose_1658": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1659"
            ],
            "ir": "pybuda",
            "name": "transpose_1658",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1657"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1658
        },
        "transpose_1659": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1660"
            ],
            "ir": "pybuda",
            "name": "transpose_1659",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1658"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1659
        },
        "transpose_1665": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1666"
            ],
            "ir": "pybuda",
            "name": "transpose_1665",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1665
        },
        "transpose_1666": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1666",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1666
        },
        "transpose_1667": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1668"
            ],
            "ir": "pybuda",
            "name": "transpose_1667",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1667
        },
        "transpose_1668": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1668",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1667"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1668
        },
        "transpose_1669": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1670"
            ],
            "ir": "pybuda",
            "name": "transpose_1669",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1669
        },
        "transpose_1670": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1670",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1670
        },
        "transpose_1678": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1679"
            ],
            "ir": "pybuda",
            "name": "transpose_1678",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1678
        },
        "transpose_1679": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.9.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1679",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1679
        },
        "transpose_1680": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1681"
            ],
            "ir": "pybuda",
            "name": "transpose_1680",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1680
        },
        "transpose_1681": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1681",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1681
        },
        "transpose_1683": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1684"
            ],
            "ir": "pybuda",
            "name": "transpose_1683",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1683
        },
        "transpose_1684": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1685"
            ],
            "ir": "pybuda",
            "name": "transpose_1684",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364ddd30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1684
        },
        "transpose_1685": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1686"
            ],
            "ir": "pybuda",
            "name": "transpose_1685",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1685
        },
        "transpose_1691": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1692"
            ],
            "ir": "pybuda",
            "name": "transpose_1691",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1691
        },
        "transpose_1692": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1692",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1691"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1692
        },
        "transpose_1695": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1696"
            ],
            "ir": "pybuda",
            "name": "transpose_1695",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1695
        },
        "transpose_1696": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1697"
            ],
            "ir": "pybuda",
            "name": "transpose_1696",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1696
        },
        "transpose_1702": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1703"
            ],
            "ir": "pybuda",
            "name": "transpose_1702",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1702
        },
        "transpose_1703": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1703",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1703
        },
        "transpose_1704": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1705"
            ],
            "ir": "pybuda",
            "name": "transpose_1704",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1704
        },
        "transpose_1705": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1705",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1704"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1705
        },
        "transpose_1706": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1707"
            ],
            "ir": "pybuda",
            "name": "transpose_1706",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_893"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1706
        },
        "transpose_1707": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1707",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1706"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1707
        },
        "transpose_1715": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1716"
            ],
            "ir": "pybuda",
            "name": "transpose_1715",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1715
        },
        "transpose_1716": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.10.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1716",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1716
        },
        "transpose_1717": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1718"
            ],
            "ir": "pybuda",
            "name": "transpose_1717",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1717
        },
        "transpose_1718": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1718",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1718
        },
        "transpose_1720": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1721"
            ],
            "ir": "pybuda",
            "name": "transpose_1720",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1719"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1720
        },
        "transpose_1721": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1722"
            ],
            "ir": "pybuda",
            "name": "transpose_1721",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b87670), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1721
        },
        "transpose_1722": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1723"
            ],
            "ir": "pybuda",
            "name": "transpose_1722",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1721"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1722
        },
        "transpose_1728": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1729"
            ],
            "ir": "pybuda",
            "name": "transpose_1728",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1728
        },
        "transpose_1729": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1729",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1728"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1729
        },
        "transpose_1732": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1733"
            ],
            "ir": "pybuda",
            "name": "transpose_1732",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1732
        },
        "transpose_1733": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1734"
            ],
            "ir": "pybuda",
            "name": "transpose_1733",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1733
        },
        "transpose_1739": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1740"
            ],
            "ir": "pybuda",
            "name": "transpose_1739",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1739
        },
        "transpose_1740": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1740",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1740
        },
        "transpose_1741": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1742"
            ],
            "ir": "pybuda",
            "name": "transpose_1741",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1741
        },
        "transpose_1742": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1742",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1741"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1742
        },
        "transpose_1743": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1744"
            ],
            "ir": "pybuda",
            "name": "transpose_1743",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_856"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1743
        },
        "transpose_1744": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1744",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1743"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1744
        },
        "transpose_1752": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1753"
            ],
            "ir": "pybuda",
            "name": "transpose_1752",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_851"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1752
        },
        "transpose_1753": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.11.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1753",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1753
        },
        "transpose_1754": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1755"
            ],
            "ir": "pybuda",
            "name": "transpose_1754",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_844"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1754
        },
        "transpose_1755": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1755",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1755
        },
        "transpose_1757": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1758"
            ],
            "ir": "pybuda",
            "name": "transpose_1757",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1757
        },
        "transpose_1758": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1759"
            ],
            "ir": "pybuda",
            "name": "transpose_1758",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9aef10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1758
        },
        "transpose_1759": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1760"
            ],
            "ir": "pybuda",
            "name": "transpose_1759",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1758"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1759
        },
        "transpose_1765": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1766"
            ],
            "ir": "pybuda",
            "name": "transpose_1765",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1765
        },
        "transpose_1766": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1766",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1765"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1766
        },
        "transpose_1769": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1770"
            ],
            "ir": "pybuda",
            "name": "transpose_1769",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1769
        },
        "transpose_1770": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1771"
            ],
            "ir": "pybuda",
            "name": "transpose_1770",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1769"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1770
        },
        "transpose_1776": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1777"
            ],
            "ir": "pybuda",
            "name": "transpose_1776",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1776
        },
        "transpose_1777": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1777",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1776"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1777
        },
        "transpose_1778": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1779"
            ],
            "ir": "pybuda",
            "name": "transpose_1778",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1778
        },
        "transpose_1779": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1779",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1779
        },
        "transpose_1780": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1781"
            ],
            "ir": "pybuda",
            "name": "transpose_1780",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1780
        },
        "transpose_1781": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1781",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1781
        },
        "transpose_1789": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1790"
            ],
            "ir": "pybuda",
            "name": "transpose_1789",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_814"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1789
        },
        "transpose_1790": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.12.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1790",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1789"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1790
        },
        "transpose_1791": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1792"
            ],
            "ir": "pybuda",
            "name": "transpose_1791",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_807"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1791
        },
        "transpose_1792": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1792",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1792
        },
        "transpose_1794": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1795"
            ],
            "ir": "pybuda",
            "name": "transpose_1794",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1793"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1794
        },
        "transpose_1795": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1796"
            ],
            "ir": "pybuda",
            "name": "transpose_1795",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1794"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7458b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1795
        },
        "transpose_1796": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1797"
            ],
            "ir": "pybuda",
            "name": "transpose_1796",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1795"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1796
        },
        "transpose_1802": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1803"
            ],
            "ir": "pybuda",
            "name": "transpose_1802",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1800"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1802
        },
        "transpose_1803": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1803",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1802"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1803
        },
        "transpose_1806": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1807"
            ],
            "ir": "pybuda",
            "name": "transpose_1806",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1805"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1806
        },
        "transpose_1807": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1808"
            ],
            "ir": "pybuda",
            "name": "transpose_1807",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1806"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1807
        },
        "transpose_1813": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1814"
            ],
            "ir": "pybuda",
            "name": "transpose_1813",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1811"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1813
        },
        "transpose_1814": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1814",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1814
        },
        "transpose_1815": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1816"
            ],
            "ir": "pybuda",
            "name": "transpose_1815",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_789"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1815
        },
        "transpose_1816": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1816",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1815"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1816
        },
        "transpose_1817": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1818"
            ],
            "ir": "pybuda",
            "name": "transpose_1817",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_782"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1817
        },
        "transpose_1818": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1818",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1817"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1818
        },
        "transpose_1826": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1827"
            ],
            "ir": "pybuda",
            "name": "transpose_1826",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_777"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1826
        },
        "transpose_1827": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.13.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1827",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1827
        },
        "transpose_1828": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1829"
            ],
            "ir": "pybuda",
            "name": "transpose_1828",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1828
        },
        "transpose_1829": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1829",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1828"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1829
        },
        "transpose_1831": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1832"
            ],
            "ir": "pybuda",
            "name": "transpose_1831",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1830"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1831
        },
        "transpose_1832": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1833"
            ],
            "ir": "pybuda",
            "name": "transpose_1832",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3643b8a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1832
        },
        "transpose_1833": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1834"
            ],
            "ir": "pybuda",
            "name": "transpose_1833",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1832"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1833
        },
        "transpose_1839": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1840"
            ],
            "ir": "pybuda",
            "name": "transpose_1839",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1837"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1839
        },
        "transpose_1840": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1840",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1840
        },
        "transpose_1843": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1844"
            ],
            "ir": "pybuda",
            "name": "transpose_1843",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1842"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1843
        },
        "transpose_1844": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1845"
            ],
            "ir": "pybuda",
            "name": "transpose_1844",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1843"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1844
        },
        "transpose_1850": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1851"
            ],
            "ir": "pybuda",
            "name": "transpose_1850",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1848"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1850
        },
        "transpose_1851": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1851",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1851
        },
        "transpose_1852": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1853"
            ],
            "ir": "pybuda",
            "name": "transpose_1852",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1852
        },
        "transpose_1853": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1853",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1852"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1853
        },
        "transpose_1854": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1855"
            ],
            "ir": "pybuda",
            "name": "transpose_1854",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_745"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1854
        },
        "transpose_1855": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1855",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1855
        },
        "transpose_1863": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1864"
            ],
            "ir": "pybuda",
            "name": "transpose_1863",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_740"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1863
        },
        "transpose_1864": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.14.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1864",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1864
        },
        "transpose_1865": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1866"
            ],
            "ir": "pybuda",
            "name": "transpose_1865",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1865
        },
        "transpose_1866": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1866",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1865"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1866
        },
        "transpose_1868": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1869"
            ],
            "ir": "pybuda",
            "name": "transpose_1868",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1868
        },
        "transpose_1869": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1870"
            ],
            "ir": "pybuda",
            "name": "transpose_1869",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1868"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf753f70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1869
        },
        "transpose_1870": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1871"
            ],
            "ir": "pybuda",
            "name": "transpose_1870",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1869"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1870
        },
        "transpose_1876": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1877"
            ],
            "ir": "pybuda",
            "name": "transpose_1876",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1876
        },
        "transpose_1877": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1877",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1876"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1877
        },
        "transpose_1880": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1881"
            ],
            "ir": "pybuda",
            "name": "transpose_1880",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1880
        },
        "transpose_1881": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1882"
            ],
            "ir": "pybuda",
            "name": "transpose_1881",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1881
        },
        "transpose_1887": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1888"
            ],
            "ir": "pybuda",
            "name": "transpose_1887",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1885"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1887
        },
        "transpose_1888": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1888",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1887"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1888
        },
        "transpose_1889": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1890"
            ],
            "ir": "pybuda",
            "name": "transpose_1889",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1889
        },
        "transpose_1890": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1890",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1889"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1890
        },
        "transpose_1891": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1892"
            ],
            "ir": "pybuda",
            "name": "transpose_1891",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1891
        },
        "transpose_1892": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1892",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1891"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1892
        },
        "transpose_1900": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1901"
            ],
            "ir": "pybuda",
            "name": "transpose_1900",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_703"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1900
        },
        "transpose_1901": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.15.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1901",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1901
        },
        "transpose_1902": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1903"
            ],
            "ir": "pybuda",
            "name": "transpose_1902",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1902
        },
        "transpose_1903": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1903",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1902"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1903
        },
        "transpose_1905": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1906"
            ],
            "ir": "pybuda",
            "name": "transpose_1905",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1904"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1905
        },
        "transpose_1906": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1907"
            ],
            "ir": "pybuda",
            "name": "transpose_1906",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1905"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x280000a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1906
        },
        "transpose_1907": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1908"
            ],
            "ir": "pybuda",
            "name": "transpose_1907",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1906"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1907
        },
        "transpose_1913": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1914"
            ],
            "ir": "pybuda",
            "name": "transpose_1913",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1913
        },
        "transpose_1914": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1914",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1913"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1914
        },
        "transpose_1917": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1918"
            ],
            "ir": "pybuda",
            "name": "transpose_1917",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1916"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1917
        },
        "transpose_1918": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1919"
            ],
            "ir": "pybuda",
            "name": "transpose_1918",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1917"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1918
        },
        "transpose_1924": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1925"
            ],
            "ir": "pybuda",
            "name": "transpose_1924",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1924
        },
        "transpose_1925": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1925",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1925
        },
        "transpose_1926": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1927"
            ],
            "ir": "pybuda",
            "name": "transpose_1926",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1926
        },
        "transpose_1927": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1927",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1926"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1927
        },
        "transpose_1928": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1929"
            ],
            "ir": "pybuda",
            "name": "transpose_1928",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1928
        },
        "transpose_1929": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1929",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1928"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1929
        },
        "transpose_1937": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1938"
            ],
            "ir": "pybuda",
            "name": "transpose_1937",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_666"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1937
        },
        "transpose_1938": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.16.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1938",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1937"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1938
        },
        "transpose_1939": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1940"
            ],
            "ir": "pybuda",
            "name": "transpose_1939",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_659"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1939
        },
        "transpose_1940": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1940",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1939"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1940
        },
        "transpose_1942": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1943"
            ],
            "ir": "pybuda",
            "name": "transpose_1942",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1941"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1942
        },
        "transpose_1943": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1944"
            ],
            "ir": "pybuda",
            "name": "transpose_1943",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28029d70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1943
        },
        "transpose_1944": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1945"
            ],
            "ir": "pybuda",
            "name": "transpose_1944",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1943"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1944
        },
        "transpose_1950": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1951"
            ],
            "ir": "pybuda",
            "name": "transpose_1950",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1950
        },
        "transpose_1951": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1951",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1950"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1951
        },
        "transpose_1954": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1955"
            ],
            "ir": "pybuda",
            "name": "transpose_1954",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1954
        },
        "transpose_1955": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1956"
            ],
            "ir": "pybuda",
            "name": "transpose_1955",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1954"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1955
        },
        "transpose_1961": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1962"
            ],
            "ir": "pybuda",
            "name": "transpose_1961",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1961
        },
        "transpose_1962": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1962",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1961"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1962
        },
        "transpose_1963": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1964"
            ],
            "ir": "pybuda",
            "name": "transpose_1963",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1963
        },
        "transpose_1964": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1964",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1964
        },
        "transpose_1965": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1966"
            ],
            "ir": "pybuda",
            "name": "transpose_1965",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1965
        },
        "transpose_1966": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1966",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1965"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1966
        },
        "transpose_1974": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1975"
            ],
            "ir": "pybuda",
            "name": "transpose_1974",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1974
        },
        "transpose_1975": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.17.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1975",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1975
        },
        "transpose_1976": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1977"
            ],
            "ir": "pybuda",
            "name": "transpose_1976",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1976
        },
        "transpose_1977": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1977",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1976"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1977
        },
        "transpose_1979": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1980"
            ],
            "ir": "pybuda",
            "name": "transpose_1979",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1978"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1979
        },
        "transpose_1980": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1981"
            ],
            "ir": "pybuda",
            "name": "transpose_1980",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1979"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2800f560), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1980
        },
        "transpose_1981": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1982"
            ],
            "ir": "pybuda",
            "name": "transpose_1981",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1980"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1981
        },
        "transpose_1987": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1988"
            ],
            "ir": "pybuda",
            "name": "transpose_1987",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1987
        },
        "transpose_1988": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1988",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1988
        },
        "transpose_1991": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1992"
            ],
            "ir": "pybuda",
            "name": "transpose_1991",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1990"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1991
        },
        "transpose_1992": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1993"
            ],
            "ir": "pybuda",
            "name": "transpose_1992",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1991"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1992
        },
        "transpose_1998": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1999"
            ],
            "ir": "pybuda",
            "name": "transpose_1998",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1998
        },
        "transpose_1999": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_1999",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1998"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1999
        },
        "transpose_2000": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2001"
            ],
            "ir": "pybuda",
            "name": "transpose_2000",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_604"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2000
        },
        "transpose_2001": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2001",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2000"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2001
        },
        "transpose_2002": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2003"
            ],
            "ir": "pybuda",
            "name": "transpose_2002",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_597"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2002
        },
        "transpose_2003": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2003",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2003
        },
        "transpose_2011": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2012"
            ],
            "ir": "pybuda",
            "name": "transpose_2011",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2011
        },
        "transpose_2012": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.18.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2012",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2011"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2012
        },
        "transpose_2013": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2014"
            ],
            "ir": "pybuda",
            "name": "transpose_2013",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2013
        },
        "transpose_2014": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2014",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2013"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2014
        },
        "transpose_2016": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2017"
            ],
            "ir": "pybuda",
            "name": "transpose_2016",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2015"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2016
        },
        "transpose_2017": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2018"
            ],
            "ir": "pybuda",
            "name": "transpose_2017",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2016"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7ddcd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2017
        },
        "transpose_2018": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2019"
            ],
            "ir": "pybuda",
            "name": "transpose_2018",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2017"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2018
        },
        "transpose_2024": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2025"
            ],
            "ir": "pybuda",
            "name": "transpose_2024",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2022"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2024
        },
        "transpose_2025": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2025",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2024"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2025
        },
        "transpose_2028": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2029"
            ],
            "ir": "pybuda",
            "name": "transpose_2028",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2027"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2028
        },
        "transpose_2029": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2030"
            ],
            "ir": "pybuda",
            "name": "transpose_2029",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2028"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2029
        },
        "transpose_2035": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2036"
            ],
            "ir": "pybuda",
            "name": "transpose_2035",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2033"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2035
        },
        "transpose_2036": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2036",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2036
        },
        "transpose_2037": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2038"
            ],
            "ir": "pybuda",
            "name": "transpose_2037",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2037
        },
        "transpose_2038": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2038",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2037"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2038
        },
        "transpose_2039": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2040"
            ],
            "ir": "pybuda",
            "name": "transpose_2039",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2039
        },
        "transpose_2040": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2040",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2039"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2040
        },
        "transpose_2048": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2049"
            ],
            "ir": "pybuda",
            "name": "transpose_2048",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_555"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2048
        },
        "transpose_2049": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.19.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2049",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2048"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2049
        },
        "transpose_2050": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2051"
            ],
            "ir": "pybuda",
            "name": "transpose_2050",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_548"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2050
        },
        "transpose_2051": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2051",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2050"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2051
        },
        "transpose_2053": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2054"
            ],
            "ir": "pybuda",
            "name": "transpose_2053",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2052"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2053
        },
        "transpose_2054": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2055"
            ],
            "ir": "pybuda",
            "name": "transpose_2054",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2053"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15042810), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2054
        },
        "transpose_2055": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2056"
            ],
            "ir": "pybuda",
            "name": "transpose_2055",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2054"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2055
        },
        "transpose_2061": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2062"
            ],
            "ir": "pybuda",
            "name": "transpose_2061",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2061
        },
        "transpose_2062": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2062",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2061"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2062
        },
        "transpose_2065": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2066"
            ],
            "ir": "pybuda",
            "name": "transpose_2065",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2064"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2065
        },
        "transpose_2066": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2067"
            ],
            "ir": "pybuda",
            "name": "transpose_2066",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2065"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2066
        },
        "transpose_2072": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2073"
            ],
            "ir": "pybuda",
            "name": "transpose_2072",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2072
        },
        "transpose_2073": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2073",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2072"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2073
        },
        "transpose_2074": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2075"
            ],
            "ir": "pybuda",
            "name": "transpose_2074",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2074
        },
        "transpose_2075": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2075",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2074"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2075
        },
        "transpose_2076": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2077"
            ],
            "ir": "pybuda",
            "name": "transpose_2076",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2076
        },
        "transpose_2077": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2077",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2076"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2077
        },
        "transpose_2085": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2086"
            ],
            "ir": "pybuda",
            "name": "transpose_2085",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2085
        },
        "transpose_2086": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.20.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2086",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2085"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2086
        },
        "transpose_2087": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2088"
            ],
            "ir": "pybuda",
            "name": "transpose_2087",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2087
        },
        "transpose_2088": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2088",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2087"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2088
        },
        "transpose_2090": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2091"
            ],
            "ir": "pybuda",
            "name": "transpose_2090",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2089"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2090
        },
        "transpose_2091": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2092"
            ],
            "ir": "pybuda",
            "name": "transpose_2091",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2090"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x1508cdd0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2091
        },
        "transpose_2092": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2093"
            ],
            "ir": "pybuda",
            "name": "transpose_2092",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2091"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2092
        },
        "transpose_2098": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2099"
            ],
            "ir": "pybuda",
            "name": "transpose_2098",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2098
        },
        "transpose_2099": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2099",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2098"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2099
        },
        "transpose_2102": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2103"
            ],
            "ir": "pybuda",
            "name": "transpose_2102",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2101"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2102
        },
        "transpose_2103": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2104"
            ],
            "ir": "pybuda",
            "name": "transpose_2103",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2102"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2103
        },
        "transpose_2109": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2110"
            ],
            "ir": "pybuda",
            "name": "transpose_2109",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2109
        },
        "transpose_2110": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2110",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2109"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2110
        },
        "transpose_2111": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2112"
            ],
            "ir": "pybuda",
            "name": "transpose_2111",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2111
        },
        "transpose_2112": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2112",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2111"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2112
        },
        "transpose_2113": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2114"
            ],
            "ir": "pybuda",
            "name": "transpose_2113",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2113
        },
        "transpose_2114": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2114",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2113"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2114
        },
        "transpose_2122": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2123"
            ],
            "ir": "pybuda",
            "name": "transpose_2122",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2122
        },
        "transpose_2123": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.21.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2123",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2123
        },
        "transpose_2124": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2125"
            ],
            "ir": "pybuda",
            "name": "transpose_2124",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2124
        },
        "transpose_2125": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2125",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2124"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2125
        },
        "transpose_2127": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2128"
            ],
            "ir": "pybuda",
            "name": "transpose_2127",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2127
        },
        "transpose_2128": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2129"
            ],
            "ir": "pybuda",
            "name": "transpose_2128",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150376e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2128
        },
        "transpose_2129": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2130"
            ],
            "ir": "pybuda",
            "name": "transpose_2129",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2128"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2129
        },
        "transpose_2135": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2136"
            ],
            "ir": "pybuda",
            "name": "transpose_2135",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2133"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2135
        },
        "transpose_2136": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2136",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2135"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2136
        },
        "transpose_2139": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2140"
            ],
            "ir": "pybuda",
            "name": "transpose_2139",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2138"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2139
        },
        "transpose_2140": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2141"
            ],
            "ir": "pybuda",
            "name": "transpose_2140",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2139"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2140
        },
        "transpose_2146": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2147"
            ],
            "ir": "pybuda",
            "name": "transpose_2146",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2144"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2146
        },
        "transpose_2147": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2147",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2146"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2147
        },
        "transpose_2148": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2149"
            ],
            "ir": "pybuda",
            "name": "transpose_2148",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2148
        },
        "transpose_2149": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2149",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2148"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2149
        },
        "transpose_2150": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2151"
            ],
            "ir": "pybuda",
            "name": "transpose_2150",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2150
        },
        "transpose_2151": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2151",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2151
        },
        "transpose_2159": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2160"
            ],
            "ir": "pybuda",
            "name": "transpose_2159",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2159
        },
        "transpose_2160": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.22.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2160",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2159"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2160
        },
        "transpose_2161": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2162"
            ],
            "ir": "pybuda",
            "name": "transpose_2161",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_437"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2161
        },
        "transpose_2162": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2162",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2161"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2162
        },
        "transpose_2164": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2165"
            ],
            "ir": "pybuda",
            "name": "transpose_2164",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2163"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2164
        },
        "transpose_2165": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2166"
            ],
            "ir": "pybuda",
            "name": "transpose_2165",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2164"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::transpose, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37bd65b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2165
        },
        "transpose_2166": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2167"
            ],
            "ir": "pybuda",
            "name": "transpose_2166",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2165"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2166
        },
        "transpose_2172": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2173"
            ],
            "ir": "pybuda",
            "name": "transpose_2172",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2170"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2172
        },
        "transpose_2173": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2173",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2172"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2173
        },
        "transpose_2176": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2177"
            ],
            "ir": "pybuda",
            "name": "transpose_2176",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_2175"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2176
        },
        "transpose_2177": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_2178"
            ],
            "ir": "pybuda",
            "name": "transpose_2177",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2176"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2177
        },
        "transpose_2183": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2184"
            ],
            "ir": "pybuda",
            "name": "transpose_2183",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_2181"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2183
        },
        "transpose_2184": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2184",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2183"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2184
        },
        "transpose_2185": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2186"
            ],
            "ir": "pybuda",
            "name": "transpose_2185",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2185
        },
        "transpose_2186": {
            "cache": {
                "shape": [
                    1024,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2186",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2185"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2186
        },
        "transpose_2187": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2188"
            ],
            "ir": "pybuda",
            "name": "transpose_2187",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2187
        },
        "transpose_2188": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2188",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2187"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2188
        },
        "transpose_2196": {
            "cache": {
                "shape": [
                    1024,
                    4096
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2197"
            ],
            "ir": "pybuda",
            "name": "transpose_2196",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2196
        },
        "transpose_2197": {
            "cache": {
                "shape": [
                    4096,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "bert.encoder.layer.23.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2197",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2196"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2197
        },
        "transpose_2198": {
            "cache": {
                "shape": [
                    2,
                    1024
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_2199"
            ],
            "ir": "pybuda",
            "name": "transpose_2198",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2198
        },
        "transpose_2199": {
            "cache": {
                "shape": [
                    1024,
                    2
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "transpose_2199",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_2198"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 2199
        },
        "transpose_422": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_423"
            ],
            "ir": "pybuda",
            "name": "transpose_422",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 422
        },
        "transpose_433": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_434"
            ],
            "ir": "pybuda",
            "name": "transpose_433",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 433
        },
        "transpose_459": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_460"
            ],
            "ir": "pybuda",
            "name": "transpose_459",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_458"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 459
        },
        "transpose_470": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_471"
            ],
            "ir": "pybuda",
            "name": "transpose_470",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 470
        },
        "transpose_496": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_497"
            ],
            "ir": "pybuda",
            "name": "transpose_496",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 496
        },
        "transpose_507": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_508"
            ],
            "ir": "pybuda",
            "name": "transpose_507",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 507
        },
        "transpose_533": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_534"
            ],
            "ir": "pybuda",
            "name": "transpose_533",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 533
        },
        "transpose_544": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_545"
            ],
            "ir": "pybuda",
            "name": "transpose_544",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 544
        },
        "transpose_570": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_571"
            ],
            "ir": "pybuda",
            "name": "transpose_570",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 570
        },
        "transpose_581": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_582"
            ],
            "ir": "pybuda",
            "name": "transpose_581",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_580"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 581
        },
        "transpose_607": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_608"
            ],
            "ir": "pybuda",
            "name": "transpose_607",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 607
        },
        "transpose_618": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_619"
            ],
            "ir": "pybuda",
            "name": "transpose_618",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 618
        },
        "transpose_644": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_645"
            ],
            "ir": "pybuda",
            "name": "transpose_644",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_643"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 644
        },
        "transpose_655": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_656"
            ],
            "ir": "pybuda",
            "name": "transpose_655",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 655
        },
        "transpose_681": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_682"
            ],
            "ir": "pybuda",
            "name": "transpose_681",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 681
        },
        "transpose_692": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_693"
            ],
            "ir": "pybuda",
            "name": "transpose_692",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_691"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 692
        },
        "transpose_718": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_719"
            ],
            "ir": "pybuda",
            "name": "transpose_718",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 718
        },
        "transpose_729": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_730"
            ],
            "ir": "pybuda",
            "name": "transpose_729",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_728"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 729
        },
        "transpose_755": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_756"
            ],
            "ir": "pybuda",
            "name": "transpose_755",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 755
        },
        "transpose_766": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_767"
            ],
            "ir": "pybuda",
            "name": "transpose_766",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_765"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 766
        },
        "transpose_792": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_793"
            ],
            "ir": "pybuda",
            "name": "transpose_792",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 792
        },
        "transpose_803": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_804"
            ],
            "ir": "pybuda",
            "name": "transpose_803",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_802"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 803
        },
        "transpose_829": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_830"
            ],
            "ir": "pybuda",
            "name": "transpose_829",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_828"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 829
        },
        "transpose_840": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_841"
            ],
            "ir": "pybuda",
            "name": "transpose_840",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 840
        },
        "transpose_866": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_867"
            ],
            "ir": "pybuda",
            "name": "transpose_866",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_865"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 866
        },
        "transpose_877": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_878"
            ],
            "ir": "pybuda",
            "name": "transpose_877",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_876"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 877
        },
        "transpose_903": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_904"
            ],
            "ir": "pybuda",
            "name": "transpose_903",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_902"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 903
        },
        "transpose_914": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_915"
            ],
            "ir": "pybuda",
            "name": "transpose_914",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_913"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 914
        },
        "transpose_940": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_941"
            ],
            "ir": "pybuda",
            "name": "transpose_940",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_939"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 940
        },
        "transpose_951": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_952"
            ],
            "ir": "pybuda",
            "name": "transpose_951",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_950"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 951
        },
        "transpose_977": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_978"
            ],
            "ir": "pybuda",
            "name": "transpose_977",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_976"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 977
        },
        "transpose_988": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_989"
            ],
            "ir": "pybuda",
            "name": "transpose_988",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 988
        },
        "tuple_395": {
            "cache": {
                "shape": [
                    [
                        "1",
                        "384"
                    ],
                    [
                        "1",
                        "384"
                    ]
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "squeeze_396",
                "squeeze_2200"
            ],
            "ir": "pybuda",
            "name": "tuple_395",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 395
        }
    }
}