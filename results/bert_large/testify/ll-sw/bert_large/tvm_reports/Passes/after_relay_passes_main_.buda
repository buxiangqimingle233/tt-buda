{
    "graph": {},
    "nodes": {
        "add_1003": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1004",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1003",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1002"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31ba9a90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1003
        },
        "add_1010": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1011",
                "bert.encoder.layer.7.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1010",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1009"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1010
        },
        "add_1015": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1016",
                "layernorm_1026"
            ],
            "ir": "pybuda",
            "name": "add_1015",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1014"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output, 0x19bb3910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1015
        },
        "add_1017": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1018",
                "bert.encoder.layer.6.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1017",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1016"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1017
        },
        "add_1022": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1023",
                "bert.encoder.layer.6.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1022",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1021",
                "multiply_1428"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1022
        },
        "add_1027": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1028",
                "layernorm_1050"
            ],
            "ir": "pybuda",
            "name": "add_1027",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1026"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a5206a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1027
        },
        "add_1029": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1030",
                "bert.encoder.layer.6.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1029",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1028"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1029
        },
        "add_1039": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1040",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1039",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1038"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a509a40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1039
        },
        "add_1046": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1047",
                "bert.encoder.layer.6.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1046",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1045"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1046
        },
        "add_1051": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1052",
                "layernorm_1062"
            ],
            "ir": "pybuda",
            "name": "add_1051",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1050"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9c3520), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1051
        },
        "add_1053": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1054",
                "bert.encoder.layer.5.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1053",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1052"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1053
        },
        "add_1058": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1059",
                "bert.encoder.layer.5.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1058",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1057",
                "multiply_1407"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1058
        },
        "add_1063": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1064",
                "layernorm_1086"
            ],
            "ir": "pybuda",
            "name": "add_1063",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1062"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a500890), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1063
        },
        "add_1065": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1066",
                "bert.encoder.layer.5.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1065",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1064"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1065
        },
        "add_1075": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1076",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1075",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1074"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91823d90), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1075
        },
        "add_1082": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1083",
                "bert.encoder.layer.5.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1082",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1081"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1082
        },
        "add_1087": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1088",
                "layernorm_1098"
            ],
            "ir": "pybuda",
            "name": "add_1087",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1086"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output, 0x2fb49910), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1087
        },
        "add_1089": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1090",
                "bert.encoder.layer.4.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1089",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1088"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1089
        },
        "add_1094": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1095",
                "bert.encoder.layer.4.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1094",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1093",
                "multiply_1386"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1094
        },
        "add_1099": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1100",
                "layernorm_1122"
            ],
            "ir": "pybuda",
            "name": "add_1099",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1098"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a45ddb0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1099
        },
        "add_1101": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1102",
                "bert.encoder.layer.4.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1101",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1100"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1101
        },
        "add_1111": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1112",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1111",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1110"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4890c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1111
        },
        "add_1118": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1119",
                "bert.encoder.layer.4.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1118",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1117"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1118
        },
        "add_1123": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1124",
                "layernorm_1134"
            ],
            "ir": "pybuda",
            "name": "add_1123",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1122"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output, 0x8ab077c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1123
        },
        "add_1125": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1126",
                "bert.encoder.layer.3.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1125",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1124"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1125
        },
        "add_1130": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1131",
                "bert.encoder.layer.3.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1130",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1129",
                "multiply_1365"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1130
        },
        "add_1135": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1136",
                "layernorm_1158"
            ],
            "ir": "pybuda",
            "name": "add_1135",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1134"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba60c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1135
        },
        "add_1137": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1138",
                "bert.encoder.layer.3.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1137",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1136"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1137
        },
        "add_1147": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1148",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1147",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1146"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bbfab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1147
        },
        "add_1154": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1155",
                "bert.encoder.layer.3.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1154",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1153"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1154
        },
        "add_1159": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1160",
                "layernorm_1170"
            ],
            "ir": "pybuda",
            "name": "add_1159",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1158"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output, 0x917a5e00), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1159
        },
        "add_1161": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1162",
                "bert.encoder.layer.2.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1161",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1160"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1161
        },
        "add_1166": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1167",
                "bert.encoder.layer.2.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1166",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1165",
                "multiply_1344"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1166
        },
        "add_1171": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1172",
                "layernorm_1194"
            ],
            "ir": "pybuda",
            "name": "add_1171",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1170"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x19ba7070), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1171
        },
        "add_1173": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1174",
                "bert.encoder.layer.2.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1173",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1172"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1173
        },
        "add_1183": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1184",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1183",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1182"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b5bbd0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1183
        },
        "add_1190": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1191",
                "bert.encoder.layer.2.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1190",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1189"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1190
        },
        "add_1195": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1196",
                "layernorm_1206"
            ],
            "ir": "pybuda",
            "name": "add_1195",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1194"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9be180), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1195
        },
        "add_1197": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1198",
                "bert.encoder.layer.1.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1197",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1196"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1197
        },
        "add_1202": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1203",
                "bert.encoder.layer.1.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1202",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1201",
                "multiply_1323"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1202
        },
        "add_1207": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1208",
                "layernorm_1230"
            ],
            "ir": "pybuda",
            "name": "add_1207",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x8ab53930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1207
        },
        "add_1209": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1210",
                "bert.encoder.layer.1.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1209",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1208"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1209
        },
        "add_1219": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1220",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1219",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1218"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9e4730), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1219
        },
        "add_1226": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1227",
                "bert.encoder.layer.1.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1226",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1225"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1226
        },
        "add_1231": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1232",
                "layernorm_1242"
            ],
            "ir": "pybuda",
            "name": "add_1231",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1230"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output, 0xd950e20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1231
        },
        "add_1233": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1234",
                "bert.encoder.layer.0.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1233",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1232"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1233
        },
        "add_1238": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1239",
                "bert.encoder.layer.0.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1238",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1237",
                "multiply_1302"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1238
        },
        "add_1243": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1244",
                "nn.dropout_1266"
            ],
            "ir": "pybuda",
            "name": "add_1243",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1242"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xd96bf40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1243
        },
        "add_1245": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1246",
                "bert.encoder.layer.0.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_1245",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1244"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1245
        },
        "add_1255": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_1256",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_1255",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_1254"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9182dc30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1255
        },
        "add_1262": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1263",
                "bert.encoder.layer.0.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_1262",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1261"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1262
        },
        "add_1268": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "add_1269",
                "embedding_1274"
            ],
            "ir": "pybuda",
            "name": "add_1268",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_1267"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add_, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x8ab40e80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1268
        },
        "add_1269": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "embedding_1270",
                "embedding_1272"
            ],
            "ir": "pybuda",
            "name": "add_1269",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1268"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x79f6e300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1269
        },
        "add_1280": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1281",
                "bert.encoder.layer.0.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1280",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1279"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1280
        },
        "add_1295": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1296",
                "bert.encoder.layer.0.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1295",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1294"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1295
        },
        "add_1298": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1299",
                "multiply_1300"
            ],
            "ir": "pybuda",
            "name": "add_1298",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1237"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1298
        },
        "add_1308": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1309",
                "bert.encoder.layer.1.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1308",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1307"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1308
        },
        "add_1316": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1317",
                "bert.encoder.layer.1.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1316",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1315"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1316
        },
        "add_1319": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1320",
                "multiply_1321"
            ],
            "ir": "pybuda",
            "name": "add_1319",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1201"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1319
        },
        "add_1329": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1330",
                "bert.encoder.layer.2.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1329",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1328"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1329
        },
        "add_1337": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1338",
                "bert.encoder.layer.2.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1337",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1336"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1337
        },
        "add_1340": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1341",
                "multiply_1342"
            ],
            "ir": "pybuda",
            "name": "add_1340",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1165"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1340
        },
        "add_1350": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1351",
                "bert.encoder.layer.3.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1350",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1349"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1350
        },
        "add_1358": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1359",
                "bert.encoder.layer.3.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1358",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1357"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1358
        },
        "add_1361": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1362",
                "multiply_1363"
            ],
            "ir": "pybuda",
            "name": "add_1361",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1129"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1361
        },
        "add_1371": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1372",
                "bert.encoder.layer.4.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1371",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1370"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1371
        },
        "add_1379": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1380",
                "bert.encoder.layer.4.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1379",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1378"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1379
        },
        "add_1382": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1383",
                "multiply_1384"
            ],
            "ir": "pybuda",
            "name": "add_1382",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1093"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1382
        },
        "add_1392": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1393",
                "bert.encoder.layer.5.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1392",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1391"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1392
        },
        "add_1400": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1401",
                "bert.encoder.layer.5.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1400",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1399"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1400
        },
        "add_1403": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1404",
                "multiply_1405"
            ],
            "ir": "pybuda",
            "name": "add_1403",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1057"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1403
        },
        "add_1413": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1414",
                "bert.encoder.layer.6.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1413",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1412"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1413
        },
        "add_1421": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1422",
                "bert.encoder.layer.6.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1421",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1420"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1421
        },
        "add_1424": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1425",
                "multiply_1426"
            ],
            "ir": "pybuda",
            "name": "add_1424",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1021"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1424
        },
        "add_1434": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1435",
                "bert.encoder.layer.7.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1434",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1433"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1434
        },
        "add_1442": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1443",
                "bert.encoder.layer.7.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1442",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1441"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1442
        },
        "add_1445": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1446",
                "multiply_1447"
            ],
            "ir": "pybuda",
            "name": "add_1445",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_985"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1445
        },
        "add_1455": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1456",
                "bert.encoder.layer.8.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1455",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1454"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1455
        },
        "add_1463": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1464",
                "bert.encoder.layer.8.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1463",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1462"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1463
        },
        "add_1466": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1467",
                "multiply_1468"
            ],
            "ir": "pybuda",
            "name": "add_1466",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_949"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1466
        },
        "add_1476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1477",
                "bert.encoder.layer.9.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1476",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1475"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1476
        },
        "add_1484": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1485",
                "bert.encoder.layer.9.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1484",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1483"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1484
        },
        "add_1487": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1488",
                "multiply_1489"
            ],
            "ir": "pybuda",
            "name": "add_1487",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_913"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1487
        },
        "add_1497": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1498",
                "bert.encoder.layer.10.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1497",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1496"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1497
        },
        "add_1505": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1506",
                "bert.encoder.layer.10.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1505",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1504"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1505
        },
        "add_1508": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1509",
                "multiply_1510"
            ],
            "ir": "pybuda",
            "name": "add_1508",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_877"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1508
        },
        "add_1518": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1519",
                "bert.encoder.layer.11.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1518",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1517"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1518
        },
        "add_1526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1527",
                "bert.encoder.layer.11.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1526",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1525"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1526
        },
        "add_1529": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1530",
                "multiply_1531"
            ],
            "ir": "pybuda",
            "name": "add_1529",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_841"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1529
        },
        "add_1539": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1540",
                "bert.encoder.layer.12.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1539",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1538"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1539
        },
        "add_1547": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1548",
                "bert.encoder.layer.12.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1547",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1546"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1547
        },
        "add_1550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1551",
                "multiply_1552"
            ],
            "ir": "pybuda",
            "name": "add_1550",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_805"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1550
        },
        "add_1560": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1561",
                "bert.encoder.layer.13.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1560",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1559"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1560
        },
        "add_1568": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1569",
                "bert.encoder.layer.13.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1568",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1567"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1568
        },
        "add_1571": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1572",
                "multiply_1573"
            ],
            "ir": "pybuda",
            "name": "add_1571",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_769"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1571
        },
        "add_1581": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1582",
                "bert.encoder.layer.14.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1581",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1580"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1581
        },
        "add_1589": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1590",
                "bert.encoder.layer.14.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1589",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1588"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1589
        },
        "add_1592": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1593",
                "multiply_1594"
            ],
            "ir": "pybuda",
            "name": "add_1592",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1592
        },
        "add_1602": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1603",
                "bert.encoder.layer.15.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1602",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1601"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1602
        },
        "add_1610": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1611",
                "bert.encoder.layer.15.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1610",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1609"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1610
        },
        "add_1613": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1614",
                "multiply_1615"
            ],
            "ir": "pybuda",
            "name": "add_1613",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1613
        },
        "add_1623": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1624",
                "bert.encoder.layer.16.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1623",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1622"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1623
        },
        "add_1631": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1632",
                "bert.encoder.layer.16.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1631",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1630"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1631
        },
        "add_1634": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1635",
                "multiply_1636"
            ],
            "ir": "pybuda",
            "name": "add_1634",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_661"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1634
        },
        "add_1644": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1645",
                "bert.encoder.layer.17.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1644",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1643"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1644
        },
        "add_1652": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1653",
                "bert.encoder.layer.17.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1652",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1651"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1652
        },
        "add_1655": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1656",
                "multiply_1657"
            ],
            "ir": "pybuda",
            "name": "add_1655",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_625"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1655
        },
        "add_1665": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1666",
                "bert.encoder.layer.18.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1665",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1664"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1665
        },
        "add_1673": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1674",
                "bert.encoder.layer.18.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1673",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1672"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1673
        },
        "add_1676": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1677",
                "multiply_1678"
            ],
            "ir": "pybuda",
            "name": "add_1676",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1676
        },
        "add_1686": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1687",
                "bert.encoder.layer.19.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1686",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1685"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1686
        },
        "add_1694": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1695",
                "bert.encoder.layer.19.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1694",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1693"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1694
        },
        "add_1697": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1698",
                "multiply_1699"
            ],
            "ir": "pybuda",
            "name": "add_1697",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1697
        },
        "add_1707": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1708",
                "bert.encoder.layer.20.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1707",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1706"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1707
        },
        "add_1715": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1716",
                "bert.encoder.layer.20.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1715",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1714"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1715
        },
        "add_1718": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1719",
                "multiply_1720"
            ],
            "ir": "pybuda",
            "name": "add_1718",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_517"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1718
        },
        "add_1728": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1729",
                "bert.encoder.layer.21.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1728",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1727"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1728
        },
        "add_1736": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1737",
                "bert.encoder.layer.21.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1736",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1735"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1736
        },
        "add_1739": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1740",
                "multiply_1741"
            ],
            "ir": "pybuda",
            "name": "add_1739",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1739
        },
        "add_1749": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1750",
                "bert.encoder.layer.22.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1749",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1748"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1749
        },
        "add_1757": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1758",
                "bert.encoder.layer.22.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1757",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1756"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1757
        },
        "add_1760": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1761",
                "multiply_1762"
            ],
            "ir": "pybuda",
            "name": "add_1760",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1760
        },
        "add_1770": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1771",
                "bert.encoder.layer.23.attention.self.key.bias"
            ],
            "ir": "pybuda",
            "name": "add_1770",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1769"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1770
        },
        "add_1778": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_1779",
                "bert.encoder.layer.23.attention.self.value.bias"
            ],
            "ir": "pybuda",
            "name": "add_1778",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1777"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 1778
        },
        "add_1781": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "constant_1782",
                "multiply_1783"
            ],
            "ir": "pybuda",
            "name": "add_1781",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_409"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 1781
        },
        "add_398": {
            "cache": {
                "shape": [
                    1,
                    384,
                    2
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_399",
                "qa_outputs.bias"
            ],
            "ir": "pybuda",
            "name": "add_398",
            "opcode": "RelayOp",
            "output_nodes": [
                "split_397",
                "split_397"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 398
        },
        "add_403": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_404",
                "layernorm_414"
            ],
            "ir": "pybuda",
            "name": "add_403",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output, 0x94142930), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 403
        },
        "add_405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_406",
                "bert.encoder.layer.23.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_405",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_404"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 405
        },
        "add_410": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_411",
                "bert.encoder.layer.23.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_410",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_409",
                "multiply_1785"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 410
        },
        "add_415": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_416",
                "layernorm_438"
            ],
            "ir": "pybuda",
            "name": "add_415",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x126d55e0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 415
        },
        "add_417": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_418",
                "bert.encoder.layer.23.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_417",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_416"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 417
        },
        "add_427": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_428",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_427",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94190e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 427
        },
        "add_434": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_435",
                "bert.encoder.layer.23.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_434",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_433"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 434
        },
        "add_439": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_440",
                "layernorm_450"
            ],
            "ir": "pybuda",
            "name": "add_439",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output, 0x126a7350), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 439
        },
        "add_441": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_442",
                "bert.encoder.layer.22.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_441",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_440"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 441
        },
        "add_446": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_447",
                "bert.encoder.layer.22.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_446",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_445",
                "multiply_1764"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 446
        },
        "add_451": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_452",
                "layernorm_474"
            ],
            "ir": "pybuda",
            "name": "add_451",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_450"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x917b0210), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 451
        },
        "add_453": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_454",
                "bert.encoder.layer.22.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_453",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_452"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 453
        },
        "add_463": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_464",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_463",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_462"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f668f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 463
        },
        "add_470": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_471",
                "bert.encoder.layer.22.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_470",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_469"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 470
        },
        "add_475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_476",
                "layernorm_486"
            ],
            "ir": "pybuda",
            "name": "add_475",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output, 0x941d25a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 475
        },
        "add_477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_478",
                "bert.encoder.layer.21.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_477",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_476"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 477
        },
        "add_482": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_483",
                "bert.encoder.layer.21.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_482",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_481",
                "multiply_1743"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 482
        },
        "add_487": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_488",
                "layernorm_510"
            ],
            "ir": "pybuda",
            "name": "add_487",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x94179fa0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 487
        },
        "add_489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_490",
                "bert.encoder.layer.21.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_489",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_488"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 489
        },
        "add_499": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_500",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_499",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126af900), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 499
        },
        "add_506": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_507",
                "bert.encoder.layer.21.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_506",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_505"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 506
        },
        "add_511": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_512",
                "layernorm_522"
            ],
            "ir": "pybuda",
            "name": "add_511",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a445480), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 511
        },
        "add_513": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_514",
                "bert.encoder.layer.20.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_513",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_512"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 513
        },
        "add_518": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_519",
                "bert.encoder.layer.20.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_518",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_517",
                "multiply_1722"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 518
        },
        "add_523": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_524",
                "layernorm_546"
            ],
            "ir": "pybuda",
            "name": "add_523",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf78a620), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 523
        },
        "add_525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_526",
                "bert.encoder.layer.20.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_525",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_524"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 525
        },
        "add_535": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_536",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_535",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_534"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049c80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 535
        },
        "add_542": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_543",
                "bert.encoder.layer.20.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_542",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_541"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 542
        },
        "add_547": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_548",
                "layernorm_558"
            ],
            "ir": "pybuda",
            "name": "add_547",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output, 0xf739860), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 547
        },
        "add_549": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_550",
                "bert.encoder.layer.19.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_549",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_548"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 549
        },
        "add_554": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_555",
                "bert.encoder.layer.19.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_554",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_553",
                "multiply_1701"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 554
        },
        "add_559": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_560",
                "layernorm_582"
            ],
            "ir": "pybuda",
            "name": "add_559",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b39bf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 559
        },
        "add_561": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_562",
                "bert.encoder.layer.19.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_561",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_560"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 561
        },
        "add_571": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_572",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_571",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3652b260), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 571
        },
        "add_578": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_579",
                "bert.encoder.layer.19.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_578",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_577"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 578
        },
        "add_583": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_584",
                "layernorm_594"
            ],
            "ir": "pybuda",
            "name": "add_583",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_582"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output, 0x27f39310), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 583
        },
        "add_585": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_586",
                "bert.encoder.layer.18.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_585",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_584"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 585
        },
        "add_590": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_591",
                "bert.encoder.layer.18.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_590",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_589",
                "multiply_1680"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 590
        },
        "add_595": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_596",
                "layernorm_618"
            ],
            "ir": "pybuda",
            "name": "add_595",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf76bc40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 595
        },
        "add_597": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_598",
                "bert.encoder.layer.18.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_597",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_596"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 597
        },
        "add_607": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_608",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_607",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fecf60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 607
        },
        "add_614": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_615",
                "bert.encoder.layer.18.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_614",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_613"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 614
        },
        "add_619": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_620",
                "layernorm_630"
            ],
            "ir": "pybuda",
            "name": "add_619",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_618"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9d6cf0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 619
        },
        "add_621": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_622",
                "bert.encoder.layer.17.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_621",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_620"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 621
        },
        "add_626": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_627",
                "bert.encoder.layer.17.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_626",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_625",
                "multiply_1659"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 626
        },
        "add_631": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_632",
                "layernorm_654"
            ],
            "ir": "pybuda",
            "name": "add_631",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_630"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x150b3e70), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 631
        },
        "add_633": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_634",
                "bert.encoder.layer.17.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_633",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_632"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 633
        },
        "add_643": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_644",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_643",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_642"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf81bf50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 643
        },
        "add_650": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_651",
                "bert.encoder.layer.17.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_650",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_649"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 650
        },
        "add_655": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_656",
                "layernorm_666"
            ],
            "ir": "pybuda",
            "name": "add_655",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output, 0x3645c290), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 655
        },
        "add_657": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_658",
                "bert.encoder.layer.16.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_657",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_656"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 657
        },
        "add_662": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_663",
                "bert.encoder.layer.16.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_662",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_661",
                "multiply_1638"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 662
        },
        "add_667": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_668",
                "layernorm_690"
            ],
            "ir": "pybuda",
            "name": "add_667",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_666"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x280244f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 667
        },
        "add_669": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_670",
                "bert.encoder.layer.16.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_669",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_668"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 669
        },
        "add_679": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_680",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_679",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3643dac0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 679
        },
        "add_686": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_687",
                "bert.encoder.layer.16.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_686",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_685"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 686
        },
        "add_691": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_692",
                "layernorm_702"
            ],
            "ir": "pybuda",
            "name": "add_691",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_690"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output, 0x27fce810), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 691
        },
        "add_693": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_694",
                "bert.encoder.layer.15.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_693",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_692"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 693
        },
        "add_698": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_699",
                "bert.encoder.layer.15.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_698",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_697",
                "multiply_1617"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 698
        },
        "add_703": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_704",
                "layernorm_726"
            ],
            "ir": "pybuda",
            "name": "add_703",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_702"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x15061a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 703
        },
        "add_705": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_706",
                "bert.encoder.layer.15.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_705",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_704"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 705
        },
        "add_715": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_716",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_715",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_714"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c9850), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 715
        },
        "add_722": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_723",
                "bert.encoder.layer.15.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_722",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_721"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 722
        },
        "add_727": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_728",
                "layernorm_738"
            ],
            "ir": "pybuda",
            "name": "add_727",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output, 0x2a4d73f0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 727
        },
        "add_729": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_730",
                "bert.encoder.layer.14.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_729",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_728"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 729
        },
        "add_734": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_735",
                "bert.encoder.layer.14.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_734",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_733",
                "multiply_1596"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 734
        },
        "add_739": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_740",
                "layernorm_762"
            ],
            "ir": "pybuda",
            "name": "add_739",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x27f42770), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 739
        },
        "add_741": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_742",
                "bert.encoder.layer.14.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_741",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_740"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 741
        },
        "add_751": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_752",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_751",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fa7ca0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 751
        },
        "add_758": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_759",
                "bert.encoder.layer.14.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_758",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_757"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 758
        },
        "add_763": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_764",
                "layernorm_774"
            ],
            "ir": "pybuda",
            "name": "add_763",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e53a0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 763
        },
        "add_765": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_766",
                "bert.encoder.layer.13.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_765",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_764"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 765
        },
        "add_770": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_771",
                "bert.encoder.layer.13.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_770",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_769",
                "multiply_1575"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 770
        },
        "add_775": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_776",
                "layernorm_798"
            ],
            "ir": "pybuda",
            "name": "add_775",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xf826d40), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 775
        },
        "add_777": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_778",
                "bert.encoder.layer.13.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_777",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_776"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 777
        },
        "add_787": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_788",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_787",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_786"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19be8370), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 787
        },
        "add_794": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_795",
                "bert.encoder.layer.13.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_794",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_793"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 794
        },
        "add_799": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_800",
                "layernorm_810"
            ],
            "ir": "pybuda",
            "name": "add_799",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_798"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output, 0x31bc3c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 799
        },
        "add_801": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_802",
                "bert.encoder.layer.12.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_801",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_800"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 801
        },
        "add_806": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_807",
                "bert.encoder.layer.12.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_806",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_805",
                "multiply_1554"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 806
        },
        "add_811": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_812",
                "layernorm_834"
            ],
            "ir": "pybuda",
            "name": "add_811",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_810"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b3d300), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 811
        },
        "add_813": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_814",
                "bert.encoder.layer.12.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_813",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_812"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 813
        },
        "add_823": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_824",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_823",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_822"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824de0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 823
        },
        "add_830": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_831",
                "bert.encoder.layer.12.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_830",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_829"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 830
        },
        "add_835": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_836",
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "add_835",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output, 0xf76f920), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 835
        },
        "add_837": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_838",
                "bert.encoder.layer.11.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_837",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_836"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 837
        },
        "add_842": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_843",
                "bert.encoder.layer.11.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_842",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_841",
                "multiply_1533"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 842
        },
        "add_847": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_848",
                "layernorm_870"
            ],
            "ir": "pybuda",
            "name": "add_847",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x31b40c10), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 847
        },
        "add_849": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_850",
                "bert.encoder.layer.11.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_849",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_848"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 849
        },
        "add_859": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_860",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_859",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_858"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a503c30), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 859
        },
        "add_866": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_867",
                "bert.encoder.layer.11.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_866",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_865"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 866
        },
        "add_871": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_872",
                "layernorm_882"
            ],
            "ir": "pybuda",
            "name": "add_871",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_870"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output, 0xda20c20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 871
        },
        "add_873": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_874",
                "bert.encoder.layer.10.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_873",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_872"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 873
        },
        "add_878": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_879",
                "bert.encoder.layer.10.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_878",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_877",
                "multiply_1512"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 878
        },
        "add_883": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_884",
                "layernorm_906"
            ],
            "ir": "pybuda",
            "name": "add_883",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_882"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a518f60), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 883
        },
        "add_885": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_886",
                "bert.encoder.layer.10.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_885",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_884"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 885
        },
        "add_895": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_896",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_895",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_894"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3648ed50), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 895
        },
        "add_902": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_903",
                "bert.encoder.layer.10.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_902",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_901"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 902
        },
        "add_907": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_908",
                "layernorm_918"
            ],
            "ir": "pybuda",
            "name": "add_907",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_906"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output, 0xd9e4190), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 907
        },
        "add_909": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_910",
                "bert.encoder.layer.9.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_909",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_908"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 909
        },
        "add_914": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_915",
                "bert.encoder.layer.9.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_914",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_913",
                "multiply_1491"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 914
        },
        "add_919": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_920",
                "layernorm_942"
            ],
            "ir": "pybuda",
            "name": "add_919",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a4cfa80), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 919
        },
        "add_921": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_922",
                "bert.encoder.layer.9.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_921",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_920"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 921
        },
        "add_931": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_932",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_931",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_930"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36458280), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 931
        },
        "add_938": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_939",
                "bert.encoder.layer.9.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_938",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_937"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 938
        },
        "add_943": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_944",
                "layernorm_954"
            ],
            "ir": "pybuda",
            "name": "add_943",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_942"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output, 0x36446a20), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 943
        },
        "add_945": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_946",
                "bert.encoder.layer.8.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_945",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_944"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 945
        },
        "add_950": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_951",
                "bert.encoder.layer.8.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_950",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_949",
                "multiply_1470"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 950
        },
        "add_955": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_956",
                "layernorm_978"
            ],
            "ir": "pybuda",
            "name": "add_955",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_954"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0xda20440), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 955
        },
        "add_957": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_958",
                "bert.encoder.layer.8.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_957",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_956"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 957
        },
        "add_967": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "divide_968",
                "multiply_1284"
            ],
            "ir": "pybuda",
            "name": "add_967",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.softmax_966"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b6cff0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 967
        },
        "add_974": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_975",
                "bert.encoder.layer.8.attention.self.query.bias"
            ],
            "ir": "pybuda",
            "name": "add_974",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_973"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 974
        },
        "add_979": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_980",
                "layernorm_990"
            ],
            "ir": "pybuda",
            "name": "add_979",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_978"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output, 0x31b556d0), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 979
        },
        "add_981": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_982",
                "bert.encoder.layer.7.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_981",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_980"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 981
        },
        "add_986": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_987",
                "bert.encoder.layer.7.intermediate.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_986",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_985",
                "multiply_1449"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 986
        },
        "add_991": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_992",
                "layernorm_1014"
            ],
            "ir": "pybuda",
            "name": "add_991",
            "opcode": "RelayOp",
            "output_nodes": [
                "layernorm_990"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::add, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output, 0x2a505020), 0, 0, 0, 0)",
            "type": "add",
            "unique_id": 991
        },
        "add_993": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "add",
            "epoch": 0,
            "input_nodes": [
                "reshape_994",
                "bert.encoder.layer.7.attention.output.dense.bias"
            ],
            "ir": "pybuda",
            "name": "add_993",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_992"
            ],
            "pybuda": 1,
            "span": "None",
            "type": "add",
            "unique_id": 993
        },
        "attention_mask_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "attention_mask_1",
            "opcode": "Input",
            "output_nodes": [
                "expand_dims_1289"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 2
        },
        "bert.embeddings.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1267"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 8
        },
        "bert.embeddings.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1267"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 7
        },
        "bert.embeddings.position_embeddings.weight": {
            "cache": {
                "shape": [
                    "512",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1274"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 5
        },
        "bert.embeddings.position_ids": {
            "cache": {
                "shape": [
                    "1",
                    "512"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.position_ids",
            "opcode": "Input",
            "output_nodes": [
                "strided_slice_1276"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 6
        },
        "bert.embeddings.token_type_embeddings.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.token_type_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1272"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 4
        },
        "bert.embeddings.word_embeddings.weight": {
            "cache": {
                "shape": [
                    "28996",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.embeddings.word_embeddings.weight",
            "opcode": "Input",
            "output_nodes": [
                "embedding_1270"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 3
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1242"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 18
        },
        "bert.encoder.layer.0.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1242"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 17
        },
        "bert.encoder.layer.0.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1245"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 16
        },
        "bert.encoder.layer.0.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1247"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 15
        },
        "bert.encoder.layer.0.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1280"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 12
        },
        "bert.encoder.layer.0.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1282"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 11
        },
        "bert.encoder.layer.0.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1262"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 10
        },
        "bert.encoder.layer.0.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1264"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 9
        },
        "bert.encoder.layer.0.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1295"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 14
        },
        "bert.encoder.layer.0.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1297"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 13
        },
        "bert.encoder.layer.0.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1238"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 20
        },
        "bert.encoder.layer.0.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1240"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 19
        },
        "bert.encoder.layer.0.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1230"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 24
        },
        "bert.encoder.layer.0.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1230"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 23
        },
        "bert.encoder.layer.0.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1233"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 22
        },
        "bert.encoder.layer.0.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.0.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1235"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 21
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 34
        },
        "bert.encoder.layer.1.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1206"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 33
        },
        "bert.encoder.layer.1.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1209"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 32
        },
        "bert.encoder.layer.1.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1211"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 31
        },
        "bert.encoder.layer.1.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1308"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 28
        },
        "bert.encoder.layer.1.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1310"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 27
        },
        "bert.encoder.layer.1.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1226"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 26
        },
        "bert.encoder.layer.1.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1228"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 25
        },
        "bert.encoder.layer.1.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1316"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 30
        },
        "bert.encoder.layer.1.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1318"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 29
        },
        "bert.encoder.layer.1.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1202"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 36
        },
        "bert.encoder.layer.1.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1204"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 35
        },
        "bert.encoder.layer.1.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1194"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 40
        },
        "bert.encoder.layer.1.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1194"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 39
        },
        "bert.encoder.layer.1.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1197"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 38
        },
        "bert.encoder.layer.1.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.1.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1199"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 37
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_882"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 178
        },
        "bert.encoder.layer.10.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_882"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 177
        },
        "bert.encoder.layer.10.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_885"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 176
        },
        "bert.encoder.layer.10.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_887"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 175
        },
        "bert.encoder.layer.10.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1497"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 172
        },
        "bert.encoder.layer.10.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1499"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 171
        },
        "bert.encoder.layer.10.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_902"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 170
        },
        "bert.encoder.layer.10.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_904"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 169
        },
        "bert.encoder.layer.10.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1505"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 174
        },
        "bert.encoder.layer.10.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1507"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 173
        },
        "bert.encoder.layer.10.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_878"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 180
        },
        "bert.encoder.layer.10.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_880"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 179
        },
        "bert.encoder.layer.10.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_870"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 184
        },
        "bert.encoder.layer.10.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_870"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 183
        },
        "bert.encoder.layer.10.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_873"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 182
        },
        "bert.encoder.layer.10.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.10.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_875"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 181
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 194
        },
        "bert.encoder.layer.11.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_846"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 193
        },
        "bert.encoder.layer.11.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_849"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 192
        },
        "bert.encoder.layer.11.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_851"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 191
        },
        "bert.encoder.layer.11.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1518"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 188
        },
        "bert.encoder.layer.11.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1520"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 187
        },
        "bert.encoder.layer.11.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_866"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 186
        },
        "bert.encoder.layer.11.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_868"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 185
        },
        "bert.encoder.layer.11.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1526"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 190
        },
        "bert.encoder.layer.11.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1528"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 189
        },
        "bert.encoder.layer.11.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_842"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 196
        },
        "bert.encoder.layer.11.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_844"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 195
        },
        "bert.encoder.layer.11.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 200
        },
        "bert.encoder.layer.11.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_834"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 199
        },
        "bert.encoder.layer.11.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_837"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 198
        },
        "bert.encoder.layer.11.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.11.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_839"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 197
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_810"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 210
        },
        "bert.encoder.layer.12.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_810"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 209
        },
        "bert.encoder.layer.12.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_813"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 208
        },
        "bert.encoder.layer.12.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_815"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 207
        },
        "bert.encoder.layer.12.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1539"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 204
        },
        "bert.encoder.layer.12.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1541"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 203
        },
        "bert.encoder.layer.12.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_830"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 202
        },
        "bert.encoder.layer.12.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_832"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 201
        },
        "bert.encoder.layer.12.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1547"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 206
        },
        "bert.encoder.layer.12.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1549"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 205
        },
        "bert.encoder.layer.12.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_806"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 212
        },
        "bert.encoder.layer.12.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_808"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 211
        },
        "bert.encoder.layer.12.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_798"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 216
        },
        "bert.encoder.layer.12.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_798"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 215
        },
        "bert.encoder.layer.12.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_801"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 214
        },
        "bert.encoder.layer.12.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.12.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_803"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 213
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_774"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 226
        },
        "bert.encoder.layer.13.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_774"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 225
        },
        "bert.encoder.layer.13.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_777"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 224
        },
        "bert.encoder.layer.13.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_779"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 223
        },
        "bert.encoder.layer.13.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1560"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 220
        },
        "bert.encoder.layer.13.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1562"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 219
        },
        "bert.encoder.layer.13.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_794"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 218
        },
        "bert.encoder.layer.13.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_796"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 217
        },
        "bert.encoder.layer.13.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1568"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 222
        },
        "bert.encoder.layer.13.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1570"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 221
        },
        "bert.encoder.layer.13.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_770"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 228
        },
        "bert.encoder.layer.13.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 227
        },
        "bert.encoder.layer.13.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_762"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 232
        },
        "bert.encoder.layer.13.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_762"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 231
        },
        "bert.encoder.layer.13.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_765"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 230
        },
        "bert.encoder.layer.13.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.13.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_767"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 229
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_738"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 242
        },
        "bert.encoder.layer.14.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_738"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 241
        },
        "bert.encoder.layer.14.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_741"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 240
        },
        "bert.encoder.layer.14.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_743"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 239
        },
        "bert.encoder.layer.14.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1581"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 236
        },
        "bert.encoder.layer.14.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1583"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 235
        },
        "bert.encoder.layer.14.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_758"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 234
        },
        "bert.encoder.layer.14.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_760"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 233
        },
        "bert.encoder.layer.14.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1589"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 238
        },
        "bert.encoder.layer.14.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1591"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 237
        },
        "bert.encoder.layer.14.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_734"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 244
        },
        "bert.encoder.layer.14.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_736"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 243
        },
        "bert.encoder.layer.14.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_726"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 248
        },
        "bert.encoder.layer.14.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_726"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 247
        },
        "bert.encoder.layer.14.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_729"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 246
        },
        "bert.encoder.layer.14.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.14.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_731"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 245
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 258
        },
        "bert.encoder.layer.15.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_702"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 257
        },
        "bert.encoder.layer.15.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_705"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 256
        },
        "bert.encoder.layer.15.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_707"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 255
        },
        "bert.encoder.layer.15.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1602"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 252
        },
        "bert.encoder.layer.15.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1604"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 251
        },
        "bert.encoder.layer.15.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_722"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 250
        },
        "bert.encoder.layer.15.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_724"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 249
        },
        "bert.encoder.layer.15.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1610"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 254
        },
        "bert.encoder.layer.15.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1612"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 253
        },
        "bert.encoder.layer.15.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_698"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 260
        },
        "bert.encoder.layer.15.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_700"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 259
        },
        "bert.encoder.layer.15.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_690"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 264
        },
        "bert.encoder.layer.15.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_690"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 263
        },
        "bert.encoder.layer.15.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_693"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 262
        },
        "bert.encoder.layer.15.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.15.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_695"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 261
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_666"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 274
        },
        "bert.encoder.layer.16.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_666"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 273
        },
        "bert.encoder.layer.16.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_669"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 272
        },
        "bert.encoder.layer.16.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_671"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 271
        },
        "bert.encoder.layer.16.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1623"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 268
        },
        "bert.encoder.layer.16.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1625"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 267
        },
        "bert.encoder.layer.16.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_686"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 266
        },
        "bert.encoder.layer.16.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_688"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 265
        },
        "bert.encoder.layer.16.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1631"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 270
        },
        "bert.encoder.layer.16.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1633"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 269
        },
        "bert.encoder.layer.16.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_662"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 276
        },
        "bert.encoder.layer.16.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_664"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 275
        },
        "bert.encoder.layer.16.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_654"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 280
        },
        "bert.encoder.layer.16.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_654"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 279
        },
        "bert.encoder.layer.16.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_657"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 278
        },
        "bert.encoder.layer.16.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.16.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_659"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 277
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_630"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 290
        },
        "bert.encoder.layer.17.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_630"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 289
        },
        "bert.encoder.layer.17.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_633"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 288
        },
        "bert.encoder.layer.17.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_635"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 287
        },
        "bert.encoder.layer.17.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1644"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 284
        },
        "bert.encoder.layer.17.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1646"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 283
        },
        "bert.encoder.layer.17.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_650"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 282
        },
        "bert.encoder.layer.17.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_652"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 281
        },
        "bert.encoder.layer.17.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1652"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 286
        },
        "bert.encoder.layer.17.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1654"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 285
        },
        "bert.encoder.layer.17.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_626"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 292
        },
        "bert.encoder.layer.17.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_628"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 291
        },
        "bert.encoder.layer.17.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_618"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 296
        },
        "bert.encoder.layer.17.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_618"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 295
        },
        "bert.encoder.layer.17.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_621"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 294
        },
        "bert.encoder.layer.17.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.17.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_623"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 293
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_594"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 306
        },
        "bert.encoder.layer.18.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_594"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 305
        },
        "bert.encoder.layer.18.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_597"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 304
        },
        "bert.encoder.layer.18.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_599"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 303
        },
        "bert.encoder.layer.18.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1665"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 300
        },
        "bert.encoder.layer.18.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1667"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 299
        },
        "bert.encoder.layer.18.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_614"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 298
        },
        "bert.encoder.layer.18.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_616"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 297
        },
        "bert.encoder.layer.18.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1673"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 302
        },
        "bert.encoder.layer.18.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1675"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 301
        },
        "bert.encoder.layer.18.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_590"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 308
        },
        "bert.encoder.layer.18.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_592"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 307
        },
        "bert.encoder.layer.18.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_582"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 312
        },
        "bert.encoder.layer.18.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_582"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 311
        },
        "bert.encoder.layer.18.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_585"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 310
        },
        "bert.encoder.layer.18.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.18.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_587"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 309
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_558"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 322
        },
        "bert.encoder.layer.19.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_558"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 321
        },
        "bert.encoder.layer.19.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_561"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 320
        },
        "bert.encoder.layer.19.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_563"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 319
        },
        "bert.encoder.layer.19.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1686"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 316
        },
        "bert.encoder.layer.19.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1688"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 315
        },
        "bert.encoder.layer.19.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_578"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 314
        },
        "bert.encoder.layer.19.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_580"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 313
        },
        "bert.encoder.layer.19.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1694"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 318
        },
        "bert.encoder.layer.19.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1696"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 317
        },
        "bert.encoder.layer.19.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_554"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 324
        },
        "bert.encoder.layer.19.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_556"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 323
        },
        "bert.encoder.layer.19.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 328
        },
        "bert.encoder.layer.19.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_546"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 327
        },
        "bert.encoder.layer.19.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_549"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 326
        },
        "bert.encoder.layer.19.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.19.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_551"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 325
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1170"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 50
        },
        "bert.encoder.layer.2.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1170"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 49
        },
        "bert.encoder.layer.2.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1173"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 48
        },
        "bert.encoder.layer.2.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1175"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 47
        },
        "bert.encoder.layer.2.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1329"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 44
        },
        "bert.encoder.layer.2.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1331"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 43
        },
        "bert.encoder.layer.2.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1190"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 42
        },
        "bert.encoder.layer.2.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1192"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 41
        },
        "bert.encoder.layer.2.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1337"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 46
        },
        "bert.encoder.layer.2.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1339"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 45
        },
        "bert.encoder.layer.2.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1166"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 52
        },
        "bert.encoder.layer.2.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1168"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 51
        },
        "bert.encoder.layer.2.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1158"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 56
        },
        "bert.encoder.layer.2.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1158"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 55
        },
        "bert.encoder.layer.2.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1161"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 54
        },
        "bert.encoder.layer.2.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.2.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1163"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 53
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 338
        },
        "bert.encoder.layer.20.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_522"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 337
        },
        "bert.encoder.layer.20.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_525"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 336
        },
        "bert.encoder.layer.20.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_527"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 335
        },
        "bert.encoder.layer.20.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1707"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 332
        },
        "bert.encoder.layer.20.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1709"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 331
        },
        "bert.encoder.layer.20.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_542"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 330
        },
        "bert.encoder.layer.20.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_544"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 329
        },
        "bert.encoder.layer.20.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1715"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 334
        },
        "bert.encoder.layer.20.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1717"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 333
        },
        "bert.encoder.layer.20.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_518"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 340
        },
        "bert.encoder.layer.20.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_520"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 339
        },
        "bert.encoder.layer.20.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_510"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 344
        },
        "bert.encoder.layer.20.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_510"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 343
        },
        "bert.encoder.layer.20.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_513"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 342
        },
        "bert.encoder.layer.20.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.20.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_515"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 341
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_486"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 354
        },
        "bert.encoder.layer.21.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_486"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 353
        },
        "bert.encoder.layer.21.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_489"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 352
        },
        "bert.encoder.layer.21.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_491"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 351
        },
        "bert.encoder.layer.21.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1728"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 348
        },
        "bert.encoder.layer.21.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1730"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 347
        },
        "bert.encoder.layer.21.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_506"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 346
        },
        "bert.encoder.layer.21.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_508"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 345
        },
        "bert.encoder.layer.21.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1736"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 350
        },
        "bert.encoder.layer.21.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1738"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 349
        },
        "bert.encoder.layer.21.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_482"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 356
        },
        "bert.encoder.layer.21.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 355
        },
        "bert.encoder.layer.21.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_474"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 360
        },
        "bert.encoder.layer.21.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_474"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 359
        },
        "bert.encoder.layer.21.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_477"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 358
        },
        "bert.encoder.layer.21.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.21.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_479"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 357
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_450"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 370
        },
        "bert.encoder.layer.22.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_450"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 369
        },
        "bert.encoder.layer.22.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_453"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 368
        },
        "bert.encoder.layer.22.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_455"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 367
        },
        "bert.encoder.layer.22.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1749"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 364
        },
        "bert.encoder.layer.22.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1751"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 363
        },
        "bert.encoder.layer.22.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_470"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 362
        },
        "bert.encoder.layer.22.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_472"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 361
        },
        "bert.encoder.layer.22.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1757"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 366
        },
        "bert.encoder.layer.22.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1759"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 365
        },
        "bert.encoder.layer.22.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_446"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 372
        },
        "bert.encoder.layer.22.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_448"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 371
        },
        "bert.encoder.layer.22.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_438"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 376
        },
        "bert.encoder.layer.22.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_438"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 375
        },
        "bert.encoder.layer.22.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_441"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 374
        },
        "bert.encoder.layer.22.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.22.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_443"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 373
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 386
        },
        "bert.encoder.layer.23.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_414"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 385
        },
        "bert.encoder.layer.23.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_417"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 384
        },
        "bert.encoder.layer.23.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_419"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 383
        },
        "bert.encoder.layer.23.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1770"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 380
        },
        "bert.encoder.layer.23.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1772"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 379
        },
        "bert.encoder.layer.23.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_434"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 378
        },
        "bert.encoder.layer.23.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_436"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 377
        },
        "bert.encoder.layer.23.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1778"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 382
        },
        "bert.encoder.layer.23.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1780"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 381
        },
        "bert.encoder.layer.23.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_410"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 388
        },
        "bert.encoder.layer.23.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_412"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 387
        },
        "bert.encoder.layer.23.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 392
        },
        "bert.encoder.layer.23.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 391
        },
        "bert.encoder.layer.23.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_405"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 390
        },
        "bert.encoder.layer.23.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.23.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_407"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 389
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1134"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 66
        },
        "bert.encoder.layer.3.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1134"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 65
        },
        "bert.encoder.layer.3.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1137"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 64
        },
        "bert.encoder.layer.3.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1139"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 63
        },
        "bert.encoder.layer.3.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1350"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 60
        },
        "bert.encoder.layer.3.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1352"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 59
        },
        "bert.encoder.layer.3.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1154"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 58
        },
        "bert.encoder.layer.3.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1156"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 57
        },
        "bert.encoder.layer.3.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1358"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 62
        },
        "bert.encoder.layer.3.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1360"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 61
        },
        "bert.encoder.layer.3.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1130"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 68
        },
        "bert.encoder.layer.3.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1132"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 67
        },
        "bert.encoder.layer.3.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1122"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 72
        },
        "bert.encoder.layer.3.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1122"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 71
        },
        "bert.encoder.layer.3.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1125"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 70
        },
        "bert.encoder.layer.3.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.3.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1127"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 69
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1098"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 82
        },
        "bert.encoder.layer.4.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1098"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 81
        },
        "bert.encoder.layer.4.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1101"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 80
        },
        "bert.encoder.layer.4.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1103"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 79
        },
        "bert.encoder.layer.4.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1371"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 76
        },
        "bert.encoder.layer.4.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1373"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 75
        },
        "bert.encoder.layer.4.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1118"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 74
        },
        "bert.encoder.layer.4.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1120"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 73
        },
        "bert.encoder.layer.4.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1379"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 78
        },
        "bert.encoder.layer.4.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1381"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 77
        },
        "bert.encoder.layer.4.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1094"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 84
        },
        "bert.encoder.layer.4.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1096"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 83
        },
        "bert.encoder.layer.4.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1086"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 88
        },
        "bert.encoder.layer.4.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1086"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 87
        },
        "bert.encoder.layer.4.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1089"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 86
        },
        "bert.encoder.layer.4.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.4.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1091"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 85
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1062"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 98
        },
        "bert.encoder.layer.5.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1062"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 97
        },
        "bert.encoder.layer.5.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1065"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 96
        },
        "bert.encoder.layer.5.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1067"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 95
        },
        "bert.encoder.layer.5.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1392"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 92
        },
        "bert.encoder.layer.5.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1394"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 91
        },
        "bert.encoder.layer.5.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1082"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 90
        },
        "bert.encoder.layer.5.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1084"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 89
        },
        "bert.encoder.layer.5.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1400"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 94
        },
        "bert.encoder.layer.5.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1402"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 93
        },
        "bert.encoder.layer.5.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1058"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 100
        },
        "bert.encoder.layer.5.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1060"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 99
        },
        "bert.encoder.layer.5.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1050"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 104
        },
        "bert.encoder.layer.5.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1050"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 103
        },
        "bert.encoder.layer.5.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1053"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 102
        },
        "bert.encoder.layer.5.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.5.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1055"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 101
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1026"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 114
        },
        "bert.encoder.layer.6.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1026"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 113
        },
        "bert.encoder.layer.6.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1029"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 112
        },
        "bert.encoder.layer.6.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1031"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 111
        },
        "bert.encoder.layer.6.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1413"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 108
        },
        "bert.encoder.layer.6.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1415"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 107
        },
        "bert.encoder.layer.6.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1046"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 106
        },
        "bert.encoder.layer.6.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1048"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 105
        },
        "bert.encoder.layer.6.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1421"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 110
        },
        "bert.encoder.layer.6.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1423"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 109
        },
        "bert.encoder.layer.6.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1022"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 116
        },
        "bert.encoder.layer.6.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1024"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 115
        },
        "bert.encoder.layer.6.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1014"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 120
        },
        "bert.encoder.layer.6.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_1014"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 119
        },
        "bert.encoder.layer.6.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1017"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 118
        },
        "bert.encoder.layer.6.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.6.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1019"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 117
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_990"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 130
        },
        "bert.encoder.layer.7.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_990"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 129
        },
        "bert.encoder.layer.7.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_993"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 128
        },
        "bert.encoder.layer.7.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_995"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 127
        },
        "bert.encoder.layer.7.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1434"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 124
        },
        "bert.encoder.layer.7.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1436"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 123
        },
        "bert.encoder.layer.7.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1010"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 122
        },
        "bert.encoder.layer.7.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1012"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 121
        },
        "bert.encoder.layer.7.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1442"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 126
        },
        "bert.encoder.layer.7.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1444"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 125
        },
        "bert.encoder.layer.7.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_986"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 132
        },
        "bert.encoder.layer.7.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_988"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 131
        },
        "bert.encoder.layer.7.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_978"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 136
        },
        "bert.encoder.layer.7.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_978"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 135
        },
        "bert.encoder.layer.7.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_981"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 134
        },
        "bert.encoder.layer.7.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.7.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_983"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 133
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_954"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 146
        },
        "bert.encoder.layer.8.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_954"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 145
        },
        "bert.encoder.layer.8.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_957"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 144
        },
        "bert.encoder.layer.8.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_959"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 143
        },
        "bert.encoder.layer.8.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1455"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 140
        },
        "bert.encoder.layer.8.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1457"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 139
        },
        "bert.encoder.layer.8.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_974"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 138
        },
        "bert.encoder.layer.8.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_976"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 137
        },
        "bert.encoder.layer.8.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1463"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 142
        },
        "bert.encoder.layer.8.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1465"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 141
        },
        "bert.encoder.layer.8.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_950"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 148
        },
        "bert.encoder.layer.8.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_952"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 147
        },
        "bert.encoder.layer.8.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_942"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 152
        },
        "bert.encoder.layer.8.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_942"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 151
        },
        "bert.encoder.layer.8.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_945"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 150
        },
        "bert.encoder.layer.8.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.8.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_947"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 149
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 162
        },
        "bert.encoder.layer.9.attention.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_918"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 161
        },
        "bert.encoder.layer.9.attention.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_921"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 160
        },
        "bert.encoder.layer.9.attention.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_923"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 159
        },
        "bert.encoder.layer.9.attention.self.key.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1476"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 156
        },
        "bert.encoder.layer.9.attention.self.key.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.key.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1478"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 155
        },
        "bert.encoder.layer.9.attention.self.query.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_938"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 154
        },
        "bert.encoder.layer.9.attention.self.query.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.query.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_940"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 153
        },
        "bert.encoder.layer.9.attention.self.value.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_1484"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 158
        },
        "bert.encoder.layer.9.attention.self.value.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.attention.self.value.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_1486"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 157
        },
        "bert.encoder.layer.9.intermediate.dense.bias": {
            "cache": {
                "shape": [
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_914"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 164
        },
        "bert.encoder.layer.9.intermediate.dense.weight": {
            "cache": {
                "shape": [
                    "4096",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.intermediate.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_916"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 163
        },
        "bert.encoder.layer.9.output.LayerNorm.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.bias",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_906"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 168
        },
        "bert.encoder.layer.9.output.LayerNorm.weight": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.LayerNorm.weight",
            "opcode": "Input",
            "output_nodes": [
                "layernorm_906"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 167
        },
        "bert.encoder.layer.9.output.dense.bias": {
            "cache": {
                "shape": [
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_909"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 166
        },
        "bert.encoder.layer.9.output.dense.weight": {
            "cache": {
                "shape": [
                    "1024",
                    "4096"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "bert.encoder.layer.9.output.dense.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_911"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 165
        },
        "cast_1271": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_ids"
            ],
            "ir": "pybuda",
            "name": "cast_1271",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1270"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1271
        },
        "cast_1273": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "input_1"
            ],
            "ir": "pybuda",
            "name": "cast_1273",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1272"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1273
        },
        "cast_1275": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "strided_slice_1276"
            ],
            "ir": "pybuda",
            "name": "cast_1275",
            "opcode": "RelayOp",
            "output_nodes": [
                "embedding_1274"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1275
        },
        "cast_1287": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "cast",
            "epoch": 0,
            "input_nodes": [
                "expand_dims_1288"
            ],
            "ir": "pybuda",
            "name": "cast_1287",
            "opcode": "RelayOp",
            "output_nodes": [
                "subtract_1285"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::to, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917a3500), 0, 0, 0, 0)",
            "type": "cast",
            "unique_id": 1287
        },
        "constant_1283": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1283",
            "opcode": "Input",
            "output_nodes": [
                "divide_1256"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1283
        },
        "constant_1286": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1286",
            "opcode": "Input",
            "output_nodes": [
                "subtract_1285"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1286
        },
        "constant_1290": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1290",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1284"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1290
        },
        "constant_1299": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1299",
            "opcode": "Input",
            "output_nodes": [
                "add_1298"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1299
        },
        "constant_1303": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1303",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1302"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1303
        },
        "constant_1304": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1304",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1300"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1304
        },
        "constant_1311": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1311",
            "opcode": "Input",
            "output_nodes": [
                "divide_1220"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1311
        },
        "constant_1320": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1320",
            "opcode": "Input",
            "output_nodes": [
                "add_1319"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1320
        },
        "constant_1324": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1324",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1323"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1324
        },
        "constant_1325": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1325",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1321"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1325
        },
        "constant_1332": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1332",
            "opcode": "Input",
            "output_nodes": [
                "divide_1184"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1332
        },
        "constant_1341": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1341",
            "opcode": "Input",
            "output_nodes": [
                "add_1340"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1341
        },
        "constant_1345": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1345",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1344"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1345
        },
        "constant_1346": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1346",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1342"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1346
        },
        "constant_1353": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1353",
            "opcode": "Input",
            "output_nodes": [
                "divide_1148"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1353
        },
        "constant_1362": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1362",
            "opcode": "Input",
            "output_nodes": [
                "add_1361"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1362
        },
        "constant_1366": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1366",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1365"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1366
        },
        "constant_1367": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1367",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1363"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1367
        },
        "constant_1374": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1374",
            "opcode": "Input",
            "output_nodes": [
                "divide_1112"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1374
        },
        "constant_1383": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1383",
            "opcode": "Input",
            "output_nodes": [
                "add_1382"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1383
        },
        "constant_1387": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1387",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1386"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1387
        },
        "constant_1388": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1388",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1384"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1388
        },
        "constant_1395": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1395",
            "opcode": "Input",
            "output_nodes": [
                "divide_1076"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1395
        },
        "constant_1404": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1404",
            "opcode": "Input",
            "output_nodes": [
                "add_1403"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1404
        },
        "constant_1408": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1408",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1407"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1408
        },
        "constant_1409": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1409",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1405"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1409
        },
        "constant_1416": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1416",
            "opcode": "Input",
            "output_nodes": [
                "divide_1040"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1416
        },
        "constant_1425": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1425",
            "opcode": "Input",
            "output_nodes": [
                "add_1424"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1425
        },
        "constant_1429": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1429",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1428"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1429
        },
        "constant_1430": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1430",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1426"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1430
        },
        "constant_1437": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1437",
            "opcode": "Input",
            "output_nodes": [
                "divide_1004"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1437
        },
        "constant_1446": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1446",
            "opcode": "Input",
            "output_nodes": [
                "add_1445"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1446
        },
        "constant_1450": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1450",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1449"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1450
        },
        "constant_1451": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1451",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1447"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1451
        },
        "constant_1458": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1458",
            "opcode": "Input",
            "output_nodes": [
                "divide_968"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1458
        },
        "constant_1467": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1467",
            "opcode": "Input",
            "output_nodes": [
                "add_1466"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1467
        },
        "constant_1471": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1471",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1470"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1471
        },
        "constant_1472": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1472",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1468"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1472
        },
        "constant_1479": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1479",
            "opcode": "Input",
            "output_nodes": [
                "divide_932"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1479
        },
        "constant_1488": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1488",
            "opcode": "Input",
            "output_nodes": [
                "add_1487"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1488
        },
        "constant_1492": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1492",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1491"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1492
        },
        "constant_1493": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1493",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1489"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1493
        },
        "constant_1500": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1500",
            "opcode": "Input",
            "output_nodes": [
                "divide_896"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1500
        },
        "constant_1509": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1509",
            "opcode": "Input",
            "output_nodes": [
                "add_1508"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1509
        },
        "constant_1513": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1513",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1512"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1513
        },
        "constant_1514": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1514",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1510"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1514
        },
        "constant_1521": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1521",
            "opcode": "Input",
            "output_nodes": [
                "divide_860"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1521
        },
        "constant_1530": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1530",
            "opcode": "Input",
            "output_nodes": [
                "add_1529"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1530
        },
        "constant_1534": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1534",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1533"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1534
        },
        "constant_1535": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1535",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1531"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1535
        },
        "constant_1542": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1542",
            "opcode": "Input",
            "output_nodes": [
                "divide_824"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1542
        },
        "constant_1551": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1551",
            "opcode": "Input",
            "output_nodes": [
                "add_1550"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1551
        },
        "constant_1555": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1555",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1554"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1555
        },
        "constant_1556": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1556",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1552"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1556
        },
        "constant_1563": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1563",
            "opcode": "Input",
            "output_nodes": [
                "divide_788"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1563
        },
        "constant_1572": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1572",
            "opcode": "Input",
            "output_nodes": [
                "add_1571"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1572
        },
        "constant_1576": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1576",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1575"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1576
        },
        "constant_1577": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1577",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1573"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1577
        },
        "constant_1584": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1584",
            "opcode": "Input",
            "output_nodes": [
                "divide_752"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1584
        },
        "constant_1593": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1593",
            "opcode": "Input",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1593
        },
        "constant_1597": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1597",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1596"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1597
        },
        "constant_1598": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1598",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1594"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1598
        },
        "constant_1605": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1605",
            "opcode": "Input",
            "output_nodes": [
                "divide_716"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1605
        },
        "constant_1614": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1614",
            "opcode": "Input",
            "output_nodes": [
                "add_1613"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1614
        },
        "constant_1618": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1618",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1617"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1618
        },
        "constant_1619": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1619",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1615"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1619
        },
        "constant_1626": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1626",
            "opcode": "Input",
            "output_nodes": [
                "divide_680"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1626
        },
        "constant_1635": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1635",
            "opcode": "Input",
            "output_nodes": [
                "add_1634"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1635
        },
        "constant_1639": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1639",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1638"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1639
        },
        "constant_1640": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1640",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1636"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1640
        },
        "constant_1647": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1647",
            "opcode": "Input",
            "output_nodes": [
                "divide_644"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1647
        },
        "constant_1656": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1656",
            "opcode": "Input",
            "output_nodes": [
                "add_1655"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1656
        },
        "constant_1660": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1660",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1659"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1660
        },
        "constant_1661": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1661",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1657"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1661
        },
        "constant_1668": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1668",
            "opcode": "Input",
            "output_nodes": [
                "divide_608"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1668
        },
        "constant_1677": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1677",
            "opcode": "Input",
            "output_nodes": [
                "add_1676"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1677
        },
        "constant_1681": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1681",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1680"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1681
        },
        "constant_1682": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1682",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1678"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1682
        },
        "constant_1689": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1689",
            "opcode": "Input",
            "output_nodes": [
                "divide_572"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1689
        },
        "constant_1698": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1698",
            "opcode": "Input",
            "output_nodes": [
                "add_1697"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1698
        },
        "constant_1702": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1702",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1701"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1702
        },
        "constant_1703": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1703",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1699"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1703
        },
        "constant_1710": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1710",
            "opcode": "Input",
            "output_nodes": [
                "divide_536"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1710
        },
        "constant_1719": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1719",
            "opcode": "Input",
            "output_nodes": [
                "add_1718"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1719
        },
        "constant_1723": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1723",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1722"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1723
        },
        "constant_1724": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1724",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1720"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1724
        },
        "constant_1731": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1731",
            "opcode": "Input",
            "output_nodes": [
                "divide_500"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1731
        },
        "constant_1740": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1740",
            "opcode": "Input",
            "output_nodes": [
                "add_1739"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1740
        },
        "constant_1744": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1744",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1743"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1744
        },
        "constant_1745": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1745",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1741"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1745
        },
        "constant_1752": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1752",
            "opcode": "Input",
            "output_nodes": [
                "divide_464"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1752
        },
        "constant_1761": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1761",
            "opcode": "Input",
            "output_nodes": [
                "add_1760"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1761
        },
        "constant_1765": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1765",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1764"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1765
        },
        "constant_1766": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1766",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1762"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1766
        },
        "constant_1773": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1773",
            "opcode": "Input",
            "output_nodes": [
                "divide_428"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1773
        },
        "constant_1782": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1782",
            "opcode": "Input",
            "output_nodes": [
                "add_1781"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1782
        },
        "constant_1786": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1786",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1785"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1786
        },
        "constant_1787": {
            "cahce": {
                "shape": []
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "constant_1787",
            "opcode": "Input",
            "output_nodes": [
                "multiply_1783"
            ],
            "pybuda": 1,
            "type": "Input::constant",
            "unique_id": 1787
        },
        "divide_1004": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1005",
                "constant_1437"
            ],
            "ir": "pybuda",
            "name": "divide_1004",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1003"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49cbc0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1004
        },
        "divide_1040": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1041",
                "constant_1416"
            ],
            "ir": "pybuda",
            "name": "divide_1040",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1039"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511f40), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1040
        },
        "divide_1076": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1077",
                "constant_1395"
            ],
            "ir": "pybuda",
            "name": "divide_1076",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1075"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c22f20), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1076
        },
        "divide_1112": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1113",
                "constant_1374"
            ],
            "ir": "pybuda",
            "name": "divide_1112",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1111"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917b72e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1112
        },
        "divide_1148": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1149",
                "constant_1353"
            ],
            "ir": "pybuda",
            "name": "divide_1148",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1147"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91820730), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1148
        },
        "divide_1184": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1185",
                "constant_1332"
            ],
            "ir": "pybuda",
            "name": "divide_1184",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1183"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd960e90), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1184
        },
        "divide_1220": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1221",
                "constant_1311"
            ],
            "ir": "pybuda",
            "name": "divide_1220",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1219"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8abc4710), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1220
        },
        "divide_1256": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_1257",
                "constant_1283"
            ],
            "ir": "pybuda",
            "name": "divide_1256",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91826840), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 1256
        },
        "divide_428": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_429",
                "constant_1773"
            ],
            "ir": "pybuda",
            "name": "divide_428",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ec890), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 428
        },
        "divide_464": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_465",
                "constant_1752"
            ],
            "ir": "pybuda",
            "name": "divide_464",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x94171620), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 464
        },
        "divide_500": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_501",
                "constant_1731"
            ],
            "ir": "pybuda",
            "name": "divide_500",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_499"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28007220), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 500
        },
        "divide_536": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_537",
                "constant_1710"
            ],
            "ir": "pybuda",
            "name": "divide_536",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_535"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf805110), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 536
        },
        "divide_572": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_573",
                "constant_1689"
            ],
            "ir": "pybuda",
            "name": "divide_572",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb4f1e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 572
        },
        "divide_608": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_609",
                "constant_1668"
            ],
            "ir": "pybuda",
            "name": "divide_608",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27ff1540), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 608
        },
        "divide_644": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_645",
                "constant_1647"
            ],
            "ir": "pybuda",
            "name": "divide_644",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_643"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fcd060), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 644
        },
        "divide_680": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_681",
                "constant_1626"
            ],
            "ir": "pybuda",
            "name": "divide_680",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f69850), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 680
        },
        "divide_716": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_717",
                "constant_1605"
            ],
            "ir": "pybuda",
            "name": "divide_716",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d3100), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 716
        },
        "divide_752": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_753",
                "constant_1584"
            ],
            "ir": "pybuda",
            "name": "divide_752",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_751"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f45150), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 752
        },
        "divide_788": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_789",
                "constant_1563"
            ],
            "ir": "pybuda",
            "name": "divide_788",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_787"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82ecd0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 788
        },
        "divide_824": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_825",
                "constant_1542"
            ],
            "ir": "pybuda",
            "name": "divide_824",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_823"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda30d90), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 824
        },
        "divide_860": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_861",
                "constant_1521"
            ],
            "ir": "pybuda",
            "name": "divide_860",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_859"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364688e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 860
        },
        "divide_896": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_897",
                "constant_1500"
            ],
            "ir": "pybuda",
            "name": "divide_896",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_895"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36433ac0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 896
        },
        "divide_932": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_933",
                "constant_1479"
            ],
            "ir": "pybuda",
            "name": "divide_932",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_931"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bfe2e0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 932
        },
        "divide_968": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "divide",
            "epoch": 0,
            "input_nodes": [
                "reshape_969",
                "constant_1458"
            ],
            "ir": "pybuda",
            "name": "divide_968",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_967"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::div, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf19c0), 0, 0, 0, 0)",
            "type": "divide",
            "unique_id": 968
        },
        "embedding_1270": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.word_embeddings.weight",
                "cast_1271"
            ],
            "ir": "pybuda",
            "name": "embedding_1270",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::word_embeddings, 0x8ab28c40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1270
        },
        "embedding_1272": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.token_type_embeddings.weight",
                "cast_1273"
            ],
            "ir": "pybuda",
            "name": "embedding_1272",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1269"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::token_type_embeddings, 0x2216b40), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1272
        },
        "embedding_1274": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "embedding",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_embeddings.weight",
                "cast_1275"
            ],
            "ir": "pybuda",
            "name": "embedding_1274",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1268"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::embedding, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.sparse.Embedding::position_embeddings, 0x917a3520), 0, 0, 0, 0)",
            "type": "embedding",
            "unique_id": 1274
        },
        "erf_1301": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1302"
            ],
            "ir": "pybuda",
            "name": "erf_1301",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1300"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1301
        },
        "erf_1322": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1323"
            ],
            "ir": "pybuda",
            "name": "erf_1322",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1321"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1322
        },
        "erf_1343": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1344"
            ],
            "ir": "pybuda",
            "name": "erf_1343",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1342"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1343
        },
        "erf_1364": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1365"
            ],
            "ir": "pybuda",
            "name": "erf_1364",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1363"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1364
        },
        "erf_1385": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1386"
            ],
            "ir": "pybuda",
            "name": "erf_1385",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1384"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1385
        },
        "erf_1406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1407"
            ],
            "ir": "pybuda",
            "name": "erf_1406",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1405"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1406
        },
        "erf_1427": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1428"
            ],
            "ir": "pybuda",
            "name": "erf_1427",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1426"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1427
        },
        "erf_1448": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1449"
            ],
            "ir": "pybuda",
            "name": "erf_1448",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1448
        },
        "erf_1469": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1470"
            ],
            "ir": "pybuda",
            "name": "erf_1469",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1469
        },
        "erf_1490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1491"
            ],
            "ir": "pybuda",
            "name": "erf_1490",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1489"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1490
        },
        "erf_1511": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1512"
            ],
            "ir": "pybuda",
            "name": "erf_1511",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1510"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1511
        },
        "erf_1532": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1533"
            ],
            "ir": "pybuda",
            "name": "erf_1532",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1532
        },
        "erf_1553": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1554"
            ],
            "ir": "pybuda",
            "name": "erf_1553",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1553
        },
        "erf_1574": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1575"
            ],
            "ir": "pybuda",
            "name": "erf_1574",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1573"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1574
        },
        "erf_1595": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1596"
            ],
            "ir": "pybuda",
            "name": "erf_1595",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1594"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1595
        },
        "erf_1616": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1617"
            ],
            "ir": "pybuda",
            "name": "erf_1616",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1616
        },
        "erf_1637": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1638"
            ],
            "ir": "pybuda",
            "name": "erf_1637",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1637
        },
        "erf_1658": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1659"
            ],
            "ir": "pybuda",
            "name": "erf_1658",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1657"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1658
        },
        "erf_1679": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1680"
            ],
            "ir": "pybuda",
            "name": "erf_1679",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1678"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1679
        },
        "erf_1700": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1701"
            ],
            "ir": "pybuda",
            "name": "erf_1700",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1699"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1700
        },
        "erf_1721": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1722"
            ],
            "ir": "pybuda",
            "name": "erf_1721",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1721
        },
        "erf_1742": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1743"
            ],
            "ir": "pybuda",
            "name": "erf_1742",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1741"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1742
        },
        "erf_1763": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1764"
            ],
            "ir": "pybuda",
            "name": "erf_1763",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1762"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1763
        },
        "erf_1784": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "erf",
            "epoch": 0,
            "input_nodes": [
                "multiply_1785"
            ],
            "ir": "pybuda",
            "name": "erf_1784",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "erf",
            "unique_id": 1784
        },
        "expand_dims_1288": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "expand_dims",
            "epoch": 0,
            "input_nodes": [
                "expand_dims_1289"
            ],
            "ir": "pybuda",
            "name": "expand_dims_1288",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1287"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "expand_dims",
            "unique_id": 1288
        },
        "expand_dims_1289": {
            "cache": {
                "shape": [
                    1,
                    1,
                    384
                ]
            },
            "class": "expand_dims",
            "epoch": 0,
            "input_nodes": [
                "attention_mask_1"
            ],
            "ir": "pybuda",
            "name": "expand_dims_1289",
            "opcode": "RelayOp",
            "output_nodes": [
                "expand_dims_1288"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::unsqueeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x917ecc00), 0, 0, 0, 0)",
            "type": "expand_dims",
            "unique_id": 1289
        },
        "input_1": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_1",
            "opcode": "Input",
            "output_nodes": [
                "cast_1273"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 1
        },
        "input_ids": {
            "cache": {
                "shape": [
                    "1",
                    "384"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "input_ids",
            "opcode": "Input",
            "output_nodes": [
                "cast_1271"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 0
        },
        "layernorm_1014": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1015",
                "bert.encoder.layer.6.output.LayerNorm.weight",
                "bert.encoder.layer.6.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1014",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_991",
                "reshape_1013"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a456e70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1014
        },
        "layernorm_1026": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1027",
                "bert.encoder.layer.6.attention.output.LayerNorm.weight",
                "bert.encoder.layer.6.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1026",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1015",
                "reshape_1025"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19c0dd00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1026
        },
        "layernorm_1050": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1051",
                "bert.encoder.layer.5.output.LayerNorm.weight",
                "bert.encoder.layer.5.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1050",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1027",
                "reshape_1049"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4d52d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1050
        },
        "layernorm_1062": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1063",
                "bert.encoder.layer.5.attention.output.LayerNorm.weight",
                "bert.encoder.layer.5.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1062",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1051",
                "reshape_1061"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b49cb0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1062
        },
        "layernorm_1086": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1087",
                "bert.encoder.layer.4.output.LayerNorm.weight",
                "bert.encoder.layer.4.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1086",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1063",
                "reshape_1085"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19bc47e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1086
        },
        "layernorm_1098": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1099",
                "bert.encoder.layer.4.attention.output.LayerNorm.weight",
                "bert.encoder.layer.4.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1098",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1087",
                "reshape_1097"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9bd4d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1098
        },
        "layernorm_1122": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1123",
                "bert.encoder.layer.3.output.LayerNorm.weight",
                "bert.encoder.layer.3.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1122",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1099",
                "reshape_1121"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b96410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1122
        },
        "layernorm_1134": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1135",
                "bert.encoder.layer.3.attention.output.LayerNorm.weight",
                "bert.encoder.layer.3.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1134",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1123",
                "reshape_1133"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xda08cd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1134
        },
        "layernorm_1158": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1159",
                "bert.encoder.layer.2.output.LayerNorm.weight",
                "bert.encoder.layer.2.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1158",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1135",
                "reshape_1157"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b59000), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1158
        },
        "layernorm_1170": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1171",
                "bert.encoder.layer.2.attention.output.LayerNorm.weight",
                "bert.encoder.layer.2.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1170",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1159",
                "reshape_1169"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917ab600), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1170
        },
        "layernorm_1194": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1195",
                "bert.encoder.layer.1.output.LayerNorm.weight",
                "bert.encoder.layer.1.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1194",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1171",
                "reshape_1193"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9e7790), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1194
        },
        "layernorm_1206": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1207",
                "bert.encoder.layer.1.attention.output.LayerNorm.weight",
                "bert.encoder.layer.1.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1206",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1195",
                "reshape_1205"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x91832300), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1206
        },
        "layernorm_1230": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1231",
                "bert.encoder.layer.0.output.LayerNorm.weight",
                "bert.encoder.layer.0.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1230",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1207",
                "reshape_1229"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9182e6e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1230
        },
        "layernorm_1242": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1243",
                "bert.encoder.layer.0.attention.output.LayerNorm.weight",
                "bert.encoder.layer.0.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1242",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1231",
                "reshape_1241"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x917a5390), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1242
        },
        "layernorm_1267": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_1268",
                "bert.embeddings.LayerNorm.weight",
                "bert.embeddings.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_1267",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1266"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x918210f0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 1267
        },
        "layernorm_402": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_403",
                "bert.encoder.layer.23.output.LayerNorm.weight",
                "bert.encoder.layer.23.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_402",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_401"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fd6f10), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 402
        },
        "layernorm_414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_415",
                "bert.encoder.layer.23.attention.output.LayerNorm.weight",
                "bert.encoder.layer.23.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_414",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_403",
                "reshape_413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x37bd6810), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 414
        },
        "layernorm_438": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_439",
                "bert.encoder.layer.22.output.LayerNorm.weight",
                "bert.encoder.layer.22.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_438",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_415",
                "reshape_437"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x126ea410), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 438
        },
        "layernorm_450": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_451",
                "bert.encoder.layer.22.attention.output.LayerNorm.weight",
                "bert.encoder.layer.22.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_450",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_439",
                "reshape_449"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf75bdf0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 450
        },
        "layernorm_474": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_475",
                "bert.encoder.layer.21.output.LayerNorm.weight",
                "bert.encoder.layer.21.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_474",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_451",
                "reshape_473"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x12643c20), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 474
        },
        "layernorm_486": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_487",
                "bert.encoder.layer.21.attention.output.LayerNorm.weight",
                "bert.encoder.layer.21.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_486",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_475",
                "reshape_485"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150af8e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 486
        },
        "layernorm_510": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_511",
                "bert.encoder.layer.20.output.LayerNorm.weight",
                "bert.encoder.layer.20.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_510",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_487",
                "reshape_509"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7f9e90), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 510
        },
        "layernorm_522": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_523",
                "bert.encoder.layer.20.attention.output.LayerNorm.weight",
                "bert.encoder.layer.20.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_522",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_511",
                "reshape_521"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x19b4f460), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 522
        },
        "layernorm_546": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_547",
                "bert.encoder.layer.19.output.LayerNorm.weight",
                "bert.encoder.layer.19.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_546",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_523",
                "reshape_545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x9420f530), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 546
        },
        "layernorm_558": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_559",
                "bert.encoder.layer.19.attention.output.LayerNorm.weight",
                "bert.encoder.layer.19.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_558",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_547",
                "reshape_557"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941de800), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 558
        },
        "layernorm_582": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_583",
                "bert.encoder.layer.18.output.LayerNorm.weight",
                "bert.encoder.layer.18.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_582",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_559",
                "reshape_581"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150a6c60), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 582
        },
        "layernorm_594": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_595",
                "bert.encoder.layer.18.attention.output.LayerNorm.weight",
                "bert.encoder.layer.18.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_594",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_583",
                "reshape_593"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x941f5c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 594
        },
        "layernorm_618": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_619",
                "bert.encoder.layer.17.output.LayerNorm.weight",
                "bert.encoder.layer.17.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_618",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_595",
                "reshape_617"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x150e9f80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 618
        },
        "layernorm_630": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_631",
                "bert.encoder.layer.17.attention.output.LayerNorm.weight",
                "bert.encoder.layer.17.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_630",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_619",
                "reshape_629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d5c70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 630
        },
        "layernorm_654": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_655",
                "bert.encoder.layer.16.output.LayerNorm.weight",
                "bert.encoder.layer.16.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_654",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_631",
                "reshape_653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf774ee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 654
        },
        "layernorm_666": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_667",
                "bert.encoder.layer.16.attention.output.LayerNorm.weight",
                "bert.encoder.layer.16.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_666",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_655",
                "reshape_665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4bcfd0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 666
        },
        "layernorm_690": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_691",
                "bert.encoder.layer.15.output.LayerNorm.weight",
                "bert.encoder.layer.15.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_690",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_667",
                "reshape_689"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd9fb7d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 690
        },
        "layernorm_702": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_703",
                "bert.encoder.layer.15.attention.output.LayerNorm.weight",
                "bert.encoder.layer.15.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_702",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_691",
                "reshape_701"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x27fe2d50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 702
        },
        "layernorm_726": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_727",
                "bert.encoder.layer.14.output.LayerNorm.weight",
                "bert.encoder.layer.14.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_726",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_703",
                "reshape_725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4996b0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 726
        },
        "layernorm_738": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_739",
                "bert.encoder.layer.14.attention.output.LayerNorm.weight",
                "bert.encoder.layer.14.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_738",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_727",
                "reshape_737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7674e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 738
        },
        "layernorm_762": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_763",
                "bert.encoder.layer.13.output.LayerNorm.weight",
                "bert.encoder.layer.13.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_762",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_739",
                "reshape_761"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf749490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 762
        },
        "layernorm_774": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_775",
                "bert.encoder.layer.13.attention.output.LayerNorm.weight",
                "bert.encoder.layer.13.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_774",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_763",
                "reshape_773"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x365122e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 774
        },
        "layernorm_798": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_799",
                "bert.encoder.layer.12.output.LayerNorm.weight",
                "bert.encoder.layer.12.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_798",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_775",
                "reshape_797"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xf7d91c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 798
        },
        "layernorm_810": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_811",
                "bert.encoder.layer.12.attention.output.LayerNorm.weight",
                "bert.encoder.layer.12.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_810",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_799",
                "reshape_809"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a4fc5e0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 810
        },
        "layernorm_834": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_835",
                "bert.encoder.layer.11.output.LayerNorm.weight",
                "bert.encoder.layer.11.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_834",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_811",
                "reshape_833"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd974ae0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 834
        },
        "layernorm_846": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_847",
                "bert.encoder.layer.11.attention.output.LayerNorm.weight",
                "bert.encoder.layer.11.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_846",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_835",
                "reshape_845"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b455d0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 846
        },
        "layernorm_870": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_871",
                "bert.encoder.layer.10.output.LayerNorm.weight",
                "bert.encoder.layer.10.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_870",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_847",
                "reshape_869"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd98ab70), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 870
        },
        "layernorm_882": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_883",
                "bert.encoder.layer.10.attention.output.LayerNorm.weight",
                "bert.encoder.layer.10.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_882",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_871",
                "reshape_881"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x364f4230), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 882
        },
        "layernorm_906": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_907",
                "bert.encoder.layer.9.output.LayerNorm.weight",
                "bert.encoder.layer.9.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_906",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_883",
                "reshape_905"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a472c80), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 906
        },
        "layernorm_918": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_919",
                "bert.encoder.layer.9.attention.output.LayerNorm.weight",
                "bert.encoder.layer.9.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_918",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_907",
                "reshape_917"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x2a48aee0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 918
        },
        "layernorm_942": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_943",
                "bert.encoder.layer.8.output.LayerNorm.weight",
                "bert.encoder.layer.8.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_942",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_919",
                "reshape_941"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31c24e00), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 942
        },
        "layernorm_954": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_955",
                "bert.encoder.layer.8.attention.output.LayerNorm.weight",
                "bert.encoder.layer.8.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_954",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_943",
                "reshape_953"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd99a490), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 954
        },
        "layernorm_978": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_979",
                "bert.encoder.layer.7.output.LayerNorm.weight",
                "bert.encoder.layer.7.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_978",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_955",
                "reshape_977"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0xd95cb50), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 978
        },
        "layernorm_990": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "layernorm",
            "epoch": 0,
            "input_nodes": [
                "add_991",
                "bert.encoder.layer.7.attention.output.LayerNorm.weight",
                "bert.encoder.layer.7.attention.output.LayerNorm.bias"
            ],
            "ir": "pybuda",
            "name": "layernorm_990",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_979",
                "reshape_989"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::layer_norm, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.normalization.LayerNorm::LayerNorm, 0x31b8d0c0), 0, 0, 0, 0)",
            "type": "layernorm",
            "unique_id": 990
        },
        "multiply_1021": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1022",
                "add_1424"
            ],
            "ir": "pybuda",
            "name": "multiply_1021",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1020"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1021
        },
        "multiply_1057": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1058",
                "add_1403"
            ],
            "ir": "pybuda",
            "name": "multiply_1057",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1056"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1057
        },
        "multiply_1093": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1094",
                "add_1382"
            ],
            "ir": "pybuda",
            "name": "multiply_1093",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1092"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1093
        },
        "multiply_1129": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1130",
                "add_1361"
            ],
            "ir": "pybuda",
            "name": "multiply_1129",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1128"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1129
        },
        "multiply_1165": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1166",
                "add_1340"
            ],
            "ir": "pybuda",
            "name": "multiply_1165",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1164"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1165
        },
        "multiply_1201": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1202",
                "add_1319"
            ],
            "ir": "pybuda",
            "name": "multiply_1201",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1200"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1201
        },
        "multiply_1237": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1238",
                "add_1298"
            ],
            "ir": "pybuda",
            "name": "multiply_1237",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1236"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1237
        },
        "multiply_1284": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "subtract_1285",
                "constant_1290"
            ],
            "ir": "pybuda",
            "name": "multiply_1284",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_427",
                "add_463",
                "add_499",
                "add_535",
                "add_571",
                "add_607",
                "add_643",
                "add_679",
                "add_715",
                "add_751",
                "add_787",
                "add_823",
                "add_859",
                "add_895",
                "add_931",
                "add_967",
                "add_1003",
                "add_1039",
                "add_1075",
                "add_1111",
                "add_1147",
                "add_1183",
                "add_1219",
                "add_1255"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::mul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x8ab56a50), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1284
        },
        "multiply_1300": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1301",
                "constant_1304"
            ],
            "ir": "pybuda",
            "name": "multiply_1300",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1298"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1300
        },
        "multiply_1302": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1238",
                "constant_1303"
            ],
            "ir": "pybuda",
            "name": "multiply_1302",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1301"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9a24f0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1302
        },
        "multiply_1321": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1322",
                "constant_1325"
            ],
            "ir": "pybuda",
            "name": "multiply_1321",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1319"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1321
        },
        "multiply_1323": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1202",
                "constant_1324"
            ],
            "ir": "pybuda",
            "name": "multiply_1323",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1322"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd96bf60), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1323
        },
        "multiply_1342": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1343",
                "constant_1346"
            ],
            "ir": "pybuda",
            "name": "multiply_1342",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1340"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1342
        },
        "multiply_1344": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1166",
                "constant_1345"
            ],
            "ir": "pybuda",
            "name": "multiply_1344",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1343"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91829360), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1344
        },
        "multiply_1363": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1364",
                "constant_1367"
            ],
            "ir": "pybuda",
            "name": "multiply_1363",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1361"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1363
        },
        "multiply_1365": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1130",
                "constant_1366"
            ],
            "ir": "pybuda",
            "name": "multiply_1365",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1364"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xd9be050), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1365
        },
        "multiply_1384": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1385",
                "constant_1388"
            ],
            "ir": "pybuda",
            "name": "multiply_1384",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1382"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1384
        },
        "multiply_1386": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1094",
                "constant_1387"
            ],
            "ir": "pybuda",
            "name": "multiply_1386",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1385"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19bb7bf0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1386
        },
        "multiply_1405": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1406",
                "constant_1409"
            ],
            "ir": "pybuda",
            "name": "multiply_1405",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1403"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1405
        },
        "multiply_1407": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1058",
                "constant_1408"
            ],
            "ir": "pybuda",
            "name": "multiply_1407",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a45dab0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1407
        },
        "multiply_1426": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1427",
                "constant_1430"
            ],
            "ir": "pybuda",
            "name": "multiply_1426",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1424"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1426
        },
        "multiply_1428": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_1022",
                "constant_1429"
            ],
            "ir": "pybuda",
            "name": "multiply_1428",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1427"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x917e13c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1428
        },
        "multiply_1447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1448",
                "constant_1451"
            ],
            "ir": "pybuda",
            "name": "multiply_1447",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1445"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1447
        },
        "multiply_1449": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_986",
                "constant_1450"
            ],
            "ir": "pybuda",
            "name": "multiply_1449",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1449
        },
        "multiply_1468": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1469",
                "constant_1472"
            ],
            "ir": "pybuda",
            "name": "multiply_1468",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1468
        },
        "multiply_1470": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_950",
                "constant_1471"
            ],
            "ir": "pybuda",
            "name": "multiply_1470",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1469"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1470
        },
        "multiply_1489": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1490",
                "constant_1493"
            ],
            "ir": "pybuda",
            "name": "multiply_1489",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1487"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1489
        },
        "multiply_1491": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_914",
                "constant_1492"
            ],
            "ir": "pybuda",
            "name": "multiply_1491",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1491
        },
        "multiply_1510": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1511",
                "constant_1514"
            ],
            "ir": "pybuda",
            "name": "multiply_1510",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1508"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1510
        },
        "multiply_1512": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_878",
                "constant_1513"
            ],
            "ir": "pybuda",
            "name": "multiply_1512",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1511"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1512
        },
        "multiply_1531": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1532",
                "constant_1535"
            ],
            "ir": "pybuda",
            "name": "multiply_1531",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1531
        },
        "multiply_1533": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_842",
                "constant_1534"
            ],
            "ir": "pybuda",
            "name": "multiply_1533",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1532"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1533
        },
        "multiply_1552": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1553",
                "constant_1556"
            ],
            "ir": "pybuda",
            "name": "multiply_1552",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1552
        },
        "multiply_1554": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_806",
                "constant_1555"
            ],
            "ir": "pybuda",
            "name": "multiply_1554",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1553"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1554
        },
        "multiply_1573": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1574",
                "constant_1577"
            ],
            "ir": "pybuda",
            "name": "multiply_1573",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1571"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1573
        },
        "multiply_1575": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_770",
                "constant_1576"
            ],
            "ir": "pybuda",
            "name": "multiply_1575",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1575
        },
        "multiply_1594": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1595",
                "constant_1598"
            ],
            "ir": "pybuda",
            "name": "multiply_1594",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1594
        },
        "multiply_1596": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_734",
                "constant_1597"
            ],
            "ir": "pybuda",
            "name": "multiply_1596",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1595"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1596
        },
        "multiply_1615": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1616",
                "constant_1619"
            ],
            "ir": "pybuda",
            "name": "multiply_1615",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1613"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1615
        },
        "multiply_1617": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_698",
                "constant_1618"
            ],
            "ir": "pybuda",
            "name": "multiply_1617",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1616"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1617
        },
        "multiply_1636": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1637",
                "constant_1640"
            ],
            "ir": "pybuda",
            "name": "multiply_1636",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1636
        },
        "multiply_1638": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_662",
                "constant_1639"
            ],
            "ir": "pybuda",
            "name": "multiply_1638",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1637"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1638
        },
        "multiply_1657": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1658",
                "constant_1661"
            ],
            "ir": "pybuda",
            "name": "multiply_1657",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1655"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1657
        },
        "multiply_1659": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_626",
                "constant_1660"
            ],
            "ir": "pybuda",
            "name": "multiply_1659",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1658"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1659
        },
        "multiply_1678": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1679",
                "constant_1682"
            ],
            "ir": "pybuda",
            "name": "multiply_1678",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1676"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1678
        },
        "multiply_1680": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_590",
                "constant_1681"
            ],
            "ir": "pybuda",
            "name": "multiply_1680",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1679"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1680
        },
        "multiply_1699": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1700",
                "constant_1703"
            ],
            "ir": "pybuda",
            "name": "multiply_1699",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1697"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1699
        },
        "multiply_1701": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_554",
                "constant_1702"
            ],
            "ir": "pybuda",
            "name": "multiply_1701",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1701
        },
        "multiply_1720": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1721",
                "constant_1724"
            ],
            "ir": "pybuda",
            "name": "multiply_1720",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1720
        },
        "multiply_1722": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_518",
                "constant_1723"
            ],
            "ir": "pybuda",
            "name": "multiply_1722",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1721"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1722
        },
        "multiply_1741": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1742",
                "constant_1745"
            ],
            "ir": "pybuda",
            "name": "multiply_1741",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1739"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1741
        },
        "multiply_1743": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_482",
                "constant_1744"
            ],
            "ir": "pybuda",
            "name": "multiply_1743",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1742"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1743
        },
        "multiply_1762": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1763",
                "constant_1766"
            ],
            "ir": "pybuda",
            "name": "multiply_1762",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1760"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1762
        },
        "multiply_1764": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_446",
                "constant_1765"
            ],
            "ir": "pybuda",
            "name": "multiply_1764",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1763"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1764
        },
        "multiply_1783": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "erf_1784",
                "constant_1787"
            ],
            "ir": "pybuda",
            "name": "multiply_1783",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1781"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1783
        },
        "multiply_1785": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_410",
                "constant_1786"
            ],
            "ir": "pybuda",
            "name": "multiply_1785",
            "opcode": "RelayOp",
            "output_nodes": [
                "erf_1784"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 1785
        },
        "multiply_409": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_410",
                "add_1781"
            ],
            "ir": "pybuda",
            "name": "multiply_409",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_408"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1269d100), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 409
        },
        "multiply_445": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_446",
                "add_1760"
            ],
            "ir": "pybuda",
            "name": "multiply_445",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x37b739c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 445
        },
        "multiply_481": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_482",
                "add_1739"
            ],
            "ir": "pybuda",
            "name": "multiply_481",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_480"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9414c440), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 481
        },
        "multiply_517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_518",
                "add_1718"
            ],
            "ir": "pybuda",
            "name": "multiply_517",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941aaa40), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 517
        },
        "multiply_553": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_554",
                "add_1697"
            ],
            "ir": "pybuda",
            "name": "multiply_553",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_552"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27f8f600), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 553
        },
        "multiply_589": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_590",
                "add_1676"
            ],
            "ir": "pybuda",
            "name": "multiply_589",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_588"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x1508e980), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 589
        },
        "multiply_625": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_626",
                "add_1655"
            ],
            "ir": "pybuda",
            "name": "multiply_625",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x941373a0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 625
        },
        "multiply_661": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_662",
                "add_1634"
            ],
            "ir": "pybuda",
            "name": "multiply_661",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_660"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x2a4955c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 661
        },
        "multiply_697": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_698",
                "add_1613"
            ],
            "ir": "pybuda",
            "name": "multiply_697",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x27fbdcc0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 697
        },
        "multiply_733": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_734",
                "add_1592"
            ],
            "ir": "pybuda",
            "name": "multiply_733",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b66000), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 733
        },
        "multiply_769": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_770",
                "add_1571"
            ],
            "ir": "pybuda",
            "name": "multiply_769",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0xf7532c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 769
        },
        "multiply_805": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_806",
                "add_1550"
            ],
            "ir": "pybuda",
            "name": "multiply_805",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_804"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x9182d5c0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 805
        },
        "multiply_841": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_842",
                "add_1529"
            ],
            "ir": "pybuda",
            "name": "multiply_841",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_840"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x364c2130), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 841
        },
        "multiply_877": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_878",
                "add_1508"
            ],
            "ir": "pybuda",
            "name": "multiply_877",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_876"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x91833ba0), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 877
        },
        "multiply_913": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_914",
                "add_1487"
            ],
            "ir": "pybuda",
            "name": "multiply_913",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_912"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x19b94920), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 913
        },
        "multiply_949": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_950",
                "add_1466"
            ],
            "ir": "pybuda",
            "name": "multiply_949",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_948"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31c30c20), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 949
        },
        "multiply_985": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "multiply",
            "epoch": 0,
            "input_nodes": [
                "add_986",
                "add_1445"
            ],
            "ir": "pybuda",
            "name": "multiply_985",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_984"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::gelu, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/transformers.activations.GELUActivation::intermediate_act_fn, 0x31b99350), 0, 0, 0, 0)",
            "type": "multiply",
            "unique_id": 985
        },
        "nn.batch_matmul_1006": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1007",
                "reshape_1431"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1006",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1005"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1006
        },
        "nn.batch_matmul_1035": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1036",
                "reshape_1417"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1035",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1034"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1035
        },
        "nn.batch_matmul_1042": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1043",
                "reshape_1410"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1042",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1041"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1042
        },
        "nn.batch_matmul_1071": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1072",
                "reshape_1396"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1071",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1070"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1071
        },
        "nn.batch_matmul_1078": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1079",
                "reshape_1389"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1078",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1077"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1078
        },
        "nn.batch_matmul_1107": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1108",
                "reshape_1375"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1107",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1106"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1107
        },
        "nn.batch_matmul_1114": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1115",
                "reshape_1368"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1114",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1113"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1114
        },
        "nn.batch_matmul_1143": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1144",
                "reshape_1354"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1143",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1142"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1143
        },
        "nn.batch_matmul_1150": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1151",
                "reshape_1347"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1150",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1149"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1150
        },
        "nn.batch_matmul_1179": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1180",
                "reshape_1333"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1179",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1178"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1179
        },
        "nn.batch_matmul_1186": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1187",
                "reshape_1326"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1186",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1185"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1186
        },
        "nn.batch_matmul_1215": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1216",
                "reshape_1312"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1215",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1214"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1215
        },
        "nn.batch_matmul_1222": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1223",
                "reshape_1305"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1222",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1221"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1222
        },
        "nn.batch_matmul_1251": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1252",
                "reshape_1291"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1251",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1250"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1251
        },
        "nn.batch_matmul_1258": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1259",
                "reshape_1277"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_1258",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1257"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 1258
        },
        "nn.batch_matmul_423": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_424",
                "reshape_1774"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_423",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_422"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 423
        },
        "nn.batch_matmul_430": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_431",
                "reshape_1767"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_430",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_429"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 430
        },
        "nn.batch_matmul_459": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_460",
                "reshape_1753"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_459",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_458"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 459
        },
        "nn.batch_matmul_466": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_467",
                "reshape_1746"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_466",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 466
        },
        "nn.batch_matmul_495": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_496",
                "reshape_1732"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_495",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 495
        },
        "nn.batch_matmul_502": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_503",
                "reshape_1725"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_502",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 502
        },
        "nn.batch_matmul_531": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_532",
                "reshape_1711"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_531",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_530"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 531
        },
        "nn.batch_matmul_538": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_539",
                "reshape_1704"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_538",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 538
        },
        "nn.batch_matmul_567": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_568",
                "reshape_1690"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_567",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_566"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 567
        },
        "nn.batch_matmul_574": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_575",
                "reshape_1683"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_574",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_573"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 574
        },
        "nn.batch_matmul_603": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_604",
                "reshape_1669"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_603",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 603
        },
        "nn.batch_matmul_610": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_611",
                "reshape_1662"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_610",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_609"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 610
        },
        "nn.batch_matmul_639": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_640",
                "reshape_1648"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_639",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_638"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 639
        },
        "nn.batch_matmul_646": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_647",
                "reshape_1641"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_646",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 646
        },
        "nn.batch_matmul_675": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_676",
                "reshape_1627"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_675",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 675
        },
        "nn.batch_matmul_682": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_683",
                "reshape_1620"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_682",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_681"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 682
        },
        "nn.batch_matmul_711": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_712",
                "reshape_1606"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_711",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_710"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 711
        },
        "nn.batch_matmul_718": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_719",
                "reshape_1599"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_718",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 718
        },
        "nn.batch_matmul_747": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_748",
                "reshape_1585"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_747",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 747
        },
        "nn.batch_matmul_754": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_755",
                "reshape_1578"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_754",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_753"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 754
        },
        "nn.batch_matmul_783": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_784",
                "reshape_1564"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_783",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_782"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 783
        },
        "nn.batch_matmul_790": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_791",
                "reshape_1557"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_790",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_789"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 790
        },
        "nn.batch_matmul_819": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_820",
                "reshape_1543"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_819",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_818"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 819
        },
        "nn.batch_matmul_826": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_827",
                "reshape_1536"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_826",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_825"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 826
        },
        "nn.batch_matmul_855": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_856",
                "reshape_1522"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_855",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_854"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 855
        },
        "nn.batch_matmul_862": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_863",
                "reshape_1515"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_862",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_861"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 862
        },
        "nn.batch_matmul_891": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_892",
                "reshape_1501"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_891",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_890"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 891
        },
        "nn.batch_matmul_898": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_899",
                "reshape_1494"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_898",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_897"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 898
        },
        "nn.batch_matmul_927": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_928",
                "reshape_1480"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_927",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_926"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 927
        },
        "nn.batch_matmul_934": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_935",
                "reshape_1473"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_934",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_933"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 934
        },
        "nn.batch_matmul_963": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_964",
                "reshape_1459"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_963",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_962"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 963
        },
        "nn.batch_matmul_970": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_971",
                "reshape_1452"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_970",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_969"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 970
        },
        "nn.batch_matmul_999": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "nn.batch_matmul",
            "epoch": 0,
            "input_nodes": [
                "reshape_1000",
                "reshape_1438"
            ],
            "ir": "pybuda",
            "name": "nn.batch_matmul_999",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_998"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "nn.batch_matmul",
            "unique_id": 999
        },
        "nn.dense_1012": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1013",
                "bert.encoder.layer.7.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1012",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1011"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1012
        },
        "nn.dense_1019": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1020",
                "bert.encoder.layer.6.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1019",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1018"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1019
        },
        "nn.dense_1024": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1025",
                "bert.encoder.layer.6.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1024",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1023"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1024
        },
        "nn.dense_1031": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1032",
                "bert.encoder.layer.6.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1031",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1030"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1031
        },
        "nn.dense_1048": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1049",
                "bert.encoder.layer.6.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1048",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1047"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1048
        },
        "nn.dense_1055": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1056",
                "bert.encoder.layer.5.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1055",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1054"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1055
        },
        "nn.dense_1060": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1061",
                "bert.encoder.layer.5.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1060",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1059"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1060
        },
        "nn.dense_1067": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1068",
                "bert.encoder.layer.5.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1067",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1066"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1067
        },
        "nn.dense_1084": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1085",
                "bert.encoder.layer.5.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1084",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1083"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1084
        },
        "nn.dense_1091": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1092",
                "bert.encoder.layer.4.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1091",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1090"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1091
        },
        "nn.dense_1096": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1097",
                "bert.encoder.layer.4.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1096",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1095"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1096
        },
        "nn.dense_1103": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1104",
                "bert.encoder.layer.4.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1103",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1102"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1103
        },
        "nn.dense_1120": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1121",
                "bert.encoder.layer.4.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1120",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1119"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1120
        },
        "nn.dense_1127": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1128",
                "bert.encoder.layer.3.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1127",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1126"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1127
        },
        "nn.dense_1132": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1133",
                "bert.encoder.layer.3.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1132",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1131"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1132
        },
        "nn.dense_1139": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1140",
                "bert.encoder.layer.3.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1139",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1138"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1139
        },
        "nn.dense_1156": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1157",
                "bert.encoder.layer.3.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1156",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1155"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1156
        },
        "nn.dense_1163": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1164",
                "bert.encoder.layer.2.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1163",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1162"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1163
        },
        "nn.dense_1168": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1169",
                "bert.encoder.layer.2.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1168",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1167"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1168
        },
        "nn.dense_1175": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1176",
                "bert.encoder.layer.2.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1175",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1174"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1175
        },
        "nn.dense_1192": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1193",
                "bert.encoder.layer.2.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1192",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1191"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1192
        },
        "nn.dense_1199": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1200",
                "bert.encoder.layer.1.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1199",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1198"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1199
        },
        "nn.dense_1204": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1205",
                "bert.encoder.layer.1.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1204",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1203"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1204
        },
        "nn.dense_1211": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1212",
                "bert.encoder.layer.1.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1211",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1210"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1211
        },
        "nn.dense_1228": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1229",
                "bert.encoder.layer.1.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1228",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1227"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1228
        },
        "nn.dense_1235": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1236",
                "bert.encoder.layer.0.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1235",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1234"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1235
        },
        "nn.dense_1240": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1241",
                "bert.encoder.layer.0.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1240",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1239"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1240
        },
        "nn.dense_1247": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1248",
                "bert.encoder.layer.0.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1247",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1246"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1247
        },
        "nn.dense_1264": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1265",
                "bert.encoder.layer.0.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1264",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1263"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1264
        },
        "nn.dense_1282": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1265",
                "bert.encoder.layer.0.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1282",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1281"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1282
        },
        "nn.dense_1297": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1265",
                "bert.encoder.layer.0.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1297",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1296"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1297
        },
        "nn.dense_1310": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1229",
                "bert.encoder.layer.1.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1310",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1309"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1310
        },
        "nn.dense_1318": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1229",
                "bert.encoder.layer.1.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1318",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1317"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1318
        },
        "nn.dense_1331": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1193",
                "bert.encoder.layer.2.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1331",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1330"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1331
        },
        "nn.dense_1339": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1193",
                "bert.encoder.layer.2.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1339",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1338"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1339
        },
        "nn.dense_1352": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1157",
                "bert.encoder.layer.3.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1352",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1351"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1352
        },
        "nn.dense_1360": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1157",
                "bert.encoder.layer.3.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1360",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1359"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1360
        },
        "nn.dense_1373": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1121",
                "bert.encoder.layer.4.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1373",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1372"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1373
        },
        "nn.dense_1381": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1121",
                "bert.encoder.layer.4.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1381",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1380"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1381
        },
        "nn.dense_1394": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1085",
                "bert.encoder.layer.5.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1394",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1393"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1394
        },
        "nn.dense_1402": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1085",
                "bert.encoder.layer.5.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1402",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1401"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1402
        },
        "nn.dense_1415": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1049",
                "bert.encoder.layer.6.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1415",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1414"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1415
        },
        "nn.dense_1423": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1049",
                "bert.encoder.layer.6.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1423",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1422"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1423
        },
        "nn.dense_1436": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1013",
                "bert.encoder.layer.7.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1436",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1436
        },
        "nn.dense_1444": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_1013",
                "bert.encoder.layer.7.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1444",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1444
        },
        "nn.dense_1457": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_977",
                "bert.encoder.layer.8.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1457",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1457
        },
        "nn.dense_1465": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_977",
                "bert.encoder.layer.8.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1465",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1465
        },
        "nn.dense_1478": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_941",
                "bert.encoder.layer.9.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1478",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1478
        },
        "nn.dense_1486": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_941",
                "bert.encoder.layer.9.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1486",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1485"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1486
        },
        "nn.dense_1499": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_905",
                "bert.encoder.layer.10.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1499",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1498"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1499
        },
        "nn.dense_1507": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_905",
                "bert.encoder.layer.10.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1507",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1507
        },
        "nn.dense_1520": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_869",
                "bert.encoder.layer.11.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1520",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1520
        },
        "nn.dense_1528": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_869",
                "bert.encoder.layer.11.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1528",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1528
        },
        "nn.dense_1541": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "bert.encoder.layer.12.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1541",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1541
        },
        "nn.dense_1549": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "bert.encoder.layer.12.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1549",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1548"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1549
        },
        "nn.dense_1562": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_797",
                "bert.encoder.layer.13.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1562",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1562
        },
        "nn.dense_1570": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_797",
                "bert.encoder.layer.13.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1570",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1570
        },
        "nn.dense_1583": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_761",
                "bert.encoder.layer.14.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1583",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1582"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1583
        },
        "nn.dense_1591": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_761",
                "bert.encoder.layer.14.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1591",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1591
        },
        "nn.dense_1604": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_725",
                "bert.encoder.layer.15.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1604",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1604
        },
        "nn.dense_1612": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_725",
                "bert.encoder.layer.15.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1612",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1611"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1612
        },
        "nn.dense_1625": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_689",
                "bert.encoder.layer.16.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1625",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1624"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1625
        },
        "nn.dense_1633": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_689",
                "bert.encoder.layer.16.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1633",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1632"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1633
        },
        "nn.dense_1646": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_653",
                "bert.encoder.layer.17.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1646",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1645"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1646
        },
        "nn.dense_1654": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_653",
                "bert.encoder.layer.17.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1654",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1653"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1654
        },
        "nn.dense_1667": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_617",
                "bert.encoder.layer.18.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1667",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1666"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1667
        },
        "nn.dense_1675": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_617",
                "bert.encoder.layer.18.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1675",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1674"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1675
        },
        "nn.dense_1688": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_581",
                "bert.encoder.layer.19.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1688",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1688
        },
        "nn.dense_1696": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_581",
                "bert.encoder.layer.19.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1696",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1696
        },
        "nn.dense_1709": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_545",
                "bert.encoder.layer.20.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1709",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1709
        },
        "nn.dense_1717": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_545",
                "bert.encoder.layer.20.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1717",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1717
        },
        "nn.dense_1730": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_509",
                "bert.encoder.layer.21.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1730",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1729"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1730
        },
        "nn.dense_1738": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_509",
                "bert.encoder.layer.21.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1738",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1737"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1738
        },
        "nn.dense_1751": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_473",
                "bert.encoder.layer.22.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1751",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1750"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1751
        },
        "nn.dense_1759": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_473",
                "bert.encoder.layer.22.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1759",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1758"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1759
        },
        "nn.dense_1772": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_437",
                "bert.encoder.layer.23.attention.self.key.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1772",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1772
        },
        "nn.dense_1780": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_437",
                "bert.encoder.layer.23.attention.self.value.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_1780",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 1780
        },
        "nn.dense_400": {
            "cache": {
                "shape": [
                    384,
                    2
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_401",
                "qa_outputs.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_400",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_399"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 400
        },
        "nn.dense_407": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_408",
                "bert.encoder.layer.23.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_407",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_406"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 407
        },
        "nn.dense_412": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_413",
                "bert.encoder.layer.23.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_412",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_411"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 412
        },
        "nn.dense_419": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_420",
                "bert.encoder.layer.23.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_419",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_418"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 419
        },
        "nn.dense_436": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_437",
                "bert.encoder.layer.23.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_436",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_435"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 436
        },
        "nn.dense_443": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_444",
                "bert.encoder.layer.22.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_443",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 443
        },
        "nn.dense_448": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_449",
                "bert.encoder.layer.22.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_448",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_447"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 448
        },
        "nn.dense_455": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_456",
                "bert.encoder.layer.22.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_455",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_454"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 455
        },
        "nn.dense_472": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_473",
                "bert.encoder.layer.22.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_472",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_471"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 472
        },
        "nn.dense_479": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_480",
                "bert.encoder.layer.21.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_479",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_478"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 479
        },
        "nn.dense_484": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_485",
                "bert.encoder.layer.21.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_484",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_483"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 484
        },
        "nn.dense_491": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_492",
                "bert.encoder.layer.21.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_491",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_490"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 491
        },
        "nn.dense_508": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_509",
                "bert.encoder.layer.21.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_508",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 508
        },
        "nn.dense_515": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_516",
                "bert.encoder.layer.20.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_515",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_514"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 515
        },
        "nn.dense_520": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_521",
                "bert.encoder.layer.20.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_520",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_519"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 520
        },
        "nn.dense_527": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_528",
                "bert.encoder.layer.20.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_527",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_526"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 527
        },
        "nn.dense_544": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_545",
                "bert.encoder.layer.20.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_544",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 544
        },
        "nn.dense_551": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_552",
                "bert.encoder.layer.19.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_551",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_550"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 551
        },
        "nn.dense_556": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_557",
                "bert.encoder.layer.19.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_556",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_555"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 556
        },
        "nn.dense_563": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_564",
                "bert.encoder.layer.19.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_563",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_562"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 563
        },
        "nn.dense_580": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_581",
                "bert.encoder.layer.19.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_580",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 580
        },
        "nn.dense_587": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_588",
                "bert.encoder.layer.18.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_587",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 587
        },
        "nn.dense_592": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_593",
                "bert.encoder.layer.18.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_592",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 592
        },
        "nn.dense_599": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_600",
                "bert.encoder.layer.18.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_599",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_598"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 599
        },
        "nn.dense_616": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_617",
                "bert.encoder.layer.18.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_616",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_615"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 616
        },
        "nn.dense_623": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_624",
                "bert.encoder.layer.17.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_623",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_622"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 623
        },
        "nn.dense_628": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_629",
                "bert.encoder.layer.17.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_628",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 628
        },
        "nn.dense_635": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_636",
                "bert.encoder.layer.17.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_635",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_634"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 635
        },
        "nn.dense_652": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_653",
                "bert.encoder.layer.17.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_652",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_651"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 652
        },
        "nn.dense_659": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_660",
                "bert.encoder.layer.16.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_659",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_658"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 659
        },
        "nn.dense_664": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_665",
                "bert.encoder.layer.16.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_664",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 664
        },
        "nn.dense_671": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_672",
                "bert.encoder.layer.16.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_671",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 671
        },
        "nn.dense_688": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_689",
                "bert.encoder.layer.16.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_688",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_687"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 688
        },
        "nn.dense_695": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_696",
                "bert.encoder.layer.15.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_695",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 695
        },
        "nn.dense_700": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_701",
                "bert.encoder.layer.15.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_700",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_699"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 700
        },
        "nn.dense_707": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_708",
                "bert.encoder.layer.15.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_707",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_706"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 707
        },
        "nn.dense_724": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_725",
                "bert.encoder.layer.15.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_724",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_723"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 724
        },
        "nn.dense_731": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_732",
                "bert.encoder.layer.14.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_731",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_730"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 731
        },
        "nn.dense_736": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_737",
                "bert.encoder.layer.14.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_736",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_735"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 736
        },
        "nn.dense_743": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_744",
                "bert.encoder.layer.14.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_743",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_742"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 743
        },
        "nn.dense_760": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_761",
                "bert.encoder.layer.14.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_760",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 760
        },
        "nn.dense_767": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_768",
                "bert.encoder.layer.13.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_767",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_766"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 767
        },
        "nn.dense_772": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_773",
                "bert.encoder.layer.13.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_772",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_771"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 772
        },
        "nn.dense_779": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_780",
                "bert.encoder.layer.13.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_779",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 779
        },
        "nn.dense_796": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_797",
                "bert.encoder.layer.13.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_796",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_795"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 796
        },
        "nn.dense_803": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_804",
                "bert.encoder.layer.12.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_803",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_802"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 803
        },
        "nn.dense_808": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_809",
                "bert.encoder.layer.12.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_808",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_807"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 808
        },
        "nn.dense_815": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_816",
                "bert.encoder.layer.12.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_815",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_814"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 815
        },
        "nn.dense_832": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_833",
                "bert.encoder.layer.12.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_832",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_831"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 832
        },
        "nn.dense_839": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_840",
                "bert.encoder.layer.11.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_839",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_838"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 839
        },
        "nn.dense_844": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_845",
                "bert.encoder.layer.11.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_844",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_843"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 844
        },
        "nn.dense_851": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_852",
                "bert.encoder.layer.11.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_851",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_850"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 851
        },
        "nn.dense_868": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_869",
                "bert.encoder.layer.11.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_868",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_867"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 868
        },
        "nn.dense_875": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_876",
                "bert.encoder.layer.10.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_875",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_874"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 875
        },
        "nn.dense_880": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_881",
                "bert.encoder.layer.10.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_880",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_879"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 880
        },
        "nn.dense_887": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_888",
                "bert.encoder.layer.10.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_887",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_886"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 887
        },
        "nn.dense_904": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_905",
                "bert.encoder.layer.10.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_904",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_903"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 904
        },
        "nn.dense_911": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_912",
                "bert.encoder.layer.9.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_911",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_910"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 911
        },
        "nn.dense_916": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_917",
                "bert.encoder.layer.9.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_916",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_915"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 916
        },
        "nn.dense_923": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_924",
                "bert.encoder.layer.9.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_923",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_922"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 923
        },
        "nn.dense_940": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_941",
                "bert.encoder.layer.9.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_940",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_939"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 940
        },
        "nn.dense_947": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_948",
                "bert.encoder.layer.8.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_947",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_946"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 947
        },
        "nn.dense_952": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_953",
                "bert.encoder.layer.8.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_952",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_951"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 952
        },
        "nn.dense_959": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_960",
                "bert.encoder.layer.8.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_959",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_958"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 959
        },
        "nn.dense_976": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_977",
                "bert.encoder.layer.8.attention.self.query.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_976",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_975"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 976
        },
        "nn.dense_983": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_984",
                "bert.encoder.layer.7.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_983",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_982"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 983
        },
        "nn.dense_988": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_989",
                "bert.encoder.layer.7.intermediate.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_988",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_987"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 988
        },
        "nn.dense_995": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "nn.dense",
            "epoch": 0,
            "input_nodes": [
                "reshape_996",
                "bert.encoder.layer.7.attention.output.dense.weight"
            ],
            "ir": "pybuda",
            "name": "nn.dense_995",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_994"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "nn.dense",
            "unique_id": 995
        },
        "nn.dropout_1001": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1002"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1001",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1000"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1001
        },
        "nn.dropout_1016": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1017"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1016",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1015"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1016
        },
        "nn.dropout_1028": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1029"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1028",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1027"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1028
        },
        "nn.dropout_1037": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1038"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1037",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1036"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1037
        },
        "nn.dropout_1052": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1053"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1052",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1051"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1052
        },
        "nn.dropout_1064": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1065"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1064",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1063"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1064
        },
        "nn.dropout_1073": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1074"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1073",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1072"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1073
        },
        "nn.dropout_1088": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1089"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1088",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1087"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1088
        },
        "nn.dropout_1100": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1101"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1100",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1099"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1100
        },
        "nn.dropout_1109": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1110"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1109",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1108"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1109
        },
        "nn.dropout_1124": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1125"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1124",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1123"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1124
        },
        "nn.dropout_1136": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1137"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1136",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1135"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1136
        },
        "nn.dropout_1145": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1146"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1145",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1144"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1145
        },
        "nn.dropout_1160": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1161"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1160",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1159"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1160
        },
        "nn.dropout_1172": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1173"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1172",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1171"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1172
        },
        "nn.dropout_1181": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1182"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1181",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1180"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1181
        },
        "nn.dropout_1196": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1197"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1196",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1195"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1196
        },
        "nn.dropout_1208": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1209"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1208",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1207"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1208
        },
        "nn.dropout_1217": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1218"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1217",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1216"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1217
        },
        "nn.dropout_1232": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1233"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1232",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1231"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1232
        },
        "nn.dropout_1244": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_1245"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1244",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1243"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1244
        },
        "nn.dropout_1253": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_1254"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1253",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1252"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1253
        },
        "nn.dropout_1266": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1267"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_1266",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1243",
                "reshape_1265"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 1266
        },
        "nn.dropout_404": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_405"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_404",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_403"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 404
        },
        "nn.dropout_416": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_417"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_416",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_415"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 416
        },
        "nn.dropout_425": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_426"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_425",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_424"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 425
        },
        "nn.dropout_440": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_441"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_440",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_439"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 440
        },
        "nn.dropout_452": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_453"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_452",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_451"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 452
        },
        "nn.dropout_461": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_462"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_461",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_460"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 461
        },
        "nn.dropout_476": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_477"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_476",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_475"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 476
        },
        "nn.dropout_488": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_489"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_488",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_487"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 488
        },
        "nn.dropout_497": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_498"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_497",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_496"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 497
        },
        "nn.dropout_512": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_513"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_512",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_511"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 512
        },
        "nn.dropout_524": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_525"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_524",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_523"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 524
        },
        "nn.dropout_533": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_534"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_533",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_532"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 533
        },
        "nn.dropout_548": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_549"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_548",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_547"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 548
        },
        "nn.dropout_560": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_561"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_560",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_559"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 560
        },
        "nn.dropout_569": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_570"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_569",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_568"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 569
        },
        "nn.dropout_584": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_585"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_584",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_583"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 584
        },
        "nn.dropout_596": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_597"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_596",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_595"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 596
        },
        "nn.dropout_605": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_606"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_605",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_604"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 605
        },
        "nn.dropout_620": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_621"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_620",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_619"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 620
        },
        "nn.dropout_632": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_633"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_632",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_631"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 632
        },
        "nn.dropout_641": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_642"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_641",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_640"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 641
        },
        "nn.dropout_656": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_657"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_656",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_655"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 656
        },
        "nn.dropout_668": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_669"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_668",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_667"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 668
        },
        "nn.dropout_677": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_678"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_677",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_676"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 677
        },
        "nn.dropout_692": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_693"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_692",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_691"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 692
        },
        "nn.dropout_704": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_705"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_704",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_703"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 704
        },
        "nn.dropout_713": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_714"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_713",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_712"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 713
        },
        "nn.dropout_728": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_729"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_728",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_727"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 728
        },
        "nn.dropout_740": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_741"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_740",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_739"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 740
        },
        "nn.dropout_749": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_750"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_749",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_748"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 749
        },
        "nn.dropout_764": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_765"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_764",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_763"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 764
        },
        "nn.dropout_776": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_777"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_776",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_775"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 776
        },
        "nn.dropout_785": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_786"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_785",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_784"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 785
        },
        "nn.dropout_800": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_801"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_800",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_799"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 800
        },
        "nn.dropout_812": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_813"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_812",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_811"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 812
        },
        "nn.dropout_821": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_822"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_821",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_820"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 821
        },
        "nn.dropout_836": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_837"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_836",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_835"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 836
        },
        "nn.dropout_848": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_849"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_848",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_847"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 848
        },
        "nn.dropout_857": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_858"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_857",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_856"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 857
        },
        "nn.dropout_872": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_873"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_872",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_871"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 872
        },
        "nn.dropout_884": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_885"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_884",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_883"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 884
        },
        "nn.dropout_893": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_894"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_893",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_892"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 893
        },
        "nn.dropout_908": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_909"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_908",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_907"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 908
        },
        "nn.dropout_920": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_921"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_920",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_919"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 920
        },
        "nn.dropout_929": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_930"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_929",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_928"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 929
        },
        "nn.dropout_944": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_945"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_944",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_943"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 944
        },
        "nn.dropout_956": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_957"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_956",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_955"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 956
        },
        "nn.dropout_965": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "nn.softmax_966"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_965",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_964"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 965
        },
        "nn.dropout_980": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_981"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_980",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_979"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 980
        },
        "nn.dropout_992": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "nn.dropout",
            "epoch": 0,
            "input_nodes": [
                "add_993"
            ],
            "ir": "pybuda",
            "name": "nn.dropout_992",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_991"
            ],
            "pybuda": 1,
            "type": "nn.dropout",
            "unique_id": 992
        },
        "nn.softmax_1002": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1003"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1002",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1001"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bdeb50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1002
        },
        "nn.softmax_1038": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1039"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1038",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1037"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a511de0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1038
        },
        "nn.softmax_1074": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1075"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1074",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1073"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49d340), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1074
        },
        "nn.softmax_1110": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1111"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1110",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1109"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c25db0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1110
        },
        "nn.softmax_1146": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1147"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1146",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1145"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19c1d990), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1146
        },
        "nn.softmax_1182": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1183"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1182",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1181"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b65130), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1182
        },
        "nn.softmax_1218": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1219"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1218",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1217"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98a870), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1218
        },
        "nn.softmax_1254": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_1255"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_1254",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_1253"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9af750), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 1254
        },
        "nn.softmax_426": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_427"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_426",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_425"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37bd2dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 426
        },
        "nn.softmax_462": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_463"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_462",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9422d960), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 462
        },
        "nn.softmax_498": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_499"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_498",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_497"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7b0540), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 498
        },
        "nn.softmax_534": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_535"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_534",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_533"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x126863e0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 534
        },
        "nn.softmax_570": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_571"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_570",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_569"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1270), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 570
        },
        "nn.softmax_606": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_607"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_606",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_605"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9723b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 606
        },
        "nn.softmax_642": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_643"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_642",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x28027dc0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 642
        },
        "nn.softmax_678": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_679"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_678",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_677"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150e2880), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 678
        },
        "nn.softmax_714": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_715"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_714",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_713"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15044f50), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 714
        },
        "nn.softmax_750": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_751"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_750",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x280119a0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 750
        },
        "nn.softmax_786": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_787"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_786",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_785"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f55ff0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 786
        },
        "nn.softmax_822": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_823"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_822",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_821"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd98d0b0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 822
        },
        "nn.softmax_858": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_859"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_858",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_857"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf778820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 858
        },
        "nn.softmax_894": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_895"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_894",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_893"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364e52c0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 894
        },
        "nn.softmax_930": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_931"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_930",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_929"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36479bd0), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 930
        },
        "nn.softmax_966": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "nn.softmax",
            "epoch": 0,
            "input_nodes": [
                "add_967"
            ],
            "ir": "pybuda",
            "name": "nn.softmax_966",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dropout_965"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::softmax, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c23820), 0, 0, 0, 0)",
            "type": "nn.softmax",
            "unique_id": 966
        },
        "qa_outputs.bias": {
            "cache": {
                "shape": [
                    "2"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.bias",
            "opcode": "Input",
            "output_nodes": [
                "add_398"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 394
        },
        "qa_outputs.weight": {
            "cache": {
                "shape": [
                    "2",
                    "1024"
                ]
            },
            "class": "Input::",
            "epoch": 0,
            "input_nodes": [],
            "ir": "pybuda",
            "name": "qa_outputs.weight",
            "opcode": "Input",
            "output_nodes": [
                "nn.dense_400"
            ],
            "pybuda": 1,
            "type": "Input::input",
            "unique_id": 393
        },
        "reshape_1000": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1001"
            ],
            "ir": "pybuda",
            "name": "reshape_1000",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1000
        },
        "reshape_1005": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1006"
            ],
            "ir": "pybuda",
            "name": "reshape_1005",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1004"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1005
        },
        "reshape_1007": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1008"
            ],
            "ir": "pybuda",
            "name": "reshape_1007",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1007
        },
        "reshape_1009": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1010"
            ],
            "ir": "pybuda",
            "name": "reshape_1009",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1008"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1009
        },
        "reshape_1011": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1012"
            ],
            "ir": "pybuda",
            "name": "reshape_1011",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1010"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1011
        },
        "reshape_1013": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1014"
            ],
            "ir": "pybuda",
            "name": "reshape_1013",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1012",
                "nn.dense_1436",
                "nn.dense_1444"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31b554d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1013
        },
        "reshape_1018": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1019"
            ],
            "ir": "pybuda",
            "name": "reshape_1018",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1017"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1018
        },
        "reshape_1020": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1021"
            ],
            "ir": "pybuda",
            "name": "reshape_1020",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1019"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd95cb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1020
        },
        "reshape_1023": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1024"
            ],
            "ir": "pybuda",
            "name": "reshape_1023",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1022"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1023
        },
        "reshape_1025": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1026"
            ],
            "ir": "pybuda",
            "name": "reshape_1025",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1024"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9ccb00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1025
        },
        "reshape_1030": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1031"
            ],
            "ir": "pybuda",
            "name": "reshape_1030",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1029"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1030
        },
        "reshape_1032": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1033"
            ],
            "ir": "pybuda",
            "name": "reshape_1032",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1031"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a520820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1032
        },
        "reshape_1034": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1035"
            ],
            "ir": "pybuda",
            "name": "reshape_1034",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1033"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1034
        },
        "reshape_1036": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1037"
            ],
            "ir": "pybuda",
            "name": "reshape_1036",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1036
        },
        "reshape_1041": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1042"
            ],
            "ir": "pybuda",
            "name": "reshape_1041",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1040"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1041
        },
        "reshape_1043": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1044"
            ],
            "ir": "pybuda",
            "name": "reshape_1043",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1043
        },
        "reshape_1045": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1046"
            ],
            "ir": "pybuda",
            "name": "reshape_1045",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1044"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1045
        },
        "reshape_1047": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1048"
            ],
            "ir": "pybuda",
            "name": "reshape_1047",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1046"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1047
        },
        "reshape_1049": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1050"
            ],
            "ir": "pybuda",
            "name": "reshape_1049",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1048",
                "nn.dense_1415",
                "nn.dense_1423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4eff20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1049
        },
        "reshape_1054": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1055"
            ],
            "ir": "pybuda",
            "name": "reshape_1054",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1053"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1054
        },
        "reshape_1056": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1057"
            ],
            "ir": "pybuda",
            "name": "reshape_1056",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1055"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c081d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1056
        },
        "reshape_1059": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1060"
            ],
            "ir": "pybuda",
            "name": "reshape_1059",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1058"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1059
        },
        "reshape_1061": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1062"
            ],
            "ir": "pybuda",
            "name": "reshape_1061",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1060"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c226a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1061
        },
        "reshape_1066": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1067"
            ],
            "ir": "pybuda",
            "name": "reshape_1066",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1065"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1066
        },
        "reshape_1068": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1069"
            ],
            "ir": "pybuda",
            "name": "reshape_1068",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1067"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c12820), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1068
        },
        "reshape_1070": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1071"
            ],
            "ir": "pybuda",
            "name": "reshape_1070",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1069"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1070
        },
        "reshape_1072": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1073"
            ],
            "ir": "pybuda",
            "name": "reshape_1072",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1071"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1072
        },
        "reshape_1077": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1078"
            ],
            "ir": "pybuda",
            "name": "reshape_1077",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1076"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1077
        },
        "reshape_1079": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1080"
            ],
            "ir": "pybuda",
            "name": "reshape_1079",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1079
        },
        "reshape_1081": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1082"
            ],
            "ir": "pybuda",
            "name": "reshape_1081",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1080"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1081
        },
        "reshape_1083": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1084"
            ],
            "ir": "pybuda",
            "name": "reshape_1083",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1082"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1083
        },
        "reshape_1085": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1086"
            ],
            "ir": "pybuda",
            "name": "reshape_1085",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1084",
                "nn.dense_1394",
                "nn.dense_1402"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a4bc9a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1085
        },
        "reshape_1090": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1091"
            ],
            "ir": "pybuda",
            "name": "reshape_1090",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1089"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1090
        },
        "reshape_1092": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1093"
            ],
            "ir": "pybuda",
            "name": "reshape_1092",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1091"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b360), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1092
        },
        "reshape_1095": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1096"
            ],
            "ir": "pybuda",
            "name": "reshape_1095",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1094"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1095
        },
        "reshape_1097": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1098"
            ],
            "ir": "pybuda",
            "name": "reshape_1097",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1096"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19c28450), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1097
        },
        "reshape_1102": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1103"
            ],
            "ir": "pybuda",
            "name": "reshape_1102",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1101"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1102
        },
        "reshape_1104": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1105"
            ],
            "ir": "pybuda",
            "name": "reshape_1104",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1103"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x91823ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1104
        },
        "reshape_1106": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1107"
            ],
            "ir": "pybuda",
            "name": "reshape_1106",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1105"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1106
        },
        "reshape_1108": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1109"
            ],
            "ir": "pybuda",
            "name": "reshape_1108",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1108
        },
        "reshape_1113": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1114"
            ],
            "ir": "pybuda",
            "name": "reshape_1113",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1112"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1113
        },
        "reshape_1115": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1116"
            ],
            "ir": "pybuda",
            "name": "reshape_1115",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1114"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1115
        },
        "reshape_1117": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1118"
            ],
            "ir": "pybuda",
            "name": "reshape_1117",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1116"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1117
        },
        "reshape_1119": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1120"
            ],
            "ir": "pybuda",
            "name": "reshape_1119",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1118"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1119
        },
        "reshape_1121": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1122"
            ],
            "ir": "pybuda",
            "name": "reshape_1121",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1120",
                "nn.dense_1373",
                "nn.dense_1381"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19c28320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1121
        },
        "reshape_1126": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1127"
            ],
            "ir": "pybuda",
            "name": "reshape_1126",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1125"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1126
        },
        "reshape_1128": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1129"
            ],
            "ir": "pybuda",
            "name": "reshape_1128",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1127"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bb84e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1128
        },
        "reshape_1131": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1132"
            ],
            "ir": "pybuda",
            "name": "reshape_1131",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1130"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1131
        },
        "reshape_1133": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1134"
            ],
            "ir": "pybuda",
            "name": "reshape_1133",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1132"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x917e3840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1133
        },
        "reshape_1138": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1139"
            ],
            "ir": "pybuda",
            "name": "reshape_1138",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1137"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1138
        },
        "reshape_1140": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1141"
            ],
            "ir": "pybuda",
            "name": "reshape_1140",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1139"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd96e900), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1140
        },
        "reshape_1142": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1143"
            ],
            "ir": "pybuda",
            "name": "reshape_1142",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1141"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1142
        },
        "reshape_1144": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1145"
            ],
            "ir": "pybuda",
            "name": "reshape_1144",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1144
        },
        "reshape_1149": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1150"
            ],
            "ir": "pybuda",
            "name": "reshape_1149",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1148"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1149
        },
        "reshape_1151": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1152"
            ],
            "ir": "pybuda",
            "name": "reshape_1151",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1151
        },
        "reshape_1153": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1154"
            ],
            "ir": "pybuda",
            "name": "reshape_1153",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1152"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1153
        },
        "reshape_1155": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1156"
            ],
            "ir": "pybuda",
            "name": "reshape_1155",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1154"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1155
        },
        "reshape_1157": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1158"
            ],
            "ir": "pybuda",
            "name": "reshape_1157",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1156",
                "nn.dense_1352",
                "nn.dense_1360"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x19bb8000), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1157
        },
        "reshape_1162": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1163"
            ],
            "ir": "pybuda",
            "name": "reshape_1162",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1161"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1162
        },
        "reshape_1164": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1165"
            ],
            "ir": "pybuda",
            "name": "reshape_1164",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1163"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd991d10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1164
        },
        "reshape_1167": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1168"
            ],
            "ir": "pybuda",
            "name": "reshape_1167",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1166"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1167
        },
        "reshape_1169": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1170"
            ],
            "ir": "pybuda",
            "name": "reshape_1169",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1168"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd975120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1169
        },
        "reshape_1174": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1175"
            ],
            "ir": "pybuda",
            "name": "reshape_1174",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1173"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1174
        },
        "reshape_1176": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1177"
            ],
            "ir": "pybuda",
            "name": "reshape_1176",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1175"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xda10f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1176
        },
        "reshape_1178": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1179"
            ],
            "ir": "pybuda",
            "name": "reshape_1178",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1177"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1178
        },
        "reshape_1180": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1181"
            ],
            "ir": "pybuda",
            "name": "reshape_1180",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1179"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1180
        },
        "reshape_1185": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1186"
            ],
            "ir": "pybuda",
            "name": "reshape_1185",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1184"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1185
        },
        "reshape_1187": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1188"
            ],
            "ir": "pybuda",
            "name": "reshape_1187",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1186"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1187
        },
        "reshape_1189": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1190"
            ],
            "ir": "pybuda",
            "name": "reshape_1189",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1188"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1189
        },
        "reshape_1191": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1192"
            ],
            "ir": "pybuda",
            "name": "reshape_1191",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1190"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1191
        },
        "reshape_1193": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1194"
            ],
            "ir": "pybuda",
            "name": "reshape_1193",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1192",
                "nn.dense_1331",
                "nn.dense_1339"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9e8750), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1193
        },
        "reshape_1198": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1199"
            ],
            "ir": "pybuda",
            "name": "reshape_1198",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1197"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1198
        },
        "reshape_1200": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1201"
            ],
            "ir": "pybuda",
            "name": "reshape_1200",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1199"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda33db0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1200
        },
        "reshape_1203": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1204"
            ],
            "ir": "pybuda",
            "name": "reshape_1203",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1202"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1203
        },
        "reshape_1205": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1206"
            ],
            "ir": "pybuda",
            "name": "reshape_1205",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1204"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9c4640), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1205
        },
        "reshape_1210": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1211"
            ],
            "ir": "pybuda",
            "name": "reshape_1210",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1209"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1210
        },
        "reshape_1212": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1213"
            ],
            "ir": "pybuda",
            "name": "reshape_1212",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1211"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9d0310), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1212
        },
        "reshape_1214": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1215"
            ],
            "ir": "pybuda",
            "name": "reshape_1214",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1213"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1214
        },
        "reshape_1216": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1217"
            ],
            "ir": "pybuda",
            "name": "reshape_1216",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1215"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1216
        },
        "reshape_1221": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1222"
            ],
            "ir": "pybuda",
            "name": "reshape_1221",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1220"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1221
        },
        "reshape_1223": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1224"
            ],
            "ir": "pybuda",
            "name": "reshape_1223",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1223
        },
        "reshape_1225": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1226"
            ],
            "ir": "pybuda",
            "name": "reshape_1225",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1224"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1225
        },
        "reshape_1227": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1228"
            ],
            "ir": "pybuda",
            "name": "reshape_1227",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1226"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1227
        },
        "reshape_1229": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1230"
            ],
            "ir": "pybuda",
            "name": "reshape_1229",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1228",
                "nn.dense_1310",
                "nn.dense_1318"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9c4370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1229
        },
        "reshape_1234": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1235"
            ],
            "ir": "pybuda",
            "name": "reshape_1234",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1233"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1234
        },
        "reshape_1236": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_1237"
            ],
            "ir": "pybuda",
            "name": "reshape_1236",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1235"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd99aa20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1236
        },
        "reshape_1239": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1240"
            ],
            "ir": "pybuda",
            "name": "reshape_1239",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1238"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1239
        },
        "reshape_1241": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_1242"
            ],
            "ir": "pybuda",
            "name": "reshape_1241",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1240"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xd9a7c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1241
        },
        "reshape_1246": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1247"
            ],
            "ir": "pybuda",
            "name": "reshape_1246",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1245"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1246
        },
        "reshape_1248": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1249"
            ],
            "ir": "pybuda",
            "name": "reshape_1248",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1247"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xd987470), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1248
        },
        "reshape_1250": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1251"
            ],
            "ir": "pybuda",
            "name": "reshape_1250",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1249"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1250
        },
        "reshape_1252": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1253"
            ],
            "ir": "pybuda",
            "name": "reshape_1252",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1252
        },
        "reshape_1257": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_1258"
            ],
            "ir": "pybuda",
            "name": "reshape_1257",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_1256"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1257
        },
        "reshape_1259": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1260"
            ],
            "ir": "pybuda",
            "name": "reshape_1259",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1259
        },
        "reshape_1261": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1262"
            ],
            "ir": "pybuda",
            "name": "reshape_1261",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1260"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1261
        },
        "reshape_1263": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1264"
            ],
            "ir": "pybuda",
            "name": "reshape_1263",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1262"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1263
        },
        "reshape_1265": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_1266"
            ],
            "ir": "pybuda",
            "name": "reshape_1265",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_1264",
                "nn.dense_1282",
                "nn.dense_1297"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x917e2ab0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1265
        },
        "reshape_1277": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1278"
            ],
            "ir": "pybuda",
            "name": "reshape_1277",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1258"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1277
        },
        "reshape_1279": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1280"
            ],
            "ir": "pybuda",
            "name": "reshape_1279",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1278"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1279
        },
        "reshape_1281": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1282"
            ],
            "ir": "pybuda",
            "name": "reshape_1281",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1280"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b2cc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1281
        },
        "reshape_1291": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1292"
            ],
            "ir": "pybuda",
            "name": "reshape_1291",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1251"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1291
        },
        "reshape_1294": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1295"
            ],
            "ir": "pybuda",
            "name": "reshape_1294",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1293"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab23bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1294
        },
        "reshape_1296": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1297"
            ],
            "ir": "pybuda",
            "name": "reshape_1296",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1295"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x91817840), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1296
        },
        "reshape_1305": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1306"
            ],
            "ir": "pybuda",
            "name": "reshape_1305",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1222"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1305
        },
        "reshape_1307": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1308"
            ],
            "ir": "pybuda",
            "name": "reshape_1307",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1306"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1307
        },
        "reshape_1309": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1310"
            ],
            "ir": "pybuda",
            "name": "reshape_1309",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1308"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9686c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1309
        },
        "reshape_1312": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1313"
            ],
            "ir": "pybuda",
            "name": "reshape_1312",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1215"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1312
        },
        "reshape_1315": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1316"
            ],
            "ir": "pybuda",
            "name": "reshape_1315",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1314"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd961bf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1315
        },
        "reshape_1317": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1318"
            ],
            "ir": "pybuda",
            "name": "reshape_1317",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1316"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9bbde0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1317
        },
        "reshape_1326": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1327"
            ],
            "ir": "pybuda",
            "name": "reshape_1326",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1186"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1326
        },
        "reshape_1328": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1329"
            ],
            "ir": "pybuda",
            "name": "reshape_1328",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1327"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1328
        },
        "reshape_1330": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1331"
            ],
            "ir": "pybuda",
            "name": "reshape_1330",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1329"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xd9ccae0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1330
        },
        "reshape_1333": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1334"
            ],
            "ir": "pybuda",
            "name": "reshape_1333",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1179"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1333
        },
        "reshape_1336": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1337"
            ],
            "ir": "pybuda",
            "name": "reshape_1336",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1335"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda0ebf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1336
        },
        "reshape_1338": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1339"
            ],
            "ir": "pybuda",
            "name": "reshape_1338",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1337"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda20c40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1338
        },
        "reshape_1347": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1348"
            ],
            "ir": "pybuda",
            "name": "reshape_1347",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1150"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1347
        },
        "reshape_1349": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1350"
            ],
            "ir": "pybuda",
            "name": "reshape_1349",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1348"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1349
        },
        "reshape_1351": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1352"
            ],
            "ir": "pybuda",
            "name": "reshape_1351",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1350"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b88ed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1351
        },
        "reshape_1354": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1355"
            ],
            "ir": "pybuda",
            "name": "reshape_1354",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1143"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1354
        },
        "reshape_1357": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1358"
            ],
            "ir": "pybuda",
            "name": "reshape_1357",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1356"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b764b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1357
        },
        "reshape_1359": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1360"
            ],
            "ir": "pybuda",
            "name": "reshape_1359",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1358"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b97520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1359
        },
        "reshape_1368": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1369"
            ],
            "ir": "pybuda",
            "name": "reshape_1368",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1114"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1368
        },
        "reshape_1370": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1371"
            ],
            "ir": "pybuda",
            "name": "reshape_1370",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1369"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1370
        },
        "reshape_1372": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1373"
            ],
            "ir": "pybuda",
            "name": "reshape_1372",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1371"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917b11c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1372
        },
        "reshape_1375": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1376"
            ],
            "ir": "pybuda",
            "name": "reshape_1375",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1107"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1375
        },
        "reshape_1378": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1379"
            ],
            "ir": "pybuda",
            "name": "reshape_1378",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1377"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91824fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1378
        },
        "reshape_1380": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1381"
            ],
            "ir": "pybuda",
            "name": "reshape_1380",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1379"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19c08d40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1380
        },
        "reshape_1389": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1390"
            ],
            "ir": "pybuda",
            "name": "reshape_1389",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1078"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1389
        },
        "reshape_1391": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1392"
            ],
            "ir": "pybuda",
            "name": "reshape_1391",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1390"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1391
        },
        "reshape_1393": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1394"
            ],
            "ir": "pybuda",
            "name": "reshape_1393",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1392"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917a79c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1393
        },
        "reshape_1396": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1397"
            ],
            "ir": "pybuda",
            "name": "reshape_1396",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1071"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1396
        },
        "reshape_1399": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1400"
            ],
            "ir": "pybuda",
            "name": "reshape_1399",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda111d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1399
        },
        "reshape_1401": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1402"
            ],
            "ir": "pybuda",
            "name": "reshape_1401",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19bf1760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1401
        },
        "reshape_1410": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1411"
            ],
            "ir": "pybuda",
            "name": "reshape_1410",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1042"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1410
        },
        "reshape_1412": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1413"
            ],
            "ir": "pybuda",
            "name": "reshape_1412",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1411"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1412
        },
        "reshape_1414": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1415"
            ],
            "ir": "pybuda",
            "name": "reshape_1414",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1413"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b59520), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1414
        },
        "reshape_1417": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1418"
            ],
            "ir": "pybuda",
            "name": "reshape_1417",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1035"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1417
        },
        "reshape_1420": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1421"
            ],
            "ir": "pybuda",
            "name": "reshape_1420",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bac8f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1420
        },
        "reshape_1422": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1423"
            ],
            "ir": "pybuda",
            "name": "reshape_1422",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xda1b4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1422
        },
        "reshape_1431": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1432"
            ],
            "ir": "pybuda",
            "name": "reshape_1431",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_1006"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1431
        },
        "reshape_1433": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1434"
            ],
            "ir": "pybuda",
            "name": "reshape_1433",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1433
        },
        "reshape_1435": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1436"
            ],
            "ir": "pybuda",
            "name": "reshape_1435",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1434"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x917e6200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1435
        },
        "reshape_1438": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1439"
            ],
            "ir": "pybuda",
            "name": "reshape_1438",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_999"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1438
        },
        "reshape_1441": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1442"
            ],
            "ir": "pybuda",
            "name": "reshape_1441",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1440"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b5b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1441
        },
        "reshape_1443": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1444"
            ],
            "ir": "pybuda",
            "name": "reshape_1443",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1442"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xd9c3a00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1443
        },
        "reshape_1452": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1453"
            ],
            "ir": "pybuda",
            "name": "reshape_1452",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1452
        },
        "reshape_1454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1455"
            ],
            "ir": "pybuda",
            "name": "reshape_1454",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1453"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1454
        },
        "reshape_1456": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1457"
            ],
            "ir": "pybuda",
            "name": "reshape_1456",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x31b75f90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1456
        },
        "reshape_1459": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1460"
            ],
            "ir": "pybuda",
            "name": "reshape_1459",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1459
        },
        "reshape_1462": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1463"
            ],
            "ir": "pybuda",
            "name": "reshape_1462",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1461"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1462
        },
        "reshape_1464": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1465"
            ],
            "ir": "pybuda",
            "name": "reshape_1464",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1463"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a504f70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1464
        },
        "reshape_1473": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1474"
            ],
            "ir": "pybuda",
            "name": "reshape_1473",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1473
        },
        "reshape_1475": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1476"
            ],
            "ir": "pybuda",
            "name": "reshape_1475",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1474"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1475
        },
        "reshape_1477": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1478"
            ],
            "ir": "pybuda",
            "name": "reshape_1477",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1476"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x2a4cdfa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1477
        },
        "reshape_1480": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1481"
            ],
            "ir": "pybuda",
            "name": "reshape_1480",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_927"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1480
        },
        "reshape_1483": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1484"
            ],
            "ir": "pybuda",
            "name": "reshape_1483",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1482"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1483
        },
        "reshape_1485": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1486"
            ],
            "ir": "pybuda",
            "name": "reshape_1485",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x2a4aea30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1485
        },
        "reshape_1494": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1495"
            ],
            "ir": "pybuda",
            "name": "reshape_1494",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_898"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1494
        },
        "reshape_1496": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1497"
            ],
            "ir": "pybuda",
            "name": "reshape_1496",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1496
        },
        "reshape_1498": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1499"
            ],
            "ir": "pybuda",
            "name": "reshape_1498",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1497"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b62540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1498
        },
        "reshape_1501": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1502"
            ],
            "ir": "pybuda",
            "name": "reshape_1501",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_891"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1501
        },
        "reshape_1504": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1505"
            ],
            "ir": "pybuda",
            "name": "reshape_1504",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1504
        },
        "reshape_1506": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1507"
            ],
            "ir": "pybuda",
            "name": "reshape_1506",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1505"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364425d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1506
        },
        "reshape_1515": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1516"
            ],
            "ir": "pybuda",
            "name": "reshape_1515",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1515
        },
        "reshape_1517": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1518"
            ],
            "ir": "pybuda",
            "name": "reshape_1517",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1516"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1517
        },
        "reshape_1519": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1520"
            ],
            "ir": "pybuda",
            "name": "reshape_1519",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x8ab50240), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1519
        },
        "reshape_1522": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1523"
            ],
            "ir": "pybuda",
            "name": "reshape_1522",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1522
        },
        "reshape_1525": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1526"
            ],
            "ir": "pybuda",
            "name": "reshape_1525",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1524"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1525
        },
        "reshape_1527": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1528"
            ],
            "ir": "pybuda",
            "name": "reshape_1527",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1526"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36498070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1527
        },
        "reshape_1536": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1537"
            ],
            "ir": "pybuda",
            "name": "reshape_1536",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1536
        },
        "reshape_1538": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1539"
            ],
            "ir": "pybuda",
            "name": "reshape_1538",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1537"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1538
        },
        "reshape_1540": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1541"
            ],
            "ir": "pybuda",
            "name": "reshape_1540",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf774dd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1540
        },
        "reshape_1543": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1544"
            ],
            "ir": "pybuda",
            "name": "reshape_1543",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1543
        },
        "reshape_1546": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1547"
            ],
            "ir": "pybuda",
            "name": "reshape_1546",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1545"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1546
        },
        "reshape_1548": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1549"
            ],
            "ir": "pybuda",
            "name": "reshape_1548",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1547"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c0e6e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1548
        },
        "reshape_1557": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1558"
            ],
            "ir": "pybuda",
            "name": "reshape_1557",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_790"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1557
        },
        "reshape_1559": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1560"
            ],
            "ir": "pybuda",
            "name": "reshape_1559",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1558"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1559
        },
        "reshape_1561": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1562"
            ],
            "ir": "pybuda",
            "name": "reshape_1561",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1560"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf74ace0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1561
        },
        "reshape_1564": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1565"
            ],
            "ir": "pybuda",
            "name": "reshape_1564",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1564
        },
        "reshape_1567": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1568"
            ],
            "ir": "pybuda",
            "name": "reshape_1567",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1566"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1567
        },
        "reshape_1569": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1570"
            ],
            "ir": "pybuda",
            "name": "reshape_1569",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1568"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x36481da0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1569
        },
        "reshape_1578": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1579"
            ],
            "ir": "pybuda",
            "name": "reshape_1578",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1578
        },
        "reshape_1580": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1581"
            ],
            "ir": "pybuda",
            "name": "reshape_1580",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1579"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1580
        },
        "reshape_1582": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1583"
            ],
            "ir": "pybuda",
            "name": "reshape_1582",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1581"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27f7f250), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1582
        },
        "reshape_1585": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1586"
            ],
            "ir": "pybuda",
            "name": "reshape_1585",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1585
        },
        "reshape_1588": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1589"
            ],
            "ir": "pybuda",
            "name": "reshape_1588",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1588
        },
        "reshape_1590": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1591"
            ],
            "ir": "pybuda",
            "name": "reshape_1590",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1589"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31bf5aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1590
        },
        "reshape_1599": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1600"
            ],
            "ir": "pybuda",
            "name": "reshape_1599",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1599
        },
        "reshape_1601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1602"
            ],
            "ir": "pybuda",
            "name": "reshape_1601",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1601
        },
        "reshape_1603": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1604"
            ],
            "ir": "pybuda",
            "name": "reshape_1603",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1602"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x19b75c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1603
        },
        "reshape_1606": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1607"
            ],
            "ir": "pybuda",
            "name": "reshape_1606",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1606
        },
        "reshape_1609": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1610"
            ],
            "ir": "pybuda",
            "name": "reshape_1609",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1609
        },
        "reshape_1611": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1612"
            ],
            "ir": "pybuda",
            "name": "reshape_1611",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x31c237d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1611
        },
        "reshape_1620": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1621"
            ],
            "ir": "pybuda",
            "name": "reshape_1620",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1620
        },
        "reshape_1622": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1623"
            ],
            "ir": "pybuda",
            "name": "reshape_1622",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1621"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1622
        },
        "reshape_1624": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1625"
            ],
            "ir": "pybuda",
            "name": "reshape_1624",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x36465a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1624
        },
        "reshape_1627": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1628"
            ],
            "ir": "pybuda",
            "name": "reshape_1627",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1627
        },
        "reshape_1630": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1631"
            ],
            "ir": "pybuda",
            "name": "reshape_1630",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1629"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1630
        },
        "reshape_1632": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1633"
            ],
            "ir": "pybuda",
            "name": "reshape_1632",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1631"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x27ff4830), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1632
        },
        "reshape_1641": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1642"
            ],
            "ir": "pybuda",
            "name": "reshape_1641",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1641
        },
        "reshape_1643": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1644"
            ],
            "ir": "pybuda",
            "name": "reshape_1643",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1642"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1643
        },
        "reshape_1645": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1646"
            ],
            "ir": "pybuda",
            "name": "reshape_1645",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1644"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf740ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1645
        },
        "reshape_1648": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1649"
            ],
            "ir": "pybuda",
            "name": "reshape_1648",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1648
        },
        "reshape_1651": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1652"
            ],
            "ir": "pybuda",
            "name": "reshape_1651",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1650"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1651
        },
        "reshape_1653": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1654"
            ],
            "ir": "pybuda",
            "name": "reshape_1653",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1652"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x150807d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1653
        },
        "reshape_1662": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1663"
            ],
            "ir": "pybuda",
            "name": "reshape_1662",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1662
        },
        "reshape_1664": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1665"
            ],
            "ir": "pybuda",
            "name": "reshape_1664",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1663"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1664
        },
        "reshape_1666": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1667"
            ],
            "ir": "pybuda",
            "name": "reshape_1666",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1665"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x150afc30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1666
        },
        "reshape_1669": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1670"
            ],
            "ir": "pybuda",
            "name": "reshape_1669",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1669
        },
        "reshape_1672": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1673"
            ],
            "ir": "pybuda",
            "name": "reshape_1672",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1672
        },
        "reshape_1674": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1675"
            ],
            "ir": "pybuda",
            "name": "reshape_1674",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1673"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf74a7d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1674
        },
        "reshape_1683": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1684"
            ],
            "ir": "pybuda",
            "name": "reshape_1683",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1683
        },
        "reshape_1685": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1686"
            ],
            "ir": "pybuda",
            "name": "reshape_1685",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1685
        },
        "reshape_1687": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1688"
            ],
            "ir": "pybuda",
            "name": "reshape_1687",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x1508b200), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1687
        },
        "reshape_1690": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1691"
            ],
            "ir": "pybuda",
            "name": "reshape_1690",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1690
        },
        "reshape_1693": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1694"
            ],
            "ir": "pybuda",
            "name": "reshape_1693",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1692"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1693
        },
        "reshape_1695": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1696"
            ],
            "ir": "pybuda",
            "name": "reshape_1695",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1694"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x19b84b90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1695
        },
        "reshape_1704": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1705"
            ],
            "ir": "pybuda",
            "name": "reshape_1704",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1704
        },
        "reshape_1706": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1707"
            ],
            "ir": "pybuda",
            "name": "reshape_1706",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1705"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1706
        },
        "reshape_1708": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1709"
            ],
            "ir": "pybuda",
            "name": "reshape_1708",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1707"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x27fff370), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1708
        },
        "reshape_1711": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1712"
            ],
            "ir": "pybuda",
            "name": "reshape_1711",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1711
        },
        "reshape_1714": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1715"
            ],
            "ir": "pybuda",
            "name": "reshape_1714",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1713"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1714
        },
        "reshape_1716": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1717"
            ],
            "ir": "pybuda",
            "name": "reshape_1716",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1715"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x364da550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1716
        },
        "reshape_1725": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1726"
            ],
            "ir": "pybuda",
            "name": "reshape_1725",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1725
        },
        "reshape_1727": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1728"
            ],
            "ir": "pybuda",
            "name": "reshape_1727",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1726"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1727
        },
        "reshape_1729": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1730"
            ],
            "ir": "pybuda",
            "name": "reshape_1729",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1728"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x364a1460), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1729
        },
        "reshape_1732": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1733"
            ],
            "ir": "pybuda",
            "name": "reshape_1732",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1732
        },
        "reshape_1735": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1736"
            ],
            "ir": "pybuda",
            "name": "reshape_1735",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1734"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1735
        },
        "reshape_1737": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1738"
            ],
            "ir": "pybuda",
            "name": "reshape_1737",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1736"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x9420e620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1737
        },
        "reshape_1746": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1747"
            ],
            "ir": "pybuda",
            "name": "reshape_1746",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1746
        },
        "reshape_1748": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1749"
            ],
            "ir": "pybuda",
            "name": "reshape_1748",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1748
        },
        "reshape_1750": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1751"
            ],
            "ir": "pybuda",
            "name": "reshape_1750",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1749"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0xf7f9c10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1750
        },
        "reshape_1753": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1754"
            ],
            "ir": "pybuda",
            "name": "reshape_1753",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1753
        },
        "reshape_1756": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1757"
            ],
            "ir": "pybuda",
            "name": "reshape_1756",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1756
        },
        "reshape_1758": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1759"
            ],
            "ir": "pybuda",
            "name": "reshape_1758",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1757"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0x12634070), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1758
        },
        "reshape_1767": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1768"
            ],
            "ir": "pybuda",
            "name": "reshape_1767",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1767
        },
        "reshape_1769": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1770"
            ],
            "ir": "pybuda",
            "name": "reshape_1769",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1768"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1769
        },
        "reshape_1771": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1772"
            ],
            "ir": "pybuda",
            "name": "reshape_1771",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::key, 0x15128a30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1771
        },
        "reshape_1774": {
            "cache": {
                "shape": [
                    16,
                    64,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_1775"
            ],
            "ir": "pybuda",
            "name": "reshape_1774",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1774
        },
        "reshape_1777": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_1778"
            ],
            "ir": "pybuda",
            "name": "reshape_1777",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1776"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1777
        },
        "reshape_1779": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_1780"
            ],
            "ir": "pybuda",
            "name": "reshape_1779",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_1778"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::value, 0xf772620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 1779
        },
        "reshape_399": {
            "cache": {
                "shape": [
                    1,
                    384,
                    2
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_400"
            ],
            "ir": "pybuda",
            "name": "reshape_399",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_398"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 399
        },
        "reshape_401": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_402"
            ],
            "ir": "pybuda",
            "name": "reshape_401",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_400"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/torch.nn.modules.linear.Linear::qa_outputs, 0x151128b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 401
        },
        "reshape_406": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_407"
            ],
            "ir": "pybuda",
            "name": "reshape_406",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_405"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 406
        },
        "reshape_408": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_409"
            ],
            "ir": "pybuda",
            "name": "reshape_408",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_407"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x37c1d320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 408
        },
        "reshape_411": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_412"
            ],
            "ir": "pybuda",
            "name": "reshape_411",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_410"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 411
        },
        "reshape_413": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_414"
            ],
            "ir": "pybuda",
            "name": "reshape_413",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_412"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x37b3dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 413
        },
        "reshape_418": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_419"
            ],
            "ir": "pybuda",
            "name": "reshape_418",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_417"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 418
        },
        "reshape_420": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_421"
            ],
            "ir": "pybuda",
            "name": "reshape_420",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_419"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126d62c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 420
        },
        "reshape_422": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_423"
            ],
            "ir": "pybuda",
            "name": "reshape_422",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_421"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 422
        },
        "reshape_424": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_425"
            ],
            "ir": "pybuda",
            "name": "reshape_424",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_423"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 424
        },
        "reshape_429": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_430"
            ],
            "ir": "pybuda",
            "name": "reshape_429",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_428"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 429
        },
        "reshape_431": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_432"
            ],
            "ir": "pybuda",
            "name": "reshape_431",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_430"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 431
        },
        "reshape_433": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_434"
            ],
            "ir": "pybuda",
            "name": "reshape_433",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_432"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b91190), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 433
        },
        "reshape_435": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_436"
            ],
            "ir": "pybuda",
            "name": "reshape_435",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_434"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 435
        },
        "reshape_437": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_438"
            ],
            "ir": "pybuda",
            "name": "reshape_437",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_436",
                "nn.dense_1772",
                "nn.dense_1780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x27f8b620), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 437
        },
        "reshape_442": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_443"
            ],
            "ir": "pybuda",
            "name": "reshape_442",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_441"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 442
        },
        "reshape_444": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_445"
            ],
            "ir": "pybuda",
            "name": "reshape_444",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_443"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7dccb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 444
        },
        "reshape_447": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_448"
            ],
            "ir": "pybuda",
            "name": "reshape_447",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_446"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 447
        },
        "reshape_449": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_450"
            ],
            "ir": "pybuda",
            "name": "reshape_449",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_448"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x1504a3e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 449
        },
        "reshape_454": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_455"
            ],
            "ir": "pybuda",
            "name": "reshape_454",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_453"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 454
        },
        "reshape_456": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_457"
            ],
            "ir": "pybuda",
            "name": "reshape_456",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_455"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf74ba80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 456
        },
        "reshape_458": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_459"
            ],
            "ir": "pybuda",
            "name": "reshape_458",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_457"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 458
        },
        "reshape_460": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_461"
            ],
            "ir": "pybuda",
            "name": "reshape_460",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 460
        },
        "reshape_465": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_466"
            ],
            "ir": "pybuda",
            "name": "reshape_465",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_464"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 465
        },
        "reshape_467": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_468"
            ],
            "ir": "pybuda",
            "name": "reshape_467",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_466"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 467
        },
        "reshape_469": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_470"
            ],
            "ir": "pybuda",
            "name": "reshape_469",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_468"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f56fd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 469
        },
        "reshape_471": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_472"
            ],
            "ir": "pybuda",
            "name": "reshape_471",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_470"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 471
        },
        "reshape_473": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_474"
            ],
            "ir": "pybuda",
            "name": "reshape_473",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_472",
                "nn.dense_1751",
                "nn.dense_1759"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c0f320), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 473
        },
        "reshape_478": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_479"
            ],
            "ir": "pybuda",
            "name": "reshape_478",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_477"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 478
        },
        "reshape_480": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_481"
            ],
            "ir": "pybuda",
            "name": "reshape_480",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_479"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x941f0210), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 480
        },
        "reshape_483": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_484"
            ],
            "ir": "pybuda",
            "name": "reshape_483",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_482"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 483
        },
        "reshape_485": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_486"
            ],
            "ir": "pybuda",
            "name": "reshape_485",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_484"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x94216560), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 485
        },
        "reshape_490": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_491"
            ],
            "ir": "pybuda",
            "name": "reshape_490",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_489"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 490
        },
        "reshape_492": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_493"
            ],
            "ir": "pybuda",
            "name": "reshape_492",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_491"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x126184b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 492
        },
        "reshape_494": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_495"
            ],
            "ir": "pybuda",
            "name": "reshape_494",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_493"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 494
        },
        "reshape_496": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_497"
            ],
            "ir": "pybuda",
            "name": "reshape_496",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_495"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 496
        },
        "reshape_501": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_502"
            ],
            "ir": "pybuda",
            "name": "reshape_501",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_500"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 501
        },
        "reshape_503": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_504"
            ],
            "ir": "pybuda",
            "name": "reshape_503",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 503
        },
        "reshape_505": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_506"
            ],
            "ir": "pybuda",
            "name": "reshape_505",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_504"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941ab160), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 505
        },
        "reshape_507": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_508"
            ],
            "ir": "pybuda",
            "name": "reshape_507",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_506"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 507
        },
        "reshape_509": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_510"
            ],
            "ir": "pybuda",
            "name": "reshape_509",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_508",
                "nn.dense_1730",
                "nn.dense_1738"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x364ffe20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 509
        },
        "reshape_514": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_515"
            ],
            "ir": "pybuda",
            "name": "reshape_514",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_513"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 514
        },
        "reshape_516": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_517"
            ],
            "ir": "pybuda",
            "name": "reshape_516",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x12680f30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 516
        },
        "reshape_519": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_520"
            ],
            "ir": "pybuda",
            "name": "reshape_519",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_518"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 519
        },
        "reshape_521": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_522"
            ],
            "ir": "pybuda",
            "name": "reshape_521",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_520"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b565e0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 521
        },
        "reshape_526": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_527"
            ],
            "ir": "pybuda",
            "name": "reshape_526",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_525"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 526
        },
        "reshape_528": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_529"
            ],
            "ir": "pybuda",
            "name": "reshape_528",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_527"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x150c88c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 528
        },
        "reshape_530": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_531"
            ],
            "ir": "pybuda",
            "name": "reshape_530",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_529"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 530
        },
        "reshape_532": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_533"
            ],
            "ir": "pybuda",
            "name": "reshape_532",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_531"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 532
        },
        "reshape_537": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_538"
            ],
            "ir": "pybuda",
            "name": "reshape_537",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 537
        },
        "reshape_539": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_540"
            ],
            "ir": "pybuda",
            "name": "reshape_539",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_538"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 539
        },
        "reshape_541": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_542"
            ],
            "ir": "pybuda",
            "name": "reshape_541",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_540"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7c2c90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 541
        },
        "reshape_543": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_544"
            ],
            "ir": "pybuda",
            "name": "reshape_543",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_542"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 543
        },
        "reshape_545": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_546"
            ],
            "ir": "pybuda",
            "name": "reshape_545",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_544",
                "nn.dense_1709",
                "nn.dense_1717"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x94172f40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 545
        },
        "reshape_550": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_551"
            ],
            "ir": "pybuda",
            "name": "reshape_550",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_549"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 550
        },
        "reshape_552": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_553"
            ],
            "ir": "pybuda",
            "name": "reshape_552",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_551"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x1510eb60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 552
        },
        "reshape_555": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_556"
            ],
            "ir": "pybuda",
            "name": "reshape_555",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_554"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 555
        },
        "reshape_557": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_558"
            ],
            "ir": "pybuda",
            "name": "reshape_557",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_556"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x9417d150), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 557
        },
        "reshape_562": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_563"
            ],
            "ir": "pybuda",
            "name": "reshape_562",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_561"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 562
        },
        "reshape_564": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_565"
            ],
            "ir": "pybuda",
            "name": "reshape_564",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_563"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x27f8d2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 564
        },
        "reshape_566": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_567"
            ],
            "ir": "pybuda",
            "name": "reshape_566",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 566
        },
        "reshape_568": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_569"
            ],
            "ir": "pybuda",
            "name": "reshape_568",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_567"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 568
        },
        "reshape_573": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_574"
            ],
            "ir": "pybuda",
            "name": "reshape_573",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_572"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 573
        },
        "reshape_575": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_576"
            ],
            "ir": "pybuda",
            "name": "reshape_575",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_574"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 575
        },
        "reshape_577": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_578"
            ],
            "ir": "pybuda",
            "name": "reshape_577",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_576"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9413eb20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 577
        },
        "reshape_579": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_580"
            ],
            "ir": "pybuda",
            "name": "reshape_579",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 579
        },
        "reshape_581": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_582"
            ],
            "ir": "pybuda",
            "name": "reshape_581",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_580",
                "nn.dense_1688",
                "nn.dense_1696"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15065510), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 581
        },
        "reshape_586": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_587"
            ],
            "ir": "pybuda",
            "name": "reshape_586",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 586
        },
        "reshape_588": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_589"
            ],
            "ir": "pybuda",
            "name": "reshape_588",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_587"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bcf6b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 588
        },
        "reshape_591": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_592"
            ],
            "ir": "pybuda",
            "name": "reshape_591",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_590"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 591
        },
        "reshape_593": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_594"
            ],
            "ir": "pybuda",
            "name": "reshape_593",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_592"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x941cfeb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 593
        },
        "reshape_598": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_599"
            ],
            "ir": "pybuda",
            "name": "reshape_598",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_597"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 598
        },
        "reshape_600": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_601"
            ],
            "ir": "pybuda",
            "name": "reshape_600",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x94186760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 600
        },
        "reshape_602": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_603"
            ],
            "ir": "pybuda",
            "name": "reshape_602",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_601"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 602
        },
        "reshape_604": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_605"
            ],
            "ir": "pybuda",
            "name": "reshape_604",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_603"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 604
        },
        "reshape_609": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_610"
            ],
            "ir": "pybuda",
            "name": "reshape_609",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_608"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 609
        },
        "reshape_611": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_612"
            ],
            "ir": "pybuda",
            "name": "reshape_611",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_610"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 611
        },
        "reshape_613": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_614"
            ],
            "ir": "pybuda",
            "name": "reshape_613",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b74aa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 613
        },
        "reshape_615": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_616"
            ],
            "ir": "pybuda",
            "name": "reshape_615",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_614"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 615
        },
        "reshape_617": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_618"
            ],
            "ir": "pybuda",
            "name": "reshape_617",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_616",
                "nn.dense_1667",
                "nn.dense_1675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x941592a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 617
        },
        "reshape_622": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_623"
            ],
            "ir": "pybuda",
            "name": "reshape_622",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_621"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 622
        },
        "reshape_624": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_625"
            ],
            "ir": "pybuda",
            "name": "reshape_624",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_623"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x27feb2f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 624
        },
        "reshape_627": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_628"
            ],
            "ir": "pybuda",
            "name": "reshape_627",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_626"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 627
        },
        "reshape_629": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_630"
            ],
            "ir": "pybuda",
            "name": "reshape_629",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bfd5b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 629
        },
        "reshape_634": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_635"
            ],
            "ir": "pybuda",
            "name": "reshape_634",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 634
        },
        "reshape_636": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_637"
            ],
            "ir": "pybuda",
            "name": "reshape_636",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_635"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf827590), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 636
        },
        "reshape_638": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_639"
            ],
            "ir": "pybuda",
            "name": "reshape_638",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_637"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 638
        },
        "reshape_640": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_641"
            ],
            "ir": "pybuda",
            "name": "reshape_640",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_639"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 640
        },
        "reshape_645": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_646"
            ],
            "ir": "pybuda",
            "name": "reshape_645",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_644"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 645
        },
        "reshape_647": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_648"
            ],
            "ir": "pybuda",
            "name": "reshape_647",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_646"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 647
        },
        "reshape_649": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_650"
            ],
            "ir": "pybuda",
            "name": "reshape_649",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150fdfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 649
        },
        "reshape_651": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_652"
            ],
            "ir": "pybuda",
            "name": "reshape_651",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_650"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 651
        },
        "reshape_653": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_654"
            ],
            "ir": "pybuda",
            "name": "reshape_653",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_652",
                "nn.dense_1646",
                "nn.dense_1654"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x1504e850), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 653
        },
        "reshape_658": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_659"
            ],
            "ir": "pybuda",
            "name": "reshape_658",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_657"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 658
        },
        "reshape_660": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_661"
            ],
            "ir": "pybuda",
            "name": "reshape_660",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_659"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf739fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 660
        },
        "reshape_663": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_664"
            ],
            "ir": "pybuda",
            "name": "reshape_663",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 663
        },
        "reshape_665": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_666"
            ],
            "ir": "pybuda",
            "name": "reshape_665",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_664"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31bf8fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 665
        },
        "reshape_670": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_671"
            ],
            "ir": "pybuda",
            "name": "reshape_670",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 670
        },
        "reshape_672": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_673"
            ],
            "ir": "pybuda",
            "name": "reshape_672",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_671"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x15039540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 672
        },
        "reshape_674": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_675"
            ],
            "ir": "pybuda",
            "name": "reshape_674",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_673"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 674
        },
        "reshape_676": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_677"
            ],
            "ir": "pybuda",
            "name": "reshape_676",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_675"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 676
        },
        "reshape_681": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_682"
            ],
            "ir": "pybuda",
            "name": "reshape_681",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_680"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 681
        },
        "reshape_683": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_684"
            ],
            "ir": "pybuda",
            "name": "reshape_683",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_682"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 683
        },
        "reshape_685": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_686"
            ],
            "ir": "pybuda",
            "name": "reshape_685",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_684"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364c0120), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 685
        },
        "reshape_687": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_688"
            ],
            "ir": "pybuda",
            "name": "reshape_687",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_686"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 687
        },
        "reshape_689": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_690"
            ],
            "ir": "pybuda",
            "name": "reshape_689",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_688",
                "nn.dense_1625",
                "nn.dense_1633"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x15037b20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 689
        },
        "reshape_694": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_695"
            ],
            "ir": "pybuda",
            "name": "reshape_694",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_693"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 694
        },
        "reshape_696": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_697"
            ],
            "ir": "pybuda",
            "name": "reshape_696",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_695"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xd9aa920), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 696
        },
        "reshape_699": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_700"
            ],
            "ir": "pybuda",
            "name": "reshape_699",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_698"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 699
        },
        "reshape_701": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_702"
            ],
            "ir": "pybuda",
            "name": "reshape_701",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_700"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x918246a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 701
        },
        "reshape_706": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_707"
            ],
            "ir": "pybuda",
            "name": "reshape_706",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_705"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 706
        },
        "reshape_708": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_709"
            ],
            "ir": "pybuda",
            "name": "reshape_708",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_707"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b47d20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 708
        },
        "reshape_710": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_711"
            ],
            "ir": "pybuda",
            "name": "reshape_710",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_709"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 710
        },
        "reshape_712": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_713"
            ],
            "ir": "pybuda",
            "name": "reshape_712",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 712
        },
        "reshape_717": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_718"
            ],
            "ir": "pybuda",
            "name": "reshape_717",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_716"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 717
        },
        "reshape_719": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_720"
            ],
            "ir": "pybuda",
            "name": "reshape_719",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_718"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 719
        },
        "reshape_721": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_722"
            ],
            "ir": "pybuda",
            "name": "reshape_721",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_720"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27fdc030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 721
        },
        "reshape_723": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_724"
            ],
            "ir": "pybuda",
            "name": "reshape_723",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_722"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 723
        },
        "reshape_725": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_726"
            ],
            "ir": "pybuda",
            "name": "reshape_725",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_724",
                "nn.dense_1604",
                "nn.dense_1612"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7903d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 725
        },
        "reshape_730": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_731"
            ],
            "ir": "pybuda",
            "name": "reshape_730",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_729"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 730
        },
        "reshape_732": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_733"
            ],
            "ir": "pybuda",
            "name": "reshape_732",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_731"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19bf34f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 732
        },
        "reshape_735": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_736"
            ],
            "ir": "pybuda",
            "name": "reshape_735",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_734"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 735
        },
        "reshape_737": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_738"
            ],
            "ir": "pybuda",
            "name": "reshape_737",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_736"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf80dac0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 737
        },
        "reshape_742": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_743"
            ],
            "ir": "pybuda",
            "name": "reshape_742",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_741"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 742
        },
        "reshape_744": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_745"
            ],
            "ir": "pybuda",
            "name": "reshape_744",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_743"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a19a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 744
        },
        "reshape_746": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_747"
            ],
            "ir": "pybuda",
            "name": "reshape_746",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_745"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 746
        },
        "reshape_748": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_749"
            ],
            "ir": "pybuda",
            "name": "reshape_748",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_747"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 748
        },
        "reshape_753": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_754"
            ],
            "ir": "pybuda",
            "name": "reshape_753",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_752"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 753
        },
        "reshape_755": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_756"
            ],
            "ir": "pybuda",
            "name": "reshape_755",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 755
        },
        "reshape_757": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_758"
            ],
            "ir": "pybuda",
            "name": "reshape_757",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_756"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7908d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 757
        },
        "reshape_759": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_760"
            ],
            "ir": "pybuda",
            "name": "reshape_759",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_758"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 759
        },
        "reshape_761": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_762"
            ],
            "ir": "pybuda",
            "name": "reshape_761",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_760",
                "nn.dense_1583",
                "nn.dense_1591"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xf7fe4d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 761
        },
        "reshape_766": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_767"
            ],
            "ir": "pybuda",
            "name": "reshape_766",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_765"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 766
        },
        "reshape_768": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_769"
            ],
            "ir": "pybuda",
            "name": "reshape_768",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_767"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xda1cbe0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 768
        },
        "reshape_771": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_772"
            ],
            "ir": "pybuda",
            "name": "reshape_771",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_770"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 771
        },
        "reshape_773": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_774"
            ],
            "ir": "pybuda",
            "name": "reshape_773",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_772"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x27f354d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 773
        },
        "reshape_778": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_779"
            ],
            "ir": "pybuda",
            "name": "reshape_778",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_777"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 778
        },
        "reshape_780": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_781"
            ],
            "ir": "pybuda",
            "name": "reshape_780",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_779"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0xf80fc20), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 780
        },
        "reshape_782": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_783"
            ],
            "ir": "pybuda",
            "name": "reshape_782",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_781"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 782
        },
        "reshape_784": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_785"
            ],
            "ir": "pybuda",
            "name": "reshape_784",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_783"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 784
        },
        "reshape_789": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_790"
            ],
            "ir": "pybuda",
            "name": "reshape_789",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_788"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 789
        },
        "reshape_791": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_792"
            ],
            "ir": "pybuda",
            "name": "reshape_791",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_790"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 791
        },
        "reshape_793": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_794"
            ],
            "ir": "pybuda",
            "name": "reshape_793",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_792"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf779030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 793
        },
        "reshape_795": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_796"
            ],
            "ir": "pybuda",
            "name": "reshape_795",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_794"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 795
        },
        "reshape_797": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_798"
            ],
            "ir": "pybuda",
            "name": "reshape_797",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_796",
                "nn.dense_1562",
                "nn.dense_1570"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3644f860), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 797
        },
        "reshape_802": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_803"
            ],
            "ir": "pybuda",
            "name": "reshape_802",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_801"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 802
        },
        "reshape_804": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_805"
            ],
            "ir": "pybuda",
            "name": "reshape_804",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_803"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0xf7a9b00), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 804
        },
        "reshape_807": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_808"
            ],
            "ir": "pybuda",
            "name": "reshape_807",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_806"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 807
        },
        "reshape_809": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_810"
            ],
            "ir": "pybuda",
            "name": "reshape_809",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_808"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0xf773690), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 809
        },
        "reshape_814": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_815"
            ],
            "ir": "pybuda",
            "name": "reshape_814",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_813"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 814
        },
        "reshape_816": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_817"
            ],
            "ir": "pybuda",
            "name": "reshape_816",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_815"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a51f2d0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 816
        },
        "reshape_818": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_819"
            ],
            "ir": "pybuda",
            "name": "reshape_818",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_817"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 818
        },
        "reshape_820": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_821"
            ],
            "ir": "pybuda",
            "name": "reshape_820",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_819"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 820
        },
        "reshape_825": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_826"
            ],
            "ir": "pybuda",
            "name": "reshape_825",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_824"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 825
        },
        "reshape_827": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_828"
            ],
            "ir": "pybuda",
            "name": "reshape_827",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_826"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 827
        },
        "reshape_829": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_830"
            ],
            "ir": "pybuda",
            "name": "reshape_829",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_828"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31c281a0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 829
        },
        "reshape_831": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_832"
            ],
            "ir": "pybuda",
            "name": "reshape_831",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_830"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 831
        },
        "reshape_833": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_834"
            ],
            "ir": "pybuda",
            "name": "reshape_833",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_832",
                "nn.dense_1541",
                "nn.dense_1549"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0xd9812c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 833
        },
        "reshape_838": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_839"
            ],
            "ir": "pybuda",
            "name": "reshape_838",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_837"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 838
        },
        "reshape_840": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_841"
            ],
            "ir": "pybuda",
            "name": "reshape_840",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_839"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a43b2c0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 840
        },
        "reshape_843": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_844"
            ],
            "ir": "pybuda",
            "name": "reshape_843",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_842"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 843
        },
        "reshape_845": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_846"
            ],
            "ir": "pybuda",
            "name": "reshape_845",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_844"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2a4d7bd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 845
        },
        "reshape_850": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_851"
            ],
            "ir": "pybuda",
            "name": "reshape_850",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_849"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 850
        },
        "reshape_852": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_853"
            ],
            "ir": "pybuda",
            "name": "reshape_852",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_851"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b6bc70), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 852
        },
        "reshape_854": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_855"
            ],
            "ir": "pybuda",
            "name": "reshape_854",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_853"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 854
        },
        "reshape_856": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_857"
            ],
            "ir": "pybuda",
            "name": "reshape_856",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_855"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 856
        },
        "reshape_861": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_862"
            ],
            "ir": "pybuda",
            "name": "reshape_861",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_860"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 861
        },
        "reshape_863": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_864"
            ],
            "ir": "pybuda",
            "name": "reshape_863",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_862"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 863
        },
        "reshape_865": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_866"
            ],
            "ir": "pybuda",
            "name": "reshape_865",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_864"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a49c350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 865
        },
        "reshape_867": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_868"
            ],
            "ir": "pybuda",
            "name": "reshape_867",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_866"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 867
        },
        "reshape_869": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_870"
            ],
            "ir": "pybuda",
            "name": "reshape_869",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_868",
                "nn.dense_1520",
                "nn.dense_1528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x2a50fcf0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 869
        },
        "reshape_874": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_875"
            ],
            "ir": "pybuda",
            "name": "reshape_874",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_873"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 874
        },
        "reshape_876": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_877"
            ],
            "ir": "pybuda",
            "name": "reshape_876",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_875"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b95720), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 876
        },
        "reshape_879": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_880"
            ],
            "ir": "pybuda",
            "name": "reshape_879",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_878"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 879
        },
        "reshape_881": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_882"
            ],
            "ir": "pybuda",
            "name": "reshape_881",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_880"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31c2a230), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 881
        },
        "reshape_886": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_887"
            ],
            "ir": "pybuda",
            "name": "reshape_886",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_885"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 886
        },
        "reshape_888": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_889"
            ],
            "ir": "pybuda",
            "name": "reshape_888",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_887"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x36512ff0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 888
        },
        "reshape_890": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_891"
            ],
            "ir": "pybuda",
            "name": "reshape_890",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_889"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 890
        },
        "reshape_892": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_893"
            ],
            "ir": "pybuda",
            "name": "reshape_892",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_891"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 892
        },
        "reshape_897": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_898"
            ],
            "ir": "pybuda",
            "name": "reshape_897",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_896"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 897
        },
        "reshape_899": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_900"
            ],
            "ir": "pybuda",
            "name": "reshape_899",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_898"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 899
        },
        "reshape_901": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_902"
            ],
            "ir": "pybuda",
            "name": "reshape_901",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_900"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19b49af0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 901
        },
        "reshape_903": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_904"
            ],
            "ir": "pybuda",
            "name": "reshape_903",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_902"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 903
        },
        "reshape_905": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_906"
            ],
            "ir": "pybuda",
            "name": "reshape_905",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_904",
                "nn.dense_1499",
                "nn.dense_1507"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x3647ed80), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 905
        },
        "reshape_910": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_911"
            ],
            "ir": "pybuda",
            "name": "reshape_910",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_909"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 910
        },
        "reshape_912": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_913"
            ],
            "ir": "pybuda",
            "name": "reshape_912",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_911"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4e0540), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 912
        },
        "reshape_915": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_916"
            ],
            "ir": "pybuda",
            "name": "reshape_915",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_914"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 915
        },
        "reshape_917": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_918"
            ],
            "ir": "pybuda",
            "name": "reshape_917",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_916"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x2fb4cb90), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 917
        },
        "reshape_922": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_923"
            ],
            "ir": "pybuda",
            "name": "reshape_922",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_921"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 922
        },
        "reshape_924": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_925"
            ],
            "ir": "pybuda",
            "name": "reshape_924",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_923"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a464870), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 924
        },
        "reshape_926": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_927"
            ],
            "ir": "pybuda",
            "name": "reshape_926",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_925"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 926
        },
        "reshape_928": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_929"
            ],
            "ir": "pybuda",
            "name": "reshape_928",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_927"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 928
        },
        "reshape_933": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_934"
            ],
            "ir": "pybuda",
            "name": "reshape_933",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_932"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 933
        },
        "reshape_935": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_936"
            ],
            "ir": "pybuda",
            "name": "reshape_935",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_934"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 935
        },
        "reshape_937": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_938"
            ],
            "ir": "pybuda",
            "name": "reshape_937",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_936"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31bc5fa0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 937
        },
        "reshape_939": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_940"
            ],
            "ir": "pybuda",
            "name": "reshape_939",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_938"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 939
        },
        "reshape_941": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_942"
            ],
            "ir": "pybuda",
            "name": "reshape_941",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_940",
                "nn.dense_1478",
                "nn.dense_1486"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31bf5550), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 941
        },
        "reshape_946": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_947"
            ],
            "ir": "pybuda",
            "name": "reshape_946",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_945"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 946
        },
        "reshape_948": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_949"
            ],
            "ir": "pybuda",
            "name": "reshape_948",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_947"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x19c1dfc0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 948
        },
        "reshape_951": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_952"
            ],
            "ir": "pybuda",
            "name": "reshape_951",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_950"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 951
        },
        "reshape_953": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_954"
            ],
            "ir": "pybuda",
            "name": "reshape_953",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_952"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x19bb78f0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 953
        },
        "reshape_958": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_959"
            ],
            "ir": "pybuda",
            "name": "reshape_958",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_957"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 958
        },
        "reshape_960": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_961"
            ],
            "ir": "pybuda",
            "name": "reshape_960",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_959"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31b77670), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 960
        },
        "reshape_962": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_963"
            ],
            "ir": "pybuda",
            "name": "reshape_962",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_961"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 962
        },
        "reshape_964": {
            "cache": {
                "shape": [
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dropout_965"
            ],
            "ir": "pybuda",
            "name": "reshape_964",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_963"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 964
        },
        "reshape_969": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    384
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_970"
            ],
            "ir": "pybuda",
            "name": "reshape_969",
            "opcode": "RelayOp",
            "output_nodes": [
                "divide_968"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 969
        },
        "reshape_971": {
            "cache": {
                "shape": [
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_972"
            ],
            "ir": "pybuda",
            "name": "reshape_971",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.batch_matmul_970"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 971
        },
        "reshape_973": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "add_974"
            ],
            "ir": "pybuda",
            "name": "reshape_973",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_972"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::view, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bc8f60), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 973
        },
        "reshape_975": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_976"
            ],
            "ir": "pybuda",
            "name": "reshape_975",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_974"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 975
        },
        "reshape_977": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_978"
            ],
            "ir": "pybuda",
            "name": "reshape_977",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_976",
                "nn.dense_1457",
                "nn.dense_1465"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self/torch.nn.modules.linear.Linear::query, 0x31c2afd0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 977
        },
        "reshape_982": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_983"
            ],
            "ir": "pybuda",
            "name": "reshape_982",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_981"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 982
        },
        "reshape_984": {
            "cache": {
                "shape": [
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "multiply_985"
            ],
            "ir": "pybuda",
            "name": "reshape_984",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_983"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertOutput::output/torch.nn.modules.linear.Linear::dense, 0x2a4f1080), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 984
        },
        "reshape_987": {
            "cache": {
                "shape": [
                    1,
                    384,
                    4096
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_988"
            ],
            "ir": "pybuda",
            "name": "reshape_987",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_986"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 987
        },
        "reshape_989": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "layernorm_990"
            ],
            "ir": "pybuda",
            "name": "reshape_989",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_988"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertIntermediate::intermediate/torch.nn.modules.linear.Linear::dense, 0x31b32ee0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 989
        },
        "reshape_994": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.dense_995"
            ],
            "ir": "pybuda",
            "name": "reshape_994",
            "opcode": "RelayOp",
            "output_nodes": [
                "add_993"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 994
        },
        "reshape_996": {
            "cache": {
                "shape": [
                    384,
                    1024
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "transpose_997"
            ],
            "ir": "pybuda",
            "name": "reshape_996",
            "opcode": "RelayOp",
            "output_nodes": [
                "nn.dense_995"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::linear, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfOutput::output/torch.nn.modules.linear.Linear::dense, 0x31bd1fb0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 996
        },
        "reshape_998": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "reshape",
            "epoch": 0,
            "input_nodes": [
                "nn.batch_matmul_999"
            ],
            "ir": "pybuda",
            "name": "reshape_998",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_997"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "reshape",
            "unique_id": 998
        },
        "split_397": {
            "cache": {
                "shape": [
                    1,
                    384,
                    1
                ]
            },
            "class": "split",
            "epoch": 0,
            "input_nodes": [
                "add_398",
                "add_398"
            ],
            "ir": "pybuda",
            "name": "split_397",
            "opcode": "RelayOp",
            "output_nodes": [
                "squeeze_396",
                "squeeze_1788"
            ],
            "pybuda": 1,
            "type": "split",
            "unique_id": 397
        },
        "squeeze_1788": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "squeeze",
            "epoch": 0,
            "input_nodes": [
                "split_397"
            ],
            "ir": "pybuda",
            "name": "squeeze_1788",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "squeeze",
            "unique_id": 1788
        },
        "squeeze_396": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "squeeze",
            "epoch": 0,
            "input_nodes": [
                "split_397"
            ],
            "ir": "pybuda",
            "name": "squeeze_396",
            "opcode": "RelayOp",
            "output_nodes": [
                "tuple_395"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::squeeze, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::, 0x9414eda0), 0, 0, 0, 0)",
            "type": "squeeze",
            "unique_id": 396
        },
        "strided_slice_1276": {
            "cache": {
                "shape": [
                    1,
                    384
                ]
            },
            "class": "strided_slice",
            "epoch": 0,
            "input_nodes": [
                "bert.embeddings.position_ids"
            ],
            "ir": "pybuda",
            "name": "strided_slice_1276",
            "opcode": "RelayOp",
            "output_nodes": [
                "cast_1275"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::slice, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEmbeddings::embeddings, 0x2fb4dde0), 0, 0, 0, 0)",
            "type": "strided_slice",
            "unique_id": 1276
        },
        "subtract_1285": {
            "cache": {
                "shape": [
                    1,
                    1,
                    1,
                    384
                ]
            },
            "class": "subtract",
            "epoch": 0,
            "input_nodes": [
                "constant_1286",
                "cast_1287"
            ],
            "ir": "pybuda",
            "name": "subtract_1285",
            "opcode": "RelayOp",
            "output_nodes": [
                "multiply_1284"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::rsub, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert, 0x918176a0), 0, 0, 0, 0)",
            "type": "subtract",
            "unique_id": 1285
        },
        "transpose_1008": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1009"
            ],
            "ir": "pybuda",
            "name": "transpose_1008",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1007"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1008
        },
        "transpose_1033": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1034"
            ],
            "ir": "pybuda",
            "name": "transpose_1033",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1032"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1033
        },
        "transpose_1044": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1045"
            ],
            "ir": "pybuda",
            "name": "transpose_1044",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1043"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1044
        },
        "transpose_1069": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1070"
            ],
            "ir": "pybuda",
            "name": "transpose_1069",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1068"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1069
        },
        "transpose_1080": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1081"
            ],
            "ir": "pybuda",
            "name": "transpose_1080",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1079"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1080
        },
        "transpose_1105": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1106"
            ],
            "ir": "pybuda",
            "name": "transpose_1105",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1104"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1105
        },
        "transpose_1116": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1117"
            ],
            "ir": "pybuda",
            "name": "transpose_1116",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1115"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1116
        },
        "transpose_1141": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1142"
            ],
            "ir": "pybuda",
            "name": "transpose_1141",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1140"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1141
        },
        "transpose_1152": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1153"
            ],
            "ir": "pybuda",
            "name": "transpose_1152",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1151"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1152
        },
        "transpose_1177": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1178"
            ],
            "ir": "pybuda",
            "name": "transpose_1177",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1176"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1177
        },
        "transpose_1188": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1189"
            ],
            "ir": "pybuda",
            "name": "transpose_1188",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1187"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1188
        },
        "transpose_1213": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1214"
            ],
            "ir": "pybuda",
            "name": "transpose_1213",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1212"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1213
        },
        "transpose_1224": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1225"
            ],
            "ir": "pybuda",
            "name": "transpose_1224",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1223"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1224
        },
        "transpose_1249": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1250"
            ],
            "ir": "pybuda",
            "name": "transpose_1249",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1248"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1249
        },
        "transpose_1260": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1261"
            ],
            "ir": "pybuda",
            "name": "transpose_1260",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1259"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1260
        },
        "transpose_1278": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1279"
            ],
            "ir": "pybuda",
            "name": "transpose_1278",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1277"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1278
        },
        "transpose_1292": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1293"
            ],
            "ir": "pybuda",
            "name": "transpose_1292",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1291"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2fb441d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1292
        },
        "transpose_1293": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1294"
            ],
            "ir": "pybuda",
            "name": "transpose_1293",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1292"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.0/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x8ab428c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1293
        },
        "transpose_1306": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1307"
            ],
            "ir": "pybuda",
            "name": "transpose_1306",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1305"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1306
        },
        "transpose_1313": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1314"
            ],
            "ir": "pybuda",
            "name": "transpose_1313",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1312"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e160), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1313
        },
        "transpose_1314": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1315"
            ],
            "ir": "pybuda",
            "name": "transpose_1314",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1313"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.1/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x91816a50), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1314
        },
        "transpose_1327": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1328"
            ],
            "ir": "pybuda",
            "name": "transpose_1327",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1326"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1327
        },
        "transpose_1334": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1335"
            ],
            "ir": "pybuda",
            "name": "transpose_1334",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1333"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917ec990), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1334
        },
        "transpose_1335": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1336"
            ],
            "ir": "pybuda",
            "name": "transpose_1335",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1334"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.2/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9b2460), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1335
        },
        "transpose_1348": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1349"
            ],
            "ir": "pybuda",
            "name": "transpose_1348",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1347"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1348
        },
        "transpose_1355": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1356"
            ],
            "ir": "pybuda",
            "name": "transpose_1355",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1354"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96ef90), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1355
        },
        "transpose_1356": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1357"
            ],
            "ir": "pybuda",
            "name": "transpose_1356",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1355"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.3/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x9178fa20), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1356
        },
        "transpose_1369": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1370"
            ],
            "ir": "pybuda",
            "name": "transpose_1369",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1368"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1369
        },
        "transpose_1376": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1377"
            ],
            "ir": "pybuda",
            "name": "transpose_1376",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1375"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bb6040), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1376
        },
        "transpose_1377": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1378"
            ],
            "ir": "pybuda",
            "name": "transpose_1377",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1376"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.4/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19ba72e0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1377
        },
        "transpose_1390": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1391"
            ],
            "ir": "pybuda",
            "name": "transpose_1390",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1389"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1390
        },
        "transpose_1397": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1398"
            ],
            "ir": "pybuda",
            "name": "transpose_1397",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1396"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1c00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1397
        },
        "transpose_1398": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1399"
            ],
            "ir": "pybuda",
            "name": "transpose_1398",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1397"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.5/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9fb440), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1398
        },
        "transpose_1411": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1412"
            ],
            "ir": "pybuda",
            "name": "transpose_1411",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1410"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1411
        },
        "transpose_1418": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1419"
            ],
            "ir": "pybuda",
            "name": "transpose_1418",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1417"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a473320), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1418
        },
        "transpose_1419": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1420"
            ],
            "ir": "pybuda",
            "name": "transpose_1419",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1418"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.6/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x917a0910), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1419
        },
        "transpose_1432": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1433"
            ],
            "ir": "pybuda",
            "name": "transpose_1432",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1432
        },
        "transpose_1439": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1440"
            ],
            "ir": "pybuda",
            "name": "transpose_1439",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1438"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a5234b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1439
        },
        "transpose_1440": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1441"
            ],
            "ir": "pybuda",
            "name": "transpose_1440",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1439"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1440
        },
        "transpose_1453": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1454"
            ],
            "ir": "pybuda",
            "name": "transpose_1453",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1452"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1453
        },
        "transpose_1460": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1461"
            ],
            "ir": "pybuda",
            "name": "transpose_1460",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1459"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf1d30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1460
        },
        "transpose_1461": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1462"
            ],
            "ir": "pybuda",
            "name": "transpose_1461",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1460"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1461
        },
        "transpose_1474": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1475"
            ],
            "ir": "pybuda",
            "name": "transpose_1474",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1473"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1474
        },
        "transpose_1481": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1482"
            ],
            "ir": "pybuda",
            "name": "transpose_1481",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1480"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9ef350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1481
        },
        "transpose_1482": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1483"
            ],
            "ir": "pybuda",
            "name": "transpose_1482",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1481"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1482
        },
        "transpose_1495": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1496"
            ],
            "ir": "pybuda",
            "name": "transpose_1495",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1494"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1495
        },
        "transpose_1502": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1503"
            ],
            "ir": "pybuda",
            "name": "transpose_1502",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1501"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a507e40), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1502
        },
        "transpose_1503": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1504"
            ],
            "ir": "pybuda",
            "name": "transpose_1503",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1502"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1503
        },
        "transpose_1516": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1517"
            ],
            "ir": "pybuda",
            "name": "transpose_1516",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1515"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1516
        },
        "transpose_1523": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1524"
            ],
            "ir": "pybuda",
            "name": "transpose_1523",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1522"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd96e030), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1523
        },
        "transpose_1524": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1525"
            ],
            "ir": "pybuda",
            "name": "transpose_1524",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1523"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1524
        },
        "transpose_1537": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1538"
            ],
            "ir": "pybuda",
            "name": "transpose_1537",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1536"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1537
        },
        "transpose_1544": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1545"
            ],
            "ir": "pybuda",
            "name": "transpose_1544",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1543"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364343a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1544
        },
        "transpose_1545": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1546"
            ],
            "ir": "pybuda",
            "name": "transpose_1545",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1544"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1545
        },
        "transpose_1558": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1559"
            ],
            "ir": "pybuda",
            "name": "transpose_1558",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1557"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1558
        },
        "transpose_1565": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1566"
            ],
            "ir": "pybuda",
            "name": "transpose_1565",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a444760), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1565
        },
        "transpose_1566": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1567"
            ],
            "ir": "pybuda",
            "name": "transpose_1566",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1565"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1566
        },
        "transpose_1579": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1580"
            ],
            "ir": "pybuda",
            "name": "transpose_1579",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1578"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1579
        },
        "transpose_1586": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1587"
            ],
            "ir": "pybuda",
            "name": "transpose_1586",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1585"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x19bf20b0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1586
        },
        "transpose_1587": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1588"
            ],
            "ir": "pybuda",
            "name": "transpose_1587",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1586"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1587
        },
        "transpose_1600": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1601"
            ],
            "ir": "pybuda",
            "name": "transpose_1600",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1599"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1600
        },
        "transpose_1607": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1608"
            ],
            "ir": "pybuda",
            "name": "transpose_1607",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1606"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15036b10), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1607
        },
        "transpose_1608": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1609"
            ],
            "ir": "pybuda",
            "name": "transpose_1608",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1607"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1608
        },
        "transpose_1621": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1622"
            ],
            "ir": "pybuda",
            "name": "transpose_1621",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1620"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1621
        },
        "transpose_1628": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1629"
            ],
            "ir": "pybuda",
            "name": "transpose_1628",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1627"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f9bf70), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1628
        },
        "transpose_1629": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1630"
            ],
            "ir": "pybuda",
            "name": "transpose_1629",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1628"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1629
        },
        "transpose_1642": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1643"
            ],
            "ir": "pybuda",
            "name": "transpose_1642",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1641"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1642
        },
        "transpose_1649": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1650"
            ],
            "ir": "pybuda",
            "name": "transpose_1649",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1648"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7fbed0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1649
        },
        "transpose_1650": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1651"
            ],
            "ir": "pybuda",
            "name": "transpose_1650",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1649"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1650
        },
        "transpose_1663": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1664"
            ],
            "ir": "pybuda",
            "name": "transpose_1663",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1662"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1663
        },
        "transpose_1670": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1671"
            ],
            "ir": "pybuda",
            "name": "transpose_1670",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1669"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4705d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1670
        },
        "transpose_1671": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1672"
            ],
            "ir": "pybuda",
            "name": "transpose_1671",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1670"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1671
        },
        "transpose_1684": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1685"
            ],
            "ir": "pybuda",
            "name": "transpose_1684",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1684
        },
        "transpose_1691": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1692"
            ],
            "ir": "pybuda",
            "name": "transpose_1691",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1690"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf82fd00), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1691
        },
        "transpose_1692": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1693"
            ],
            "ir": "pybuda",
            "name": "transpose_1692",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1691"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1692
        },
        "transpose_1705": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1706"
            ],
            "ir": "pybuda",
            "name": "transpose_1705",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1704"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1705
        },
        "transpose_1712": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1713"
            ],
            "ir": "pybuda",
            "name": "transpose_1712",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1711"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b3700), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1712
        },
        "transpose_1713": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1714"
            ],
            "ir": "pybuda",
            "name": "transpose_1713",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1712"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1713
        },
        "transpose_1726": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1727"
            ],
            "ir": "pybuda",
            "name": "transpose_1726",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1725"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1726
        },
        "transpose_1733": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1734"
            ],
            "ir": "pybuda",
            "name": "transpose_1733",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1732"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124970), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1733
        },
        "transpose_1734": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1735"
            ],
            "ir": "pybuda",
            "name": "transpose_1734",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1733"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1734
        },
        "transpose_1747": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1748"
            ],
            "ir": "pybuda",
            "name": "transpose_1747",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1746"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1747
        },
        "transpose_1754": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1755"
            ],
            "ir": "pybuda",
            "name": "transpose_1754",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1753"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a3cb0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1754
        },
        "transpose_1755": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1756"
            ],
            "ir": "pybuda",
            "name": "transpose_1755",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1754"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1755
        },
        "transpose_1768": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1769"
            ],
            "ir": "pybuda",
            "name": "transpose_1768",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1767"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1768
        },
        "transpose_1775": {
            "cache": {
                "shape": [
                    1,
                    16,
                    64,
                    384
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "transpose_1776"
            ],
            "ir": "pybuda",
            "name": "transpose_1775",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_1774"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::matmul, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15049a80), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1775
        },
        "transpose_1776": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_1777"
            ],
            "ir": "pybuda",
            "name": "transpose_1776",
            "opcode": "RelayOp",
            "output_nodes": [
                "transpose_1775"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 1776
        },
        "transpose_421": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_422"
            ],
            "ir": "pybuda",
            "name": "transpose_421",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_420"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 421
        },
        "transpose_432": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_433"
            ],
            "ir": "pybuda",
            "name": "transpose_432",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_431"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.23/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x37b7c600), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 432
        },
        "transpose_457": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_458"
            ],
            "ir": "pybuda",
            "name": "transpose_457",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_456"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 457
        },
        "transpose_468": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_469"
            ],
            "ir": "pybuda",
            "name": "transpose_468",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_467"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.22/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x150b1770), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 468
        },
        "transpose_493": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_494"
            ],
            "ir": "pybuda",
            "name": "transpose_493",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_492"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 493
        },
        "transpose_504": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_505"
            ],
            "ir": "pybuda",
            "name": "transpose_504",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_503"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.21/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x151069d0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 504
        },
        "transpose_529": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_530"
            ],
            "ir": "pybuda",
            "name": "transpose_529",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_528"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 529
        },
        "transpose_540": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_541"
            ],
            "ir": "pybuda",
            "name": "transpose_540",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_539"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.20/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x941c7280), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 540
        },
        "transpose_565": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_566"
            ],
            "ir": "pybuda",
            "name": "transpose_565",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_564"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 565
        },
        "transpose_576": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_577"
            ],
            "ir": "pybuda",
            "name": "transpose_576",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_575"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.19/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xf7d5da0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 576
        },
        "transpose_601": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_602"
            ],
            "ir": "pybuda",
            "name": "transpose_601",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_600"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 601
        },
        "transpose_612": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_613"
            ],
            "ir": "pybuda",
            "name": "transpose_612",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_611"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.18/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x15124f60), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 612
        },
        "transpose_637": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_638"
            ],
            "ir": "pybuda",
            "name": "transpose_637",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_636"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 637
        },
        "transpose_648": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_649"
            ],
            "ir": "pybuda",
            "name": "transpose_648",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_647"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.17/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xd9888f0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 648
        },
        "transpose_673": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_674"
            ],
            "ir": "pybuda",
            "name": "transpose_673",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_672"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 673
        },
        "transpose_684": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_685"
            ],
            "ir": "pybuda",
            "name": "transpose_684",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_683"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.16/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x3645b6a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 684
        },
        "transpose_709": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_710"
            ],
            "ir": "pybuda",
            "name": "transpose_709",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_708"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 709
        },
        "transpose_720": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_721"
            ],
            "ir": "pybuda",
            "name": "transpose_720",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_719"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.15/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x27f47660), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 720
        },
        "transpose_745": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_746"
            ],
            "ir": "pybuda",
            "name": "transpose_745",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_744"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 745
        },
        "transpose_756": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_757"
            ],
            "ir": "pybuda",
            "name": "transpose_756",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_755"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.14/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a523ba0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 756
        },
        "transpose_781": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_782"
            ],
            "ir": "pybuda",
            "name": "transpose_781",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_780"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 781
        },
        "transpose_792": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_793"
            ],
            "ir": "pybuda",
            "name": "transpose_792",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_791"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.13/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0xda108a0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 792
        },
        "transpose_817": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_818"
            ],
            "ir": "pybuda",
            "name": "transpose_817",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_816"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 817
        },
        "transpose_828": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_829"
            ],
            "ir": "pybuda",
            "name": "transpose_828",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_827"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.12/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x364467c0), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 828
        },
        "transpose_853": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_854"
            ],
            "ir": "pybuda",
            "name": "transpose_853",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_852"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 853
        },
        "transpose_864": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_865"
            ],
            "ir": "pybuda",
            "name": "transpose_864",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_863"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.11/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4b3350), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 864
        },
        "transpose_889": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_890"
            ],
            "ir": "pybuda",
            "name": "transpose_889",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_888"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 889
        },
        "transpose_900": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_901"
            ],
            "ir": "pybuda",
            "name": "transpose_900",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_899"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.10/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x36461b30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 900
        },
        "transpose_925": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_926"
            ],
            "ir": "pybuda",
            "name": "transpose_925",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_924"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 925
        },
        "transpose_936": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_937"
            ],
            "ir": "pybuda",
            "name": "transpose_936",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_935"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.9/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x2a4a6870), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 936
        },
        "transpose_961": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_962"
            ],
            "ir": "pybuda",
            "name": "transpose_961",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_960"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 961
        },
        "transpose_972": {
            "cache": {
                "shape": [
                    1,
                    16,
                    384,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_973"
            ],
            "ir": "pybuda",
            "name": "transpose_972",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_971"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.8/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b79e30), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 972
        },
        "transpose_997": {
            "cache": {
                "shape": [
                    1,
                    384,
                    16,
                    64
                ]
            },
            "class": "transpose",
            "epoch": 0,
            "input_nodes": [
                "reshape_998"
            ],
            "ir": "pybuda",
            "name": "transpose_997",
            "opcode": "RelayOp",
            "output_nodes": [
                "reshape_996"
            ],
            "pybuda": 1,
            "span": "Span(SourceName(C.graph: aten::permute, jit._trace.TopLevelTracedModule: transformers.models.bert.modeling_bert.BertForQuestionAnswering::/transformers.models.bert.modeling_bert.BertModel::bert/transformers.models.bert.modeling_bert.BertEncoder::encoder/transformers.models.bert.modeling_bert.BertLayer::layer.7/transformers.models.bert.modeling_bert.BertAttention::attention/transformers.models.bert.modeling_bert.BertSelfAttention::self, 0x31b80310), 0, 0, 0, 0)",
            "type": "transpose",
            "unique_id": 997
        },
        "tuple_395": {
            "cache": {
                "shape": [
                    [
                        "1",
                        "384"
                    ],
                    [
                        "1",
                        "384"
                    ]
                ]
            },
            "class": "tuple",
            "epoch": 0,
            "input_nodes": [
                "squeeze_396",
                "squeeze_1788"
            ],
            "ir": "pybuda",
            "name": "tuple_395",
            "opcode": "RelayOp",
            "output_nodes": [],
            "pybuda": 1,
            "type": "tuple",
            "unique_id": 395
        }
    }
}